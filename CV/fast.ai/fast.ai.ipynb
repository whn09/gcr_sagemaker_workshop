{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è¯¾ç¨‹å¤§çº²ï¼š\n",
    " - fast.ai æ¦‚è¿°\n",
    " - å›¾åƒè¯†åˆ«go through\n",
    " - fast.aiå°ä¼˜åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fast.ai ä½œè€…æ›¾å–å¾—å¤šæ¬¡Kaggleç«èµ›ç¬¬ä¸€åï¼ŒåŸºäºè‡ªå·±å¯¹MLçš„ç†è§£ï¼Œä»¥åŠæ—¶ä¸‹æœ€ç«çƒ­çš„paperï¼Œåœ¨PyTorchåŸºç¡€ä¸Šæ„å»ºäº†fast.aiæ¡†æ¶ï¼Œå¸®åŠ©åˆå­¦è€…å¿«é€Ÿæ„å»ºé«˜å‡†ç¡®ç‡çš„MLåº”ç”¨ï¼Œå…ˆå®‰è£…å¿…è¦çš„è½¯ä»¶åŒ…ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»å¯¼å…¥fastaiå„ä¸ªæ¨¡å—å¼€å§‹ï¼Œfast.aiæ¨èçš„åšæ³•æ˜¯æŒ‰ç…§æ¨¡å—å¯¼å…¥*ï¼Œå¦‚æœç§‘å­¦å®¶ä¸çŸ¥é“å¯¼å…¥æŸä¸ªå…·ä½“çš„æ¨¡å—ï¼Œå¯ç›´æ¥å¯¼å…¥ fastai.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®¾ç½®batchSizeï¼Œå–å†³äºè¾“å…¥å›¾åƒçš„åˆ†è¾¨ç‡ï¼Œæ¨¡å‹å¤§å°å’Œæ˜¾å¡çš„ç¼“å­˜å¤§å°ï¼Œå¦‚æœè¿‡å¤§ï¼Œå¯é€‚å½“è°ƒå°bså€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bs = 64\n",
    "bs = 32   # uncomment this line if you run out of memory even after clicking Kernel->Restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŸ¥éªŒæ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ¬æ¬¡å®éªŒå°†ä½¿ç”¨[O. M. Parkhi et al., 2012](http://www.robots.ox.ac.uk/~vgg/publications/2012/parkhi12a/parkhi12a.pdf)ä¸­æä¾›çš„[Oxford-IIIT Pet Dataset](http://www.robots.ox.ac.uk/~vgg/data/pets/)ä½œä¸ºæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æä¾›äº†12ç±»ğŸ±åŠ25ç±»ğŸ¶çš„å›¾ç‰‡ï¼Œæˆ‘ä»¬çš„æ¨¡å‹éœ€è¦å­¦ä¼šåˆ†è¾¨è¿™37ç±»ä¸åŒçš„åŠ¨ç‰©ã€‚æ®è®ºæ–‡ä¸­çš„æè¿°ï¼Œ2012å¹´èƒ½å–å¾—çš„æœ€å¥½å‡†ç¡®ç‡ä¸º59.21%, æ¥ä¸‹æ¥æˆ‘ä»¬å°†æ„å»ºè‡ªå·±çš„æ¨¡å‹ï¼Œçœ‹çœ‹èƒ½å–å¾—æ€æ ·çš„å‡†ç¡®ç‡!\n",
    "\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨ `untar_data` å‡½æ•°æ¥ä¸‹è½½å¹¶è§£å‹æ•°æ®é›†ï¼Œæ­¤å‡½æ•°éœ€è¦ä¸€ä¸ªURLæ¥ä½œä¸ºè¾“å…¥å‚æ•°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(untar_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™ç§å†™æ³•ä¸ºçš„æ˜¯èŠ‚çº¦è¡Œæ•°ï¼Œå…¶å®æ˜¯ä¸¤æ¡è¯­å¥ï¼Œå…ˆèµ‹å€¼ï¼Œåæ‰“å°.\n",
    "URLsé‡ŒåŒ…å«äº†ä¸€äº›å¯ç›´æ¥ä½¿ç”¨çš„æ•°æ®é›†çš„urlï¼Œå‚è§ï¼šhttps://github.com/fastai/fastai/blob/master/fastai/datasets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS); path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™æ˜¯Python3é‡Œçš„è¯­æ³•ç³–ï¼Œç”¨äºæ„å»ºè·¨å¹³å°çš„è·¯å¾„ï¼ŒLinuxç³»ç»Ÿä¸‹ç”¨/æ¥åˆ†å‰²è·¯å¾„ï¼ŒWindowsç³»ç»Ÿä¸‹ç”¨\\æ¥åˆ†å‰²è·¯å¾„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_anno = path/'annotations'\n",
    "path_img = path/'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½“æˆ‘ä»¬å¤„ç†é—®é¢˜æ—¶ï¼Œæˆ‘ä»¬è¦åšçš„ç¬¬ä¸€ä»¶äº‹å°±æ˜¯çœ‹çœ‹æ•°æ®ã€‚ æˆ‘ä»¬æ€»æ˜¯éœ€è¦éå¸¸æ¸…æ¥šåœ°äº†è§£é—®é¢˜æ˜¯ä»€ä¹ˆï¼Œä»¥åŠæ•°æ®æ˜¯ä»€ä¹ˆæ ·å­ï¼Œç„¶åæˆ‘ä»¬æ‰èƒ½å¼„æ¸…æ¥šå¦‚ä½•è§£å†³é—®é¢˜ã€‚ æŸ¥çœ‹æ•°æ®æ„å‘³ç€äº†è§£æ•°æ®ç›®å½•çš„ç»“æ„ã€æ ‡ç­¾æ˜¯ä»€ä¹ˆä»¥åŠæŸäº›ç¤ºä¾‹å›¾åƒçš„æ ·å­.\n",
    "\n",
    "å¤„ç†ä¸åŒçš„å›¾åƒåˆ†ç±»æ•°æ®é›†ä¹‹é—´çš„ä¸»è¦åŒºåˆ«åœ¨äºæ ‡æ³¨çš„å­˜å‚¨æ–¹å¼ï¼Œæ¯”å¦‚ImageNetç”¨åˆ†ç±»ç¼–å·ä½œä¸ºç›®å½•åã€‚ åœ¨æœ¬å®éªŒä¸­ä½¿ç”¨çš„æ•°æ®é›†ä¸­ï¼Œæ ‡ç­¾å­˜å‚¨åœ¨æ–‡ä»¶åä¸­ã€‚ æˆ‘ä»¬éœ€è¦æå–å®ƒä»¬ï¼Œä»¥ä¾¿èƒ½å¤Ÿå°†å›¾ç‰‡åˆ†ç±»ä¸ºæ­£ç¡®çš„ç±»åˆ«ã€‚ å¹¸è¿çš„æ˜¯ï¼Œfastai åº“æœ‰ä¸€ä¸ªæ–¹ä¾¿çš„åŠŸèƒ½å¯ç”¨äºè¿™ä¸ªç›®çš„ï¼Œ `ImageDataBunch.from_name_re` é€šè¿‡ [æ­£åˆ™è¡¨è¾¾å¼](https://docs.python.org/3.6/library/re.html)æ¥ä»æ–‡ä»¶åè·å–å›¾ç‰‡åˆ†ç±»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = get_image_files(path_img)\n",
    "fnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "pat = r'/([^/]+)_\\d+.jpg$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(), size=224, bs=bs\n",
    "                                  ).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(7,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.classesä¸data.cç­‰æ•ˆï¼Œç”¨äºè·å–æ•°æ®é›†çš„åˆ†ç±»æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.classes)\n",
    "len(data.classes),data.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¨¡å‹è®­ç»ƒ: resnet34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å°†å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [å·ç§¯ç¥ç»ç½‘ç»œ] (http://cs231n.github.io/convolutional-networks/) éª¨å¹²ï¼Œå•ä¸ªéšè—å±‚ä»¥åŠå…¨è¿æ¥ä½œä¸ºåˆ†ç±»å™¨ã€‚fastaiåº“é‡Œå·²åŒ…å«å·ç§¯ç¥ç»ç½‘ç»œï¼Œç›´æ¥ä½¿ç”¨`cnn_learner`å³å¯æ„å»ºä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚`cnn_learner`å¯ç›´æ¥ä½¿ç”¨torchvisionä¸­çš„æ¨¡å‹å®šä¹‰ï¼Œå®Œå…¨ä¸ç”¨è‡ªå·±æ„å»ºæ¨¡å‹ï¼ˆç»å¤§å¤šæ•°æƒ…å†µä¸‹ä¹Ÿä¸éœ€è¦è‡ªå·±æ„å»ºï¼‰ï¼Œå‚è§ï¼šhttps://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "\n",
    "è®­ç»ƒæ¬¡æ•°ä¸º4ä¸ªepochs (æ‰€æœ‰æ•°æ®çš„4æ¬¡å¾ªç¯).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet34, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‰“å°æ¨¡å‹ç»“æ„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastaiå°ä¼˜åŒ–1: fit_one_cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Cycle-Policy å¤§æ¦‚æœ‰ä¸‰ä¸ªæ­¥éª¤ï¼š\n",
    "\n",
    "æˆ‘ä»¬é€æ¸å°†å­¦ä¹ ç‡ä» lr_max / div_factor æé«˜åˆ° lr_maxï¼ŒåŒæ—¶æˆ‘ä»¬é€æ¸å‡å°‘ä» mom_max åˆ° mom_min çš„åŠ¨é‡(momentum)ã€‚\n",
    "\n",
    "åå‘å†åšä¸€æ¬¡ï¼šæˆ‘ä»¬é€æ¸å°†å­¦ä¹ ç‡ä» lr_max é™ä½åˆ° lr_max / div_factorï¼ŒåŒæ—¶æˆ‘ä»¬é€æ¸å¢åŠ ä» mom_min åˆ° mom_max çš„åŠ¨é‡ã€‚\n",
    "\n",
    "æˆ‘ä»¬è¿›ä¸€æ­¥å°†å­¦ä¹ ç‡ä» lr_max / div_factor é™ä½åˆ° lr_max /ï¼ˆdiv_factor x 100ï¼‰ï¼Œæˆ‘ä»¬ä¿æŒåŠ¨åŠ›ç¨³å®šåœ¨ mom_maxã€‚\n",
    "\n",
    "æ­£æ˜¯åœ¨ä¸€ä¸ªepoché‡Œlearning rateå°±å·²ç»ä¸æ–­è°ƒæ•´å¹¶è¢«è§‚å¯Ÿï¼Œæ‰€ä»¥åç»­å¯é€šè¿‡lr_find()å‡½æ•°å¯»æ‰¾æœ€ä½³çš„lrï¼Œä¸å¿…é€šè¿‡HPOå»é€šè¿‡ä¸åŒçš„epochæ¥å¯»æ‰¾æœ€ä¼˜learning rateå‚æ•°ï¼Œç¼©çŸ­è®­ç»ƒæ—¶é—´ï¼Œå¹¶æé«˜å‡†ç¡®åº¦ã€‚\n",
    "\n",
    "è¿™é‡Œå…ˆç®€å•ä»‹ç»ä¸€ä¸‹åŸç†ï¼Œå…·ä½“å¦‚ä½•ä½¿ç”¨å…ˆä¸å±•å¼€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¿å­˜æ¨¡å‹ç»“æ„å’Œæ¨¡å‹å‚æ•°ï¼Œè®­ç»ƒå®Œåä¿å­˜ä»¥ä¸‹æ¨¡å‹æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ï¼Œé¿å…åç»­è°ƒæ•´æ“ä½œå½±å“æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è®­ç»ƒç»“æœ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬æ¥çœ‹çœ‹ç»“æœå¦‚ä½•ã€‚ \n",
    "\n",
    "æˆ‘ä»¬å°†é¦–å…ˆçœ‹åˆ°å“ªäº›æ˜¯æ¨¡å‹å½¼æ­¤æ··æ·†æœ€å¤šçš„ç±»åˆ«ã€‚ æˆ‘ä»¬å°†å°è¯•çœ‹çœ‹æ¨¡å‹é¢„æµ‹æ˜¯å¦åˆç†ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé”™è¯¯çœ‹èµ·æ¥åˆç†ï¼ˆæ²¡æœ‰æ˜æ˜¾çš„ä½çº§é”™è¯¯ï¼‰ã€‚ è¿™è¡¨æ˜æˆ‘ä»¬çš„åˆ†ç±»å™¨å·¥ä½œæ­£å¸¸ã€‚ \n",
    "\n",
    "æ­¤å¤–ï¼Œå½“æˆ‘ä»¬ç»˜åˆ¶æ··æ·†çŸ©é˜µæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åˆ†å¸ƒä¸¥é‡åæ–œï¼šæ¨¡å‹ä¸€éåˆä¸€éåœ°çŠ¯ä¸‹åŒæ ·çš„é”™è¯¯ï¼Œä½†å¾ˆå°‘æ··æ·†å…¶ä»–ç±»åˆ«ã€‚ è¿™è¡¨æ˜æ¨¡å‹åªæ˜¯å¾ˆéš¾åŒºåˆ†æŸäº›ç‰¹å®šç±»åˆ«ï¼Œè¿™æ˜¯æ­£å¸¸çš„è¡Œä¸ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "losses,idxs = interp.top_losses()\n",
    "\n",
    "len(data.valid_ds)==len(losses)==len(idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥ï¼Œæ‰“å°å‡ºæœ€å®¹æ˜“æ··æ·†çš„å›¾ç‰‡ç±»åˆ«ï¼Œæ¯å¼ å›¾ç‰‡ä¸Šæ–¹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç»™å‡ºç»“æœï¼š é¢„æµ‹å€¼/çœŸå®å€¼/æŸå¤±/ç½®ä¿¡åº¦ï¼ŒæŒ‰ç…§æŸå¤±å€¼ä»é«˜åˆ°ä½æ’åˆ—ï¼ŒæŸå¤±å€¼è¶Šé«˜ï¼Œè¡¨æ˜é¢„æµ‹ç»“æœå’ŒçœŸå®å€¼çš„å·®å¼‚è¶Šå¤§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(interp.plot_top_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚ä½•è§£è¯»æ··æ·†çŸ©é˜µï¼Ÿçºµåæ ‡è¡¨ç¤ºçœŸå®çš„åˆ†ç±»ï¼Œæ¨ªåæ ‡è¡¨ç¤ºæ¨¡å‹é¢„æµ‹çš„åˆ†ç±»ï¼Œä»å·¦ä¸Šè§’åˆ°å³ä¸‹è§’çš„å¯¹è§’çº¿ä¸Šçš„å€¼è¡¨ç¤ºé¢„æµ‹æ­£ç¡®çš„æ•°é‡ï¼Œå…¶ä»–å€¼éƒ½æ˜¯é¢„æµ‹é”™è¯¯çš„æ•°é‡ï¼Œæˆ‘ä»¬å¯æ ¹æ®å…¶å€¼æ¥åˆ†æå“ªäº›ç±»åˆ«çš„å›¾ç‰‡å®¹æ˜“è¢«è¯¯åˆ¤ï¼Œå¹¶å¯»æ‰¾ä¼˜åŒ–çš„æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦ä¸€ç§æ–¹å¼ï¼Œå°±æ˜¯é€šè¿‡`most_confused`å‡½æ•°æ¥æ‰“å°å‡ºæœ€å®¹å‡ºé”™çš„åˆ¤æ–­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è§£å†»ã€å¾®è°ƒå’Œå­¦ä¹ ç‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ—¢ç„¶æˆ‘ä»¬çš„æ¨¡å‹æ­£å¦‚æˆ‘ä»¬æ‰€æœŸæœ›çš„é‚£æ ·å·¥ä½œï¼Œæˆ‘ä»¬å°† *è§£å†»*æ¨¡å‹å¹¶ç»§ç»­è¿›è¡Œè®­ç»ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŠ è½½ä¹‹å‰ä¿å­˜çš„æ¨¡å‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¥ç€è®¨è®ºfit_one_cycleçš„æ”¶ç›Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç»è¿‡fit_one_cycleï¼Œåœ¨ä¸€ä¸ªepoché‡Œå·²ç»å°è¯•è¿‡äº†ä¸åŒçš„learning rateï¼Œç³»ç»Ÿä¼šè®°å½•ä¸åŒlrä¸‹çš„lossï¼Œé€šè¿‡lr_find()å‡½æ•°ï¼Œæ•´ç†å‡ºä¸åŒçš„lrå¯¹åº”çš„lossï¼Œé€šè¿‡å›¾è¡¨å¯ä»¥ç›´è§‚çš„å±•ç¤ºå“ªä¸€ä¸ªlrå¯¹åº”çš„lossæœ€ä½ï¼Œå†æ¬¡è¿›è¡Œè®­ç»ƒæ—¶ï¼Œå°±å¯ä»¥é€‰æ‹©æŸä¸ªåŒºé—´çš„lrè¿›ä¸€æ­¥ä¼˜åŒ–è®­ç»ƒç»“æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™å·²ç»æ˜¯å‡†ç¡®åº¦ç›¸å½“é«˜çš„æ¨¡å‹äº†ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬è¿˜å¯é€šè¿‡æ›¿æ¢éª¨å¹²æ¥æ„å»ºæ›´å¤æ‚çš„æ¨¡å‹ï¼Œè¿›ä¸€æ­¥æé«˜å‡†ç¡®åº¦!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¨¡å‹è®­ç»ƒ: resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å°†ç”¨ä¸ä»¥å‰ç›¸åŒçš„æ–¹å¼è®­ç»ƒï¼Œä½†æœ‰ä¸€ä¸ªåŒºåˆ«ï¼šæˆ‘ä»¬å°†ä½¿ç”¨resnet50è€Œä¸æ˜¯ä½¿ç”¨resnet34ä½œä¸ºæ¶æ„ï¼Œï¼ˆresnet34 æ˜¯ä¸€ä¸ª34å±‚çš„æ®‹å·®ç½‘ç»œï¼Œè€Œ resnet50æœ‰50å±‚ã€‚ å…³äº[æ®‹å·®ç½‘ç»œ](https://arxiv.org/pdf/1512.03385.pdf)å¯å‚è§è®ºæ–‡ï¼‰ã€‚ åŸºæœ¬ä¸Šï¼Œresnet50 é€šå¸¸è¡¨ç°æ›´å¥½ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå…·æœ‰æ›´å¤šå‚æ•°çš„æ›´æ·±çš„ç½‘ç»œã€‚ è®©æˆ‘ä»¬æ¥çœ‹çœ‹æˆ‘ä»¬æ˜¯å¦å¯ä»¥åœ¨è¿™é‡Œå®ç°æ›´é«˜çš„æ€§èƒ½ã€‚ ä¸ºäº†æ›´å¥½çš„è®­ç»ƒï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨è¾ƒå¤§çš„å›¾åƒï¼Œå› ä¸ºè¿™æ ·ç½‘ç»œå¯ä»¥çœ‹åˆ°æ›´å¤šç»†èŠ‚ã€‚ æˆ‘ä»¬å‡å°‘äº†ä¸€ç‚¹æ‰¹å¤„ç†å¤§å°ï¼Œå¦åˆ™è¿™ä¸ªè¾ƒå¤§çš„ç½‘ç»œå°†éœ€è¦æ›´å¤šçš„ GPU æ˜¾å­˜ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŠ è½½æ•°æ®ï¼Œå¹¶è¿›è¡Œnormalizeï¼Œä¸€ä¸ªå‡½æ•°æå®šã€‚å…·ä½“imagenet_statså‚è§ï¼šhttps://github.com/fastai/fastai/blob/3d6d17250cce719cb77d274b3f723d4295df07fd/fastai/vision/data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(),\n",
    "                                   size=299, bs=bs//2).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet50, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1-50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œèƒ½å¤Ÿå¦‚æ­¤å‡†ç¡®åœ°è¯†åˆ«å® ç‰©å“ç§ï¼ è®©æˆ‘ä»¬çœ‹çœ‹å®Œå…¨å¾®è°ƒæ˜¯å¦æœ‰å¸®åŠ©ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3, max_lr=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæ²¡æœ‰ï¼Œæ‚¨å¯ä»¥éšæ—¶è¿”å›åˆ°ä»¥å‰çš„æ¨¡å‹ã€‚è¿™ä¹Ÿå°±æ˜¯ä¹‹å‰ä¸ºä»€ä¹ˆæ¨èåŠæ—¶ä¿å­˜æ¨¡å‹çš„åŸå› ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-1-50');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused(min_val=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å…¶ä»–æ•°æ®é›†çš„ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE); path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(do_flip=False)\n",
    "data = ImageDataBunch.from_folder(path, ds_tfms=tfms, size=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet18, metrics=accuracy)\n",
    "learn.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'labels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_csv(path, ds_tfms=tfms, size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(5,5))\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_df(path, df, ds_tfms=tfms, size=24)\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_paths = [path/name for name in df['name']]; fn_paths[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = r\"/(\\d)/\\d+\\.png$\"\n",
    "data = ImageDataBunch.from_name_re(path, fn_paths, pat=pat, ds_tfms=tfms, size=24)\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_name_func(path, fn_paths, ds_tfms=tfms, size=24,\n",
    "        label_func = lambda x: '3' if '/3/' in str(x) else '7')\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [('3' if '/3/' in str(x) else '7') for x in fn_paths]\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_lists(path, fn_paths, labels=labels, ds_tfms=tfms, size=24)\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é¢å¤–çš„bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation æ•°æ®å¢å¼ºï¼Œå¯¹å·²æœ‰çš„æ•°æ®è¿›è¡Œè½¬æ¢å’Œå¾®è°ƒï¼Œäº§ç”Ÿæ›´å¤šçš„ç›¸ä¼¼æ•°æ®ã€‚ä¸€æ–¹é¢è§£å†³äº†æ•°æ®ä¸å¤Ÿä¸°å¯Œçš„é—®é¢˜ï¼Œå¦ä¸€æ–¹é¢ï¼Œä¹Ÿå¯ä»¥å¯¹ç°æœ‰æ•°æ®è¿›è¡Œæ³›åŒ–ï¼Œä¸€æ–¹é¢èƒ½å¾ˆå¤§ç¨‹åº¦è§£å†³overfittingçš„é—®é¢˜ï¼Œå¦ä¸€æ–¹é¢ä¹Ÿå¯ä»¥æåˆ°æ¨¡å‹è®­ç»ƒçš„å‡†ç¡®åº¦ã€‚å¯¹äºä¸åŒç±»å‹çš„æ•°æ®æœ‰ä¸€äº›å¸¸è§çš„data augmentationçš„æ–¹æ³•ï¼Œä¾‹å¦‚å¯¹å›¾ç‰‡æ•°æ®ï¼Œå¯ä»¥è¿›è¡Œç¿»è½¬ã€æ—‹è½¬ã€äº®åº¦è°ƒèŠ‚ã€é”åº¦è°ƒèŠ‚ã€æˆªå–ã€å¡«å……ç­‰æ–¹å¼æ¥è¿›è¡Œå›¾åƒå¢å¼ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](data_augmentation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jpeg](da.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯¹å›¾åƒçš„è£å‰ªã€æ—‹è½¬æ˜¯å¸¸è§çš„data augmentationæ–¹æ³•ï¼Œå¯å‚è€ƒhttps://docs.fast.ai/vision.transform.html è¿˜æœ‰ä¸€ç§æ–¹å¼ï¼Œå°†ä¸€å¼ çŒ«ğŸ±çš„å›¾ç‰‡å’Œä¸€å¼ ç‹—ğŸ¶çš„å›¾ç‰‡æ··åˆåœ¨ä¸€èµ·ï¼Œé‚£ä¹ˆç»“æœæ˜¯çŒ«è¿˜æ˜¯ğŸ¶ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fast.aié€šè¿‡mixupæ–¹å¼å®ç°äº†è¿™ç§æ•°æ®å¢å¼ºçš„æ–¹å¼ï¼Œé‚£ä¹ˆï¼Œä»€ä¹ˆæ˜¯mixupï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is mixup?\n",
    "This module contains the implementation of a data augmentation technique called mixup. It is extremely efficient at regularizing models in computer vision (we used it to get our time to train CIFAR10 to 94% on one GPU to 6 minutes).\n",
    "\n",
    "As the name kind of suggests, the authors of the mixup article propose training the model on mixes of the training set images. For example, suppose weâ€™re training on CIFAR10. Instead of feeding the model the raw images, we take two images (not necessarily from the same class) and make a linear combination of them: in terms of tensors, we have:\n",
    "\n",
    "new_image = t * image1 + (1-t) * image2\n",
    "\n",
    "where t is a float between 0 and 1. The target we assign to that new image is the same combination of the original targets:\n",
    "\n",
    "new_target = t * target1 + (1-t) * target2\n",
    "\n",
    "assuming the targets are one-hot encoded (which isnâ€™t the case in PyTorch usually). And it's as simple as that.\n",
    "\n",
    "![png](mixup.png)\n",
    "\n",
    "Dog or cat? The right answer here is 70% dog and 30% cat!\n",
    "\n",
    "As the picture above shows, itâ€™s a bit hard for the human eye to make sense of images obtained in this way (although we do see the shapes of a dog and a cat). However, it somehow makes a lot of sense to the model, which trains more efficiently. One important side note is that when training with mixup, the final loss (training or validation) will be higher than when training without it, even when the accuracy is far better: a model trained like this will make predictions that are a bit less confident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.gen_doc.nbdoc import *\n",
    "from fastai.callbacks.mixup import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "data = ImageDataBunch.from_folder(path)\n",
    "model = simple_cnn((3,16,16,2))\n",
    "learn = Learner(data, model, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_cnn((3,16,16,2))\n",
    "learner = Learner(data, model, metrics=[accuracy]).mixup()\n",
    "learner.fit(8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
