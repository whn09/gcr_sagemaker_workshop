{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an IAM role called [SageMakerRole] with AmazonSageMakerFullAccess and AmazonEC2ContainerRegistryFullAccess manually\n",
    "\n",
    "Add the IAM role of the notebook with AmazonEC2ContainerRegistryFullAccess mannually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create MXNet Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the binary\n",
    "!git clone https://github.com/aws/sagemaker-mxnet-container.git\n",
    "!cd sagemaker-mxnet-container\n",
    "!git checkout v3.1.2\n",
    "!python setup.py sdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MXNet 1.4.1, Python 3, CPU\n",
    "!cp dist/sagemaker_mxnet_container-3.1.2.tar.gz docker/1.4.1/py3/sagemaker_mxnet_container.tar.gz\n",
    "!cd docker/1.4.1/py3/\n",
    "!docker build -t preprod-mxnet:1.4.1-cpu-py3 -f Dockerfile.cpu ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload container to ECS\n",
    "# create-repository in ECR mannually\n",
    "!$(aws ecr get-login --region us-east-1 --no-include-email)\n",
    "!docker tag preprod-mxnet:1.4.1-cpu-py3 579019700964.dkr.ecr.us-east-1.amazonaws.com/preprod-mxnet:1.4.1-cpu-py3\n",
    "!aws ecr create-repository --repository-name preprod-mxnet\n",
    "!docker push 579019700964.dkr.ecr.us-east-1.amazonaws.com/preprod-mxnet:1.4.1-cpu-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../../../\n",
    "!pip install -e .[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May fail\n",
    "!tox test/unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May fail\n",
    "!tox -- test/integration/local --docker-base-name preprod-mxnet \\\n",
    "                              --tag 1.4.1-cpu-py3 \\\n",
    "                              --py-version 3 \\\n",
    "                              --framework-version 1.4.1 \\\n",
    "                              --processor cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May fail\n",
    "!tox -- test/integration/sagemaker --aws-id 579019700964 \\\n",
    "                                  --docker-base-name preprod-mxnet \\\n",
    "                                  --instance-type ml.m4.xlarge \\\n",
    "                                  --tag 1.4.1-cpu-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TextClassification Train Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train\n",
    "\n",
    "# create hyperparameters.json\n",
    "\n",
    "# create inputdataconfig.json\n",
    "\n",
    "# create resourceconfig.json\n",
    "\n",
    "# create Dockerfile.train\n",
    "\n",
    "!./classification-example.sh\n",
    "\n",
    "!./build_and_push.sh text-classification-train train\n",
    "\n",
    "!docker run text-classification-train train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test TextClassification Train Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579019700964.dkr.ecr.us-east-1.amazonaws.com/text-classification-train:latest\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "region = my_session.region_name\n",
    "\n",
    "algorithm_name = 'text-classification-train'\n",
    "\n",
    "ecr_image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)\n",
    "\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/dbpedia.train to s3://sagemaker-us-east-1-579019700964/gcr_sagemaker_workshop/NLP/gluonnlp/data/dbpedia.train\n",
      "upload: data/dbpedia.test to s3://sagemaker-us-east-1-579019700964/gcr_sagemaker_workshop/NLP/gluonnlp/data/dbpedia.test\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp data/dbpedia.train s3://sagemaker-us-east-1-579019700964/gcr_sagemaker_workshop/NLP/gluonnlp/data/dbpedia.train\n",
    "!aws s3 cp data/dbpedia.test s3://sagemaker-us-east-1-579019700964/gcr_sagemaker_workshop/NLP/gluonnlp/data/dbpedia.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-12 06:02:13 Starting - Starting the training job...\n",
      "2019-09-12 06:02:15 Starting - Launching requested ML instances......\n",
      "2019-09-12 06:03:16 Starting - Preparing the instances for training...\n",
      "2019-09-12 06:03:58 Downloading - Downloading input data...\n",
      "2019-09-12 06:04:25 Training - Downloading the training image......\n",
      "2019-09-12 06:05:25 Training - Training image download completed. Training in progress................\n",
      "2019-09-12 06:08:10 Uploading - Uploading generated training model.\n",
      "\u001b[31mException during training: Return Code: -9, CMD: ['/usr/local/bin/python', 'fasttext_word_ngram.py', '--ngrams', '2', '--epochs', '10', '--emsize', '100', '--lr', '0.05', '--input', '/opt/ml/input/data/train/dbpedia.train', '--validation', '/opt/ml/input/data/validation/dbpedia.test', '--output', '/opt/ml/model/gluonnlp.model', '--log_file', '/opt/ml/output/output.log'], Err: b\"2019-09-12 06:05:26,712 - fasttext_word_ngram.py[line:348] - INFO: Ngrams range for the training run : 2\\n2019-09-12 06:05:26,713 - fasttext_word_ngram.py[line:349] - INFO: Loading Training data\\n2019-09-12 06:05:26,713 - fasttext_word_ngram.py[line:191] - INFO: Opening file /opt/ml/input/data/train/dbpedia.train for reading input\\n2019-09-12 06:05:28,013 - fasttext_word_ngram.py[line:351] - INFO: Loading Test data\\n2019-09-12 06:05:28,014 - fasttext_word_ngram.py[line:191] - INFO: Opening file /opt/ml/input/data/validation/dbpedia.test for reading input\\n2019-09-12 06:05:40,301 - fasttext_word_ngram.py[line:359] - INFO: Vocabulary size: 803505\\n2019-09-12 06:05:40,301 - fasttext_word_ngram.py[line:360] - INFO: Training data converting to sequences...\\n2019-09-12 06:06:07,559 - fasttext_word_ngram.py[line:299] - INFO: Done! Sequence conversion Time=27.26s, #Sentences=560000\\n2019-09-12 06:06:21,266 - fasttext_word_ngram.py[line:299] - INFO: Done! Sequence conversion Time=13.71s, #Sentences=70000\\n2019-09-12 06:06:21,266 - fasttext_word_ngram.py[line:367] - INFO: Adding 2-gram features\\n2019-09-12 06:07:33,690 - fasttext_word_ngram.py[line:380] - INFO: Added n-gram features to train and test datasets!! \\n2019-09-12 06:07:33,690 - fasttext_word_ngram.py[line:381] - INFO: Encoding labels\\n2019-09-12 06:07:33,959 - fasttext_word_ngram.py[line:257] - INFO: Label mapping:{'__label__1': 0, '__label__10': 1, '__label__11': 2, '__label__12': 3, '__label__13': 4, '__label__14': 5, '__label__2': 6, '__label__3': 7, '__label__4': 8, '__label__5': 9, '__label__6': 10, '__label__7': 11, '__label__8': 12, '__label__9': 13}\\n2019-09-12 06:07:54,843 - fasttext_word_ngram.py[line:312] - INFO: Done! Preprocessing Time=20.76s, #Sentences=560000\\n2019-09-12 06:07:55,908 - fasttext_word_ngram.py[line:312] - INFO: Done! Preprocessing Time=1.06s, #Sentences=70000\\n/usr/local/lib/python3.6/site-packages/gluonnlp/data/batchify/batchify.py:228: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\\n  'Padding value is not given and will be set automatically to 0 '\\n/usr/local/lib/python3.6/site-packages/gluonnlp/data/sampler.py:354: UserWarning: Some buckets are empty and will be removed. Unused bucket keys=[1656, 1805, 1954, 2252, 2401, 2848]\\n  str(unused_bucket_keys))\\n2019-09-12 06:07:56,765 - fasttext_word_ngram.py[line:395] - INFO: Number of labels: 14\\n2019-09-12 06:07:56,765 - fasttext_word_ngram.py[line:396] - INFO: Initializing network\\n2019-09-12 06:07:56,765 - fasttext_word_ngram.py[line:398] - INFO: Running Training on ctx:cpu(0)\\n2019-09-12 06:07:56,766 - fasttext_word_ngram.py[line:400] - INFO: Embedding Matrix Length:6328901\\n2019-09-12 06:07:56,766 - fasttext_word_ngram.py[line:114] - INFO: Number of output units in the last layer :14\\n2019-09-12 06:07:56,774 - fasttext_word_ngram.py[line:405] - INFO: Network initialized\\n2019-09-12 06:07:56,774 - fasttext_word_ngram.py[line:416] - INFO: Loss function for training:SoftmaxCrossEntropyLoss(batch_axis=0, w=None)\\n2019-09-12 06:07:56,775 - fasttext_word_ngram.py[line:419] - INFO: Starting Training!\\n2019-09-12 06:07:56,775 - fasttext_word_ngram.py[line:426] - INFO: Training on 560000 samples and testing on 70000 samples\\n2019-09-12 06:07:56,775 - fasttext_word_ngram.py[line:428] - INFO: Number of batches for each epoch : 35000.0, Display cadence: 3500\\n2019-09-12 06:08:04,922 - fasttext_word_ngram.py[line:440] - INFO: Epoch : 0, Batches complete :0\\n\"\u001b[0m\n",
      "\u001b[31mTraceback (most recent call last):\n",
      "  File \"/opt/ml/code/train\", line 82, in <module>\n",
      "    _run(train_cmd)\n",
      "  File \"/opt/ml/code/train\", line 50, in _run\n",
      "    raise Exception(error_msg)\u001b[0m\n",
      "\u001b[31mException: Return Code: -9, CMD: ['/usr/local/bin/python', 'fasttext_word_ngram.py', '--ngrams', '2', '--epochs', '10', '--emsize', '100', '--lr', '0.05', '--input', '/opt/ml/input/data/train/dbpedia.train', '--validation', '/opt/ml/input/data/validation/dbpedia.test', '--output', '/opt/ml/model/gluonnlp.model', '--log_file', '/opt/ml/output/output.log'], Err: b\"2019-09-12 06:05:26,712 - fasttext_word_ngram.py[line:348] - INFO: Ngrams range for the training run : 2\\n2019-09-12 06:05:26,713 - fasttext_word_ngram.py[line:349] - INFO: Loading Training data\\n2019-09-12 06:05:26,713 - fasttext_word_ngram.py[line:191] - INFO: Opening file /opt/ml/input/data/train/dbpedia.train for reading input\\n2019-09-12 06:05:28,013 - fasttext_word_ngram.py[line:351] - INFO: Loading Test data\\n2019-09-12 06:05:28,014 - fasttext_word_ngram.py[line:191] - INFO: Opening file /opt/ml/input/data/validation/dbpedia.test for reading input\\n2019-09-12 06:05:40,301 - fasttext_word_ngram.py[line:359] - INFO: Vocabulary size: 803505\\n2019-09-12 06:05:40,301 - fasttext_word_ngram.py[line:360] - INFO: Training data converting to sequences...\\n2019-09-12 06:06:07,559 - fasttext_word_ngram.py[line:299] - INFO: Done! Sequence conversion Time=27.26s, #Sentences=560000\\n2019-09-12 06:06:21,266 - fasttext_word_ngram.py[line:299] - INFO: Done! Sequence conversion Time=13.71s, #Sentences=70000\\n2019-09-12 06:06:21,266 - fasttext_word_ngram.py[line:367] - INFO: Adding 2-gram features\\n2019-09-12 06:07:33,690 - fasttext_word_ngram.py[line:380] - INFO: Added n-gram features to train and test datasets!! \\n2019-09-12 06:07:33,690 - fasttext_word_ngram.py[line:381] - INFO: Encoding labels\\n2019-09-12 06:07:33,959 - fasttext_word_ngram.py[line:257] - INFO: Label mapping:{'__label__1': 0, '__label__10': 1, '__label__11': 2, '__label__12': 3, '__label__13': 4, '__label__14': 5, '__label__2': 6, '__label__3': 7, '__label__4': 8, '__label__5': 9, '__label__6': 10, '__label__7': 11, '__label__8': 12, '__label__9': 13}\\n2019-09-12 06:07:54,843 - fasttext_word_ngram.py[line:312] - INFO: Done! Preprocessing Time=20.76s, #Sentences=560000\\n2019-09-12 06:07:55,908 - fasttext_word_ngram.py[line:312] - INFO: Done! Preprocessing Time=1.06s, #Sentences=70000\\n/usr/local/lib/python3.6/site-packages/gluonnlp/data/batchify/batchify.py:228: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\\n  'Padding value is not given and will be set automatically to 0 '\\n/usr/local/lib/python3.6/site-packages/gluonnlp/data/sampler.py:354: UserWarning: Some buckets are empty and will be removed. Unused bucket keys=[1656, 1805, 1954, 2252, 2401, 2848]\\n  str(unused_bucket_keys))\\n2019-09-12 06:07:56,765 - fasttext_word_ngram.py[line:395] - INFO: Number of labels: 14\\n2019-09-12 06:07:56,765 - fasttext_word_ngram.py[line:396] - INFO: Initializing network\\n2019-09-12 06:07:56,765 - fasttext_word_ngram.py[line:398] - INFO: Running Training on ctx:cpu(0)\\n2019-09-12 06:07:56,766 - fasttext_word_ngram.py[line:400] - INFO: Embedding Matrix Length:6328901\\n2019-09-12 06:07:56,766 - fasttext_word_ngram.py[line:114] - INFO: Number of output units in the last layer :14\\n2019-09-12 06:07:56,774 - fasttext_word_ngram.py[line:405] - INFO: Network initialized\\n2019-09-12 06:07:56,774 - fasttext_word_ngram.py[line:416] - INFO: Loss function for training:SoftmaxCrossEntropyLoss(batch_axis=0, w=None)\\n2019-09-12 06:07:56,775 - fasttext_word_ngram.py[line:419] - INFO: Starting Training!\\n2019-09-12 06:07:56,775 - fasttext_word_ngram.py[line:426] - INFO: Training on 560000 samples and testing on 70000 samples\\n2019-09-12 06:07:56,775 - fasttext_word_ngram.py[line:428] - INFO: Number of batches for each epoch : 35000.0, Display cadence: 3500\\n2019-09-12 06:08:04,922 - fasttext_word_ngram.py[line:440] - INFO: Epoch : 0, Batches complete :0\\n\"\n",
      "\u001b[0m\n",
      "\n",
      "2019-09-12 06:08:16 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job text-classification-train-2019-09-12-06-02-13-063: Failed. Reason: AlgorithmError: Exception during training: Return Code: -9, CMD: ['/usr/local/bin/python', 'fasttext_word_ngram.py', '--ngrams', '2', '--epochs', '10', '--emsize', '100', '--lr', '0.05', '--input', '/opt/ml/input/data/train/dbpedia.train', '--validation', '/opt/ml/input/data/validation/dbpedia.test', '--output', '/opt/ml/model/gluonnlp.model', '--log_file', '/opt/ml/output/output.log'], Err: b\"2019-09-12 06:05:26,712 - fasttext_word_ngram.py[line:348] - INFO: Ngrams range for the training run : 2\\n2019-09-12 06:05:26,713 - fasttext_word_ngram.py[line:349] - INFO: Loading Training data\\n2019-09-12 06:05:26,713 - fasttext_word_ngram.py[line:191] - INFO: Opening file /opt/ml/input/data/train/dbpedia.train for reading input\\n2019-09-12 06:05:28,013 - fasttext_word_ngram.py[line:351] - INFO: Loading Test data\\n2019-09-12 06:05:28,014 - fasttext_word_ngram.py[line:191] - INFO: Opening file /opt/ml/input/data/validation/dbpedia.test for reading input\\n2019-09-12 06:05:40,301 - fasttext_word_ngram.py[line:359] - INFO",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-42758b472ac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                       hyperparameters=hyperparameters)\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \"\"\"\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   1464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 ),\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m             )\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job text-classification-train-2019-09-12-06-02-13-063: Failed. Reason: AlgorithmError: Exception during training: Return Code: -9, CMD: ['/usr/local/bin/python', 'fasttext_word_ngram.py', '--ngrams', '2', '--epochs', '10', '--emsize', '100', '--lr', '0.05', '--input', '/opt/ml/input/data/train/dbpedia.train', '--validation', '/opt/ml/input/data/validation/dbpedia.test', '--output', '/opt/ml/model/gluonnlp.model', '--log_file', '/opt/ml/output/output.log'], Err: b\"2019-09-12 06:05:26,712 - fasttext_word_ngram.py[line:348] - INFO: Ngrams range for the training run : 2\\n2019-09-12 06:05:26,713 - fasttext_word_ngram.py[line:349] - INFO: Loading Training data\\n2019-09-12 06:05:26,713 - fasttext_word_ngram.py[line:191] - INFO: Opening file /opt/ml/input/data/train/dbpedia.train for reading input\\n2019-09-12 06:05:28,013 - fasttext_word_ngram.py[line:351] - INFO: Loading Test data\\n2019-09-12 06:05:28,014 - fasttext_word_ngram.py[line:191] - INFO: Opening file /opt/ml/input/data/validation/dbpedia.test for reading input\\n2019-09-12 06:05:40,301 - fasttext_word_ngram.py[line:359] - INFO"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role, Session\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "hyperparameters = json.load(open('hyperparameters.json', 'r'))\n",
    "\n",
    "bucket = Session().default_bucket()\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, 'gcr_sagemaker_workshop/NLP/gluonnlp/data/dbpedia.train')\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, 'gcr_sagemaker_workshop/NLP/gluonnlp/data/dbpedia.test')\n",
    "train_data = session.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='text/plain', s3_data_type='S3Prefix')\n",
    "validation_data = session.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='text/plain', s3_data_type='S3Prefix')\n",
    "data_channels = {'train': train_data, 'validation': validation_data}\n",
    "\n",
    "instance_type = 'ml.m4.xlarge'\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type=instance_type,\n",
    "                      image_name=ecr_image,\n",
    "                      hyperparameters=hyperparameters)\n",
    "\n",
    "estimator.fit(data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create MXNet Serving Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/aws/sagemaker-mxnet-serving-container.git\n",
    "!cd sagemaker-mxnet-serving-container\n",
    "!git checkout v1.1.3\n",
    "!python setup.py sdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp dist/sagemaker_mxnet_serving_container-1.1.3.tar.gz docker/1.4.1/py3/sagemaker_mxnet_serving_container.tar.gz\n",
    "!cd docker/1.4.1/py3/\n",
    "!docker build -t preprod-mxnet-serving:1.4.1-cpu-py3 -f Dockerfile.cpu ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../../../\n",
    "!pip install -e .[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tox test/unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May fail\n",
    "!tox test/integration/local -- --docker-base-name preprod-mxnet-serving \\\n",
    "                              --tag 1.4.1-cpu-py3 \\\n",
    "                              --py-version 3 \\\n",
    "                              --framework-version 1.4.1 \\\n",
    "                              --processor cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload container to ECS\n",
    "# create-repository in ECR mannually\n",
    "!$(aws ecr get-login --region us-east-1 --no-include-email)\n",
    "!docker tag preprod-mxnet-serving:1.4.1-cpu-py3 579019700964.dkr.ecr.us-east-1.amazonaws.com/preprod-mxnet-serving:1.4.1-cpu-py3\n",
    "!docker push 579019700964.dkr.ecr.us-east-1.amazonaws.com/preprod-mxnet-serving:1.4.1-cpu-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May fail\n",
    "!tox test/integration/sagemaker -- --aws-id 579019700964 \\\n",
    "                                  --docker-base-name preprod-mxnet-serving \\\n",
    "                                  --instance-type ml.m4.xlarge \\\n",
    "                                  --tag 1.4.1-cpu-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TextClassification Serving Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd gluon-nlp/model_zoo/text_classification/\n",
    "\n",
    "# create serve\n",
    "\n",
    "# create Dockerfile.serve\n",
    "\n",
    "chmod +x build_and_push.sh\n",
    "./build_and_push.sh text-classification-serve serve\n",
    "\n",
    "!docker run text_classification_serve serve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
