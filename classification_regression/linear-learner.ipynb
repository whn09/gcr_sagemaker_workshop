{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = sess.default_bucket()\n",
    "region_name = boto3.Session().region_name\n",
    "prefix = 'gcr_sagemaker_workshop/classification_regression/linear_learner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libraries for working with data\n",
    "import numpy as np\n",
    "import pandas as pd# Read in csv and store in a pandas dataframe\n",
    "df = pd.read_csv('./data/linear-learner-MatchData.csv', sep=',' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify that the csv was read correctly you can execute df.head() to get a list of the top 5 entries in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv has a lot of data that we don’t need right now, we should create a dataframe with only the information we care about. Let’s create a new pandas df with only the columns we require for the excercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep player name for readability and manual checking\n",
    "data = df.loc[:, ['player_name', 'K', 'H', 'M', 'T', 'G', 'B', 'HO', 'FF', 'FA', 'AF']]# Remove player name as it is irrelevant for calcs\n",
    "playerStats = data.loc[:, ['K', 'H','M','T','G','B','HO','FF','FA']]# confirm we got the data we wanted\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an array of all the relevant player stats for every game of AFL in the 2018 season so far as well as the Fantasy Points that the player scored.\n",
    "\n",
    "Now AFL fantasy points are calculated by the following formula:\n",
    "\n",
    "Kick (3), Handball (2), Mark (3), Tackle (4), Goal (6), Behind (1), Hit Out (1), Free Kick For (1), Free Kick Against (-3)\n",
    "\n",
    "I’ve ordered these in the same order as our array so that we can create a weightings array in this order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightings = [3, 2, 3, 4, 6, 1, 1, 1, -3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run any ML algorithms we should verify that our data and weighting array are valid. Lets write a simple function to confirm this.\n",
    "\n",
    "This function will take an array of player stats and a vector of weights and multiply each stat by the relevant weight and sum them together to give us calculated Fantasy Points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fantasy_points(playerStats, Weightings):\n",
    "    return np.dot(playerStats, np.transpose(weightings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate fantasy points based on the weightings vector we have created and verify that they are indeed the correct weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Fantasy Points\n",
    "data['calculated'] = calculate_fantasy_points(playerStats, weightings)# Get the difference between actual points and predicted\n",
    "data['diff'] = data['AF'] - calculate_fantasy_points(playerStats, weightings)# Take the sum of the difference over all data points and verify that is is zero\n",
    "data['diff'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we see that indeed, the weighting vector we created above is correct and does generate the Fantasy Points we would expect. The next step is to see if the SageMaker Linear Learner can find that weighting vector if it was unknown to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using SageMaker Linear Learner\n",
    "The first thing we need to do is to prepare the data in a format that SageMaker can use. The Linear Learner requires a numpy array of type float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kicks, handballs, goals etc\n",
    "modelData = np.array(data.iloc[:, 1:10]).astype('float32')\n",
    "\n",
    "# Actual Fantasy Points\n",
    "target = np.array(data.iloc[:, 10]).astype('float32')\n",
    "\n",
    "#Verify that the conversion worked\n",
    "print(modelData[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to import some librarys to communicate with the ML instances\n",
    "!!! Don't forget to change the bucket and prefix name as you like.!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "# Use the IO buffer as dataset is small\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, modelData, target)\n",
    "buf.seek(0)\n",
    "\n",
    "key = 'linearlearner'\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))\n",
    "\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(region_name, 'linear-learner')\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we’ve done some setup and configuration, we can look at running the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.c4.xlarge',\n",
    "                                       output_path=output_location,\n",
    "                                       sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set some model parameters for this model. Specifically we need to tell the linear learner that we have 9 parameters to fit, that we want a regression model, and most importantly we do not want to normalise the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.set_hyperparameters(feature_dim=9,\n",
    "                           predictor_type='regressor',\n",
    "                           normalize_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to deploy our model to an instance to run the linear learner and get results. To deploy this model we simply run the following codes.\n",
    "This will take a couple of minutes to provision and run and will let you know when it’s done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.fit({'train': s3_train_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictor = linear.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accessing the results\n",
    "Once the model has been trained, we can send new data to the model and obtain predictions. In this case we are just going to send it the training data back and see how close it got to finding the correct weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "linear_predictor.content_type = 'text/csv'\n",
    "linear_predictor.serializer = csv_serializer\n",
    "linear_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass all the data to the predictor and get all the results back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for array in modelData:\n",
    "    result = linear_predictor.predict(array)\n",
    "    predictions += [r['score'] for r in result['predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)\n",
    "# Push into our pandas dataframe\n",
    "data['Predicted'] = predictions.astype(int)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# envaluation\n",
    "y_predicted = data['Predicted']\n",
    "y = data['calculated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationModel(y,y_pre):\n",
    "    accuracy_cnt = 0\n",
    "    for i,j in zip(y,y_pre):\n",
    "        if abs(i-j) <= 1:\n",
    "            accuracy_cnt += 1\n",
    "    accuracy_rate = float(accuracy_cnt) / len(y_predicted)\n",
    "    print ('test samples：{0}'.format(len(y_predicted)))\n",
    "    print ('accurate samples：{0}'.format(accuracy_cnt))\n",
    "    print ('accuracy rate：{0:.3f}'.format((accuracy_rate)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluationModel(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results were very close.\n",
    "And Sagemaker make it possible to deliver the ease of setting up the model, and just a little domain knowledge required to run this simple regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Optional) Delete the Endpoint\n",
    "\n",
    "If you're ready to be done with this notebook, please run the delete_endpoint line in the cell below. This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(linear_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
