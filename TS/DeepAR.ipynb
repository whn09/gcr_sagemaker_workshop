{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker/DeepAR demo on Stores Daily Sales\n",
    "\n",
    "In this lab, we will use Amazon SageMaker build-in algorithm DeepAR to forecast 1604 stores daily sales.\n",
    "\n",
    "In particular, we will see how to:\n",
    "* Use the SageMaker Python SDK to train a DeepAR model and deploy it\n",
    "* Make requests to the deployed model to obtain forecasts interactively\n",
    "* Illustrate advanced features of DeepAR: additional time features and category information\n",
    "\n",
    "Running this notebook takes around 40 min on a ml.c4.2xlarge for the training, and inference is done on a ml.m4.xlarge (the usage time will depend on how long you leave your served model running).\n",
    "\n",
    "For more information see the DeepAR [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html) or [paper](https://arxiv.org/abs/1704.04110), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "from dateutil.parser import parse\n",
    "import json\n",
    "from random import shuffle\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import s3fs\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import IntSlider, FloatSlider, Checkbox\n",
    "\n",
    "from decouple import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, we can override the default values for the following:\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = sagemaker.Session().default_bucket()  # replace with an existing bucket if needed\n",
    "s3_prefix = 'tko-ts-workshop'    # prefix used for all data stored within the bucket\n",
    "\n",
    "role = sagemaker.get_execution_role()             # IAM role to use by SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we configure the container image to be used for the region that we are running in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset and upload it to S3 to make it available for Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already has pre-processed the data we will use, it is under the same folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'data/timeseries_raw.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load and parse the dataset and convert it to a collection of Pandas time series, which makes common time series operations such as indexing by time periods or resampling much easier. The data has been processed, and the frequency is 1 day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(FILE_NAME, sep=\",\", index_col=0, parse_dates=True, decimal=',')\n",
    "data.index = pd.DatetimeIndex(data.index,freq=\"1D\")\n",
    "\n",
    "num_timeseries = data.shape[1]\n",
    "\n",
    "timeseries = []\n",
    "for i in range(num_timeseries):\n",
    "    timeseries.append(np.trim_zeros(data.iloc[:,i], trim='f').astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the resulting time series for the first ten stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019-07-10 00:00:00 to 2019-10-09 23:59:59\n",
    "\n",
    "DATETIME_START_OF_TRAIN = config('DATETIME_START_OF_TRAIN')\n",
    "DATETIME_END_OF_TRAIN = config('DATETIME_END_OF_TRAIN')\n",
    "DATETIME_START_OF_TEST = config('DATETIME_START_OF_TEST')\n",
    "DATETIME_END_OF_TEST = config('DATETIME_END_OF_TEST')\n",
    "DATETIME_START_OF_PREDICT = config('DATETIME_START_OF_PREDICT')\n",
    "DATETIME_END_OF_PREDICT = config('DATETIME_END_OF_PREDICT')\n",
    "\n",
    "# we use 1 day frequency for the time series\n",
    "freq = config('freq')\n",
    "\n",
    "# we predict for 7 days\n",
    "prediction_length = config('prediction_length', cast=int)\n",
    "\n",
    "# we also use 14 days as context length, this is the number of state updates accomplished before making predictions\n",
    "context_length = config('context_length', cast=int)\n",
    "\n",
    "sample_sites = config('sample_sites', cast=lambda v: [int(s.strip()) for s in v.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(len(sample_sites), 1, figsize=(15, 10), sharex=True)\n",
    "axx = axs.ravel()\n",
    "for i, site in enumerate(sample_sites):\n",
    "    timeseries[site].loc[DATETIME_START_OF_TRAIN:DATETIME_END_OF_PREDICT].astype(float).plot(ax=axx[i])\n",
    "    axx[i].set_xlabel(\"date\")    \n",
    "    axx[i].set_ylabel(\"sales RMB\")   \n",
    "    axx[i].grid(which='minor', axis='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test splits\n",
    "\n",
    "Often times one is interested in evaluating the model or tuning its hyperparameters by looking at error metrics on a hold-out test set. Here we split the available data into train and test sets for evaluating the trained model. For standard machine learning tasks such as classification and regression, one typically obtains this split by randomly separating examples into train and test sets. However, in forecasting it is important to do this train/test split based on time rather than by time series.\n",
    "\n",
    "In this example, we will reserve the last section of each of the time series for evalutation purpose and use only the first part as training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify here the portion of the data that is used for training: the model sees data from 2019-07-10 to 2019-09-16 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dataset = pd.Timestamp(DATETIME_START_OF_TRAIN, freq=freq)\n",
    "end_training = pd.Timestamp(DATETIME_END_OF_TRAIN, freq=freq)\n",
    "end_test = pd.Timestamp(DATETIME_END_OF_TEST, freq=freq)\n",
    "start_predict = pd.Timestamp(DATETIME_START_OF_PREDICT, freq=freq)\n",
    "end_predict = pd.Timestamp(DATETIME_END_OF_PREDICT, freq=freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DeepAR JSON input format represents each time series as a JSON object. In the simplest case each time series just consists of a start time stamp (``start``) and a list of values (``target``). For more complex cases, DeepAR also supports the fields ``dynamic_feat`` for time-series features and ``cat`` for categorical features, which we will use  later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    }
   ],
   "source": [
    "training_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[start_dataset:end_training - 1].tolist()  # We use -1, because pandas indexing includes the upper bound \n",
    "    }\n",
    "    for ts in timeseries\n",
    "]\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As test data, we will consider time series extending beyond the training range: these will be used for computing test scores, by using the trained model to forecast their trailing 7 days, and comparing predictions with actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-09-24 00:00:00', freq='D')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[start_dataset:end_test - 1].tolist()\n",
    "    }\n",
    "    for ts in timeseries\n",
    "]\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now write the dictionary to the `jsonlines` file format that DeepAR understands (it also supports gzipped jsonlines and parquet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80.5 ms, sys: 4.15 ms, total: 84.6 ms\n",
      "Wall time: 83.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"data/train.json\", training_data)\n",
    "write_dicts_to_file(\"data/test.json\", test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data files locally, let us copy them to S3 where DeepAR can access them. Depending on your connection, this may take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith('s3://')\n",
    "    split = s3_path.split('/')\n",
    "    bucket = split[2]\n",
    "    path = '/'.join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "    \n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print('File s3://{}/{} already exists.\\nSet override to upload anyway.\\n'.format(s3_bucket, s3_path))\n",
    "            return\n",
    "        else:\n",
    "            print('Overwriting existing file')\n",
    "    with open(local_file, 'rb') as data:\n",
    "        print('Uploading file to {}'.format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file to s3://sagemaker-us-west-2-169088282855/YOUR_BUCKET_NAME/data/train/train.json\n",
      "Uploading file to s3://sagemaker-us-west-2-169088282855/YOUR_BUCKET_NAME/data/test/test.json\n",
      "CPU times: user 32.1 ms, sys: 6.03 ms, total: 38.1 ms\n",
      "Wall time: 264 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_to_s3(\"data/train.json\", s3_data_path + \"/train/train.json\")\n",
    "copy_to_s3(\"data/test.json\", s3_data_path + \"/test/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to what we just wrote to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2019-07-10 00:00:00\", \"target\": [14.0, 18.0, 22.4, 28.5, 25.0, 7.3, 31.1, 0.0, 27.6, 46.1...\n"
     ]
    }
   ],
   "source": [
    "s3filesystem = s3fs.S3FileSystem()\n",
    "with s3filesystem.open(s3_data_path + \"/train/train.json\", 'rb') as fp:\n",
    "    print(fp.readline().decode(\"utf-8\")[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are all set with our dataset processing, we can now call DeepAR to train a model and generate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model\n",
    "\n",
    "Here we define the estimator that will launch the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")\n",
    "\n",
    "role = sagemaker.get_execution_role()             # IAM role to use by SageMaker\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='deepar-stores-sales-demo',\n",
    "    output_path=s3_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to set the hyperparameters for the training job. For example frequency of the time series used, number of data points the model will look at in the past, number of predicted data points. The other hyperparameters concern the model to train (number of layers, number of cells per layer, likelihood function) and the training options (number of epochs, batch size, learning rate...). We use default parameters for every optional parameter in this case (you can always use [Sagemaker Automated Model Tuning](https://aws.amazon.com/blogs/aws/sagemaker-automatic-model-tuning/) to tune them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to launch the training job. SageMaker will start an EC2 instance, download the data from S3, start training the model and save the trained model.\n",
    "\n",
    "If you provide the `test` data channel as we do in this example, DeepAR will also calculate accuracy metrics for the trained model on this test. This is done by predicting the last `prediction_length` points of each time-series in the test set and comparing this to the actual value of the time-series. \n",
    "\n",
    "**Note:** the next cell may take a few minutes to complete, depending on data size, model complexity, training options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-26 14:13:04 Starting - Starting the training job...\n",
      "2019-12-26 14:13:05 Starting - Launching requested ML instances......\n",
      "2019-12-26 14:14:06 Starting - Preparing the instances for training...\n",
      "2019-12-26 14:14:53 Downloading - Downloading input data\n",
      "2019-12-26 14:14:53 Training - Downloading the training image...\n",
      "2019-12-26 14:15:24 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:26 INFO 140207931545408] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:26 INFO 140207931545408] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'7', u'epochs': u'400', u'time_freq': u'1D', u'context_length': u'14', u'mini_batch_size': u'32', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:26 INFO 140207931545408] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'32', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'7', u'time_freq': u'1D', u'context_length': u'14', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:26 INFO 140207931545408] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:26 INFO 140207931545408] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:26 INFO 140207931545408] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:26 INFO 140207931545408] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Training set statistics:\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Real time series\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] number of time series: 1604\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] number of observations: 110676\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] mean target length: 69\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] min/mean/max target: 0.0/21018.1296408/1653507.875\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] mean abs(target): 21018.1296408\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] contains missing values: no\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Test set statistics:\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Real time series\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] number of time series: 1604\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] number of observations: 121904\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] mean target length: 76\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] min/mean/max target: 0.0/20798.7399189/1653507.875\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] mean abs(target): 20798.7399189\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] contains missing values: no\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] nvidia-smi took: 0.0252528190613 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 51.69391632080078, \"sum\": 51.69391632080078, \"min\": 51.69391632080078}}, \"EndTime\": 1577369727.307209, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369727.254624}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 136.35611534118652, \"sum\": 136.35611534118652, \"min\": 136.35611534118652}}, \"EndTime\": 1577369727.391104, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369727.307275}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Epoch[0] Batch[0] avg_epoch_loss=11.155746\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=11.1557455063\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Epoch[0] Batch[5] avg_epoch_loss=10.470427\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=10.4704270363\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Epoch[0] Batch [5]#011Speed: 1604.81 samples/sec#011loss=10.470427\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Epoch[0] Batch[10] avg_epoch_loss=9.859208\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=9.12574558258\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Epoch[0] Batch [10]#011Speed: 920.69 samples/sec#011loss=9.125746\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Epoch[0] Batch[15] avg_epoch_loss=9.663733\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=0, batch=15 train loss <loss>=9.23368854523\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:27 INFO 140207931545408] Epoch[0] Batch [15]#011Speed: 1797.23 samples/sec#011loss=9.233689\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch[20] avg_epoch_loss=9.509927\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=0, batch=20 train loss <loss>=9.01774749756\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch [20]#011Speed: 1038.53 samples/sec#011loss=9.017747\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch[25] avg_epoch_loss=9.399869\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=0, batch=25 train loss <loss>=8.93762321472\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch [25]#011Speed: 1684.85 samples/sec#011loss=8.937623\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch[30] avg_epoch_loss=9.271840\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=0, batch=30 train loss <loss>=8.60608930588\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch [30]#011Speed: 992.03 samples/sec#011loss=8.606089\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch[35] avg_epoch_loss=9.210758\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=0, batch=35 train loss <loss>=8.8320476532\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch [35]#011Speed: 2099.16 samples/sec#011loss=8.832048\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch[40] avg_epoch_loss=9.083546\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=0, batch=40 train loss <loss>=8.1676240921\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch [40]#011Speed: 1103.39 samples/sec#011loss=8.167624\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch[45] avg_epoch_loss=8.977879\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=0, batch=45 train loss <loss>=8.11141233444\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch [45]#011Speed: 1780.83 samples/sec#011loss=8.111412\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch[50] avg_epoch_loss=8.894021\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=0, batch=50 train loss <loss>=8.12252149582\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[0] Batch [50]#011Speed: 1067.18 samples/sec#011loss=8.122521\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] processed a total of 1602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 1397.1118927001953, \"sum\": 1397.1118927001953, \"min\": 1397.1118927001953}}, \"EndTime\": 1577369728.788381, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369727.391171}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1146.54943663 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=0, train loss <loss>=8.8940208005\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_0c79c11c-0669-47ca-9620-44404caa5e27-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.40288734436035, \"sum\": 17.40288734436035, \"min\": 17.40288734436035}}, \"EndTime\": 1577369728.806559, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369728.78846}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] Epoch[1] Batch[0] avg_epoch_loss=8.561900\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=8.56190013885\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch[5] avg_epoch_loss=8.621452\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=8.6214521726\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch [5]#011Speed: 1437.83 samples/sec#011loss=8.621452\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch[10] avg_epoch_loss=8.720665\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=8.83972129822\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch [10]#011Speed: 761.54 samples/sec#011loss=8.839721\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch[15] avg_epoch_loss=8.731098\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=1, batch=15 train loss <loss>=8.75405044556\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch [15]#011Speed: 1482.00 samples/sec#011loss=8.754050\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch[20] avg_epoch_loss=8.708620\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=1, batch=20 train loss <loss>=8.63669052124\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch [20]#011Speed: 805.68 samples/sec#011loss=8.636691\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch[25] avg_epoch_loss=8.701446\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=1, batch=25 train loss <loss>=8.67131652832\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch [25]#011Speed: 2075.79 samples/sec#011loss=8.671317\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch[30] avg_epoch_loss=8.624769\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=1, batch=30 train loss <loss>=8.22604942322\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch [30]#011Speed: 1066.22 samples/sec#011loss=8.226049\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch[35] avg_epoch_loss=8.574295\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=1, batch=35 train loss <loss>=8.26135454178\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:29 INFO 140207931545408] Epoch[1] Batch [35]#011Speed: 1873.38 samples/sec#011loss=8.261355\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[1] Batch[40] avg_epoch_loss=8.504711\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=1, batch=40 train loss <loss>=8.00370817184\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[1] Batch [40]#011Speed: 1006.90 samples/sec#011loss=8.003708\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[1] Batch[45] avg_epoch_loss=8.455524\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=1, batch=45 train loss <loss>=8.05219125748\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[1] Batch [45]#011Speed: 1648.21 samples/sec#011loss=8.052191\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[1] Batch[50] avg_epoch_loss=8.400437\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=1, batch=50 train loss <loss>=7.89363126755\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[1] Batch [50]#011Speed: 1322.58 samples/sec#011loss=7.893631\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] processed a total of 1620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1455.989122390747, \"sum\": 1455.989122390747, \"min\": 1455.989122390747}}, \"EndTime\": 1577369730.262701, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369728.80664}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1112.54565847 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=1, train loss <loss>=8.40043686885\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_4c0f7abd-4425-4060-bbd2-c6ea4b260f7e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.245084762573242, \"sum\": 10.245084762573242, \"min\": 10.245084762573242}}, \"EndTime\": 1577369730.273564, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369730.262788}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[2] Batch[0] avg_epoch_loss=8.417032\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=8.41703224182\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[2] Batch[5] avg_epoch_loss=8.570205\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=8.57020529111\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[2] Batch [5]#011Speed: 1674.52 samples/sec#011loss=8.570205\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[2] Batch[10] avg_epoch_loss=8.620176\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=8.6801410675\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[2] Batch [10]#011Speed: 944.01 samples/sec#011loss=8.680141\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[2] Batch[15] avg_epoch_loss=8.661164\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=8.75133876801\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[2] Batch [15]#011Speed: 1697.22 samples/sec#011loss=8.751339\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[2] Batch[20] avg_epoch_loss=8.628046\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=2, batch=20 train loss <loss>=8.52206573486\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[2] Batch [20]#011Speed: 974.93 samples/sec#011loss=8.522066\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[2] Batch[25] avg_epoch_loss=8.567959\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=2, batch=25 train loss <loss>=8.31559715271\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:30 INFO 140207931545408] Epoch[2] Batch [25]#011Speed: 1630.64 samples/sec#011loss=8.315597\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[2] Batch[30] avg_epoch_loss=8.532437\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=2, batch=30 train loss <loss>=8.3477230072\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[2] Batch [30]#011Speed: 1097.85 samples/sec#011loss=8.347723\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[2] Batch[35] avg_epoch_loss=8.506693\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=2, batch=35 train loss <loss>=8.34708003998\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[2] Batch [35]#011Speed: 1602.05 samples/sec#011loss=8.347080\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[2] Batch[40] avg_epoch_loss=8.446091\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=2, batch=40 train loss <loss>=8.00975294113\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[2] Batch [40]#011Speed: 946.06 samples/sec#011loss=8.009753\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[2] Batch[45] avg_epoch_loss=8.423699\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=2, batch=45 train loss <loss>=8.24008388519\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[2] Batch [45]#011Speed: 2130.06 samples/sec#011loss=8.240084\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] processed a total of 1595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1295.55082321167, \"sum\": 1295.55082321167, \"min\": 1295.55082321167}}, \"EndTime\": 1577369731.569223, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369730.273608}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1231.01877024 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=2, train loss <loss>=8.39291643143\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_f9de6858-e59e-41b9-8d78-5ade5ae65e0a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.250205993652344, \"sum\": 15.250205993652344, \"min\": 15.250205993652344}}, \"EndTime\": 1577369731.585036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369731.569305}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[3] Batch[0] avg_epoch_loss=8.323981\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=8.3239812851\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[3] Batch[5] avg_epoch_loss=8.584207\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=8.58420689901\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[3] Batch [5]#011Speed: 1543.06 samples/sec#011loss=8.584207\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[3] Batch[10] avg_epoch_loss=8.703514\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=8.84668331146\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:31 INFO 140207931545408] Epoch[3] Batch [10]#011Speed: 903.68 samples/sec#011loss=8.846683\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch[15] avg_epoch_loss=8.735698\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=8.80650272369\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch [15]#011Speed: 1936.07 samples/sec#011loss=8.806503\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch[20] avg_epoch_loss=8.753945\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=3, batch=20 train loss <loss>=8.81233310699\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch [20]#011Speed: 939.67 samples/sec#011loss=8.812333\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch[25] avg_epoch_loss=8.691702\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=3, batch=25 train loss <loss>=8.43028049469\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch [25]#011Speed: 2055.07 samples/sec#011loss=8.430280\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch[30] avg_epoch_loss=8.598877\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=3, batch=30 train loss <loss>=8.11618642807\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch [30]#011Speed: 897.24 samples/sec#011loss=8.116186\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch[35] avg_epoch_loss=8.549336\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=3, batch=35 train loss <loss>=8.24218244553\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch [35]#011Speed: 2151.73 samples/sec#011loss=8.242182\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch[40] avg_epoch_loss=8.485327\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=3, batch=40 train loss <loss>=8.02446546555\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch [40]#011Speed: 967.83 samples/sec#011loss=8.024465\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch[45] avg_epoch_loss=8.465350\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=3, batch=45 train loss <loss>=8.30153408051\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[3] Batch [45]#011Speed: 1782.01 samples/sec#011loss=8.301534\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] processed a total of 1541 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1286.9641780853271, \"sum\": 1286.9641780853271, \"min\": 1286.9641780853271}}, \"EndTime\": 1577369732.872115, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369731.585092}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1197.26997757 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=3, train loss <loss>=8.40816882192\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] Epoch[4] Batch[0] avg_epoch_loss=8.377588\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=8.37758827209\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch[5] avg_epoch_loss=8.153905\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=8.15390459696\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch [5]#011Speed: 1670.09 samples/sec#011loss=8.153905\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch[10] avg_epoch_loss=8.420622\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=8.74068336487\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch [10]#011Speed: 1009.32 samples/sec#011loss=8.740683\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch[15] avg_epoch_loss=8.523888\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=8.75107288361\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch [15]#011Speed: 2060.37 samples/sec#011loss=8.751073\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch[20] avg_epoch_loss=8.470207\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=4, batch=20 train loss <loss>=8.29842777252\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch [20]#011Speed: 989.29 samples/sec#011loss=8.298428\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch[25] avg_epoch_loss=8.454046\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=4, batch=25 train loss <loss>=8.38616867065\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch [25]#011Speed: 2096.65 samples/sec#011loss=8.386169\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch[30] avg_epoch_loss=8.399417\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=4, batch=30 train loss <loss>=8.1153465271\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch [30]#011Speed: 1014.24 samples/sec#011loss=8.115347\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch[35] avg_epoch_loss=8.362298\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=4, batch=35 train loss <loss>=8.13216161728\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch [35]#011Speed: 1698.93 samples/sec#011loss=8.132162\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch[40] avg_epoch_loss=8.324408\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=4, batch=40 train loss <loss>=8.05159778595\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:33 INFO 140207931545408] Epoch[4] Batch [40]#011Speed: 961.80 samples/sec#011loss=8.051598\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[4] Batch[45] avg_epoch_loss=8.315621\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=4, batch=45 train loss <loss>=8.24356584549\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[4] Batch [45]#011Speed: 1603.48 samples/sec#011loss=8.243566\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[4] Batch[50] avg_epoch_loss=8.292719\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=4, batch=50 train loss <loss>=8.08202466965\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[4] Batch [50]#011Speed: 1436.06 samples/sec#011loss=8.082025\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] processed a total of 1633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1315.6349658966064, \"sum\": 1315.6349658966064, \"min\": 1315.6349658966064}}, \"EndTime\": 1577369734.188313, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369732.872205}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1241.10407461 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=4, train loss <loss>=8.27827278467\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_8465e64a-4530-4755-8c0c-6448caa4c7ea-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.000871658325195, \"sum\": 11.000871658325195, \"min\": 11.000871658325195}}, \"EndTime\": 1577369734.199889, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369734.1884}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[5] Batch[0] avg_epoch_loss=8.277604\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=8.27760410309\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[5] Batch[5] avg_epoch_loss=8.321717\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=8.32171726227\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[5] Batch [5]#011Speed: 1965.24 samples/sec#011loss=8.321717\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[5] Batch[10] avg_epoch_loss=8.330948\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=8.34202461243\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[5] Batch [10]#011Speed: 838.35 samples/sec#011loss=8.342025\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[5] Batch[15] avg_epoch_loss=8.471485\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=8.78066654205\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[5] Batch [15]#011Speed: 1649.08 samples/sec#011loss=8.780667\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[5] Batch[20] avg_epoch_loss=8.442082\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=5, batch=20 train loss <loss>=8.34799137115\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[5] Batch [20]#011Speed: 873.34 samples/sec#011loss=8.347991\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[5] Batch[25] avg_epoch_loss=8.389636\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=5, batch=25 train loss <loss>=8.16936502457\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:34 INFO 140207931545408] Epoch[5] Batch [25]#011Speed: 2079.08 samples/sec#011loss=8.169365\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[5] Batch[30] avg_epoch_loss=8.361349\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=5, batch=30 train loss <loss>=8.21425523758\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[5] Batch [30]#011Speed: 1056.83 samples/sec#011loss=8.214255\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[5] Batch[35] avg_epoch_loss=8.298151\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=5, batch=35 train loss <loss>=7.90632562637\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[5] Batch [35]#011Speed: 2068.52 samples/sec#011loss=7.906326\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[5] Batch[40] avg_epoch_loss=8.263446\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=5, batch=40 train loss <loss>=8.01356611252\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[5] Batch [40]#011Speed: 905.99 samples/sec#011loss=8.013566\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[5] Batch[45] avg_epoch_loss=8.282194\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=5, batch=45 train loss <loss>=8.43593082428\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[5] Batch [45]#011Speed: 2066.25 samples/sec#011loss=8.435931\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[5] Batch[50] avg_epoch_loss=8.197870\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=5, batch=50 train loss <loss>=7.42208957672\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[5] Batch [50]#011Speed: 1644.41 samples/sec#011loss=7.422090\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] processed a total of 1617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1312.0520114898682, \"sum\": 1312.0520114898682, \"min\": 1312.0520114898682}}, \"EndTime\": 1577369735.512091, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369734.199953}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1232.29279418 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=5, train loss <loss>=8.19787016102\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_d9470cbf-ec7d-4d8b-b477-2527d1c57903-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.308027267456055, \"sum\": 10.308027267456055, \"min\": 10.308027267456055}}, \"EndTime\": 1577369735.522976, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369735.512159}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[6] Batch[0] avg_epoch_loss=8.470501\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=8.47050094604\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[6] Batch[5] avg_epoch_loss=8.343373\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=8.34337337812\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[6] Batch [5]#011Speed: 2038.50 samples/sec#011loss=8.343373\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[6] Batch[10] avg_epoch_loss=8.383940\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=8.43261985779\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[6] Batch [10]#011Speed: 1062.71 samples/sec#011loss=8.432620\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[6] Batch[15] avg_epoch_loss=8.488411\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=8.7182472229\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:35 INFO 140207931545408] Epoch[6] Batch [15]#011Speed: 1904.21 samples/sec#011loss=8.718247\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[6] Batch[20] avg_epoch_loss=8.498011\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=6, batch=20 train loss <loss>=8.52873153687\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[6] Batch [20]#011Speed: 943.72 samples/sec#011loss=8.528732\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[6] Batch[25] avg_epoch_loss=8.466360\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=6, batch=25 train loss <loss>=8.33342561722\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[6] Batch [25]#011Speed: 1676.38 samples/sec#011loss=8.333426\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[6] Batch[30] avg_epoch_loss=8.374049\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=6, batch=30 train loss <loss>=7.89403076172\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[6] Batch [30]#011Speed: 959.50 samples/sec#011loss=7.894031\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[6] Batch[35] avg_epoch_loss=8.344656\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=6, batch=35 train loss <loss>=8.16242275238\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[6] Batch [35]#011Speed: 1646.55 samples/sec#011loss=8.162423\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[6] Batch[40] avg_epoch_loss=8.326614\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=6, batch=40 train loss <loss>=8.19671192169\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[6] Batch [40]#011Speed: 961.45 samples/sec#011loss=8.196712\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[6] Batch[45] avg_epoch_loss=8.298871\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=6, batch=45 train loss <loss>=8.07137804031\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[6] Batch [45]#011Speed: 1489.16 samples/sec#011loss=8.071378\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] processed a total of 1559 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1265.1150226593018, \"sum\": 1265.1150226593018, \"min\": 1265.1150226593018}}, \"EndTime\": 1577369736.788214, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369735.523038}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1232.18407273 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=6, train loss <loss>=8.27463111099\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[7] Batch[0] avg_epoch_loss=8.642645\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=8.6426448822\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[7] Batch[5] avg_epoch_loss=8.560768\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=8.56076780955\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:36 INFO 140207931545408] Epoch[7] Batch [5]#011Speed: 1984.03 samples/sec#011loss=8.560768\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch[10] avg_epoch_loss=8.524717\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=8.48145513535\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch [10]#011Speed: 1009.71 samples/sec#011loss=8.481455\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch[15] avg_epoch_loss=8.593797\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=7, batch=15 train loss <loss>=8.74577541351\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch [15]#011Speed: 1887.30 samples/sec#011loss=8.745775\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch[20] avg_epoch_loss=8.599634\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=7, batch=20 train loss <loss>=8.61830997467\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch [20]#011Speed: 953.83 samples/sec#011loss=8.618310\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch[25] avg_epoch_loss=8.530716\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=7, batch=25 train loss <loss>=8.24125900269\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch [25]#011Speed: 2165.56 samples/sec#011loss=8.241259\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch[30] avg_epoch_loss=8.420894\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=7, batch=30 train loss <loss>=7.84982414246\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch [30]#011Speed: 1011.35 samples/sec#011loss=7.849824\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch[35] avg_epoch_loss=8.334953\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=7, batch=35 train loss <loss>=7.80211524963\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch [35]#011Speed: 1859.65 samples/sec#011loss=7.802115\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch[40] avg_epoch_loss=8.314379\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=7, batch=40 train loss <loss>=8.16624403\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch [40]#011Speed: 939.33 samples/sec#011loss=8.166244\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch[45] avg_epoch_loss=8.280255\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=7, batch=45 train loss <loss>=8.00044116974\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:37 INFO 140207931545408] Epoch[7] Batch [45]#011Speed: 2064.91 samples/sec#011loss=8.000441\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[7] Batch[50] avg_epoch_loss=8.205229\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=7, batch=50 train loss <loss>=7.51499319077\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[7] Batch [50]#011Speed: 1505.34 samples/sec#011loss=7.514993\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] processed a total of 1620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1258.9471340179443, \"sum\": 1258.9471340179443, \"min\": 1258.9471340179443}}, \"EndTime\": 1577369738.047695, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369736.78829}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1286.67428156 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=7, train loss <loss>=8.20522928238\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch[0] avg_epoch_loss=7.612115\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=7.61211490631\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch[5] avg_epoch_loss=8.233436\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=8.23343586922\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch [5]#011Speed: 1655.60 samples/sec#011loss=8.233436\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch[10] avg_epoch_loss=8.318968\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=8.42160625458\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch [10]#011Speed: 1054.02 samples/sec#011loss=8.421606\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch[15] avg_epoch_loss=8.424927\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=8, batch=15 train loss <loss>=8.65803852081\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch [15]#011Speed: 1783.70 samples/sec#011loss=8.658039\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch[20] avg_epoch_loss=8.431777\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=8, batch=20 train loss <loss>=8.45369586945\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch [20]#011Speed: 1054.21 samples/sec#011loss=8.453696\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch[25] avg_epoch_loss=8.409225\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=8, batch=25 train loss <loss>=8.31450634003\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch [25]#011Speed: 1710.06 samples/sec#011loss=8.314506\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch[30] avg_epoch_loss=8.350384\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=8, batch=30 train loss <loss>=8.04441299438\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch [30]#011Speed: 1014.25 samples/sec#011loss=8.044413\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch[35] avg_epoch_loss=8.314449\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=8, batch=35 train loss <loss>=8.09164838791\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:38 INFO 140207931545408] Epoch[8] Batch [35]#011Speed: 2029.04 samples/sec#011loss=8.091648\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[8] Batch[40] avg_epoch_loss=8.239340\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=8, batch=40 train loss <loss>=7.69855899811\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[8] Batch [40]#011Speed: 1123.57 samples/sec#011loss=7.698559\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[8] Batch[45] avg_epoch_loss=8.198278\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=8, batch=45 train loss <loss>=7.86156625748\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[8] Batch [45]#011Speed: 1472.35 samples/sec#011loss=7.861566\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] processed a total of 1570 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1253.3760070800781, \"sum\": 1253.3760070800781, \"min\": 1253.3760070800781}}, \"EndTime\": 1577369739.30163, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369738.047767}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1252.39012916 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=8, train loss <loss>=8.17724040985\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_88d03646-145e-447c-baf5-e12bef534f6f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 16.672849655151367, \"sum\": 16.672849655151367, \"min\": 16.672849655151367}}, \"EndTime\": 1577369739.319027, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369739.301809}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[9] Batch[0] avg_epoch_loss=9.054789\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=9.05478858948\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[9] Batch[5] avg_epoch_loss=8.295725\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=8.2957247893\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[9] Batch [5]#011Speed: 1506.04 samples/sec#011loss=8.295725\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[9] Batch[10] avg_epoch_loss=8.339031\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=8.39099769592\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[9] Batch [10]#011Speed: 887.10 samples/sec#011loss=8.390998\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[9] Batch[15] avg_epoch_loss=8.499742\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=9, batch=15 train loss <loss>=8.85330619812\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[9] Batch [15]#011Speed: 1641.23 samples/sec#011loss=8.853306\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[9] Batch[20] avg_epoch_loss=8.482250\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=9, batch=20 train loss <loss>=8.42627429962\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:39 INFO 140207931545408] Epoch[9] Batch [20]#011Speed: 978.83 samples/sec#011loss=8.426274\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[9] Batch[25] avg_epoch_loss=8.438465\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=9, batch=25 train loss <loss>=8.25456905365\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[9] Batch [25]#011Speed: 1736.57 samples/sec#011loss=8.254569\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[9] Batch[30] avg_epoch_loss=8.380724\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=9, batch=30 train loss <loss>=8.08047332764\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[9] Batch [30]#011Speed: 912.16 samples/sec#011loss=8.080473\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[9] Batch[35] avg_epoch_loss=8.322277\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=9, batch=35 train loss <loss>=7.9599023819\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[9] Batch [35]#011Speed: 1856.04 samples/sec#011loss=7.959902\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[9] Batch[40] avg_epoch_loss=8.277474\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=9, batch=40 train loss <loss>=7.95489215851\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[9] Batch [40]#011Speed: 1001.95 samples/sec#011loss=7.954892\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[9] Batch[45] avg_epoch_loss=8.257017\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=9, batch=45 train loss <loss>=8.08926763535\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[9] Batch [45]#011Speed: 1957.41 samples/sec#011loss=8.089268\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[9] Batch[50] avg_epoch_loss=8.214558\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=9, batch=50 train loss <loss>=7.82393884659\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[9] Batch [50]#011Speed: 1742.20 samples/sec#011loss=7.823939\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] processed a total of 1635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1379.276990890503, \"sum\": 1379.276990890503, \"min\": 1379.276990890503}}, \"EndTime\": 1577369740.698445, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369739.319093}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1185.28585567 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=9, train loss <loss>=8.13431233626\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_473e7f47-f5bb-49f8-b24f-9fff069279d0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 16.35885238647461, \"sum\": 16.35885238647461, \"min\": 16.35885238647461}}, \"EndTime\": 1577369740.715402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369740.698531}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[10] Batch[0] avg_epoch_loss=7.901000\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=7.90100049973\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[10] Batch[5] avg_epoch_loss=8.376385\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=8.37638529142\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:40 INFO 140207931545408] Epoch[10] Batch [5]#011Speed: 1890.85 samples/sec#011loss=8.376385\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch[10] avg_epoch_loss=8.489545\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=8.62533760071\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch [10]#011Speed: 919.28 samples/sec#011loss=8.625338\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch[15] avg_epoch_loss=8.532187\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=8.62599945068\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch [15]#011Speed: 1545.97 samples/sec#011loss=8.625999\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch[20] avg_epoch_loss=8.497568\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=10, batch=20 train loss <loss>=8.38678627014\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch [20]#011Speed: 880.38 samples/sec#011loss=8.386786\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch[25] avg_epoch_loss=8.467835\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=10, batch=25 train loss <loss>=8.34295768738\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch [25]#011Speed: 1647.62 samples/sec#011loss=8.342958\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch[30] avg_epoch_loss=8.385446\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=10, batch=30 train loss <loss>=7.95702152252\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch [30]#011Speed: 988.76 samples/sec#011loss=7.957022\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch[35] avg_epoch_loss=8.325750\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=10, batch=35 train loss <loss>=7.95563220978\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch [35]#011Speed: 1894.99 samples/sec#011loss=7.955632\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch[40] avg_epoch_loss=8.282392\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=10, batch=40 train loss <loss>=7.97021436691\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch [40]#011Speed: 958.57 samples/sec#011loss=7.970214\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch[45] avg_epoch_loss=8.297218\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=10, batch=45 train loss <loss>=8.41879310608\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:41 INFO 140207931545408] Epoch[10] Batch [45]#011Speed: 1784.10 samples/sec#011loss=8.418793\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] processed a total of 1580 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1341.6268825531006, \"sum\": 1341.6268825531006, \"min\": 1341.6268825531006}}, \"EndTime\": 1577369742.057175, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369740.715479}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1177.58238634 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=10, train loss <loss>=8.25134573936\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch[0] avg_epoch_loss=8.252490\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=8.25249004364\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch[5] avg_epoch_loss=8.106825\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=8.10682479541\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch [5]#011Speed: 1876.17 samples/sec#011loss=8.106825\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch[10] avg_epoch_loss=8.182453\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=8.27320728302\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch [10]#011Speed: 911.63 samples/sec#011loss=8.273207\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch[15] avg_epoch_loss=8.405836\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=11, batch=15 train loss <loss>=8.89727745056\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch [15]#011Speed: 2023.19 samples/sec#011loss=8.897277\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch[20] avg_epoch_loss=8.448777\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=11, batch=20 train loss <loss>=8.58618888855\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch [20]#011Speed: 1086.14 samples/sec#011loss=8.586189\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch[25] avg_epoch_loss=8.420932\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=11, batch=25 train loss <loss>=8.30398235321\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch [25]#011Speed: 2045.36 samples/sec#011loss=8.303982\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch[30] avg_epoch_loss=8.357744\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=11, batch=30 train loss <loss>=8.02916707993\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch [30]#011Speed: 981.33 samples/sec#011loss=8.029167\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch[35] avg_epoch_loss=8.292741\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=11, batch=35 train loss <loss>=7.88972053528\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:42 INFO 140207931545408] Epoch[11] Batch [35]#011Speed: 2043.42 samples/sec#011loss=7.889721\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[11] Batch[40] avg_epoch_loss=8.246707\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=11, batch=40 train loss <loss>=7.91526069641\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[11] Batch [40]#011Speed: 1080.53 samples/sec#011loss=7.915261\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[11] Batch[45] avg_epoch_loss=8.224772\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=11, batch=45 train loss <loss>=8.04490509033\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[11] Batch [45]#011Speed: 1621.19 samples/sec#011loss=8.044905\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[11] Batch[50] avg_epoch_loss=8.222803\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=11, batch=50 train loss <loss>=8.2046877861\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[11] Batch [50]#011Speed: 1611.70 samples/sec#011loss=8.204688\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] processed a total of 1618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1247.9979991912842, \"sum\": 1247.9979991912842, \"min\": 1247.9979991912842}}, \"EndTime\": 1577369743.305709, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369742.057242}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1296.33824683 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=11, train loss <loss>=8.22280263901\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[12] Batch[0] avg_epoch_loss=7.641130\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=7.64112997055\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[12] Batch[5] avg_epoch_loss=8.339971\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=8.33997114499\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[12] Batch [5]#011Speed: 2048.53 samples/sec#011loss=8.339971\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[12] Batch[10] avg_epoch_loss=8.447776\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=8.57714195251\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[12] Batch [10]#011Speed: 1122.37 samples/sec#011loss=8.577142\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[12] Batch[15] avg_epoch_loss=8.548207\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=8.76915569305\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[12] Batch [15]#011Speed: 2067.34 samples/sec#011loss=8.769156\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[12] Batch[20] avg_epoch_loss=8.540971\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=12, batch=20 train loss <loss>=8.5178155899\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[12] Batch [20]#011Speed: 1086.98 samples/sec#011loss=8.517816\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[12] Batch[25] avg_epoch_loss=8.476280\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=12, batch=25 train loss <loss>=8.20457983017\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:43 INFO 140207931545408] Epoch[12] Batch [25]#011Speed: 2113.16 samples/sec#011loss=8.204580\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[12] Batch[30] avg_epoch_loss=8.395849\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=12, batch=30 train loss <loss>=7.9776055336\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[12] Batch [30]#011Speed: 1009.67 samples/sec#011loss=7.977606\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[12] Batch[35] avg_epoch_loss=8.320908\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=12, batch=35 train loss <loss>=7.85627555847\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[12] Batch [35]#011Speed: 1861.37 samples/sec#011loss=7.856276\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[12] Batch[40] avg_epoch_loss=8.272206\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=12, batch=40 train loss <loss>=7.9215508461\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[12] Batch [40]#011Speed: 984.69 samples/sec#011loss=7.921551\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[12] Batch[45] avg_epoch_loss=8.247950\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=12, batch=45 train loss <loss>=8.04904661179\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[12] Batch [45]#011Speed: 2025.34 samples/sec#011loss=8.049047\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[12] Batch[50] avg_epoch_loss=8.227492\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=12, batch=50 train loss <loss>=8.0392829895\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[12] Batch [50]#011Speed: 1331.31 samples/sec#011loss=8.039283\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] processed a total of 1603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1222.4171161651611, \"sum\": 1222.4171161651611, \"min\": 1222.4171161651611}}, \"EndTime\": 1577369744.52867, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369743.305797}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1311.19492985 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=12, train loss <loss>=8.22749215481\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[13] Batch[0] avg_epoch_loss=8.889654\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=8.88965415955\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[13] Batch[5] avg_epoch_loss=8.275627\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=8.27562729518\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[13] Batch [5]#011Speed: 2073.40 samples/sec#011loss=8.275627\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[13] Batch[10] avg_epoch_loss=8.434904\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=8.62603569031\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[13] Batch [10]#011Speed: 965.97 samples/sec#011loss=8.626036\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[13] Batch[15] avg_epoch_loss=8.500271\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=13, batch=15 train loss <loss>=8.64407901764\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:44 INFO 140207931545408] Epoch[13] Batch [15]#011Speed: 2066.87 samples/sec#011loss=8.644079\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch[20] avg_epoch_loss=8.429296\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=13, batch=20 train loss <loss>=8.20217723846\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch [20]#011Speed: 1065.21 samples/sec#011loss=8.202177\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch[25] avg_epoch_loss=8.357483\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=13, batch=25 train loss <loss>=8.05586557388\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch [25]#011Speed: 2071.54 samples/sec#011loss=8.055866\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch[30] avg_epoch_loss=8.301943\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=13, batch=30 train loss <loss>=8.01313428879\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch [30]#011Speed: 984.10 samples/sec#011loss=8.013134\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch[35] avg_epoch_loss=8.225232\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=13, batch=35 train loss <loss>=7.74962568283\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch [35]#011Speed: 2125.62 samples/sec#011loss=7.749626\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch[40] avg_epoch_loss=8.176638\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=13, batch=40 train loss <loss>=7.82676019669\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch [40]#011Speed: 962.97 samples/sec#011loss=7.826760\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch[45] avg_epoch_loss=8.204145\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=13, batch=45 train loss <loss>=8.42970581055\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch [45]#011Speed: 1812.56 samples/sec#011loss=8.429706\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch[50] avg_epoch_loss=8.150703\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=13, batch=50 train loss <loss>=7.65903530121\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[13] Batch [50]#011Speed: 1521.83 samples/sec#011loss=7.659035\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] processed a total of 1613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1274.0190029144287, \"sum\": 1274.0190029144287, \"min\": 1274.0190029144287}}, \"EndTime\": 1577369745.803217, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369744.528758}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1265.95181742 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=13, train loss <loss>=8.15070309358\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[14] Batch[0] avg_epoch_loss=8.670157\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=8.67015743256\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[14] Batch[5] avg_epoch_loss=8.427054\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=8.42705408732\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:45 INFO 140207931545408] Epoch[14] Batch [5]#011Speed: 1933.56 samples/sec#011loss=8.427054\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch[10] avg_epoch_loss=8.466666\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=8.51419944763\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch [10]#011Speed: 1021.90 samples/sec#011loss=8.514199\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch[15] avg_epoch_loss=8.487825\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=8.53437633514\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch [15]#011Speed: 2022.61 samples/sec#011loss=8.534376\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch[20] avg_epoch_loss=8.484746\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=14, batch=20 train loss <loss>=8.47489128113\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch [20]#011Speed: 971.92 samples/sec#011loss=8.474891\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch[25] avg_epoch_loss=8.419873\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=14, batch=25 train loss <loss>=8.14740514755\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch [25]#011Speed: 1883.32 samples/sec#011loss=8.147405\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch[30] avg_epoch_loss=8.329518\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=14, batch=30 train loss <loss>=7.85967750549\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch [30]#011Speed: 1086.34 samples/sec#011loss=7.859678\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch[35] avg_epoch_loss=8.310244\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=14, batch=35 train loss <loss>=8.19074258804\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch [35]#011Speed: 1898.37 samples/sec#011loss=8.190743\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch[40] avg_epoch_loss=8.256532\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=14, batch=40 train loss <loss>=7.86980848312\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch [40]#011Speed: 1082.27 samples/sec#011loss=7.869808\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch[45] avg_epoch_loss=8.220266\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=14, batch=45 train loss <loss>=7.92288331985\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:46 INFO 140207931545408] Epoch[14] Batch [45]#011Speed: 2119.99 samples/sec#011loss=7.922883\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] processed a total of 1578 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1207.984209060669, \"sum\": 1207.984209060669, \"min\": 1207.984209060669}}, \"EndTime\": 1577369747.011821, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369745.803295}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1306.19632262 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=14, train loss <loss>=8.18820967674\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch[0] avg_epoch_loss=8.794679\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=8.79467868805\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch[5] avg_epoch_loss=8.333777\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=8.33377718925\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch [5]#011Speed: 1827.36 samples/sec#011loss=8.333777\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch[10] avg_epoch_loss=8.457788\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=8.60660057068\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch [10]#011Speed: 979.27 samples/sec#011loss=8.606601\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch[15] avg_epoch_loss=8.470693\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=8.49908494949\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch [15]#011Speed: 1641.62 samples/sec#011loss=8.499085\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch[20] avg_epoch_loss=8.467704\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=15, batch=20 train loss <loss>=8.45813751221\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch [20]#011Speed: 1044.69 samples/sec#011loss=8.458138\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch[25] avg_epoch_loss=8.415895\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=15, batch=25 train loss <loss>=8.19829902649\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch [25]#011Speed: 2063.53 samples/sec#011loss=8.198299\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch[30] avg_epoch_loss=8.307142\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=15, batch=30 train loss <loss>=7.74162282944\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch [30]#011Speed: 1000.32 samples/sec#011loss=7.741623\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch[35] avg_epoch_loss=8.227193\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=15, batch=35 train loss <loss>=7.73151245117\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:47 INFO 140207931545408] Epoch[15] Batch [35]#011Speed: 1850.67 samples/sec#011loss=7.731512\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[15] Batch[40] avg_epoch_loss=8.229623\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=15, batch=40 train loss <loss>=8.24711561203\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[15] Batch [40]#011Speed: 985.01 samples/sec#011loss=8.247116\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[15] Batch[45] avg_epoch_loss=8.225991\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=15, batch=45 train loss <loss>=8.19620866776\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[15] Batch [45]#011Speed: 1727.80 samples/sec#011loss=8.196209\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] processed a total of 1581 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1254.2171478271484, \"sum\": 1254.2171478271484, \"min\": 1254.2171478271484}}, \"EndTime\": 1577369748.266671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369747.011886}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1260.40782414 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=15, train loss <loss>=8.17159296989\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[16] Batch[0] avg_epoch_loss=8.778277\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=8.77827739716\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[16] Batch[5] avg_epoch_loss=8.258048\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=8.25804805756\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[16] Batch [5]#011Speed: 2018.80 samples/sec#011loss=8.258048\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[16] Batch[10] avg_epoch_loss=8.339182\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=8.43654298782\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[16] Batch [10]#011Speed: 951.78 samples/sec#011loss=8.436543\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[16] Batch[15] avg_epoch_loss=8.506808\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=8.87558460236\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[16] Batch [15]#011Speed: 2068.98 samples/sec#011loss=8.875585\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[16] Batch[20] avg_epoch_loss=8.431815\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=16, batch=20 train loss <loss>=8.19183712006\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[16] Batch [20]#011Speed: 957.59 samples/sec#011loss=8.191837\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[16] Batch[25] avg_epoch_loss=8.348837\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=16, batch=25 train loss <loss>=8.0003285408\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:48 INFO 140207931545408] Epoch[16] Batch [25]#011Speed: 1644.79 samples/sec#011loss=8.000329\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[16] Batch[30] avg_epoch_loss=8.268848\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=16, batch=30 train loss <loss>=7.8529091835\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[16] Batch [30]#011Speed: 947.15 samples/sec#011loss=7.852909\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[16] Batch[35] avg_epoch_loss=8.231656\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=16, batch=35 train loss <loss>=8.00106220245\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[16] Batch [35]#011Speed: 1681.63 samples/sec#011loss=8.001062\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[16] Batch[40] avg_epoch_loss=8.201224\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=16, batch=40 train loss <loss>=7.98211717606\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[16] Batch [40]#011Speed: 928.06 samples/sec#011loss=7.982117\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[16] Batch[45] avg_epoch_loss=8.175361\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=16, batch=45 train loss <loss>=7.96328392029\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[16] Batch [45]#011Speed: 1630.45 samples/sec#011loss=7.963284\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] processed a total of 1582 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1310.703992843628, \"sum\": 1310.703992843628, \"min\": 1310.703992843628}}, \"EndTime\": 1577369749.57797, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369748.266763}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1206.85960398 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=16, train loss <loss>=8.1132858181\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_09977c76-d19f-4865-bfd7-6f705b5dfe07-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 13.139963150024414, \"sum\": 13.139963150024414, \"min\": 13.139963150024414}}, \"EndTime\": 1577369749.591795, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369749.57806}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[17] Batch[0] avg_epoch_loss=8.011485\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=8.01148509979\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[17] Batch[5] avg_epoch_loss=8.189995\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=8.18999457359\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[17] Batch [5]#011Speed: 1642.42 samples/sec#011loss=8.189995\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[17] Batch[10] avg_epoch_loss=8.306370\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=8.44602088928\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:49 INFO 140207931545408] Epoch[17] Batch [10]#011Speed: 1030.39 samples/sec#011loss=8.446021\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch[15] avg_epoch_loss=8.372503\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=8.51799583435\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch [15]#011Speed: 2070.53 samples/sec#011loss=8.517996\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch[20] avg_epoch_loss=8.373600\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=17, batch=20 train loss <loss>=8.37711019516\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch [20]#011Speed: 980.17 samples/sec#011loss=8.377110\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch[25] avg_epoch_loss=8.314156\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=17, batch=25 train loss <loss>=8.0644908905\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch [25]#011Speed: 1672.82 samples/sec#011loss=8.064491\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch[30] avg_epoch_loss=8.292187\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=17, batch=30 train loss <loss>=8.17794780731\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch [30]#011Speed: 920.88 samples/sec#011loss=8.177948\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch[35] avg_epoch_loss=8.220677\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=17, batch=35 train loss <loss>=7.77731342316\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch [35]#011Speed: 1877.80 samples/sec#011loss=7.777313\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch[40] avg_epoch_loss=8.194486\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=17, batch=40 train loss <loss>=8.00591106415\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch [40]#011Speed: 835.26 samples/sec#011loss=8.005911\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch[45] avg_epoch_loss=8.184885\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=17, batch=45 train loss <loss>=8.10615501404\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch [45]#011Speed: 1840.41 samples/sec#011loss=8.106155\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch[50] avg_epoch_loss=8.140588\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=17, batch=50 train loss <loss>=7.73306369781\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] Epoch[17] Batch [50]#011Speed: 1799.96 samples/sec#011loss=7.733064\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] processed a total of 1649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1341.8760299682617, \"sum\": 1341.8760299682617, \"min\": 1341.8760299682617}}, \"EndTime\": 1577369750.933847, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369749.591872}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1228.7684908 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=17, train loss <loss>=8.17452427057\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:50 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch[0] avg_epoch_loss=8.217552\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=8.21755218506\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch[5] avg_epoch_loss=8.410570\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=8.41056998571\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch [5]#011Speed: 2095.70 samples/sec#011loss=8.410570\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch[10] avg_epoch_loss=8.400419\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=8.38823699951\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch [10]#011Speed: 1042.77 samples/sec#011loss=8.388237\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch[15] avg_epoch_loss=8.483094\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=18, batch=15 train loss <loss>=8.66497879028\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch [15]#011Speed: 1885.99 samples/sec#011loss=8.664979\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch[20] avg_epoch_loss=8.543382\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=18, batch=20 train loss <loss>=8.73630409241\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch [20]#011Speed: 1061.51 samples/sec#011loss=8.736304\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch[25] avg_epoch_loss=8.466661\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=18, batch=25 train loss <loss>=8.1444357872\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch [25]#011Speed: 1723.83 samples/sec#011loss=8.144436\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch[30] avg_epoch_loss=8.395837\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=18, batch=30 train loss <loss>=8.02754707336\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch [30]#011Speed: 961.76 samples/sec#011loss=8.027547\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch[35] avg_epoch_loss=8.326471\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=18, batch=35 train loss <loss>=7.89640445709\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch [35]#011Speed: 2069.72 samples/sec#011loss=7.896404\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch[40] avg_epoch_loss=8.293775\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=18, batch=40 train loss <loss>=8.0583609581\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:51 INFO 140207931545408] Epoch[18] Batch [40]#011Speed: 1006.11 samples/sec#011loss=8.058361\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[18] Batch[45] avg_epoch_loss=8.253241\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=18, batch=45 train loss <loss>=7.92086935043\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[18] Batch [45]#011Speed: 2026.06 samples/sec#011loss=7.920869\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] processed a total of 1600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1227.98490524292, \"sum\": 1227.98490524292, \"min\": 1227.98490524292}}, \"EndTime\": 1577369752.162427, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369750.933922}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1302.82214963 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=18, train loss <loss>=8.21427623749\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch[0] avg_epoch_loss=8.405264\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=8.40526390076\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch[5] avg_epoch_loss=8.379004\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=8.37900368373\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch [5]#011Speed: 1869.60 samples/sec#011loss=8.379004\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch[10] avg_epoch_loss=8.483532\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=8.60896530151\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch [10]#011Speed: 1022.89 samples/sec#011loss=8.608965\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch[15] avg_epoch_loss=8.537472\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=19, batch=15 train loss <loss>=8.65614109039\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch [15]#011Speed: 2093.01 samples/sec#011loss=8.656141\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch[20] avg_epoch_loss=8.519736\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=19, batch=20 train loss <loss>=8.46297836304\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch [20]#011Speed: 1092.87 samples/sec#011loss=8.462978\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch[25] avg_epoch_loss=8.421266\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=19, batch=25 train loss <loss>=8.00769481659\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch [25]#011Speed: 1647.57 samples/sec#011loss=8.007695\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch[30] avg_epoch_loss=8.345274\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=19, batch=30 train loss <loss>=7.95011634827\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:52 INFO 140207931545408] Epoch[19] Batch [30]#011Speed: 999.79 samples/sec#011loss=7.950116\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[19] Batch[35] avg_epoch_loss=8.268673\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=19, batch=35 train loss <loss>=7.79374599457\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[19] Batch [35]#011Speed: 1717.24 samples/sec#011loss=7.793746\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[19] Batch[40] avg_epoch_loss=8.276115\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=19, batch=40 train loss <loss>=8.32969779968\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[19] Batch [40]#011Speed: 1083.77 samples/sec#011loss=8.329698\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[19] Batch[45] avg_epoch_loss=8.211447\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=19, batch=45 train loss <loss>=7.68117246628\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[19] Batch [45]#011Speed: 1741.33 samples/sec#011loss=7.681172\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] processed a total of 1527 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1177.7398586273193, \"sum\": 1177.7398586273193, \"min\": 1177.7398586273193}}, \"EndTime\": 1577369753.34071, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369752.162501}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1296.41024578 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=19, train loss <loss>=8.17439467708\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[20] Batch[0] avg_epoch_loss=8.586427\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=8.58642673492\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[20] Batch[5] avg_epoch_loss=8.389415\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=8.38941462835\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[20] Batch [5]#011Speed: 2033.01 samples/sec#011loss=8.389415\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[20] Batch[10] avg_epoch_loss=8.419384\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=8.45534629822\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[20] Batch [10]#011Speed: 1046.39 samples/sec#011loss=8.455346\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[20] Batch[15] avg_epoch_loss=8.423432\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=20, batch=15 train loss <loss>=8.43233757019\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[20] Batch [15]#011Speed: 1620.38 samples/sec#011loss=8.432338\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[20] Batch[20] avg_epoch_loss=8.462794\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=20, batch=20 train loss <loss>=8.58875465393\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[20] Batch [20]#011Speed: 1042.53 samples/sec#011loss=8.588755\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[20] Batch[25] avg_epoch_loss=8.440004\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=20, batch=25 train loss <loss>=8.34428291321\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:53 INFO 140207931545408] Epoch[20] Batch [25]#011Speed: 1985.02 samples/sec#011loss=8.344283\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] Epoch[20] Batch[30] avg_epoch_loss=8.341802\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=20, batch=30 train loss <loss>=7.83115444183\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] Epoch[20] Batch [30]#011Speed: 974.19 samples/sec#011loss=7.831154\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] Epoch[20] Batch[35] avg_epoch_loss=8.273332\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=20, batch=35 train loss <loss>=7.84881534576\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] Epoch[20] Batch [35]#011Speed: 1630.76 samples/sec#011loss=7.848815\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] Epoch[20] Batch[40] avg_epoch_loss=8.200210\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=20, batch=40 train loss <loss>=7.67373123169\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] Epoch[20] Batch [40]#011Speed: 923.65 samples/sec#011loss=7.673731\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] Epoch[20] Batch[45] avg_epoch_loss=8.159543\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=20, batch=45 train loss <loss>=7.82607803345\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] Epoch[20] Batch [45]#011Speed: 1607.64 samples/sec#011loss=7.826078\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] processed a total of 1587 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1301.023006439209, \"sum\": 1301.023006439209, \"min\": 1301.023006439209}}, \"EndTime\": 1577369754.642362, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369753.340795}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1219.46920201 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=20, train loss <loss>=8.12409900665\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] Epoch[21] Batch[0] avg_epoch_loss=8.404915\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=8.40491485596\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] Epoch[21] Batch[5] avg_epoch_loss=8.461791\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=8.46179072062\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:54 INFO 140207931545408] Epoch[21] Batch [5]#011Speed: 1604.43 samples/sec#011loss=8.461791\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch[10] avg_epoch_loss=8.401166\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=8.3284160614\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch [10]#011Speed: 977.61 samples/sec#011loss=8.328416\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch[15] avg_epoch_loss=8.485663\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=21, batch=15 train loss <loss>=8.67155532837\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch [15]#011Speed: 1955.36 samples/sec#011loss=8.671555\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch[20] avg_epoch_loss=8.531519\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=21, batch=20 train loss <loss>=8.67825889587\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch [20]#011Speed: 1062.59 samples/sec#011loss=8.678259\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch[25] avg_epoch_loss=8.489242\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=21, batch=25 train loss <loss>=8.31167678833\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch [25]#011Speed: 2092.13 samples/sec#011loss=8.311677\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch[30] avg_epoch_loss=8.412361\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=21, batch=30 train loss <loss>=8.01258306503\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch [30]#011Speed: 932.37 samples/sec#011loss=8.012583\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch[35] avg_epoch_loss=8.341757\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=21, batch=35 train loss <loss>=7.90401172638\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch [35]#011Speed: 1840.90 samples/sec#011loss=7.904012\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch[40] avg_epoch_loss=8.302129\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=21, batch=40 train loss <loss>=8.01680746078\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch [40]#011Speed: 1074.97 samples/sec#011loss=8.016807\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch[45] avg_epoch_loss=8.277151\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=21, batch=45 train loss <loss>=8.07233543396\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch [45]#011Speed: 1950.50 samples/sec#011loss=8.072335\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch[50] avg_epoch_loss=8.214741\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=21, batch=50 train loss <loss>=7.64055967331\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] Epoch[21] Batch [50]#011Speed: 1402.13 samples/sec#011loss=7.640560\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] processed a total of 1614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1304.3608665466309, \"sum\": 1304.3608665466309, \"min\": 1304.3608665466309}}, \"EndTime\": 1577369755.947765, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369754.642656}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1237.27749068 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=21, train loss <loss>=8.21474051943\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:55 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch[0] avg_epoch_loss=8.282650\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=8.2826499939\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch[5] avg_epoch_loss=8.312974\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=8.31297445297\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch [5]#011Speed: 1615.56 samples/sec#011loss=8.312974\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch[10] avg_epoch_loss=8.389588\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=8.48152494431\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch [10]#011Speed: 962.51 samples/sec#011loss=8.481525\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch[15] avg_epoch_loss=8.419108\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=22, batch=15 train loss <loss>=8.48404998779\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch [15]#011Speed: 1810.98 samples/sec#011loss=8.484050\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch[20] avg_epoch_loss=8.399191\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=22, batch=20 train loss <loss>=8.33545789719\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch [20]#011Speed: 974.87 samples/sec#011loss=8.335458\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch[25] avg_epoch_loss=8.356265\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=22, batch=25 train loss <loss>=8.17597637177\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch [25]#011Speed: 2076.95 samples/sec#011loss=8.175976\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch[30] avg_epoch_loss=8.271179\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=22, batch=30 train loss <loss>=7.82872991562\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch [30]#011Speed: 924.23 samples/sec#011loss=7.828730\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch[35] avg_epoch_loss=8.233337\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=22, batch=35 train loss <loss>=7.99871807098\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:56 INFO 140207931545408] Epoch[22] Batch [35]#011Speed: 1892.26 samples/sec#011loss=7.998718\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[22] Batch[40] avg_epoch_loss=8.176573\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=22, batch=40 train loss <loss>=7.76786994934\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[22] Batch [40]#011Speed: 987.78 samples/sec#011loss=7.767870\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[22] Batch[45] avg_epoch_loss=8.167171\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=22, batch=45 train loss <loss>=8.09007225037\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[22] Batch [45]#011Speed: 1990.27 samples/sec#011loss=8.090072\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] processed a total of 1591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1256.8190097808838, \"sum\": 1256.8190097808838, \"min\": 1256.8190097808838}}, \"EndTime\": 1577369757.20518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369755.947835}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1265.75741851 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=22, train loss <loss>=8.14902044296\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[23] Batch[0] avg_epoch_loss=9.187069\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=9.18706893921\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[23] Batch[5] avg_epoch_loss=8.430573\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=8.43057322502\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[23] Batch [5]#011Speed: 1793.86 samples/sec#011loss=8.430573\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[23] Batch[10] avg_epoch_loss=8.505470\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=8.59534549713\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[23] Batch [10]#011Speed: 994.70 samples/sec#011loss=8.595345\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[23] Batch[15] avg_epoch_loss=8.510191\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=23, batch=15 train loss <loss>=8.52057781219\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[23] Batch [15]#011Speed: 1951.84 samples/sec#011loss=8.520578\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[23] Batch[20] avg_epoch_loss=8.440038\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=23, batch=20 train loss <loss>=8.21554880142\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[23] Batch [20]#011Speed: 1094.03 samples/sec#011loss=8.215549\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[23] Batch[25] avg_epoch_loss=8.380188\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=23, batch=25 train loss <loss>=8.12881727219\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:57 INFO 140207931545408] Epoch[23] Batch [25]#011Speed: 2036.14 samples/sec#011loss=8.128817\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[23] Batch[30] avg_epoch_loss=8.269698\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=23, batch=30 train loss <loss>=7.69515113831\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[23] Batch [30]#011Speed: 950.85 samples/sec#011loss=7.695151\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[23] Batch[35] avg_epoch_loss=8.240914\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=23, batch=35 train loss <loss>=8.06245288849\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[23] Batch [35]#011Speed: 1781.62 samples/sec#011loss=8.062453\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[23] Batch[40] avg_epoch_loss=8.249734\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=23, batch=40 train loss <loss>=8.31323947906\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[23] Batch [40]#011Speed: 957.93 samples/sec#011loss=8.313239\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[23] Batch[45] avg_epoch_loss=8.260833\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=23, batch=45 train loss <loss>=8.35184612274\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[23] Batch [45]#011Speed: 1691.64 samples/sec#011loss=8.351846\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] processed a total of 1570 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1248.5179901123047, \"sum\": 1248.5179901123047, \"min\": 1248.5179901123047}}, \"EndTime\": 1577369758.454296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369757.20527}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1257.3761185 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=23, train loss <loss>=8.18457496643\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[24] Batch[0] avg_epoch_loss=8.422683\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=8.42268276215\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[24] Batch[5] avg_epoch_loss=8.135613\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=8.13561336199\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[24] Batch [5]#011Speed: 2111.60 samples/sec#011loss=8.135613\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[24] Batch[10] avg_epoch_loss=8.196610\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=8.26980543137\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[24] Batch [10]#011Speed: 1020.86 samples/sec#011loss=8.269805\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[24] Batch[15] avg_epoch_loss=8.243527\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=24, batch=15 train loss <loss>=8.34674367905\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:58 INFO 140207931545408] Epoch[24] Batch [15]#011Speed: 2066.43 samples/sec#011loss=8.346744\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[24] Batch[20] avg_epoch_loss=8.272082\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=24, batch=20 train loss <loss>=8.36346092224\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[24] Batch [20]#011Speed: 955.56 samples/sec#011loss=8.363461\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[24] Batch[25] avg_epoch_loss=8.257446\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=24, batch=25 train loss <loss>=8.19597444534\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[24] Batch [25]#011Speed: 1734.66 samples/sec#011loss=8.195974\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[24] Batch[30] avg_epoch_loss=8.203707\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=24, batch=30 train loss <loss>=7.9242641449\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[24] Batch [30]#011Speed: 1004.36 samples/sec#011loss=7.924264\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[24] Batch[35] avg_epoch_loss=8.136150\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=24, batch=35 train loss <loss>=7.71729536057\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[24] Batch [35]#011Speed: 1946.57 samples/sec#011loss=7.717295\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[24] Batch[40] avg_epoch_loss=8.118610\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=24, batch=40 train loss <loss>=7.99232063293\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[24] Batch [40]#011Speed: 1021.31 samples/sec#011loss=7.992321\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[24] Batch[45] avg_epoch_loss=8.093963\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=24, batch=45 train loss <loss>=7.89186105728\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[24] Batch [45]#011Speed: 1582.95 samples/sec#011loss=7.891861\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] processed a total of 1554 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1251.600980758667, \"sum\": 1251.600980758667, \"min\": 1251.600980758667}}, \"EndTime\": 1577369759.706495, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369758.454366}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1241.47094634 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=24, train loss <loss>=8.06088197475\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_a6632741-af11-4814-b3af-80cade85d028-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.548995971679688, \"sum\": 11.548995971679688, \"min\": 11.548995971679688}}, \"EndTime\": 1577369759.718731, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369759.706587}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[25] Batch[0] avg_epoch_loss=8.428244\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=8.42824363708\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[25] Batch[5] avg_epoch_loss=8.270763\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=8.27076276143\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:15:59 INFO 140207931545408] Epoch[25] Batch [5]#011Speed: 1689.74 samples/sec#011loss=8.270763\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch[10] avg_epoch_loss=8.327325\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=8.39520015717\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch [10]#011Speed: 915.67 samples/sec#011loss=8.395200\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch[15] avg_epoch_loss=8.475575\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=25, batch=15 train loss <loss>=8.80172576904\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch [15]#011Speed: 1654.64 samples/sec#011loss=8.801726\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch[20] avg_epoch_loss=8.471142\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=25, batch=20 train loss <loss>=8.45695714951\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch [20]#011Speed: 1045.31 samples/sec#011loss=8.456957\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch[25] avg_epoch_loss=8.412057\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=25, batch=25 train loss <loss>=8.16389760971\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch [25]#011Speed: 1966.32 samples/sec#011loss=8.163898\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch[30] avg_epoch_loss=8.344136\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=25, batch=30 train loss <loss>=7.99094591141\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch [30]#011Speed: 949.00 samples/sec#011loss=7.990946\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch[35] avg_epoch_loss=8.294446\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=25, batch=35 train loss <loss>=7.98637046814\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch [35]#011Speed: 1955.44 samples/sec#011loss=7.986370\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch[40] avg_epoch_loss=8.223528\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=25, batch=40 train loss <loss>=7.71292085648\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch [40]#011Speed: 882.93 samples/sec#011loss=7.712921\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch[45] avg_epoch_loss=8.204063\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=25, batch=45 train loss <loss>=8.04444761276\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:00 INFO 140207931545408] Epoch[25] Batch [45]#011Speed: 1892.42 samples/sec#011loss=8.044448\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] processed a total of 1563 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1281.7509174346924, \"sum\": 1281.7509174346924, \"min\": 1281.7509174346924}}, \"EndTime\": 1577369761.000603, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369759.718792}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1219.31727949 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=25, train loss <loss>=8.15781727616\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch[0] avg_epoch_loss=7.645345\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=7.64534521103\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch[5] avg_epoch_loss=8.317494\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=8.31749367714\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch [5]#011Speed: 2016.89 samples/sec#011loss=8.317494\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch[10] avg_epoch_loss=8.377817\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=8.45020542145\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch [10]#011Speed: 881.97 samples/sec#011loss=8.450205\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch[15] avg_epoch_loss=8.482824\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=26, batch=15 train loss <loss>=8.71384029388\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch [15]#011Speed: 1730.74 samples/sec#011loss=8.713840\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch[20] avg_epoch_loss=8.473661\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=26, batch=20 train loss <loss>=8.44433612823\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch [20]#011Speed: 1019.90 samples/sec#011loss=8.444336\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch[25] avg_epoch_loss=8.384176\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=26, batch=25 train loss <loss>=8.00834064484\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch [25]#011Speed: 1944.32 samples/sec#011loss=8.008341\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch[30] avg_epoch_loss=8.314582\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=26, batch=30 train loss <loss>=7.95269393921\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch [30]#011Speed: 1023.84 samples/sec#011loss=7.952694\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch[35] avg_epoch_loss=8.196972\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=26, batch=35 train loss <loss>=7.46779289246\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:01 INFO 140207931545408] Epoch[26] Batch [35]#011Speed: 1819.29 samples/sec#011loss=7.467793\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[26] Batch[40] avg_epoch_loss=8.164939\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=26, batch=40 train loss <loss>=7.93429431915\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[26] Batch [40]#011Speed: 1000.38 samples/sec#011loss=7.934294\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[26] Batch[45] avg_epoch_loss=8.154552\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=26, batch=45 train loss <loss>=8.06938686371\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[26] Batch [45]#011Speed: 1913.54 samples/sec#011loss=8.069387\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[26] Batch[50] avg_epoch_loss=8.162719\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=26, batch=50 train loss <loss>=8.23785409927\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[26] Batch [50]#011Speed: 1351.02 samples/sec#011loss=8.237854\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] processed a total of 1674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1336.411952972412, \"sum\": 1336.411952972412, \"min\": 1336.411952972412}}, \"EndTime\": 1577369762.337561, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369761.000682}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1252.48755872 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=26, train loss <loss>=8.13435601288\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[27] Batch[0] avg_epoch_loss=7.980929\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=7.98092937469\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[27] Batch[5] avg_epoch_loss=8.375975\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=8.37597465515\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[27] Batch [5]#011Speed: 1948.08 samples/sec#011loss=8.375975\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[27] Batch[10] avg_epoch_loss=8.414772\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=8.4613286972\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[27] Batch [10]#011Speed: 925.97 samples/sec#011loss=8.461329\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[27] Batch[15] avg_epoch_loss=8.496373\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=27, batch=15 train loss <loss>=8.67589454651\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[27] Batch [15]#011Speed: 1923.72 samples/sec#011loss=8.675895\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[27] Batch[20] avg_epoch_loss=8.461415\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=27, batch=20 train loss <loss>=8.3495513916\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:02 INFO 140207931545408] Epoch[27] Batch [20]#011Speed: 1003.82 samples/sec#011loss=8.349551\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[27] Batch[25] avg_epoch_loss=8.374934\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=27, batch=25 train loss <loss>=8.0117146492\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[27] Batch [25]#011Speed: 1780.01 samples/sec#011loss=8.011715\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[27] Batch[30] avg_epoch_loss=8.318078\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=27, batch=30 train loss <loss>=8.02242479324\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[27] Batch [30]#011Speed: 924.49 samples/sec#011loss=8.022425\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[27] Batch[35] avg_epoch_loss=8.235675\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=27, batch=35 train loss <loss>=7.7247792244\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[27] Batch [35]#011Speed: 2011.31 samples/sec#011loss=7.724779\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[27] Batch[40] avg_epoch_loss=8.198513\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=27, batch=40 train loss <loss>=7.93094701767\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[27] Batch [40]#011Speed: 1067.11 samples/sec#011loss=7.930947\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[27] Batch[45] avg_epoch_loss=8.158970\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=27, batch=45 train loss <loss>=7.83471689224\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[27] Batch [45]#011Speed: 2054.05 samples/sec#011loss=7.834717\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[27] Batch[50] avg_epoch_loss=8.127220\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=27, batch=50 train loss <loss>=7.83511581421\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[27] Batch [50]#011Speed: 1598.13 samples/sec#011loss=7.835116\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] processed a total of 1662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1282.9759120941162, \"sum\": 1282.9759120941162, \"min\": 1282.9759120941162}}, \"EndTime\": 1577369763.621163, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369762.337648}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1295.28755864 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=27, train loss <loss>=8.10734251829\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[28] Batch[0] avg_epoch_loss=9.257588\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=9.25758838654\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[28] Batch[5] avg_epoch_loss=8.575054\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=8.57505432765\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[28] Batch [5]#011Speed: 1851.06 samples/sec#011loss=8.575054\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[28] Batch[10] avg_epoch_loss=8.544762\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=8.50841083527\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:03 INFO 140207931545408] Epoch[28] Batch [10]#011Speed: 1011.72 samples/sec#011loss=8.508411\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch[15] avg_epoch_loss=8.582278\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=28, batch=15 train loss <loss>=8.66481208801\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch [15]#011Speed: 1533.77 samples/sec#011loss=8.664812\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch[20] avg_epoch_loss=8.564884\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=28, batch=20 train loss <loss>=8.50922584534\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch [20]#011Speed: 1781.84 samples/sec#011loss=8.509226\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch[25] avg_epoch_loss=8.482915\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=28, batch=25 train loss <loss>=8.13864212036\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch [25]#011Speed: 1053.96 samples/sec#011loss=8.138642\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch[30] avg_epoch_loss=8.383123\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=28, batch=30 train loss <loss>=7.86420507431\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch [30]#011Speed: 988.30 samples/sec#011loss=7.864205\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch[35] avg_epoch_loss=8.291389\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=28, batch=35 train loss <loss>=7.72264242172\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch [35]#011Speed: 1662.79 samples/sec#011loss=7.722642\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch[40] avg_epoch_loss=8.269690\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=28, batch=40 train loss <loss>=8.11345434189\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch [40]#011Speed: 964.64 samples/sec#011loss=8.113454\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch[45] avg_epoch_loss=8.270100\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=28, batch=45 train loss <loss>=8.27346019745\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch [45]#011Speed: 1580.82 samples/sec#011loss=8.273460\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch[50] avg_epoch_loss=8.192890\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=28, batch=50 train loss <loss>=7.482558918\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] Epoch[28] Batch [50]#011Speed: 1768.84 samples/sec#011loss=7.482559\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] processed a total of 1613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1299.7231483459473, \"sum\": 1299.7231483459473, \"min\": 1299.7231483459473}}, \"EndTime\": 1577369764.921472, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369763.621254}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1240.92380587 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=28, train loss <loss>=8.19288990544\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:04 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch[0] avg_epoch_loss=8.543505\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=8.54350471497\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch[5] avg_epoch_loss=8.437076\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=8.43707577387\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch [5]#011Speed: 1564.13 samples/sec#011loss=8.437076\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch[10] avg_epoch_loss=8.496170\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=8.56708364487\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch [10]#011Speed: 915.87 samples/sec#011loss=8.567084\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch[15] avg_epoch_loss=8.532811\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=29, batch=15 train loss <loss>=8.61342182159\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch [15]#011Speed: 1810.94 samples/sec#011loss=8.613422\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch[20] avg_epoch_loss=8.494242\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=29, batch=20 train loss <loss>=8.37082023621\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch [20]#011Speed: 1067.11 samples/sec#011loss=8.370820\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch[25] avg_epoch_loss=8.428100\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=29, batch=25 train loss <loss>=8.15030517578\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch [25]#011Speed: 1833.03 samples/sec#011loss=8.150305\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch[30] avg_epoch_loss=8.347810\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=29, batch=30 train loss <loss>=7.9303027153\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch [30]#011Speed: 951.31 samples/sec#011loss=7.930303\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch[35] avg_epoch_loss=8.286351\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=29, batch=35 train loss <loss>=7.90530338287\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:05 INFO 140207931545408] Epoch[29] Batch [35]#011Speed: 1883.40 samples/sec#011loss=7.905303\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[29] Batch[40] avg_epoch_loss=8.239901\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=29, batch=40 train loss <loss>=7.90546350479\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[29] Batch [40]#011Speed: 1044.44 samples/sec#011loss=7.905464\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[29] Batch[45] avg_epoch_loss=8.217481\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=29, batch=45 train loss <loss>=8.03363132477\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[29] Batch [45]#011Speed: 2026.81 samples/sec#011loss=8.033631\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[29] Batch[50] avg_epoch_loss=8.150742\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=29, batch=50 train loss <loss>=7.53674325943\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[29] Batch [50]#011Speed: 1623.44 samples/sec#011loss=7.536743\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] processed a total of 1625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1278.6328792572021, \"sum\": 1278.6328792572021, \"min\": 1278.6328792572021}}, \"EndTime\": 1577369766.200657, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369764.921542}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1270.76329206 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=29, train loss <loss>=8.15074176414\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[30] Batch[0] avg_epoch_loss=8.866780\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=8.86678028107\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[30] Batch[5] avg_epoch_loss=8.513652\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=8.51365152995\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[30] Batch [5]#011Speed: 1867.78 samples/sec#011loss=8.513652\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[30] Batch[10] avg_epoch_loss=8.538699\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=8.56875610352\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[30] Batch [10]#011Speed: 994.76 samples/sec#011loss=8.568756\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[30] Batch[15] avg_epoch_loss=8.603901\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=30, batch=15 train loss <loss>=8.74734401703\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[30] Batch [15]#011Speed: 1742.03 samples/sec#011loss=8.747344\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[30] Batch[20] avg_epoch_loss=8.508262\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=30, batch=20 train loss <loss>=8.20221853256\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[30] Batch [20]#011Speed: 1024.28 samples/sec#011loss=8.202219\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[30] Batch[25] avg_epoch_loss=8.454284\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=30, batch=25 train loss <loss>=8.22757673264\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:06 INFO 140207931545408] Epoch[30] Batch [25]#011Speed: 1959.01 samples/sec#011loss=8.227577\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[30] Batch[30] avg_epoch_loss=8.360467\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=30, batch=30 train loss <loss>=7.87261552811\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[30] Batch [30]#011Speed: 1017.78 samples/sec#011loss=7.872616\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[30] Batch[35] avg_epoch_loss=8.287314\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=30, batch=35 train loss <loss>=7.8337682724\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[30] Batch [35]#011Speed: 1918.35 samples/sec#011loss=7.833768\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[30] Batch[40] avg_epoch_loss=8.219064\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=30, batch=40 train loss <loss>=7.72766160965\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[30] Batch [40]#011Speed: 943.56 samples/sec#011loss=7.727662\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[30] Batch[45] avg_epoch_loss=8.168419\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=30, batch=45 train loss <loss>=7.75312929153\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[30] Batch [45]#011Speed: 1571.42 samples/sec#011loss=7.753129\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[30] Batch[50] avg_epoch_loss=8.161797\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=30, batch=50 train loss <loss>=8.10088033676\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[30] Batch [50]#011Speed: 1247.28 samples/sec#011loss=8.100880\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] processed a total of 1636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1339.0350341796875, \"sum\": 1339.0350341796875, \"min\": 1339.0350341796875}}, \"EndTime\": 1577369767.540214, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369766.200741}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1221.65419396 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=30, train loss <loss>=8.13761161841\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[31] Batch[0] avg_epoch_loss=7.544893\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=7.54489278793\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[31] Batch[5] avg_epoch_loss=8.073905\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=8.07390507062\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[31] Batch [5]#011Speed: 2114.72 samples/sec#011loss=8.073905\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[31] Batch[10] avg_epoch_loss=8.233513\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=8.42504272461\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[31] Batch [10]#011Speed: 898.46 samples/sec#011loss=8.425043\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[31] Batch[15] avg_epoch_loss=8.276320\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=31, batch=15 train loss <loss>=8.37049446106\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:07 INFO 140207931545408] Epoch[31] Batch [15]#011Speed: 2075.01 samples/sec#011loss=8.370494\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[31] Batch[20] avg_epoch_loss=8.299333\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=31, batch=20 train loss <loss>=8.37297430038\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[31] Batch [20]#011Speed: 1017.50 samples/sec#011loss=8.372974\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[31] Batch[25] avg_epoch_loss=8.251917\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=31, batch=25 train loss <loss>=8.05276880264\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[31] Batch [25]#011Speed: 2069.00 samples/sec#011loss=8.052769\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[31] Batch[30] avg_epoch_loss=8.193725\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=31, batch=30 train loss <loss>=7.89113082886\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[31] Batch [30]#011Speed: 976.76 samples/sec#011loss=7.891131\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[31] Batch[35] avg_epoch_loss=8.175651\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=31, batch=35 train loss <loss>=8.06358890533\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[31] Batch [35]#011Speed: 1767.37 samples/sec#011loss=8.063589\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[31] Batch[40] avg_epoch_loss=8.168017\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=31, batch=40 train loss <loss>=8.11305017471\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[31] Batch [40]#011Speed: 1054.00 samples/sec#011loss=8.113050\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[31] Batch[45] avg_epoch_loss=8.134320\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=31, batch=45 train loss <loss>=7.85801076889\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[31] Batch [45]#011Speed: 2153.40 samples/sec#011loss=7.858011\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] processed a total of 1588 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1232.978105545044, \"sum\": 1232.978105545044, \"min\": 1232.978105545044}}, \"EndTime\": 1577369768.77377, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369767.540302}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1287.79459028 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=31, train loss <loss>=8.13208349228\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[32] Batch[0] avg_epoch_loss=8.082336\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=8.08233642578\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[32] Batch[5] avg_epoch_loss=8.490471\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=8.49047072728\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:08 INFO 140207931545408] Epoch[32] Batch [5]#011Speed: 1884.20 samples/sec#011loss=8.490471\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch[10] avg_epoch_loss=8.468392\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=8.44189682007\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch [10]#011Speed: 1736.43 samples/sec#011loss=8.441897\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch[15] avg_epoch_loss=8.494616\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=32, batch=15 train loss <loss>=8.5523103714\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch [15]#011Speed: 1046.46 samples/sec#011loss=8.552310\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch[20] avg_epoch_loss=8.436164\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=32, batch=20 train loss <loss>=8.24911623001\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch [20]#011Speed: 1834.80 samples/sec#011loss=8.249116\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch[25] avg_epoch_loss=8.358872\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=32, batch=25 train loss <loss>=8.03424835205\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch [25]#011Speed: 1030.61 samples/sec#011loss=8.034248\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch[30] avg_epoch_loss=8.301577\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=32, batch=30 train loss <loss>=8.00363798141\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch [30]#011Speed: 2009.85 samples/sec#011loss=8.003638\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch[35] avg_epoch_loss=8.228612\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=32, batch=35 train loss <loss>=7.7762304306\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch [35]#011Speed: 940.23 samples/sec#011loss=7.776230\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch[40] avg_epoch_loss=8.190377\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=32, batch=40 train loss <loss>=7.91508836746\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch [40]#011Speed: 845.68 samples/sec#011loss=7.915088\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch[45] avg_epoch_loss=8.183271\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=32, batch=45 train loss <loss>=8.12499961853\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:09 INFO 140207931545408] Epoch[32] Batch [45]#011Speed: 2017.50 samples/sec#011loss=8.125000\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[32] Batch[50] avg_epoch_loss=8.117176\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=32, batch=50 train loss <loss>=7.50910568237\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[32] Batch [50]#011Speed: 1535.69 samples/sec#011loss=7.509106\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] processed a total of 1627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1303.623914718628, \"sum\": 1303.623914718628, \"min\": 1303.623914718628}}, \"EndTime\": 1577369770.077942, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369768.773865}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1247.93860203 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=32, train loss <loss>=8.11717634575\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch[0] avg_epoch_loss=8.862005\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=8.86200523376\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch[5] avg_epoch_loss=8.442640\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=8.44263982773\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch [5]#011Speed: 1916.10 samples/sec#011loss=8.442640\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch[10] avg_epoch_loss=8.450595\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=8.46014118195\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch [10]#011Speed: 1073.82 samples/sec#011loss=8.460141\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch[15] avg_epoch_loss=8.551767\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=33, batch=15 train loss <loss>=8.77434406281\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch [15]#011Speed: 1877.95 samples/sec#011loss=8.774344\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch[20] avg_epoch_loss=8.502211\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=33, batch=20 train loss <loss>=8.34363203049\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch [20]#011Speed: 921.13 samples/sec#011loss=8.343632\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch[25] avg_epoch_loss=8.416354\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=33, batch=25 train loss <loss>=8.05575408936\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch [25]#011Speed: 1974.53 samples/sec#011loss=8.055754\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch[30] avg_epoch_loss=8.331436\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=33, batch=30 train loss <loss>=7.889864254\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch [30]#011Speed: 1020.12 samples/sec#011loss=7.889864\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch[35] avg_epoch_loss=8.249296\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=33, batch=35 train loss <loss>=7.74002504349\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:10 INFO 140207931545408] Epoch[33] Batch [35]#011Speed: 1972.42 samples/sec#011loss=7.740025\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[33] Batch[40] avg_epoch_loss=8.198619\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=33, batch=40 train loss <loss>=7.83374557495\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[33] Batch [40]#011Speed: 1034.94 samples/sec#011loss=7.833746\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[33] Batch[45] avg_epoch_loss=8.190645\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=33, batch=45 train loss <loss>=8.12526025772\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[33] Batch [45]#011Speed: 2081.40 samples/sec#011loss=8.125260\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[33] Batch[50] avg_epoch_loss=8.168675\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=33, batch=50 train loss <loss>=7.96655378342\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[33] Batch [50]#011Speed: 1890.87 samples/sec#011loss=7.966554\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] processed a total of 1626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1238.1260395050049, \"sum\": 1238.1260395050049, \"min\": 1238.1260395050049}}, \"EndTime\": 1577369771.316579, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369770.078027}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1313.14150845 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=33, train loss <loss>=8.16867530112\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[34] Batch[0] avg_epoch_loss=9.129685\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=9.12968540192\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[34] Batch[5] avg_epoch_loss=8.291118\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=8.29111830393\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[34] Batch [5]#011Speed: 2081.33 samples/sec#011loss=8.291118\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[34] Batch[10] avg_epoch_loss=8.230029\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=8.15672206879\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[34] Batch [10]#011Speed: 1070.81 samples/sec#011loss=8.156722\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[34] Batch[15] avg_epoch_loss=8.323076\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=34, batch=15 train loss <loss>=8.52778015137\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[34] Batch [15]#011Speed: 2057.80 samples/sec#011loss=8.527780\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[34] Batch[20] avg_epoch_loss=8.333950\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=34, batch=20 train loss <loss>=8.36874732971\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[34] Batch [20]#011Speed: 1047.04 samples/sec#011loss=8.368747\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[34] Batch[25] avg_epoch_loss=8.250696\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=34, batch=25 train loss <loss>=7.90102529526\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:11 INFO 140207931545408] Epoch[34] Batch [25]#011Speed: 2008.48 samples/sec#011loss=7.901025\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[34] Batch[30] avg_epoch_loss=8.236158\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=34, batch=30 train loss <loss>=8.16056346893\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[34] Batch [30]#011Speed: 940.28 samples/sec#011loss=8.160563\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[34] Batch[35] avg_epoch_loss=8.169661\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=34, batch=35 train loss <loss>=7.75737533569\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[34] Batch [35]#011Speed: 2070.55 samples/sec#011loss=7.757375\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[34] Batch[40] avg_epoch_loss=8.119608\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=34, batch=40 train loss <loss>=7.75922613144\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[34] Batch [40]#011Speed: 933.35 samples/sec#011loss=7.759226\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[34] Batch[45] avg_epoch_loss=8.134017\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=34, batch=45 train loss <loss>=8.25217704773\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[34] Batch [45]#011Speed: 1965.86 samples/sec#011loss=8.252177\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[34] Batch[50] avg_epoch_loss=8.091342\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=34, batch=50 train loss <loss>=7.69872627258\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[34] Batch [50]#011Speed: 1545.10 samples/sec#011loss=7.698726\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] processed a total of 1657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1254.4329166412354, \"sum\": 1254.4329166412354, \"min\": 1254.4329166412354}}, \"EndTime\": 1577369772.57156, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369771.316664}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1320.76798958 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=34, train loss <loss>=8.04828238487\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_c4229c49-2c3d-4361-b693-686ed3378181-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.843868255615234, \"sum\": 15.843868255615234, \"min\": 15.843868255615234}}, \"EndTime\": 1577369772.588034, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369772.571658}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[35] Batch[0] avg_epoch_loss=8.233494\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=8.23349380493\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[35] Batch[5] avg_epoch_loss=8.068356\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=8.06835611661\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[35] Batch [5]#011Speed: 2054.47 samples/sec#011loss=8.068356\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[35] Batch[10] avg_epoch_loss=8.156558\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=8.2624004364\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:12 INFO 140207931545408] Epoch[35] Batch [10]#011Speed: 1077.18 samples/sec#011loss=8.262400\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch[15] avg_epoch_loss=8.256485\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=35, batch=15 train loss <loss>=8.47632274628\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch [15]#011Speed: 2062.90 samples/sec#011loss=8.476323\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch[20] avg_epoch_loss=8.262965\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=35, batch=20 train loss <loss>=8.28370456696\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch [20]#011Speed: 994.95 samples/sec#011loss=8.283705\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch[25] avg_epoch_loss=8.146334\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=35, batch=25 train loss <loss>=7.65648374557\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch [25]#011Speed: 1639.78 samples/sec#011loss=7.656484\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch[30] avg_epoch_loss=8.084962\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=35, batch=30 train loss <loss>=7.76582517624\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch [30]#011Speed: 932.82 samples/sec#011loss=7.765825\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch[35] avg_epoch_loss=8.053875\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=35, batch=35 train loss <loss>=7.8611328125\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch [35]#011Speed: 1681.70 samples/sec#011loss=7.861133\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch[40] avg_epoch_loss=8.036975\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=35, batch=40 train loss <loss>=7.91530199051\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch [40]#011Speed: 940.84 samples/sec#011loss=7.915302\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch[45] avg_epoch_loss=8.065800\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=35, batch=45 train loss <loss>=8.3021648407\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[35] Batch [45]#011Speed: 1801.22 samples/sec#011loss=8.302165\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] processed a total of 1589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1278.4578800201416, \"sum\": 1278.4578800201416, \"min\": 1278.4578800201416}}, \"EndTime\": 1577369773.86664, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369772.58812}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1242.78223193 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=35, train loss <loss>=8.02358452797\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_1f242fa8-5b30-4c01-bb32-53a5540117b5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.896081924438477, \"sum\": 15.896081924438477, \"min\": 15.896081924438477}}, \"EndTime\": 1577369773.883118, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369773.866727}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] Epoch[36] Batch[0] avg_epoch_loss=8.166484\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=8.16648387909\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch[5] avg_epoch_loss=8.241548\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=8.24154766401\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch [5]#011Speed: 1746.29 samples/sec#011loss=8.241548\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch[10] avg_epoch_loss=8.361328\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=8.50506515503\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch [10]#011Speed: 907.16 samples/sec#011loss=8.505065\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch[15] avg_epoch_loss=8.515538\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=36, batch=15 train loss <loss>=8.85479927063\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch [15]#011Speed: 1900.91 samples/sec#011loss=8.854799\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch[20] avg_epoch_loss=8.527081\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=36, batch=20 train loss <loss>=8.56402015686\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch [20]#011Speed: 951.68 samples/sec#011loss=8.564020\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch[25] avg_epoch_loss=8.495001\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=36, batch=25 train loss <loss>=8.36026325226\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch [25]#011Speed: 1902.04 samples/sec#011loss=8.360263\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch[30] avg_epoch_loss=8.409056\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=36, batch=30 train loss <loss>=7.96214380264\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch [30]#011Speed: 1033.93 samples/sec#011loss=7.962144\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch[35] avg_epoch_loss=8.332585\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=36, batch=35 train loss <loss>=7.85846376419\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:14 INFO 140207931545408] Epoch[36] Batch [35]#011Speed: 1661.99 samples/sec#011loss=7.858464\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[36] Batch[40] avg_epoch_loss=8.281784\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=36, batch=40 train loss <loss>=7.91601963043\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[36] Batch [40]#011Speed: 935.90 samples/sec#011loss=7.916020\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[36] Batch[45] avg_epoch_loss=8.258173\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=36, batch=45 train loss <loss>=8.06455593109\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[36] Batch [45]#011Speed: 1757.12 samples/sec#011loss=8.064556\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[36] Batch[50] avg_epoch_loss=8.228162\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=36, batch=50 train loss <loss>=7.95206279755\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[36] Batch [50]#011Speed: 1602.52 samples/sec#011loss=7.952063\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] processed a total of 1627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1318.3739185333252, \"sum\": 1318.3739185333252, \"min\": 1318.3739185333252}}, \"EndTime\": 1577369775.201609, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369773.883177}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1233.98934602 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=36, train loss <loss>=8.22816185858\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[37] Batch[0] avg_epoch_loss=8.495436\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=8.49543571472\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[37] Batch[5] avg_epoch_loss=8.351189\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=8.35118889809\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[37] Batch [5]#011Speed: 1604.88 samples/sec#011loss=8.351189\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[37] Batch[10] avg_epoch_loss=8.384913\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=8.42538194656\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[37] Batch [10]#011Speed: 979.54 samples/sec#011loss=8.425382\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[37] Batch[15] avg_epoch_loss=8.457354\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=37, batch=15 train loss <loss>=8.61672325134\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[37] Batch [15]#011Speed: 1903.86 samples/sec#011loss=8.616723\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[37] Batch[20] avg_epoch_loss=8.347974\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=37, batch=20 train loss <loss>=7.99795923233\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[37] Batch [20]#011Speed: 1099.26 samples/sec#011loss=7.997959\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[37] Batch[25] avg_epoch_loss=8.274012\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=37, batch=25 train loss <loss>=7.96337127686\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:15 INFO 140207931545408] Epoch[37] Batch [25]#011Speed: 1735.90 samples/sec#011loss=7.963371\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[37] Batch[30] avg_epoch_loss=8.170128\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=37, batch=30 train loss <loss>=7.62993268967\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[37] Batch [30]#011Speed: 1058.73 samples/sec#011loss=7.629933\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[37] Batch[35] avg_epoch_loss=8.122378\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=37, batch=35 train loss <loss>=7.82632980347\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[37] Batch [35]#011Speed: 999.40 samples/sec#011loss=7.826330\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[37] Batch[40] avg_epoch_loss=8.081021\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=37, batch=40 train loss <loss>=7.78324794769\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[37] Batch [40]#011Speed: 2080.24 samples/sec#011loss=7.783248\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[37] Batch[45] avg_epoch_loss=8.059986\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=37, batch=45 train loss <loss>=7.88750009537\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[37] Batch [45]#011Speed: 1594.20 samples/sec#011loss=7.887500\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] processed a total of 1562 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1216.5381908416748, \"sum\": 1216.5381908416748, \"min\": 1216.5381908416748}}, \"EndTime\": 1577369776.41867, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369775.201685}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1283.83533131 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=37, train loss <loss>=8.08704430716\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[38] Batch[0] avg_epoch_loss=8.671981\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=8.67198085785\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[38] Batch[5] avg_epoch_loss=8.282612\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=8.28261248271\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[38] Batch [5]#011Speed: 2104.76 samples/sec#011loss=8.282612\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[38] Batch[10] avg_epoch_loss=8.338811\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=8.40624876022\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[38] Batch [10]#011Speed: 933.52 samples/sec#011loss=8.406249\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[38] Batch[15] avg_epoch_loss=8.420445\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=38, batch=15 train loss <loss>=8.60003890991\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:16 INFO 140207931545408] Epoch[38] Batch [15]#011Speed: 1948.09 samples/sec#011loss=8.600039\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[38] Batch[20] avg_epoch_loss=8.389180\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=38, batch=20 train loss <loss>=8.28913421631\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[38] Batch [20]#011Speed: 941.97 samples/sec#011loss=8.289134\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[38] Batch[25] avg_epoch_loss=8.317333\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=38, batch=25 train loss <loss>=8.01557397842\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[38] Batch [25]#011Speed: 1974.97 samples/sec#011loss=8.015574\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[38] Batch[30] avg_epoch_loss=8.207905\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=38, batch=30 train loss <loss>=7.63888177872\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[38] Batch [30]#011Speed: 1042.21 samples/sec#011loss=7.638882\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[38] Batch[35] avg_epoch_loss=8.127924\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=38, batch=35 train loss <loss>=7.63203830719\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[38] Batch [35]#011Speed: 1733.86 samples/sec#011loss=7.632038\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[38] Batch[40] avg_epoch_loss=8.113271\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=38, batch=40 train loss <loss>=8.00776920319\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[38] Batch [40]#011Speed: 1007.69 samples/sec#011loss=8.007769\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[38] Batch[45] avg_epoch_loss=8.099383\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=38, batch=45 train loss <loss>=7.98550519943\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[38] Batch [45]#011Speed: 1929.45 samples/sec#011loss=7.985505\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] processed a total of 1571 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1235.8758449554443, \"sum\": 1235.8758449554443, \"min\": 1235.8758449554443}}, \"EndTime\": 1577369777.655137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369776.418755}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1271.03038725 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=38, train loss <loss>=8.07031608582\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[39] Batch[0] avg_epoch_loss=8.376488\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=8.37648773193\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[39] Batch[5] avg_epoch_loss=8.212247\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=8.21224673589\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:17 INFO 140207931545408] Epoch[39] Batch [5]#011Speed: 2069.93 samples/sec#011loss=8.212247\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch[10] avg_epoch_loss=8.427152\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=8.68503837585\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch [10]#011Speed: 993.89 samples/sec#011loss=8.685038\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch[15] avg_epoch_loss=8.424380\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=39, batch=15 train loss <loss>=8.41828231812\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch [15]#011Speed: 2090.00 samples/sec#011loss=8.418282\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch[20] avg_epoch_loss=8.432419\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=39, batch=20 train loss <loss>=8.45814161301\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch [20]#011Speed: 950.81 samples/sec#011loss=8.458142\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch[25] avg_epoch_loss=8.330853\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=39, batch=25 train loss <loss>=7.90427951813\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch [25]#011Speed: 2050.52 samples/sec#011loss=7.904280\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch[30] avg_epoch_loss=8.256144\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=39, batch=30 train loss <loss>=7.86765222549\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch [30]#011Speed: 1075.80 samples/sec#011loss=7.867652\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch[35] avg_epoch_loss=8.192288\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=39, batch=35 train loss <loss>=7.79638643265\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch [35]#011Speed: 2072.08 samples/sec#011loss=7.796386\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch[40] avg_epoch_loss=8.163280\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=39, batch=40 train loss <loss>=7.95442295074\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch [40]#011Speed: 962.22 samples/sec#011loss=7.954423\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch[45] avg_epoch_loss=8.111328\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=39, batch=45 train loss <loss>=7.68532209396\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch [45]#011Speed: 2054.10 samples/sec#011loss=7.685322\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch[50] avg_epoch_loss=8.066986\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=39, batch=50 train loss <loss>=7.65903701782\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[39] Batch [50]#011Speed: 1508.18 samples/sec#011loss=7.659037\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] processed a total of 1606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1249.450922012329, \"sum\": 1249.450922012329, \"min\": 1249.450922012329}}, \"EndTime\": 1577369778.905146, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369777.655224}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1285.24002644 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=39, train loss <loss>=8.06698614008\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] Epoch[40] Batch[0] avg_epoch_loss=8.382223\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=8.38222312927\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch[5] avg_epoch_loss=8.129318\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=8.12931847572\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch [5]#011Speed: 2081.50 samples/sec#011loss=8.129318\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch[10] avg_epoch_loss=8.180244\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=8.24135484695\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch [10]#011Speed: 1000.61 samples/sec#011loss=8.241355\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch[15] avg_epoch_loss=8.269344\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=40, batch=15 train loss <loss>=8.46536331177\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch [15]#011Speed: 1999.98 samples/sec#011loss=8.465363\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch[20] avg_epoch_loss=8.287962\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=40, batch=20 train loss <loss>=8.34753856659\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch [20]#011Speed: 873.92 samples/sec#011loss=8.347539\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch[25] avg_epoch_loss=8.228130\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=40, batch=25 train loss <loss>=7.97683563232\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch [25]#011Speed: 1722.39 samples/sec#011loss=7.976836\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch[30] avg_epoch_loss=8.185769\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=40, batch=30 train loss <loss>=7.96549272537\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch [30]#011Speed: 976.25 samples/sec#011loss=7.965493\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch[35] avg_epoch_loss=8.121649\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=40, batch=35 train loss <loss>=7.72410383224\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:19 INFO 140207931545408] Epoch[40] Batch [35]#011Speed: 1613.57 samples/sec#011loss=7.724104\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[40] Batch[40] avg_epoch_loss=8.065294\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=40, batch=40 train loss <loss>=7.65954084396\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[40] Batch [40]#011Speed: 968.32 samples/sec#011loss=7.659541\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[40] Batch[45] avg_epoch_loss=8.055002\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=40, batch=45 train loss <loss>=7.97060747147\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[40] Batch [45]#011Speed: 2163.33 samples/sec#011loss=7.970607\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[40] Batch[50] avg_epoch_loss=7.981017\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=40, batch=50 train loss <loss>=7.30035438538\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[40] Batch [50]#011Speed: 1647.72 samples/sec#011loss=7.300354\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] processed a total of 1612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1282.4139595031738, \"sum\": 1282.4139595031738, \"min\": 1282.4139595031738}}, \"EndTime\": 1577369780.188119, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369778.905224}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1256.87495455 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=40, train loss <loss>=7.98101703793\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_97000e85-9c60-48f1-897e-15e61aff1d8a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.918970108032227, \"sum\": 15.918970108032227, \"min\": 15.918970108032227}}, \"EndTime\": 1577369780.204618, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369780.188208}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[41] Batch[0] avg_epoch_loss=7.741214\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=7.74121427536\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[41] Batch[5] avg_epoch_loss=8.308271\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=8.30827085177\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[41] Batch [5]#011Speed: 2035.70 samples/sec#011loss=8.308271\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[41] Batch[10] avg_epoch_loss=8.301327\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=8.29299354553\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[41] Batch [10]#011Speed: 1101.67 samples/sec#011loss=8.292994\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[41] Batch[15] avg_epoch_loss=8.428737\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=41, batch=15 train loss <loss>=8.70904006958\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[41] Batch [15]#011Speed: 2096.82 samples/sec#011loss=8.709040\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[41] Batch[20] avg_epoch_loss=8.342615\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=41, batch=20 train loss <loss>=8.06702451706\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[41] Batch [20]#011Speed: 1008.41 samples/sec#011loss=8.067025\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[41] Batch[25] avg_epoch_loss=8.283176\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=41, batch=25 train loss <loss>=8.03353347778\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:20 INFO 140207931545408] Epoch[41] Batch [25]#011Speed: 1728.85 samples/sec#011loss=8.033533\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[41] Batch[30] avg_epoch_loss=8.220980\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=41, batch=30 train loss <loss>=7.89755811691\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[41] Batch [30]#011Speed: 1080.96 samples/sec#011loss=7.897558\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[41] Batch[35] avg_epoch_loss=8.130014\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=41, batch=35 train loss <loss>=7.56602249146\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[41] Batch [35]#011Speed: 2171.20 samples/sec#011loss=7.566022\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[41] Batch[40] avg_epoch_loss=8.107908\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=41, batch=40 train loss <loss>=7.94875173569\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[41] Batch [40]#011Speed: 954.72 samples/sec#011loss=7.948752\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[41] Batch[45] avg_epoch_loss=8.080774\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=41, batch=45 train loss <loss>=7.85827074051\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[41] Batch [45]#011Speed: 1880.91 samples/sec#011loss=7.858271\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[41] Batch[50] avg_epoch_loss=8.077396\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=41, batch=50 train loss <loss>=8.04632101059\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[41] Batch [50]#011Speed: 1314.82 samples/sec#011loss=8.046321\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] processed a total of 1655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1279.020071029663, \"sum\": 1279.020071029663, \"min\": 1279.020071029663}}, \"EndTime\": 1577369781.483769, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369780.20468}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1293.83202299 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=41, train loss <loss>=8.10577684182\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[42] Batch[0] avg_epoch_loss=8.792430\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=8.79242992401\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[42] Batch[5] avg_epoch_loss=8.388392\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=8.3883916537\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[42] Batch [5]#011Speed: 1643.18 samples/sec#011loss=8.388392\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[42] Batch[10] avg_epoch_loss=8.306588\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=8.2084233284\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[42] Batch [10]#011Speed: 933.78 samples/sec#011loss=8.208423\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[42] Batch[15] avg_epoch_loss=8.374303\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=42, batch=15 train loss <loss>=8.52327671051\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:21 INFO 140207931545408] Epoch[42] Batch [15]#011Speed: 1929.01 samples/sec#011loss=8.523277\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[42] Batch[20] avg_epoch_loss=8.388042\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=42, batch=20 train loss <loss>=8.43200817108\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[42] Batch [20]#011Speed: 1056.77 samples/sec#011loss=8.432008\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[42] Batch[25] avg_epoch_loss=8.329818\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=42, batch=25 train loss <loss>=8.08527545929\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[42] Batch [25]#011Speed: 2104.33 samples/sec#011loss=8.085275\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[42] Batch[30] avg_epoch_loss=8.256167\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=42, batch=30 train loss <loss>=7.87318334579\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[42] Batch [30]#011Speed: 1108.79 samples/sec#011loss=7.873183\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[42] Batch[35] avg_epoch_loss=8.185192\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=42, batch=35 train loss <loss>=7.74514551163\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[42] Batch [35]#011Speed: 2106.70 samples/sec#011loss=7.745146\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[42] Batch[40] avg_epoch_loss=8.163528\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=42, batch=40 train loss <loss>=8.00754594803\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[42] Batch [40]#011Speed: 1102.84 samples/sec#011loss=8.007546\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[42] Batch[45] avg_epoch_loss=8.164815\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=42, batch=45 train loss <loss>=8.17537155151\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[42] Batch [45]#011Speed: 2098.80 samples/sec#011loss=8.175372\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] processed a total of 1600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1201.509952545166, \"sum\": 1201.509952545166, \"min\": 1201.509952545166}}, \"EndTime\": 1577369782.685865, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369781.483846}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1331.51900299 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=42, train loss <loss>=8.12556351662\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[43] Batch[0] avg_epoch_loss=8.331771\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=8.33177089691\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[43] Batch[5] avg_epoch_loss=8.270016\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=8.27001571655\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:22 INFO 140207931545408] Epoch[43] Batch [5]#011Speed: 2070.23 samples/sec#011loss=8.270016\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch[10] avg_epoch_loss=8.294555\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=8.32400188446\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch [10]#011Speed: 1004.49 samples/sec#011loss=8.324002\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch[15] avg_epoch_loss=8.350258\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=43, batch=15 train loss <loss>=8.47280330658\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch [15]#011Speed: 1649.01 samples/sec#011loss=8.472803\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch[20] avg_epoch_loss=8.358971\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=43, batch=20 train loss <loss>=8.38685398102\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch [20]#011Speed: 916.92 samples/sec#011loss=8.386854\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch[25] avg_epoch_loss=8.254130\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=43, batch=25 train loss <loss>=7.81380004883\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch [25]#011Speed: 1951.48 samples/sec#011loss=7.813800\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch[30] avg_epoch_loss=8.213264\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=43, batch=30 train loss <loss>=8.00075731277\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch [30]#011Speed: 1057.87 samples/sec#011loss=8.000757\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch[35] avg_epoch_loss=8.175441\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=43, batch=35 train loss <loss>=7.94094104767\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch [35]#011Speed: 1891.93 samples/sec#011loss=7.940941\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch[40] avg_epoch_loss=8.153024\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=43, batch=40 train loss <loss>=7.99161739349\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch [40]#011Speed: 948.63 samples/sec#011loss=7.991617\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch[45] avg_epoch_loss=8.147453\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=43, batch=45 train loss <loss>=8.10177783966\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] Epoch[43] Batch [45]#011Speed: 1790.07 samples/sec#011loss=8.101778\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] processed a total of 1594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1276.9598960876465, \"sum\": 1276.9598960876465, \"min\": 1276.9598960876465}}, \"EndTime\": 1577369783.963399, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369782.685955}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1248.17355528 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=43, train loss <loss>=8.11405107498\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:23 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch[0] avg_epoch_loss=8.264307\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=8.26430702209\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch[5] avg_epoch_loss=8.485067\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=8.48506657283\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch [5]#011Speed: 1726.02 samples/sec#011loss=8.485067\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch[10] avg_epoch_loss=8.403668\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=8.30598974228\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch [10]#011Speed: 945.42 samples/sec#011loss=8.305990\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch[15] avg_epoch_loss=8.472895\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=44, batch=15 train loss <loss>=8.6251953125\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch [15]#011Speed: 1655.95 samples/sec#011loss=8.625195\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch[20] avg_epoch_loss=8.481211\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=44, batch=20 train loss <loss>=8.50782079697\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch [20]#011Speed: 979.13 samples/sec#011loss=8.507821\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch[25] avg_epoch_loss=8.387466\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=44, batch=25 train loss <loss>=7.99373931885\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch [25]#011Speed: 2144.92 samples/sec#011loss=7.993739\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch[30] avg_epoch_loss=8.329499\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=44, batch=30 train loss <loss>=8.02807121277\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch [30]#011Speed: 917.02 samples/sec#011loss=8.028071\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch[35] avg_epoch_loss=8.260871\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=44, batch=35 train loss <loss>=7.8353770256\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:24 INFO 140207931545408] Epoch[44] Batch [35]#011Speed: 1622.35 samples/sec#011loss=7.835377\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[44] Batch[40] avg_epoch_loss=8.233047\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=44, batch=40 train loss <loss>=8.03271312714\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[44] Batch [40]#011Speed: 994.06 samples/sec#011loss=8.032713\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[44] Batch[45] avg_epoch_loss=8.207571\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=44, batch=45 train loss <loss>=7.99866914749\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[44] Batch [45]#011Speed: 2156.13 samples/sec#011loss=7.998669\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] processed a total of 1599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1291.5229797363281, \"sum\": 1291.5229797363281, \"min\": 1291.5229797363281}}, \"EndTime\": 1577369785.255479, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369783.963465}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1237.93997774 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=44, train loss <loss>=8.13584415436\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[45] Batch[0] avg_epoch_loss=8.023816\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=8.0238161087\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[45] Batch[5] avg_epoch_loss=8.298670\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=8.29867045085\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[45] Batch [5]#011Speed: 2053.63 samples/sec#011loss=8.298670\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[45] Batch[10] avg_epoch_loss=8.409044\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=8.5414932251\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[45] Batch [10]#011Speed: 1017.79 samples/sec#011loss=8.541493\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[45] Batch[15] avg_epoch_loss=8.444766\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=45, batch=15 train loss <loss>=8.52335472107\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[45] Batch [15]#011Speed: 2091.73 samples/sec#011loss=8.523355\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[45] Batch[20] avg_epoch_loss=8.440854\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=45, batch=20 train loss <loss>=8.42833385468\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[45] Batch [20]#011Speed: 1080.83 samples/sec#011loss=8.428334\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[45] Batch[25] avg_epoch_loss=8.395673\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=45, batch=25 train loss <loss>=8.20591220856\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:25 INFO 140207931545408] Epoch[45] Batch [25]#011Speed: 2101.47 samples/sec#011loss=8.205912\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[45] Batch[30] avg_epoch_loss=8.270084\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=45, batch=30 train loss <loss>=7.6170249939\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[45] Batch [30]#011Speed: 963.46 samples/sec#011loss=7.617025\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[45] Batch[35] avg_epoch_loss=8.202219\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=45, batch=35 train loss <loss>=7.78145027161\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[45] Batch [35]#011Speed: 2040.63 samples/sec#011loss=7.781450\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[45] Batch[40] avg_epoch_loss=8.196659\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=45, batch=40 train loss <loss>=8.15662612915\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[45] Batch [40]#011Speed: 1005.30 samples/sec#011loss=8.156626\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[45] Batch[45] avg_epoch_loss=8.188633\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=45, batch=45 train loss <loss>=8.12282276154\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[45] Batch [45]#011Speed: 2175.36 samples/sec#011loss=8.122823\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] processed a total of 1584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1206.9251537322998, \"sum\": 1206.9251537322998, \"min\": 1206.9251537322998}}, \"EndTime\": 1577369786.462954, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369785.255574}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1312.2816483 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=45, train loss <loss>=8.18756868362\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[46] Batch[0] avg_epoch_loss=8.179329\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=8.17932891846\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[46] Batch[5] avg_epoch_loss=8.241466\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=8.24146572749\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[46] Batch [5]#011Speed: 2030.80 samples/sec#011loss=8.241466\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[46] Batch[10] avg_epoch_loss=8.334055\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=8.4451625824\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[46] Batch [10]#011Speed: 1017.09 samples/sec#011loss=8.445163\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[46] Batch[15] avg_epoch_loss=8.406296\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=46, batch=15 train loss <loss>=8.56522655487\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:26 INFO 140207931545408] Epoch[46] Batch [15]#011Speed: 1843.89 samples/sec#011loss=8.565227\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch[20] avg_epoch_loss=8.427078\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=46, batch=20 train loss <loss>=8.49357948303\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch [20]#011Speed: 1016.56 samples/sec#011loss=8.493579\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch[25] avg_epoch_loss=8.377998\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=46, batch=25 train loss <loss>=8.17186059952\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch [25]#011Speed: 1933.86 samples/sec#011loss=8.171861\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch[30] avg_epoch_loss=8.283691\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=46, batch=30 train loss <loss>=7.79329786301\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch [30]#011Speed: 943.91 samples/sec#011loss=7.793298\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch[35] avg_epoch_loss=8.198370\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=46, batch=35 train loss <loss>=7.6693780899\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch [35]#011Speed: 1665.39 samples/sec#011loss=7.669378\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch[40] avg_epoch_loss=8.151569\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=46, batch=40 train loss <loss>=7.81460466385\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch [40]#011Speed: 952.23 samples/sec#011loss=7.814605\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch[45] avg_epoch_loss=8.141584\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=46, batch=45 train loss <loss>=8.0597070694\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch [45]#011Speed: 1691.01 samples/sec#011loss=8.059707\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch[50] avg_epoch_loss=8.103485\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=46, batch=50 train loss <loss>=7.75297060013\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[46] Batch [50]#011Speed: 1448.28 samples/sec#011loss=7.752971\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] processed a total of 1644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1318.5639381408691, \"sum\": 1318.5639381408691, \"min\": 1318.5639381408691}}, \"EndTime\": 1577369787.782094, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369786.463042}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1246.67370256 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=46, train loss <loss>=8.09239088572\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[47] Batch[0] avg_epoch_loss=8.306189\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=8.30618858337\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[47] Batch[5] avg_epoch_loss=8.295044\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=8.2950442632\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:27 INFO 140207931545408] Epoch[47] Batch [5]#011Speed: 1643.84 samples/sec#011loss=8.295044\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch[10] avg_epoch_loss=8.195537\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=8.07612733841\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch [10]#011Speed: 1025.90 samples/sec#011loss=8.076127\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch[15] avg_epoch_loss=8.253044\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=47, batch=15 train loss <loss>=8.37956171036\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch [15]#011Speed: 1863.70 samples/sec#011loss=8.379562\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch[20] avg_epoch_loss=8.243915\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=47, batch=20 train loss <loss>=8.21469926834\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch [20]#011Speed: 944.41 samples/sec#011loss=8.214699\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch[25] avg_epoch_loss=8.206562\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=47, batch=25 train loss <loss>=8.04968271255\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch [25]#011Speed: 1979.12 samples/sec#011loss=8.049683\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch[30] avg_epoch_loss=8.149609\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=47, batch=30 train loss <loss>=7.85345335007\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch [30]#011Speed: 937.21 samples/sec#011loss=7.853453\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch[35] avg_epoch_loss=8.106825\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=47, batch=35 train loss <loss>=7.84156455994\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch [35]#011Speed: 2147.57 samples/sec#011loss=7.841565\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch[40] avg_epoch_loss=8.110268\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=47, batch=40 train loss <loss>=8.13505430222\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch [40]#011Speed: 950.57 samples/sec#011loss=8.135054\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch[45] avg_epoch_loss=8.119834\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=47, batch=45 train loss <loss>=8.19827899933\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:28 INFO 140207931545408] Epoch[47] Batch [45]#011Speed: 1907.37 samples/sec#011loss=8.198279\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] processed a total of 1565 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1250.6968975067139, \"sum\": 1250.6968975067139, \"min\": 1250.6968975067139}}, \"EndTime\": 1577369789.033396, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369787.782192}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1251.1611802 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=47, train loss <loss>=8.06819786344\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch[0] avg_epoch_loss=8.189933\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=8.18993282318\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch[5] avg_epoch_loss=8.299820\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=8.29982042313\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch [5]#011Speed: 1822.22 samples/sec#011loss=8.299820\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch[10] avg_epoch_loss=8.410889\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=8.54417219162\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch [10]#011Speed: 962.47 samples/sec#011loss=8.544172\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch[15] avg_epoch_loss=8.403744\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=48, batch=15 train loss <loss>=8.38802452087\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch [15]#011Speed: 2024.03 samples/sec#011loss=8.388025\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch[20] avg_epoch_loss=8.386757\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=48, batch=20 train loss <loss>=8.33239612579\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch [20]#011Speed: 1083.69 samples/sec#011loss=8.332396\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch[25] avg_epoch_loss=8.294064\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=48, batch=25 train loss <loss>=7.90475654602\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch [25]#011Speed: 2030.87 samples/sec#011loss=7.904757\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch[30] avg_epoch_loss=8.196361\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=48, batch=30 train loss <loss>=7.68830699921\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch [30]#011Speed: 1000.68 samples/sec#011loss=7.688307\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch[35] avg_epoch_loss=8.125539\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=48, batch=35 train loss <loss>=7.68644065857\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:29 INFO 140207931545408] Epoch[48] Batch [35]#011Speed: 1862.66 samples/sec#011loss=7.686441\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[48] Batch[40] avg_epoch_loss=8.090405\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=48, batch=40 train loss <loss>=7.83743934631\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[48] Batch [40]#011Speed: 1010.91 samples/sec#011loss=7.837439\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[48] Batch[45] avg_epoch_loss=8.093269\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=48, batch=45 train loss <loss>=8.11675786972\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[48] Batch [45]#011Speed: 2031.54 samples/sec#011loss=8.116758\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] processed a total of 1539 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1202.5179862976074, \"sum\": 1202.5179862976074, \"min\": 1202.5179862976074}}, \"EndTime\": 1577369790.236445, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369789.033482}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1279.67600796 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=48, train loss <loss>=8.04905380522\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[49] Batch[0] avg_epoch_loss=8.479920\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=8.47992038727\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[49] Batch[5] avg_epoch_loss=8.244054\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=8.24405384064\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[49] Batch [5]#011Speed: 2045.72 samples/sec#011loss=8.244054\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[49] Batch[10] avg_epoch_loss=8.274416\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=8.31085014343\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[49] Batch [10]#011Speed: 918.95 samples/sec#011loss=8.310850\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[49] Batch[15] avg_epoch_loss=8.329520\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=49, batch=15 train loss <loss>=8.45074882507\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[49] Batch [15]#011Speed: 2044.70 samples/sec#011loss=8.450749\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[49] Batch[20] avg_epoch_loss=8.307933\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=49, batch=20 train loss <loss>=8.23885707855\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[49] Batch [20]#011Speed: 923.26 samples/sec#011loss=8.238857\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[49] Batch[25] avg_epoch_loss=8.252760\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=49, batch=25 train loss <loss>=8.02103252411\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:30 INFO 140207931545408] Epoch[49] Batch [25]#011Speed: 2135.76 samples/sec#011loss=8.021033\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[49] Batch[30] avg_epoch_loss=8.201389\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=49, batch=30 train loss <loss>=7.9342587471\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[49] Batch [30]#011Speed: 1075.69 samples/sec#011loss=7.934259\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[49] Batch[35] avg_epoch_loss=8.150996\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=49, batch=35 train loss <loss>=7.83855819702\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[49] Batch [35]#011Speed: 1775.69 samples/sec#011loss=7.838558\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[49] Batch[40] avg_epoch_loss=8.120454\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=49, batch=40 train loss <loss>=7.90055131912\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[49] Batch [40]#011Speed: 917.96 samples/sec#011loss=7.900551\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[49] Batch[45] avg_epoch_loss=8.096534\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=49, batch=45 train loss <loss>=7.90038824081\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[49] Batch [45]#011Speed: 2144.23 samples/sec#011loss=7.900388\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[49] Batch[50] avg_epoch_loss=8.053583\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=49, batch=50 train loss <loss>=7.65843696594\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[49] Batch [50]#011Speed: 1645.56 samples/sec#011loss=7.658437\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] processed a total of 1606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1262.0420455932617, \"sum\": 1262.0420455932617, \"min\": 1262.0420455932617}}, \"EndTime\": 1577369791.499064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369790.236528}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1272.41196209 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=49, train loss <loss>=8.0535830049\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[50] Batch[0] avg_epoch_loss=8.223364\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=8.22336387634\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[50] Batch[5] avg_epoch_loss=8.337735\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=8.3377345403\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[50] Batch [5]#011Speed: 1728.78 samples/sec#011loss=8.337735\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[50] Batch[10] avg_epoch_loss=8.279500\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=8.20961780548\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[50] Batch [10]#011Speed: 966.78 samples/sec#011loss=8.209618\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[50] Batch[15] avg_epoch_loss=8.270649\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=50, batch=15 train loss <loss>=8.25117797852\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:31 INFO 140207931545408] Epoch[50] Batch [15]#011Speed: 1892.98 samples/sec#011loss=8.251178\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch[20] avg_epoch_loss=8.266832\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=50, batch=20 train loss <loss>=8.25461788177\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch [20]#011Speed: 982.78 samples/sec#011loss=8.254618\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch[25] avg_epoch_loss=8.200926\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=50, batch=25 train loss <loss>=7.92412099838\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch [25]#011Speed: 1916.95 samples/sec#011loss=7.924121\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch[30] avg_epoch_loss=8.136484\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=50, batch=30 train loss <loss>=7.8013874054\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch [30]#011Speed: 942.39 samples/sec#011loss=7.801387\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch[35] avg_epoch_loss=8.111670\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=50, batch=35 train loss <loss>=7.95782270432\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch [35]#011Speed: 2059.97 samples/sec#011loss=7.957823\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch[40] avg_epoch_loss=8.080058\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=50, batch=40 train loss <loss>=7.85244750977\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch [40]#011Speed: 964.12 samples/sec#011loss=7.852448\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch[45] avg_epoch_loss=8.111645\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=50, batch=45 train loss <loss>=8.3706615448\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch [45]#011Speed: 2096.41 samples/sec#011loss=8.370662\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch[50] avg_epoch_loss=8.080973\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=50, batch=50 train loss <loss>=7.79878873825\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[50] Batch [50]#011Speed: 1824.98 samples/sec#011loss=7.798789\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] processed a total of 1659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1275.7568359375, \"sum\": 1275.7568359375, \"min\": 1275.7568359375}}, \"EndTime\": 1577369792.775324, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369791.499151}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1300.27090466 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=50, train loss <loss>=8.05513729499\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[51] Batch[0] avg_epoch_loss=8.282931\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=8.28293132782\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[51] Batch[5] avg_epoch_loss=8.026646\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=8.02664550145\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:32 INFO 140207931545408] Epoch[51] Batch [5]#011Speed: 1932.74 samples/sec#011loss=8.026646\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch[10] avg_epoch_loss=8.180438\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=8.36499004364\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch [10]#011Speed: 1014.27 samples/sec#011loss=8.364990\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch[15] avg_epoch_loss=8.298691\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=51, batch=15 train loss <loss>=8.55884723663\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch [15]#011Speed: 2096.08 samples/sec#011loss=8.558847\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch[20] avg_epoch_loss=8.309111\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=51, batch=20 train loss <loss>=8.34245481491\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch [20]#011Speed: 1004.42 samples/sec#011loss=8.342455\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch[25] avg_epoch_loss=8.245086\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=51, batch=25 train loss <loss>=7.97618141174\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch [25]#011Speed: 1635.04 samples/sec#011loss=7.976181\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch[30] avg_epoch_loss=8.179213\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=51, batch=30 train loss <loss>=7.83667154312\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch [30]#011Speed: 962.90 samples/sec#011loss=7.836672\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch[35] avg_epoch_loss=8.100442\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=51, batch=35 train loss <loss>=7.612063694\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch [35]#011Speed: 2004.13 samples/sec#011loss=7.612064\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch[40] avg_epoch_loss=8.084623\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=51, batch=40 train loss <loss>=7.97072649002\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch [40]#011Speed: 997.25 samples/sec#011loss=7.970726\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch[45] avg_epoch_loss=8.057598\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=51, batch=45 train loss <loss>=7.83599624634\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:33 INFO 140207931545408] Epoch[51] Batch [45]#011Speed: 1893.40 samples/sec#011loss=7.835996\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] processed a total of 1596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1248.2500076293945, \"sum\": 1248.2500076293945, \"min\": 1248.2500076293945}}, \"EndTime\": 1577369794.024192, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369792.775419}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1278.45571486 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=51, train loss <loss>=8.01211693764\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch[0] avg_epoch_loss=7.740666\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=7.74066591263\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch[5] avg_epoch_loss=7.923125\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=7.92312510808\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch [5]#011Speed: 1949.84 samples/sec#011loss=7.923125\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch[10] avg_epoch_loss=8.095735\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=8.3028673172\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch [10]#011Speed: 1053.91 samples/sec#011loss=8.302867\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch[15] avg_epoch_loss=8.214670\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=52, batch=15 train loss <loss>=8.47632637024\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch [15]#011Speed: 1634.07 samples/sec#011loss=8.476326\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch[20] avg_epoch_loss=8.214934\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=52, batch=20 train loss <loss>=8.21577692032\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch [20]#011Speed: 968.83 samples/sec#011loss=8.215777\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch[25] avg_epoch_loss=8.133138\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=52, batch=25 train loss <loss>=7.78959932327\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch [25]#011Speed: 2138.18 samples/sec#011loss=7.789599\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch[30] avg_epoch_loss=8.092340\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=52, batch=30 train loss <loss>=7.88019075394\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch [30]#011Speed: 912.48 samples/sec#011loss=7.880191\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch[35] avg_epoch_loss=8.080281\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=52, batch=35 train loss <loss>=8.0055109024\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:34 INFO 140207931545408] Epoch[52] Batch [35]#011Speed: 1606.23 samples/sec#011loss=8.005511\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[52] Batch[40] avg_epoch_loss=8.076150\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=52, batch=40 train loss <loss>=8.0464094162\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[52] Batch [40]#011Speed: 940.05 samples/sec#011loss=8.046409\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[52] Batch[45] avg_epoch_loss=8.038138\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=52, batch=45 train loss <loss>=7.72643890381\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[52] Batch [45]#011Speed: 1999.23 samples/sec#011loss=7.726439\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[52] Batch[50] avg_epoch_loss=7.939333\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=52, batch=50 train loss <loss>=7.03032207489\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[52] Batch [50]#011Speed: 1440.48 samples/sec#011loss=7.030322\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] processed a total of 1602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1306.6179752349854, \"sum\": 1306.6179752349854, \"min\": 1306.6179752349854}}, \"EndTime\": 1577369795.331359, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369794.024279}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1225.95156203 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=52, train loss <loss>=7.93933256\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_fdb39aaf-085c-4e30-a114-e3a363fc8e42-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.55288314819336, \"sum\": 10.55288314819336, \"min\": 10.55288314819336}}, \"EndTime\": 1577369795.342532, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369795.33144}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[53] Batch[0] avg_epoch_loss=8.778451\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=8.77845096588\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[53] Batch[5] avg_epoch_loss=8.400346\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=8.40034596125\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[53] Batch [5]#011Speed: 1818.80 samples/sec#011loss=8.400346\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[53] Batch[10] avg_epoch_loss=8.259310\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=8.09006643295\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[53] Batch [10]#011Speed: 1024.49 samples/sec#011loss=8.090066\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[53] Batch[15] avg_epoch_loss=8.348841\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=53, batch=15 train loss <loss>=8.54580879211\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[53] Batch [15]#011Speed: 1813.07 samples/sec#011loss=8.545809\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[53] Batch[20] avg_epoch_loss=8.339822\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=53, batch=20 train loss <loss>=8.3109623909\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:35 INFO 140207931545408] Epoch[53] Batch [20]#011Speed: 1048.19 samples/sec#011loss=8.310962\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[53] Batch[25] avg_epoch_loss=8.232524\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=53, batch=25 train loss <loss>=7.7818734169\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[53] Batch [25]#011Speed: 2084.04 samples/sec#011loss=7.781873\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[53] Batch[30] avg_epoch_loss=8.167872\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=53, batch=30 train loss <loss>=7.83168325424\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[53] Batch [30]#011Speed: 921.40 samples/sec#011loss=7.831683\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[53] Batch[35] avg_epoch_loss=8.102991\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=53, batch=35 train loss <loss>=7.70072851181\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[53] Batch [35]#011Speed: 1926.69 samples/sec#011loss=7.700729\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[53] Batch[40] avg_epoch_loss=8.083988\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=53, batch=40 train loss <loss>=7.94716215134\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[53] Batch [40]#011Speed: 971.39 samples/sec#011loss=7.947162\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[53] Batch[45] avg_epoch_loss=8.071859\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=53, batch=45 train loss <loss>=7.97240304947\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[53] Batch [45]#011Speed: 2069.00 samples/sec#011loss=7.972403\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[53] Batch[50] avg_epoch_loss=8.049217\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=53, batch=50 train loss <loss>=7.84090690613\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[53] Batch [50]#011Speed: 1854.02 samples/sec#011loss=7.840907\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] processed a total of 1635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1261.6770267486572, \"sum\": 1261.6770267486572, \"min\": 1261.6770267486572}}, \"EndTime\": 1577369796.604328, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369795.342588}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1295.75883955 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=53, train loss <loss>=7.97242358098\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[54] Batch[0] avg_epoch_loss=8.232134\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=8.23213386536\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[54] Batch[5] avg_epoch_loss=8.283102\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=8.283102115\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[54] Batch [5]#011Speed: 2078.81 samples/sec#011loss=8.283102\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[54] Batch[10] avg_epoch_loss=8.234180\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=8.17547369003\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:36 INFO 140207931545408] Epoch[54] Batch [10]#011Speed: 995.33 samples/sec#011loss=8.175474\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch[15] avg_epoch_loss=8.260239\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=54, batch=15 train loss <loss>=8.31756725311\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch [15]#011Speed: 2089.02 samples/sec#011loss=8.317567\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch[20] avg_epoch_loss=8.277498\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=54, batch=20 train loss <loss>=8.33272686005\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch [20]#011Speed: 1027.80 samples/sec#011loss=8.332727\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch[25] avg_epoch_loss=8.211374\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=54, batch=25 train loss <loss>=7.93365678787\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch [25]#011Speed: 1658.34 samples/sec#011loss=7.933657\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch[30] avg_epoch_loss=8.178332\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=54, batch=30 train loss <loss>=8.00651187897\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch [30]#011Speed: 882.20 samples/sec#011loss=8.006512\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch[35] avg_epoch_loss=8.148090\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=54, batch=35 train loss <loss>=7.96059236526\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch [35]#011Speed: 1073.75 samples/sec#011loss=7.960592\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch[40] avg_epoch_loss=8.128863\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=54, batch=40 train loss <loss>=7.99042625427\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch [40]#011Speed: 2130.18 samples/sec#011loss=7.990426\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch[45] avg_epoch_loss=8.073704\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=54, batch=45 train loss <loss>=7.62139873505\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[54] Batch [45]#011Speed: 1539.84 samples/sec#011loss=7.621399\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] processed a total of 1479 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1191.4279460906982, \"sum\": 1191.4279460906982, \"min\": 1191.4279460906982}}, \"EndTime\": 1577369797.796339, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369796.604421}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1241.22771778 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=54, train loss <loss>=8.12588178351\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] Epoch[55] Batch[0] avg_epoch_loss=8.998355\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=8.9983549118\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch[5] avg_epoch_loss=8.400764\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=8.40076351166\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch [5]#011Speed: 1550.88 samples/sec#011loss=8.400764\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch[10] avg_epoch_loss=8.275866\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=8.12598991394\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch [10]#011Speed: 922.13 samples/sec#011loss=8.125990\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch[15] avg_epoch_loss=8.316755\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=55, batch=15 train loss <loss>=8.40670871735\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch [15]#011Speed: 1908.46 samples/sec#011loss=8.406709\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch[20] avg_epoch_loss=8.356489\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=55, batch=20 train loss <loss>=8.48364009857\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch [20]#011Speed: 1089.59 samples/sec#011loss=8.483640\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch[25] avg_epoch_loss=8.304079\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=55, batch=25 train loss <loss>=8.08395652771\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch [25]#011Speed: 1500.44 samples/sec#011loss=8.083957\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch[30] avg_epoch_loss=8.226977\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=55, batch=30 train loss <loss>=7.82604455948\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch [30]#011Speed: 980.82 samples/sec#011loss=7.826045\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch[35] avg_epoch_loss=8.159804\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=55, batch=35 train loss <loss>=7.74333410263\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch [35]#011Speed: 1999.05 samples/sec#011loss=7.743334\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch[40] avg_epoch_loss=8.101014\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=55, batch=40 train loss <loss>=7.67772655487\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch [40]#011Speed: 1019.57 samples/sec#011loss=7.677727\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch[45] avg_epoch_loss=8.033762\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=55, batch=45 train loss <loss>=7.48229589462\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:38 INFO 140207931545408] Epoch[55] Batch [45]#011Speed: 2040.40 samples/sec#011loss=7.482296\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[55] Batch[50] avg_epoch_loss=8.021668\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=55, batch=50 train loss <loss>=7.91039791107\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[55] Batch [50]#011Speed: 1342.08 samples/sec#011loss=7.910398\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] processed a total of 1627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1322.5688934326172, \"sum\": 1322.5688934326172, \"min\": 1322.5688934326172}}, \"EndTime\": 1577369799.119469, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369797.796429}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1230.05682197 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=55, train loss <loss>=8.02166769551\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch[0] avg_epoch_loss=8.476860\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=8.47686004639\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch[5] avg_epoch_loss=8.329757\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=8.32975713412\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch [5]#011Speed: 2070.42 samples/sec#011loss=8.329757\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch[10] avg_epoch_loss=8.324069\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=8.31724433899\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch [10]#011Speed: 1944.55 samples/sec#011loss=8.317244\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch[15] avg_epoch_loss=8.403343\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=56, batch=15 train loss <loss>=8.57774543762\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch [15]#011Speed: 953.81 samples/sec#011loss=8.577745\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch[20] avg_epoch_loss=8.460768\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=56, batch=20 train loss <loss>=8.64452781677\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch [20]#011Speed: 1015.52 samples/sec#011loss=8.644528\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch[25] avg_epoch_loss=8.360490\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=56, batch=25 train loss <loss>=7.93932027817\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch [25]#011Speed: 1608.17 samples/sec#011loss=7.939320\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch[30] avg_epoch_loss=8.292034\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=56, batch=30 train loss <loss>=7.93606204987\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:39 INFO 140207931545408] Epoch[56] Batch [30]#011Speed: 976.99 samples/sec#011loss=7.936062\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[56] Batch[35] avg_epoch_loss=8.254980\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=56, batch=35 train loss <loss>=8.02524757385\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[56] Batch [35]#011Speed: 1568.12 samples/sec#011loss=8.025248\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[56] Batch[40] avg_epoch_loss=8.214163\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=56, batch=40 train loss <loss>=7.92027931213\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[56] Batch [40]#011Speed: 989.92 samples/sec#011loss=7.920279\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[56] Batch[45] avg_epoch_loss=8.190207\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=56, batch=45 train loss <loss>=7.99376754761\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[56] Batch [45]#011Speed: 2037.78 samples/sec#011loss=7.993768\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[56] Batch[50] avg_epoch_loss=8.151994\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=56, batch=50 train loss <loss>=7.8004327774\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[56] Batch [50]#011Speed: 1858.52 samples/sec#011loss=7.800433\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] processed a total of 1659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1300.1399040222168, \"sum\": 1300.1399040222168, \"min\": 1300.1399040222168}}, \"EndTime\": 1577369800.420166, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369799.119558}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1275.90468346 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=56, train loss <loss>=8.13310874425\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[57] Batch[0] avg_epoch_loss=8.280517\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=8.28051662445\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[57] Batch[5] avg_epoch_loss=8.233704\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=8.23370361328\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[57] Batch [5]#011Speed: 1598.88 samples/sec#011loss=8.233704\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[57] Batch[10] avg_epoch_loss=8.142111\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=8.03219966888\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[57] Batch [10]#011Speed: 949.31 samples/sec#011loss=8.032200\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[57] Batch[15] avg_epoch_loss=8.286783\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=57, batch=15 train loss <loss>=8.60506038666\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:40 INFO 140207931545408] Epoch[57] Batch [15]#011Speed: 1758.90 samples/sec#011loss=8.605060\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[57] Batch[20] avg_epoch_loss=8.300209\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=57, batch=20 train loss <loss>=8.34317245483\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[57] Batch [20]#011Speed: 953.04 samples/sec#011loss=8.343172\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[57] Batch[25] avg_epoch_loss=8.198278\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=57, batch=25 train loss <loss>=7.77017059326\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[57] Batch [25]#011Speed: 1727.81 samples/sec#011loss=7.770171\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[57] Batch[30] avg_epoch_loss=8.134034\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=57, batch=30 train loss <loss>=7.79996109009\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[57] Batch [30]#011Speed: 975.99 samples/sec#011loss=7.799961\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[57] Batch[35] avg_epoch_loss=8.080680\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=57, batch=35 train loss <loss>=7.74988861084\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[57] Batch [35]#011Speed: 2027.96 samples/sec#011loss=7.749889\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[57] Batch[40] avg_epoch_loss=8.086342\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=57, batch=40 train loss <loss>=8.1271068573\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[57] Batch [40]#011Speed: 990.25 samples/sec#011loss=8.127107\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[57] Batch[45] avg_epoch_loss=8.085569\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=57, batch=45 train loss <loss>=8.07923345566\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[57] Batch [45]#011Speed: 2158.60 samples/sec#011loss=8.079233\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] processed a total of 1578 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1281.5029621124268, \"sum\": 1281.5029621124268, \"min\": 1281.5029621124268}}, \"EndTime\": 1577369801.702216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369800.420238}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1231.24065554 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=57, train loss <loss>=8.08247081757\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[58] Batch[0] avg_epoch_loss=8.342447\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=8.34244728088\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[58] Batch[5] avg_epoch_loss=8.359481\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=8.35948085785\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:41 INFO 140207931545408] Epoch[58] Batch [5]#011Speed: 1936.23 samples/sec#011loss=8.359481\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch[10] avg_epoch_loss=8.354003\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=8.34743003845\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch [10]#011Speed: 935.08 samples/sec#011loss=8.347430\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch[15] avg_epoch_loss=8.428091\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=58, batch=15 train loss <loss>=8.59108295441\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch [15]#011Speed: 1645.83 samples/sec#011loss=8.591083\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch[20] avg_epoch_loss=8.396872\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=58, batch=20 train loss <loss>=8.29697036743\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch [20]#011Speed: 939.82 samples/sec#011loss=8.296970\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch[25] avg_epoch_loss=8.326339\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=58, batch=25 train loss <loss>=8.03010120392\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch [25]#011Speed: 1810.73 samples/sec#011loss=8.030101\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch[30] avg_epoch_loss=8.276643\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=58, batch=30 train loss <loss>=8.01822786331\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch [30]#011Speed: 965.51 samples/sec#011loss=8.018228\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch[35] avg_epoch_loss=8.204493\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=58, batch=35 train loss <loss>=7.7571600914\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch [35]#011Speed: 1783.03 samples/sec#011loss=7.757160\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch[40] avg_epoch_loss=8.156080\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=58, batch=40 train loss <loss>=7.8075091362\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch [40]#011Speed: 957.77 samples/sec#011loss=7.807509\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch[45] avg_epoch_loss=8.148883\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=58, batch=45 train loss <loss>=8.08986759186\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:42 INFO 140207931545408] Epoch[58] Batch [45]#011Speed: 1951.22 samples/sec#011loss=8.089868\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[58] Batch[50] avg_epoch_loss=8.104155\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=58, batch=50 train loss <loss>=7.69265346527\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[58] Batch [50]#011Speed: 1598.47 samples/sec#011loss=7.692653\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] processed a total of 1613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1333.9710235595703, \"sum\": 1333.9710235595703, \"min\": 1333.9710235595703}}, \"EndTime\": 1577369803.036741, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369801.702305}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1209.05759517 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=58, train loss <loss>=8.10415487663\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch[0] avg_epoch_loss=8.184279\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=8.18427944183\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch[5] avg_epoch_loss=8.288353\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=8.28835296631\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch [5]#011Speed: 2046.40 samples/sec#011loss=8.288353\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch[10] avg_epoch_loss=8.276072\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=8.26133546829\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch [10]#011Speed: 1100.38 samples/sec#011loss=8.261335\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch[15] avg_epoch_loss=8.328683\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=59, batch=15 train loss <loss>=8.44442691803\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch [15]#011Speed: 1701.28 samples/sec#011loss=8.444427\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch[20] avg_epoch_loss=8.285626\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=59, batch=20 train loss <loss>=8.14784374237\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch [20]#011Speed: 978.31 samples/sec#011loss=8.147844\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch[25] avg_epoch_loss=8.245994\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=59, batch=25 train loss <loss>=8.0795416832\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch [25]#011Speed: 1861.18 samples/sec#011loss=8.079542\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch[30] avg_epoch_loss=8.186192\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=59, batch=30 train loss <loss>=7.87521982193\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch [30]#011Speed: 1020.17 samples/sec#011loss=7.875220\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch[35] avg_epoch_loss=8.086605\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=59, batch=35 train loss <loss>=7.46916360855\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:43 INFO 140207931545408] Epoch[59] Batch [35]#011Speed: 1809.22 samples/sec#011loss=7.469164\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[59] Batch[40] avg_epoch_loss=8.091230\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=59, batch=40 train loss <loss>=8.12453422546\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[59] Batch [40]#011Speed: 1022.61 samples/sec#011loss=8.124534\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[59] Batch[45] avg_epoch_loss=8.112087\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=59, batch=45 train loss <loss>=8.28311004639\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[59] Batch [45]#011Speed: 2057.85 samples/sec#011loss=8.283110\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] processed a total of 1591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1222.015142440796, \"sum\": 1222.015142440796, \"min\": 1222.015142440796}}, \"EndTime\": 1577369804.259284, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369803.036823}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1301.79369229 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=59, train loss <loss>=8.09642216682\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[60] Batch[0] avg_epoch_loss=8.241045\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=8.24104499817\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[60] Batch[5] avg_epoch_loss=8.377994\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=8.37799358368\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[60] Batch [5]#011Speed: 2067.00 samples/sec#011loss=8.377994\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[60] Batch[10] avg_epoch_loss=8.407312\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=8.4424943924\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[60] Batch [10]#011Speed: 918.75 samples/sec#011loss=8.442494\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[60] Batch[15] avg_epoch_loss=8.401701\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=60, batch=15 train loss <loss>=8.38935718536\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[60] Batch [15]#011Speed: 1642.49 samples/sec#011loss=8.389357\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[60] Batch[20] avg_epoch_loss=8.361507\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=60, batch=20 train loss <loss>=8.23288755417\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[60] Batch [20]#011Speed: 1029.56 samples/sec#011loss=8.232888\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[60] Batch[25] avg_epoch_loss=8.290168\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=60, batch=25 train loss <loss>=7.99054460526\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:44 INFO 140207931545408] Epoch[60] Batch [25]#011Speed: 1904.08 samples/sec#011loss=7.990545\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[60] Batch[30] avg_epoch_loss=8.202223\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=60, batch=30 train loss <loss>=7.74490623474\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[60] Batch [30]#011Speed: 918.82 samples/sec#011loss=7.744906\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[60] Batch[35] avg_epoch_loss=8.138603\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=60, batch=35 train loss <loss>=7.74415998459\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[60] Batch [35]#011Speed: 2036.87 samples/sec#011loss=7.744160\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[60] Batch[40] avg_epoch_loss=8.106010\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=60, batch=40 train loss <loss>=7.87134056091\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[60] Batch [40]#011Speed: 1096.30 samples/sec#011loss=7.871341\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[60] Batch[45] avg_epoch_loss=8.088810\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=60, batch=45 train loss <loss>=7.94777193069\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[60] Batch [45]#011Speed: 2012.15 samples/sec#011loss=7.947772\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] processed a total of 1552 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1225.3592014312744, \"sum\": 1225.3592014312744, \"min\": 1225.3592014312744}}, \"EndTime\": 1577369805.485243, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369804.259382}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1266.45502039 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=60, train loss <loss>=8.09876104277\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[61] Batch[0] avg_epoch_loss=8.159637\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=8.15963745117\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[61] Batch[5] avg_epoch_loss=7.991651\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=7.99165113767\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[61] Batch [5]#011Speed: 1864.93 samples/sec#011loss=7.991651\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[61] Batch[10] avg_epoch_loss=8.150240\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=8.34054727554\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[61] Batch [10]#011Speed: 940.76 samples/sec#011loss=8.340547\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[61] Batch[15] avg_epoch_loss=8.296686\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=61, batch=15 train loss <loss>=8.61886539459\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:45 INFO 140207931545408] Epoch[61] Batch [15]#011Speed: 1576.68 samples/sec#011loss=8.618865\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[61] Batch[20] avg_epoch_loss=8.276389\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=61, batch=20 train loss <loss>=8.21144037247\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[61] Batch [20]#011Speed: 895.03 samples/sec#011loss=8.211440\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[61] Batch[25] avg_epoch_loss=8.222488\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=61, batch=25 train loss <loss>=7.99610280991\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[61] Batch [25]#011Speed: 1568.69 samples/sec#011loss=7.996103\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[61] Batch[30] avg_epoch_loss=8.153652\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=61, batch=30 train loss <loss>=7.79570798874\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[61] Batch [30]#011Speed: 970.72 samples/sec#011loss=7.795708\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[61] Batch[35] avg_epoch_loss=8.095375\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=61, batch=35 train loss <loss>=7.73405580521\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[61] Batch [35]#011Speed: 1792.24 samples/sec#011loss=7.734056\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[61] Batch[40] avg_epoch_loss=8.064813\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=61, batch=40 train loss <loss>=7.84476633072\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[61] Batch [40]#011Speed: 914.13 samples/sec#011loss=7.844766\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[61] Batch[45] avg_epoch_loss=8.051061\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=61, batch=45 train loss <loss>=7.93829631805\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[61] Batch [45]#011Speed: 2039.13 samples/sec#011loss=7.938296\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] processed a total of 1576 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1314.2831325531006, \"sum\": 1314.2831325531006, \"min\": 1314.2831325531006}}, \"EndTime\": 1577369806.80012, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369805.485312}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1199.02903765 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=61, train loss <loss>=7.96676874161\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[62] Batch[0] avg_epoch_loss=7.740472\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=7.7404718399\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[62] Batch[5] avg_epoch_loss=8.204653\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=8.20465262731\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:46 INFO 140207931545408] Epoch[62] Batch [5]#011Speed: 2025.50 samples/sec#011loss=8.204653\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch[10] avg_epoch_loss=8.264414\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=8.33612804413\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch [10]#011Speed: 1003.42 samples/sec#011loss=8.336128\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch[15] avg_epoch_loss=8.363483\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=62, batch=15 train loss <loss>=8.58143281937\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch [15]#011Speed: 1909.49 samples/sec#011loss=8.581433\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch[20] avg_epoch_loss=8.338722\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=62, batch=20 train loss <loss>=8.25948705673\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch [20]#011Speed: 1079.39 samples/sec#011loss=8.259487\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch[25] avg_epoch_loss=8.229650\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=62, batch=25 train loss <loss>=7.77154779434\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch [25]#011Speed: 2087.00 samples/sec#011loss=7.771548\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch[30] avg_epoch_loss=8.153763\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=62, batch=30 train loss <loss>=7.75915231705\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch [30]#011Speed: 1053.62 samples/sec#011loss=7.759152\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch[35] avg_epoch_loss=8.126440\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=62, batch=35 train loss <loss>=7.9570400238\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch [35]#011Speed: 2081.33 samples/sec#011loss=7.957040\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch[40] avg_epoch_loss=8.106177\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=62, batch=40 train loss <loss>=7.96027650833\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch [40]#011Speed: 951.59 samples/sec#011loss=7.960277\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch[45] avg_epoch_loss=8.102538\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=62, batch=45 train loss <loss>=8.07270259857\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:47 INFO 140207931545408] Epoch[62] Batch [45]#011Speed: 2131.09 samples/sec#011loss=8.072703\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[62] Batch[50] avg_epoch_loss=8.050843\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=62, batch=50 train loss <loss>=7.57525291443\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[62] Batch [50]#011Speed: 1352.14 samples/sec#011loss=7.575253\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] processed a total of 1621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1230.3471565246582, \"sum\": 1230.3471565246582, \"min\": 1230.3471565246582}}, \"EndTime\": 1577369808.03103, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369806.800191}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1317.40837708 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=62, train loss <loss>=8.05084345387\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch[0] avg_epoch_loss=8.344407\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=8.3444070816\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch[5] avg_epoch_loss=8.282356\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=8.28235594432\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch [5]#011Speed: 1621.62 samples/sec#011loss=8.282356\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch[10] avg_epoch_loss=8.275869\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=8.26808538437\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch [10]#011Speed: 1007.30 samples/sec#011loss=8.268085\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch[15] avg_epoch_loss=8.353955\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=63, batch=15 train loss <loss>=8.52574462891\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch [15]#011Speed: 1673.06 samples/sec#011loss=8.525745\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch[20] avg_epoch_loss=8.291982\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=63, batch=20 train loss <loss>=8.09366569519\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch [20]#011Speed: 926.71 samples/sec#011loss=8.093666\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch[25] avg_epoch_loss=8.224333\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=63, batch=25 train loss <loss>=7.94020681381\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch [25]#011Speed: 1745.24 samples/sec#011loss=7.940207\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch[30] avg_epoch_loss=8.161271\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=63, batch=30 train loss <loss>=7.8333530426\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch [30]#011Speed: 985.72 samples/sec#011loss=7.833353\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch[35] avg_epoch_loss=8.085739\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=63, batch=35 train loss <loss>=7.61743717194\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:48 INFO 140207931545408] Epoch[63] Batch [35]#011Speed: 1837.81 samples/sec#011loss=7.617437\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[63] Batch[40] avg_epoch_loss=8.060164\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=63, batch=40 train loss <loss>=7.87602462769\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[63] Batch [40]#011Speed: 972.10 samples/sec#011loss=7.876025\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[63] Batch[45] avg_epoch_loss=8.041882\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=63, batch=45 train loss <loss>=7.89197235107\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[63] Batch [45]#011Speed: 2099.51 samples/sec#011loss=7.891972\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] processed a total of 1577 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1301.743984222412, \"sum\": 1301.743984222412, \"min\": 1301.743984222412}}, \"EndTime\": 1577369809.333309, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369808.031088}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1211.34834085 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=63, train loss <loss>=7.98726696968\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[64] Batch[0] avg_epoch_loss=7.709235\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=7.70923471451\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[64] Batch[5] avg_epoch_loss=8.033878\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=8.03387800852\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[64] Batch [5]#011Speed: 1775.35 samples/sec#011loss=8.033878\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[64] Batch[10] avg_epoch_loss=8.222163\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=8.44810428619\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[64] Batch [10]#011Speed: 923.10 samples/sec#011loss=8.448104\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[64] Batch[15] avg_epoch_loss=8.268858\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=64, batch=15 train loss <loss>=8.37158851624\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[64] Batch [15]#011Speed: 1858.76 samples/sec#011loss=8.371589\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[64] Batch[20] avg_epoch_loss=8.305228\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=64, batch=20 train loss <loss>=8.42161235809\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:49 INFO 140207931545408] Epoch[64] Batch [20]#011Speed: 967.06 samples/sec#011loss=8.421612\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[64] Batch[25] avg_epoch_loss=8.271608\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=64, batch=25 train loss <loss>=8.13040161133\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[64] Batch [25]#011Speed: 1675.32 samples/sec#011loss=8.130402\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[64] Batch[30] avg_epoch_loss=8.200038\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=64, batch=30 train loss <loss>=7.82787227631\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[64] Batch [30]#011Speed: 896.55 samples/sec#011loss=7.827872\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[64] Batch[35] avg_epoch_loss=8.144373\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=64, batch=35 train loss <loss>=7.79924955368\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[64] Batch [35]#011Speed: 1641.01 samples/sec#011loss=7.799250\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[64] Batch[40] avg_epoch_loss=8.169401\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=64, batch=40 train loss <loss>=8.349609375\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[64] Batch [40]#011Speed: 1008.26 samples/sec#011loss=8.349609\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[64] Batch[45] avg_epoch_loss=8.149204\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=64, batch=45 train loss <loss>=7.98358917236\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[64] Batch [45]#011Speed: 1722.26 samples/sec#011loss=7.983589\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] processed a total of 1521 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1285.7320308685303, \"sum\": 1285.7320308685303, \"min\": 1285.7320308685303}}, \"EndTime\": 1577369810.619565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369809.333374}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1182.86413058 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=64, train loss <loss>=8.10250458121\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[65] Batch[0] avg_epoch_loss=8.206659\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=8.20665931702\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[65] Batch[5] avg_epoch_loss=8.494020\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=8.49402014414\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[65] Batch [5]#011Speed: 1976.80 samples/sec#011loss=8.494020\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[65] Batch[10] avg_epoch_loss=8.420836\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=8.33301506042\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:50 INFO 140207931545408] Epoch[65] Batch [10]#011Speed: 1036.68 samples/sec#011loss=8.333015\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch[15] avg_epoch_loss=8.380166\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=65, batch=15 train loss <loss>=8.29069232941\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch [15]#011Speed: 1853.46 samples/sec#011loss=8.290692\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch[20] avg_epoch_loss=8.329560\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=65, batch=20 train loss <loss>=8.16761951447\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch [20]#011Speed: 946.43 samples/sec#011loss=8.167620\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch[25] avg_epoch_loss=8.270159\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=65, batch=25 train loss <loss>=8.02067403793\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch [25]#011Speed: 2088.66 samples/sec#011loss=8.020674\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch[30] avg_epoch_loss=8.217458\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=65, batch=30 train loss <loss>=7.94341630936\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch [30]#011Speed: 955.59 samples/sec#011loss=7.943416\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch[35] avg_epoch_loss=8.162579\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=65, batch=35 train loss <loss>=7.82233066559\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch [35]#011Speed: 1911.96 samples/sec#011loss=7.822331\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch[40] avg_epoch_loss=8.094619\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=65, batch=40 train loss <loss>=7.60530338287\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch [40]#011Speed: 943.61 samples/sec#011loss=7.605303\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch[45] avg_epoch_loss=8.072650\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=65, batch=45 train loss <loss>=7.89250907898\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch [45]#011Speed: 2049.96 samples/sec#011loss=7.892509\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch[50] avg_epoch_loss=7.977905\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=65, batch=50 train loss <loss>=7.1062417984\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[65] Batch [50]#011Speed: 1518.39 samples/sec#011loss=7.106242\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] processed a total of 1621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1278.4879207611084, \"sum\": 1278.4879207611084, \"min\": 1278.4879207611084}}, \"EndTime\": 1577369811.898631, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369810.619653}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1267.77802756 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=65, train loss <loss>=7.97790454416\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] Epoch[66] Batch[0] avg_epoch_loss=8.549873\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=8.54987335205\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch[5] avg_epoch_loss=8.076542\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=8.07654158274\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch [5]#011Speed: 1875.51 samples/sec#011loss=8.076542\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch[10] avg_epoch_loss=8.228476\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=8.41079711914\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch [10]#011Speed: 992.49 samples/sec#011loss=8.410797\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch[15] avg_epoch_loss=8.303191\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=66, batch=15 train loss <loss>=8.46756324768\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch [15]#011Speed: 1966.47 samples/sec#011loss=8.467563\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch[20] avg_epoch_loss=8.255246\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=66, batch=20 train loss <loss>=8.10182237625\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch [20]#011Speed: 934.74 samples/sec#011loss=8.101822\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch[25] avg_epoch_loss=8.205991\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=66, batch=25 train loss <loss>=7.99911937714\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch [25]#011Speed: 1656.49 samples/sec#011loss=7.999119\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch[30] avg_epoch_loss=8.160843\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=66, batch=30 train loss <loss>=7.92607402802\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch [30]#011Speed: 961.14 samples/sec#011loss=7.926074\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch[35] avg_epoch_loss=8.112937\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=66, batch=35 train loss <loss>=7.81591882706\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch [35]#011Speed: 1868.68 samples/sec#011loss=7.815919\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch[40] avg_epoch_loss=8.102677\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=66, batch=40 train loss <loss>=8.02880764008\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:52 INFO 140207931545408] Epoch[66] Batch [40]#011Speed: 1062.66 samples/sec#011loss=8.028808\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[66] Batch[45] avg_epoch_loss=8.057525\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=66, batch=45 train loss <loss>=7.68727493286\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[66] Batch [45]#011Speed: 2078.74 samples/sec#011loss=7.687275\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] processed a total of 1584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1272.1741199493408, \"sum\": 1272.1741199493408, \"min\": 1272.1741199493408}}, \"EndTime\": 1577369813.17135, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369811.898713}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1245.00711556 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=66, train loss <loss>=8.05096720695\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[67] Batch[0] avg_epoch_loss=7.826017\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=7.82601690292\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[67] Batch[5] avg_epoch_loss=8.176708\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=8.17670830091\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[67] Batch [5]#011Speed: 1747.97 samples/sec#011loss=8.176708\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[67] Batch[10] avg_epoch_loss=8.267231\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=8.37585849762\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[67] Batch [10]#011Speed: 702.11 samples/sec#011loss=8.375858\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[67] Batch[15] avg_epoch_loss=8.207882\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=67, batch=15 train loss <loss>=8.07731399536\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[67] Batch [15]#011Speed: 1809.79 samples/sec#011loss=8.077314\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[67] Batch[20] avg_epoch_loss=8.327644\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=67, batch=20 train loss <loss>=8.71088123322\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[67] Batch [20]#011Speed: 904.57 samples/sec#011loss=8.710881\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[67] Batch[25] avg_epoch_loss=8.207807\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=67, batch=25 train loss <loss>=7.7044927597\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:53 INFO 140207931545408] Epoch[67] Batch [25]#011Speed: 2071.12 samples/sec#011loss=7.704493\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[67] Batch[30] avg_epoch_loss=8.136501\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=67, batch=30 train loss <loss>=7.76571006775\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[67] Batch [30]#011Speed: 1053.85 samples/sec#011loss=7.765710\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[67] Batch[35] avg_epoch_loss=8.090190\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=67, batch=35 train loss <loss>=7.80306005478\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[67] Batch [35]#011Speed: 2143.22 samples/sec#011loss=7.803060\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[67] Batch[40] avg_epoch_loss=8.052384\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=67, batch=40 train loss <loss>=7.78018035889\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[67] Batch [40]#011Speed: 951.41 samples/sec#011loss=7.780180\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[67] Batch[45] avg_epoch_loss=8.062593\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=67, batch=45 train loss <loss>=8.14630460739\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[67] Batch [45]#011Speed: 1894.01 samples/sec#011loss=8.146305\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[67] Batch[50] avg_epoch_loss=7.997953\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=67, batch=50 train loss <loss>=7.40326852798\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[67] Batch [50]#011Speed: 1460.39 samples/sec#011loss=7.403269\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] processed a total of 1646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1368.3280944824219, \"sum\": 1368.3280944824219, \"min\": 1368.3280944824219}}, \"EndTime\": 1577369814.540234, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369813.171418}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1202.81113451 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=67, train loss <loss>=8.03682475824\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[68] Batch[0] avg_epoch_loss=8.240565\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=8.24056529999\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[68] Batch[5] avg_epoch_loss=8.328479\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=8.32847921054\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[68] Batch [5]#011Speed: 1956.78 samples/sec#011loss=8.328479\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[68] Batch[10] avg_epoch_loss=8.293428\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=8.25136756897\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[68] Batch [10]#011Speed: 915.15 samples/sec#011loss=8.251368\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[68] Batch[15] avg_epoch_loss=8.332493\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=68, batch=15 train loss <loss>=8.41843624115\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:54 INFO 140207931545408] Epoch[68] Batch [15]#011Speed: 1871.56 samples/sec#011loss=8.418436\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch[20] avg_epoch_loss=8.387651\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=68, batch=20 train loss <loss>=8.56415710449\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch [20]#011Speed: 939.22 samples/sec#011loss=8.564157\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch[25] avg_epoch_loss=8.250153\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=68, batch=25 train loss <loss>=7.67265949249\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch [25]#011Speed: 1708.32 samples/sec#011loss=7.672659\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch[30] avg_epoch_loss=8.198434\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=68, batch=30 train loss <loss>=7.92949733734\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch [30]#011Speed: 935.60 samples/sec#011loss=7.929497\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch[35] avg_epoch_loss=8.110727\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=68, batch=35 train loss <loss>=7.56694040298\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch [35]#011Speed: 1672.27 samples/sec#011loss=7.566940\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch[40] avg_epoch_loss=8.087278\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=68, batch=40 train loss <loss>=7.91844291687\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch [40]#011Speed: 929.91 samples/sec#011loss=7.918443\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch[45] avg_epoch_loss=8.086448\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=68, batch=45 train loss <loss>=8.0796462059\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch [45]#011Speed: 1698.08 samples/sec#011loss=8.079646\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch[50] avg_epoch_loss=8.030237\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=68, batch=50 train loss <loss>=7.5130947113\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[68] Batch [50]#011Speed: 1817.55 samples/sec#011loss=7.513095\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] processed a total of 1611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1326.235055923462, \"sum\": 1326.235055923462, \"min\": 1326.235055923462}}, \"EndTime\": 1577369815.867047, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369814.540323}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1214.61329865 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=68, train loss <loss>=8.03023696413\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] Epoch[69] Batch[0] avg_epoch_loss=8.577229\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=8.57722854614\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch[5] avg_epoch_loss=8.334473\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=8.33447297414\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch [5]#011Speed: 2010.02 samples/sec#011loss=8.334473\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch[10] avg_epoch_loss=8.314927\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=8.29147090912\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch [10]#011Speed: 1048.73 samples/sec#011loss=8.291471\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch[15] avg_epoch_loss=8.502081\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=69, batch=15 train loss <loss>=8.9138217926\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch [15]#011Speed: 1850.52 samples/sec#011loss=8.913822\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch[20] avg_epoch_loss=8.440712\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=69, batch=20 train loss <loss>=8.24432926178\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch [20]#011Speed: 1088.63 samples/sec#011loss=8.244329\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch[25] avg_epoch_loss=8.381310\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=69, batch=25 train loss <loss>=8.13182477951\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch [25]#011Speed: 2092.59 samples/sec#011loss=8.131825\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch[30] avg_epoch_loss=8.311432\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=69, batch=30 train loss <loss>=7.94806423187\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch [30]#011Speed: 925.29 samples/sec#011loss=7.948064\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch[35] avg_epoch_loss=8.240166\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=69, batch=35 train loss <loss>=7.79831666946\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch [35]#011Speed: 1673.20 samples/sec#011loss=7.798317\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch[40] avg_epoch_loss=8.207652\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=69, batch=40 train loss <loss>=7.97355318069\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch [40]#011Speed: 1070.17 samples/sec#011loss=7.973553\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch[45] avg_epoch_loss=8.203480\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=69, batch=45 train loss <loss>=8.16927032471\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:56 INFO 140207931545408] Epoch[69] Batch [45]#011Speed: 2162.17 samples/sec#011loss=8.169270\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[69] Batch[50] avg_epoch_loss=8.140519\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=69, batch=50 train loss <loss>=7.56127271652\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[69] Batch [50]#011Speed: 1322.75 samples/sec#011loss=7.561273\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] processed a total of 1602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1244.7290420532227, \"sum\": 1244.7290420532227, \"min\": 1244.7290420532227}}, \"EndTime\": 1577369817.112318, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369815.867117}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1286.89595703 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=69, train loss <loss>=8.14051876816\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[70] Batch[0] avg_epoch_loss=7.950228\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=7.95022773743\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[70] Batch[5] avg_epoch_loss=8.003217\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=8.00321658452\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[70] Batch [5]#011Speed: 1803.59 samples/sec#011loss=8.003217\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[70] Batch[10] avg_epoch_loss=8.250085\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=8.54632606506\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[70] Batch [10]#011Speed: 974.00 samples/sec#011loss=8.546326\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[70] Batch[15] avg_epoch_loss=8.349503\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=70, batch=15 train loss <loss>=8.56822500229\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[70] Batch [15]#011Speed: 1740.11 samples/sec#011loss=8.568225\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[70] Batch[20] avg_epoch_loss=8.286380\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=70, batch=20 train loss <loss>=8.08438510895\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[70] Batch [20]#011Speed: 945.98 samples/sec#011loss=8.084385\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[70] Batch[25] avg_epoch_loss=8.213044\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=70, batch=25 train loss <loss>=7.90503034592\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:57 INFO 140207931545408] Epoch[70] Batch [25]#011Speed: 1662.22 samples/sec#011loss=7.905030\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[70] Batch[30] avg_epoch_loss=8.127404\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=70, batch=30 train loss <loss>=7.68207941055\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[70] Batch [30]#011Speed: 885.52 samples/sec#011loss=7.682079\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[70] Batch[35] avg_epoch_loss=8.076165\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=70, batch=35 train loss <loss>=7.75848150253\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[70] Batch [35]#011Speed: 1715.94 samples/sec#011loss=7.758482\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[70] Batch[40] avg_epoch_loss=8.007853\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=70, batch=40 train loss <loss>=7.51600408554\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[70] Batch [40]#011Speed: 1001.06 samples/sec#011loss=7.516004\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[70] Batch[45] avg_epoch_loss=7.985318\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=70, batch=45 train loss <loss>=7.8005364418\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[70] Batch [45]#011Speed: 2063.83 samples/sec#011loss=7.800536\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] processed a total of 1568 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1299.217939376831, \"sum\": 1299.217939376831, \"min\": 1299.217939376831}}, \"EndTime\": 1577369818.412078, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369817.112402}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1206.74878892 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=70, train loss <loss>=7.98722237957\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[71] Batch[0] avg_epoch_loss=8.396920\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=8.39692020416\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[71] Batch[5] avg_epoch_loss=8.357076\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=8.35707600911\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[71] Batch [5]#011Speed: 2052.10 samples/sec#011loss=8.357076\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[71] Batch[10] avg_epoch_loss=8.246587\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=8.1140001297\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[71] Batch [10]#011Speed: 1060.65 samples/sec#011loss=8.114000\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[71] Batch[15] avg_epoch_loss=8.344086\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=71, batch=15 train loss <loss>=8.55858325958\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[71] Batch [15]#011Speed: 2106.78 samples/sec#011loss=8.558583\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[71] Batch[20] avg_epoch_loss=8.384247\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=71, batch=20 train loss <loss>=8.51276273727\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:58 INFO 140207931545408] Epoch[71] Batch [20]#011Speed: 951.55 samples/sec#011loss=8.512763\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[71] Batch[25] avg_epoch_loss=8.242991\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=71, batch=25 train loss <loss>=7.64971380234\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[71] Batch [25]#011Speed: 1936.46 samples/sec#011loss=7.649714\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[71] Batch[30] avg_epoch_loss=8.155680\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=71, batch=30 train loss <loss>=7.70166292191\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[71] Batch [30]#011Speed: 1092.78 samples/sec#011loss=7.701663\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[71] Batch[35] avg_epoch_loss=8.095495\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=71, batch=35 train loss <loss>=7.72234659195\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[71] Batch [35]#011Speed: 1657.19 samples/sec#011loss=7.722347\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[71] Batch[40] avg_epoch_loss=8.089953\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=71, batch=40 train loss <loss>=8.0500535965\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[71] Batch [40]#011Speed: 994.70 samples/sec#011loss=8.050054\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[71] Batch[45] avg_epoch_loss=8.050542\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=71, batch=45 train loss <loss>=7.72737493515\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[71] Batch [45]#011Speed: 2134.42 samples/sec#011loss=7.727375\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[71] Batch[50] avg_epoch_loss=7.979499\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=71, batch=50 train loss <loss>=7.32590522766\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[71] Batch [50]#011Speed: 1541.07 samples/sec#011loss=7.325905\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] processed a total of 1601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1232.132911682129, \"sum\": 1232.132911682129, \"min\": 1232.132911682129}}, \"EndTime\": 1577369819.644767, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369818.412151}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1299.23880883 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=71, train loss <loss>=7.97949945225\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[72] Batch[0] avg_epoch_loss=8.202708\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=8.20270824432\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[72] Batch[5] avg_epoch_loss=8.122419\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=8.12241856257\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[72] Batch [5]#011Speed: 2102.91 samples/sec#011loss=8.122419\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[72] Batch[10] avg_epoch_loss=8.221950\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=8.34138727188\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:16:59 INFO 140207931545408] Epoch[72] Batch [10]#011Speed: 1027.13 samples/sec#011loss=8.341387\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch[15] avg_epoch_loss=8.396217\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=72, batch=15 train loss <loss>=8.77960453033\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch [15]#011Speed: 1863.22 samples/sec#011loss=8.779605\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch[20] avg_epoch_loss=8.372566\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=72, batch=20 train loss <loss>=8.29688510895\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch [20]#011Speed: 935.63 samples/sec#011loss=8.296885\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch[25] avg_epoch_loss=8.313030\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=72, batch=25 train loss <loss>=8.06297626495\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch [25]#011Speed: 1775.98 samples/sec#011loss=8.062976\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch[30] avg_epoch_loss=8.233995\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=72, batch=30 train loss <loss>=7.82301626205\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch [30]#011Speed: 986.57 samples/sec#011loss=7.823016\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch[35] avg_epoch_loss=8.172361\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=72, batch=35 train loss <loss>=7.79022493362\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch [35]#011Speed: 1650.17 samples/sec#011loss=7.790225\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch[40] avg_epoch_loss=8.112864\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=72, batch=40 train loss <loss>=7.68448905945\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch [40]#011Speed: 1064.34 samples/sec#011loss=7.684489\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch[45] avg_epoch_loss=8.081935\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=72, batch=45 train loss <loss>=7.82831220627\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] Epoch[72] Batch [45]#011Speed: 1675.83 samples/sec#011loss=7.828312\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] processed a total of 1590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1283.1940650939941, \"sum\": 1283.1940650939941, \"min\": 1283.1940650939941}}, \"EndTime\": 1577369820.928481, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369819.644853}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1238.97004654 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] #quality_metric: host=algo-1, epoch=72, train loss <loss>=8.0801603508\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:00 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch[0] avg_epoch_loss=8.602964\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=8.60296440125\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch[5] avg_epoch_loss=8.313785\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=8.31378523509\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch [5]#011Speed: 2072.32 samples/sec#011loss=8.313785\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch[10] avg_epoch_loss=8.298062\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=8.27919445038\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch [10]#011Speed: 1119.16 samples/sec#011loss=8.279194\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch[15] avg_epoch_loss=8.239523\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=73, batch=15 train loss <loss>=8.11073818207\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch [15]#011Speed: 1985.21 samples/sec#011loss=8.110738\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch[20] avg_epoch_loss=8.256989\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=73, batch=20 train loss <loss>=8.31287689209\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch [20]#011Speed: 1068.66 samples/sec#011loss=8.312877\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch[25] avg_epoch_loss=8.192725\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=73, batch=25 train loss <loss>=7.92282075882\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch [25]#011Speed: 1862.69 samples/sec#011loss=7.922821\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch[30] avg_epoch_loss=8.120383\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=73, batch=30 train loss <loss>=7.7442032814\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch [30]#011Speed: 938.32 samples/sec#011loss=7.744203\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch[35] avg_epoch_loss=8.072089\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=73, batch=35 train loss <loss>=7.7726647377\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch [35]#011Speed: 1991.34 samples/sec#011loss=7.772665\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch[40] avg_epoch_loss=8.077910\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] #quality_metric: host=algo-1, epoch=73, batch=40 train loss <loss>=8.11982355118\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:01 INFO 140207931545408] Epoch[73] Batch [40]#011Speed: 1021.41 samples/sec#011loss=8.119824\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[73] Batch[45] avg_epoch_loss=8.070171\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=73, batch=45 train loss <loss>=8.00671014786\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[73] Batch [45]#011Speed: 2074.91 samples/sec#011loss=8.006710\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] processed a total of 1555 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1217.2179222106934, \"sum\": 1217.2179222106934, \"min\": 1217.2179222106934}}, \"EndTime\": 1577369822.146269, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369820.928569}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1277.37001497 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=73, train loss <loss>=8.04377633698\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch[0] avg_epoch_loss=8.212819\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=8.21281909943\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch[5] avg_epoch_loss=8.414361\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=8.41436100006\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch [5]#011Speed: 2095.91 samples/sec#011loss=8.414361\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch[10] avg_epoch_loss=8.397932\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=8.37821760178\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch [10]#011Speed: 1089.41 samples/sec#011loss=8.378218\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch[15] avg_epoch_loss=8.445737\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=74, batch=15 train loss <loss>=8.55090618134\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch [15]#011Speed: 1955.51 samples/sec#011loss=8.550906\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch[20] avg_epoch_loss=8.398615\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=74, batch=20 train loss <loss>=8.24782562256\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch [20]#011Speed: 1034.53 samples/sec#011loss=8.247826\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch[25] avg_epoch_loss=8.284142\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=74, batch=25 train loss <loss>=7.80335588455\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch [25]#011Speed: 1861.89 samples/sec#011loss=7.803356\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch[30] avg_epoch_loss=8.221441\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] #quality_metric: host=algo-1, epoch=74, batch=30 train loss <loss>=7.89539852142\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:02 INFO 140207931545408] Epoch[74] Batch [30]#011Speed: 1069.97 samples/sec#011loss=7.895399\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[74] Batch[35] avg_epoch_loss=8.143553\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=74, batch=35 train loss <loss>=7.6606426239\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[74] Batch [35]#011Speed: 1884.50 samples/sec#011loss=7.660643\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[74] Batch[40] avg_epoch_loss=8.061645\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=74, batch=40 train loss <loss>=7.47190761566\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[74] Batch [40]#011Speed: 1082.68 samples/sec#011loss=7.471908\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[74] Batch[45] avg_epoch_loss=8.027349\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=74, batch=45 train loss <loss>=7.7461230278\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[74] Batch [45]#011Speed: 1713.37 samples/sec#011loss=7.746123\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] processed a total of 1599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1226.5698909759521, \"sum\": 1226.5698909759521, \"min\": 1226.5698909759521}}, \"EndTime\": 1577369823.37338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369822.146355}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1303.48976888 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=74, train loss <loss>=8.02444589615\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[75] Batch[0] avg_epoch_loss=8.480392\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=8.48039245605\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[75] Batch[5] avg_epoch_loss=8.140466\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=8.14046605428\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[75] Batch [5]#011Speed: 1583.06 samples/sec#011loss=8.140466\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[75] Batch[10] avg_epoch_loss=8.247863\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=8.37673892975\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[75] Batch [10]#011Speed: 897.73 samples/sec#011loss=8.376739\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[75] Batch[15] avg_epoch_loss=8.391731\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=75, batch=15 train loss <loss>=8.70824222565\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[75] Batch [15]#011Speed: 1972.29 samples/sec#011loss=8.708242\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[75] Batch[20] avg_epoch_loss=8.386577\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] #quality_metric: host=algo-1, epoch=75, batch=20 train loss <loss>=8.37008113861\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:03 INFO 140207931545408] Epoch[75] Batch [20]#011Speed: 1070.48 samples/sec#011loss=8.370081\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[75] Batch[25] avg_epoch_loss=8.245767\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=75, batch=25 train loss <loss>=7.65436706543\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[75] Batch [25]#011Speed: 1777.07 samples/sec#011loss=7.654367\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[75] Batch[30] avg_epoch_loss=8.198646\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=75, batch=30 train loss <loss>=7.95361747742\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[75] Batch [30]#011Speed: 942.62 samples/sec#011loss=7.953617\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[75] Batch[35] avg_epoch_loss=8.144990\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=75, batch=35 train loss <loss>=7.81232271194\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[75] Batch [35]#011Speed: 1674.99 samples/sec#011loss=7.812323\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[75] Batch[40] avg_epoch_loss=8.140634\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=75, batch=40 train loss <loss>=8.10926837921\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[75] Batch [40]#011Speed: 926.94 samples/sec#011loss=8.109268\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[75] Batch[45] avg_epoch_loss=8.110175\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=75, batch=45 train loss <loss>=7.86041460037\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[75] Batch [45]#011Speed: 1689.87 samples/sec#011loss=7.860415\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[75] Batch[50] avg_epoch_loss=8.078038\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=75, batch=50 train loss <loss>=7.78237657547\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[75] Batch [50]#011Speed: 1744.06 samples/sec#011loss=7.782377\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] processed a total of 1614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1324.4669437408447, \"sum\": 1324.4669437408447, \"min\": 1324.4669437408447}}, \"EndTime\": 1577369824.698423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369823.373472}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1218.48830561 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=75, train loss <loss>=8.07803807539\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[76] Batch[0] avg_epoch_loss=8.594997\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=8.59499740601\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[76] Batch[5] avg_epoch_loss=7.966215\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=7.96621489525\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:04 INFO 140207931545408] Epoch[76] Batch [5]#011Speed: 1703.15 samples/sec#011loss=7.966215\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch[10] avg_epoch_loss=8.072950\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=8.20103282928\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch [10]#011Speed: 960.19 samples/sec#011loss=8.201033\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch[15] avg_epoch_loss=8.141045\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=76, batch=15 train loss <loss>=8.29085216522\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch [15]#011Speed: 2071.52 samples/sec#011loss=8.290852\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch[20] avg_epoch_loss=8.203354\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=76, batch=20 train loss <loss>=8.40274562836\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch [20]#011Speed: 887.29 samples/sec#011loss=8.402746\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch[25] avg_epoch_loss=8.137683\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=76, batch=25 train loss <loss>=7.86186180115\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch [25]#011Speed: 1786.49 samples/sec#011loss=7.861862\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch[30] avg_epoch_loss=8.133089\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=76, batch=30 train loss <loss>=8.10920133591\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch [30]#011Speed: 1063.69 samples/sec#011loss=8.109201\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch[35] avg_epoch_loss=8.079516\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=76, batch=35 train loss <loss>=7.74736003876\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch [35]#011Speed: 1646.77 samples/sec#011loss=7.747360\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch[40] avg_epoch_loss=8.063661\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=76, batch=40 train loss <loss>=7.94950752258\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch [40]#011Speed: 974.17 samples/sec#011loss=7.949508\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch[45] avg_epoch_loss=8.086595\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] #quality_metric: host=algo-1, epoch=76, batch=45 train loss <loss>=8.27465305328\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:05 INFO 140207931545408] Epoch[76] Batch [45]#011Speed: 2009.09 samples/sec#011loss=8.274653\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[76] Batch[50] avg_epoch_loss=8.054206\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=76, batch=50 train loss <loss>=7.7562251091\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[76] Batch [50]#011Speed: 1459.89 samples/sec#011loss=7.756225\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] processed a total of 1656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1334.45405960083, \"sum\": 1334.45405960083, \"min\": 1334.45405960083}}, \"EndTime\": 1577369826.033399, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369824.698507}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1240.82944777 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=76, train loss <loss>=8.0556851442\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch[0] avg_epoch_loss=8.484554\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=8.48455429077\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch[5] avg_epoch_loss=8.245267\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=8.24526667595\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch [5]#011Speed: 1804.57 samples/sec#011loss=8.245267\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch[10] avg_epoch_loss=8.094134\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=7.91277580261\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch [10]#011Speed: 1047.66 samples/sec#011loss=7.912776\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch[15] avg_epoch_loss=8.266386\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=77, batch=15 train loss <loss>=8.64534044266\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch [15]#011Speed: 1901.32 samples/sec#011loss=8.645340\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch[20] avg_epoch_loss=8.175003\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=77, batch=20 train loss <loss>=7.88257446289\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch [20]#011Speed: 968.70 samples/sec#011loss=7.882574\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch[25] avg_epoch_loss=8.094654\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=77, batch=25 train loss <loss>=7.75719089508\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch [25]#011Speed: 1883.55 samples/sec#011loss=7.757191\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch[30] avg_epoch_loss=8.021554\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=77, batch=30 train loss <loss>=7.64143400192\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch [30]#011Speed: 989.32 samples/sec#011loss=7.641434\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch[35] avg_epoch_loss=7.983364\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] #quality_metric: host=algo-1, epoch=77, batch=35 train loss <loss>=7.74658641815\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:06 INFO 140207931545408] Epoch[77] Batch [35]#011Speed: 1919.78 samples/sec#011loss=7.746586\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[77] Batch[40] avg_epoch_loss=7.961661\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=77, batch=40 train loss <loss>=7.80539703369\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[77] Batch [40]#011Speed: 1112.51 samples/sec#011loss=7.805397\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[77] Batch[45] avg_epoch_loss=7.956206\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=77, batch=45 train loss <loss>=7.91147966385\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[77] Batch [45]#011Speed: 1825.17 samples/sec#011loss=7.911480\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] processed a total of 1548 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1233.6959838867188, \"sum\": 1233.6959838867188, \"min\": 1233.6959838867188}}, \"EndTime\": 1577369827.26769, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369826.033481}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1254.64203959 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=77, train loss <loss>=7.9145219472\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_d88cbec0-deae-40f5-b120-99fe8a462a8d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.304927825927734, \"sum\": 10.304927825927734, \"min\": 10.304927825927734}}, \"EndTime\": 1577369827.278597, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369827.267758}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[78] Batch[0] avg_epoch_loss=7.308849\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=7.30884885788\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[78] Batch[5] avg_epoch_loss=8.000163\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=8.00016299884\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[78] Batch [5]#011Speed: 1868.18 samples/sec#011loss=8.000163\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[78] Batch[10] avg_epoch_loss=8.122217\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=8.26868095398\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[78] Batch [10]#011Speed: 968.02 samples/sec#011loss=8.268681\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[78] Batch[15] avg_epoch_loss=8.298538\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=78, batch=15 train loss <loss>=8.6864440918\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[78] Batch [15]#011Speed: 1792.31 samples/sec#011loss=8.686444\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[78] Batch[20] avg_epoch_loss=8.243274\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=78, batch=20 train loss <loss>=8.06642818451\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[78] Batch [20]#011Speed: 949.32 samples/sec#011loss=8.066428\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[78] Batch[25] avg_epoch_loss=8.161192\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] #quality_metric: host=algo-1, epoch=78, batch=25 train loss <loss>=7.8164484024\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:07 INFO 140207931545408] Epoch[78] Batch [25]#011Speed: 1783.11 samples/sec#011loss=7.816448\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[78] Batch[30] avg_epoch_loss=8.088901\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=78, batch=30 train loss <loss>=7.71298761368\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[78] Batch [30]#011Speed: 1025.82 samples/sec#011loss=7.712988\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[78] Batch[35] avg_epoch_loss=8.015483\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=78, batch=35 train loss <loss>=7.56028928757\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[78] Batch [35]#011Speed: 2016.30 samples/sec#011loss=7.560289\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[78] Batch[40] avg_epoch_loss=7.974644\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=78, batch=40 train loss <loss>=7.68060703278\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[78] Batch [40]#011Speed: 1006.58 samples/sec#011loss=7.680607\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[78] Batch[45] avg_epoch_loss=7.949741\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=78, batch=45 train loss <loss>=7.7455329895\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[78] Batch [45]#011Speed: 1906.92 samples/sec#011loss=7.745533\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[78] Batch[50] avg_epoch_loss=7.907504\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=78, batch=50 train loss <loss>=7.51892929077\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[78] Batch [50]#011Speed: 1761.40 samples/sec#011loss=7.518929\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] processed a total of 1612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1262.6278400421143, \"sum\": 1262.6278400421143, \"min\": 1262.6278400421143}}, \"EndTime\": 1577369828.541345, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369827.278661}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1276.57778075 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=78, train loss <loss>=7.90750425937\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/state_b71fc55e-4454-4146-ac28-bee3c5c76e55-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.657072067260742, \"sum\": 10.657072067260742, \"min\": 10.657072067260742}}, \"EndTime\": 1577369828.552584, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369828.541427}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[79] Batch[0] avg_epoch_loss=7.417994\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=7.41799402237\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[79] Batch[5] avg_epoch_loss=8.007402\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=8.00740249952\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[79] Batch [5]#011Speed: 2043.09 samples/sec#011loss=8.007402\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[79] Batch[10] avg_epoch_loss=8.163242\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=8.35025005341\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[79] Batch [10]#011Speed: 1081.19 samples/sec#011loss=8.350250\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[79] Batch[15] avg_epoch_loss=8.235530\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] #quality_metric: host=algo-1, epoch=79, batch=15 train loss <loss>=8.39456253052\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:08 INFO 140207931545408] Epoch[79] Batch [15]#011Speed: 2092.05 samples/sec#011loss=8.394563\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[79] Batch[20] avg_epoch_loss=8.189831\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=79, batch=20 train loss <loss>=8.04359560013\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[79] Batch [20]#011Speed: 1130.29 samples/sec#011loss=8.043596\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[79] Batch[25] avg_epoch_loss=8.117238\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=79, batch=25 train loss <loss>=7.81234445572\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[79] Batch [25]#011Speed: 1656.14 samples/sec#011loss=7.812344\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[79] Batch[30] avg_epoch_loss=8.068718\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=79, batch=30 train loss <loss>=7.81641683578\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[79] Batch [30]#011Speed: 1016.17 samples/sec#011loss=7.816417\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[79] Batch[35] avg_epoch_loss=8.026526\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=79, batch=35 train loss <loss>=7.76493549347\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[79] Batch [35]#011Speed: 1661.44 samples/sec#011loss=7.764935\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[79] Batch[40] avg_epoch_loss=8.015260\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=79, batch=40 train loss <loss>=7.93414516449\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[79] Batch [40]#011Speed: 990.76 samples/sec#011loss=7.934145\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[79] Batch[45] avg_epoch_loss=7.994547\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=79, batch=45 train loss <loss>=7.82470216751\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[79] Batch [45]#011Speed: 1934.07 samples/sec#011loss=7.824702\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] processed a total of 1564 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1219.8529243469238, \"sum\": 1219.8529243469238, \"min\": 1219.8529243469238}}, \"EndTime\": 1577369829.772581, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369828.552648}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1281.98497082 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=79, train loss <loss>=7.94725410306\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[80] Batch[0] avg_epoch_loss=7.915910\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=7.91591024399\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[80] Batch[5] avg_epoch_loss=8.154327\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=8.15432667732\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:09 INFO 140207931545408] Epoch[80] Batch [5]#011Speed: 2099.13 samples/sec#011loss=8.154327\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch[10] avg_epoch_loss=8.265340\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=8.39855594635\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch [10]#011Speed: 981.82 samples/sec#011loss=8.398556\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch[15] avg_epoch_loss=8.326552\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=80, batch=15 train loss <loss>=8.46121826172\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch [15]#011Speed: 1791.45 samples/sec#011loss=8.461218\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch[20] avg_epoch_loss=8.314149\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=80, batch=20 train loss <loss>=8.27445793152\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch [20]#011Speed: 827.72 samples/sec#011loss=8.274458\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch[25] avg_epoch_loss=8.266022\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=80, batch=25 train loss <loss>=8.06388988495\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch [25]#011Speed: 1777.58 samples/sec#011loss=8.063890\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch[30] avg_epoch_loss=8.189766\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=80, batch=30 train loss <loss>=7.79323577881\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch [30]#011Speed: 922.16 samples/sec#011loss=7.793236\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch[35] avg_epoch_loss=8.088564\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=80, batch=35 train loss <loss>=7.4611117363\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch [35]#011Speed: 2139.78 samples/sec#011loss=7.461112\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch[40] avg_epoch_loss=8.050377\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=80, batch=40 train loss <loss>=7.77542743683\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch [40]#011Speed: 1013.89 samples/sec#011loss=7.775427\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch[45] avg_epoch_loss=8.054253\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] #quality_metric: host=algo-1, epoch=80, batch=45 train loss <loss>=8.08603963852\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:10 INFO 140207931545408] Epoch[80] Batch [45]#011Speed: 1717.77 samples/sec#011loss=8.086040\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] processed a total of 1576 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1299.757957458496, \"sum\": 1299.757957458496, \"min\": 1299.757957458496}}, \"EndTime\": 1577369831.072937, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369829.772652}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1212.42692055 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=80, train loss <loss>=8.09107553482\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch[0] avg_epoch_loss=8.333062\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=8.33306217194\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch[5] avg_epoch_loss=8.243029\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=8.24302864075\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch [5]#011Speed: 2070.15 samples/sec#011loss=8.243029\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch[10] avg_epoch_loss=8.216391\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=8.18442659378\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch [10]#011Speed: 1011.99 samples/sec#011loss=8.184427\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch[15] avg_epoch_loss=8.355558\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=81, batch=15 train loss <loss>=8.66172466278\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch [15]#011Speed: 2084.94 samples/sec#011loss=8.661725\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch[20] avg_epoch_loss=8.319527\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=81, batch=20 train loss <loss>=8.20422906876\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch [20]#011Speed: 1138.42 samples/sec#011loss=8.204229\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch[25] avg_epoch_loss=8.246015\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=81, batch=25 train loss <loss>=7.93726415634\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch [25]#011Speed: 1646.16 samples/sec#011loss=7.937264\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch[30] avg_epoch_loss=8.194215\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=81, batch=30 train loss <loss>=7.92485370636\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch [30]#011Speed: 973.50 samples/sec#011loss=7.924854\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch[35] avg_epoch_loss=8.172358\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] #quality_metric: host=algo-1, epoch=81, batch=35 train loss <loss>=8.03684844971\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:11 INFO 140207931545408] Epoch[81] Batch [35]#011Speed: 2069.48 samples/sec#011loss=8.036848\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[81] Batch[40] avg_epoch_loss=8.129467\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=81, batch=40 train loss <loss>=7.82065172195\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[81] Batch [40]#011Speed: 1106.39 samples/sec#011loss=7.820652\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[81] Batch[45] avg_epoch_loss=8.086042\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=81, batch=45 train loss <loss>=7.72995271683\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[81] Batch [45]#011Speed: 1487.46 samples/sec#011loss=7.729953\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] processed a total of 1545 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1191.7319297790527, \"sum\": 1191.7319297790527, \"min\": 1191.7319297790527}}, \"EndTime\": 1577369832.265242, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369831.073012}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1296.286749 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=81, train loss <loss>=8.06123626475\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[82] Batch[0] avg_epoch_loss=8.433563\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=8.43356323242\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[82] Batch[5] avg_epoch_loss=8.357001\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=8.3570005099\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[82] Batch [5]#011Speed: 2030.38 samples/sec#011loss=8.357001\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[82] Batch[10] avg_epoch_loss=8.367991\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=8.38118019104\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[82] Batch [10]#011Speed: 928.94 samples/sec#011loss=8.381180\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[82] Batch[15] avg_epoch_loss=8.423935\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=82, batch=15 train loss <loss>=8.54701061249\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[82] Batch [15]#011Speed: 2029.86 samples/sec#011loss=8.547011\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[82] Batch[20] avg_epoch_loss=8.459308\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=82, batch=20 train loss <loss>=8.57250289917\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[82] Batch [20]#011Speed: 925.86 samples/sec#011loss=8.572503\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[82] Batch[25] avg_epoch_loss=8.354311\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] #quality_metric: host=algo-1, epoch=82, batch=25 train loss <loss>=7.91332187653\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:12 INFO 140207931545408] Epoch[82] Batch [25]#011Speed: 1906.58 samples/sec#011loss=7.913322\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[82] Batch[30] avg_epoch_loss=8.259049\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=82, batch=30 train loss <loss>=7.76368989944\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[82] Batch [30]#011Speed: 1113.44 samples/sec#011loss=7.763690\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[82] Batch[35] avg_epoch_loss=8.188599\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=82, batch=35 train loss <loss>=7.75180616379\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[82] Batch [35]#011Speed: 2012.33 samples/sec#011loss=7.751806\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[82] Batch[40] avg_epoch_loss=8.174892\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=82, batch=40 train loss <loss>=8.0762055397\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[82] Batch [40]#011Speed: 896.66 samples/sec#011loss=8.076206\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[82] Batch[45] avg_epoch_loss=8.163673\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=82, batch=45 train loss <loss>=8.07167606354\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[82] Batch [45]#011Speed: 2097.45 samples/sec#011loss=8.071676\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[82] Batch[50] avg_epoch_loss=8.125680\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=82, batch=50 train loss <loss>=7.77614707947\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[82] Batch [50]#011Speed: 1558.36 samples/sec#011loss=7.776147\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] processed a total of 1633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1287.15181350708, \"sum\": 1287.15181350708, \"min\": 1287.15181350708}}, \"EndTime\": 1577369833.55293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369832.265331}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1268.55327553 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=82, train loss <loss>=8.09385152963\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[83] Batch[0] avg_epoch_loss=8.762310\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=8.76231002808\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[83] Batch[5] avg_epoch_loss=8.490064\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=8.49006406466\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[83] Batch [5]#011Speed: 1841.75 samples/sec#011loss=8.490064\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[83] Batch[10] avg_epoch_loss=8.409117\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=8.31198139191\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[83] Batch [10]#011Speed: 920.01 samples/sec#011loss=8.311981\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[83] Batch[15] avg_epoch_loss=8.436308\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] #quality_metric: host=algo-1, epoch=83, batch=15 train loss <loss>=8.49612598419\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:13 INFO 140207931545408] Epoch[83] Batch [15]#011Speed: 1995.64 samples/sec#011loss=8.496126\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch[20] avg_epoch_loss=8.364669\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=83, batch=20 train loss <loss>=8.1354265213\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch [20]#011Speed: 1081.00 samples/sec#011loss=8.135427\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch[25] avg_epoch_loss=8.295486\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=83, batch=25 train loss <loss>=8.00491809845\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch [25]#011Speed: 1634.10 samples/sec#011loss=8.004918\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch[30] avg_epoch_loss=8.211863\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=83, batch=30 train loss <loss>=7.77701873779\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch [30]#011Speed: 952.32 samples/sec#011loss=7.777019\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch[35] avg_epoch_loss=8.148437\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=83, batch=35 train loss <loss>=7.75520029068\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch [35]#011Speed: 1922.17 samples/sec#011loss=7.755200\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch[40] avg_epoch_loss=8.097745\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=83, batch=40 train loss <loss>=7.73275728226\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch [40]#011Speed: 1046.18 samples/sec#011loss=7.732757\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch[45] avg_epoch_loss=8.096848\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=83, batch=45 train loss <loss>=8.08949337006\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch [45]#011Speed: 1658.32 samples/sec#011loss=8.089493\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch[50] avg_epoch_loss=8.040913\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=83, batch=50 train loss <loss>=7.5263176918\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[83] Batch [50]#011Speed: 1477.42 samples/sec#011loss=7.526318\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] processed a total of 1616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1291.5050983428955, \"sum\": 1291.5050983428955, \"min\": 1291.5050983428955}}, \"EndTime\": 1577369834.845027, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369833.553026}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1251.14011358 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=83, train loss <loss>=8.04091335745\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] Epoch[84] Batch[0] avg_epoch_loss=8.127738\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:14 INFO 140207931545408] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=8.12773799896\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch[5] avg_epoch_loss=8.201953\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=8.2019534111\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch [5]#011Speed: 1759.73 samples/sec#011loss=8.201953\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch[10] avg_epoch_loss=8.325242\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=8.47318744659\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch [10]#011Speed: 926.73 samples/sec#011loss=8.473187\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch[15] avg_epoch_loss=8.331155\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=84, batch=15 train loss <loss>=8.34416465759\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch [15]#011Speed: 1550.73 samples/sec#011loss=8.344165\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch[20] avg_epoch_loss=8.261717\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=84, batch=20 train loss <loss>=8.03951663971\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch [20]#011Speed: 912.92 samples/sec#011loss=8.039517\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch[25] avg_epoch_loss=8.210774\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=84, batch=25 train loss <loss>=7.99681053162\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch [25]#011Speed: 2077.60 samples/sec#011loss=7.996811\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch[30] avg_epoch_loss=8.133746\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=84, batch=30 train loss <loss>=7.733203125\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch [30]#011Speed: 921.59 samples/sec#011loss=7.733203\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch[35] avg_epoch_loss=8.054018\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] #quality_metric: host=algo-1, epoch=84, batch=35 train loss <loss>=7.55970277786\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:15 INFO 140207931545408] Epoch[84] Batch [35]#011Speed: 1619.81 samples/sec#011loss=7.559703\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[84] Batch[40] avg_epoch_loss=8.054534\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=84, batch=40 train loss <loss>=8.05825157166\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[84] Batch [40]#011Speed: 915.83 samples/sec#011loss=8.058252\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[84] Batch[45] avg_epoch_loss=8.041665\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=84, batch=45 train loss <loss>=7.93613967896\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[84] Batch [45]#011Speed: 1908.97 samples/sec#011loss=7.936140\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] processed a total of 1542 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1303.9710521697998, \"sum\": 1303.9710521697998, \"min\": 1303.9710521697998}}, \"EndTime\": 1577369836.149546, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369834.845104}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1182.41554826 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=84, train loss <loss>=8.01127210928\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch[0] avg_epoch_loss=8.196054\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=8.19605350494\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch[5] avg_epoch_loss=8.252726\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=8.25272568067\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch [5]#011Speed: 1961.39 samples/sec#011loss=8.252726\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch[10] avg_epoch_loss=8.231906\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=8.20692243576\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch [10]#011Speed: 1010.52 samples/sec#011loss=8.206922\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch[15] avg_epoch_loss=8.314588\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=85, batch=15 train loss <loss>=8.49648780823\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch [15]#011Speed: 1664.31 samples/sec#011loss=8.496488\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch[20] avg_epoch_loss=8.216415\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=85, batch=20 train loss <loss>=7.90226078033\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch [20]#011Speed: 961.40 samples/sec#011loss=7.902261\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch[25] avg_epoch_loss=8.176862\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=85, batch=25 train loss <loss>=8.01074171066\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch [25]#011Speed: 1844.13 samples/sec#011loss=8.010742\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch[30] avg_epoch_loss=8.094025\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] #quality_metric: host=algo-1, epoch=85, batch=30 train loss <loss>=7.66326847076\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:16 INFO 140207931545408] Epoch[85] Batch [30]#011Speed: 1095.13 samples/sec#011loss=7.663268\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[85] Batch[35] avg_epoch_loss=8.028939\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=85, batch=35 train loss <loss>=7.62540884018\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[85] Batch [35]#011Speed: 2093.20 samples/sec#011loss=7.625409\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[85] Batch[40] avg_epoch_loss=8.030011\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=85, batch=40 train loss <loss>=8.0377289772\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[85] Batch [40]#011Speed: 1023.01 samples/sec#011loss=8.037729\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[85] Batch[45] avg_epoch_loss=7.980863\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=85, batch=45 train loss <loss>=7.57785358429\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[85] Batch [45]#011Speed: 1599.70 samples/sec#011loss=7.577854\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] processed a total of 1517 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1210.0930213928223, \"sum\": 1210.0930213928223, \"min\": 1210.0930213928223}}, \"EndTime\": 1577369837.36018, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369836.149634}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1253.48581299 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=85, train loss <loss>=7.94029717644\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[86] Batch[0] avg_epoch_loss=8.156832\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=8.15683174133\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[86] Batch[5] avg_epoch_loss=8.136161\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=8.13616061211\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[86] Batch [5]#011Speed: 2067.29 samples/sec#011loss=8.136161\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[86] Batch[10] avg_epoch_loss=8.248102\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=8.38243217468\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[86] Batch [10]#011Speed: 1013.12 samples/sec#011loss=8.382432\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[86] Batch[15] avg_epoch_loss=8.287356\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=86, batch=15 train loss <loss>=8.37371549606\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[86] Batch [15]#011Speed: 1654.93 samples/sec#011loss=8.373715\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[86] Batch[20] avg_epoch_loss=8.356854\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] #quality_metric: host=algo-1, epoch=86, batch=20 train loss <loss>=8.57924671173\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:17 INFO 140207931545408] Epoch[86] Batch [20]#011Speed: 1912.00 samples/sec#011loss=8.579247\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[86] Batch[25] avg_epoch_loss=8.257763\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=86, batch=25 train loss <loss>=7.84158220291\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[86] Batch [25]#011Speed: 1041.75 samples/sec#011loss=7.841582\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[86] Batch[30] avg_epoch_loss=8.245006\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=86, batch=30 train loss <loss>=8.1786696434\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[86] Batch [30]#011Speed: 1671.20 samples/sec#011loss=8.178670\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[86] Batch[35] avg_epoch_loss=8.188618\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=86, batch=35 train loss <loss>=7.83901414871\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[86] Batch [35]#011Speed: 934.85 samples/sec#011loss=7.839014\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[86] Batch[40] avg_epoch_loss=8.150072\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=86, batch=40 train loss <loss>=7.87253713608\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[86] Batch [40]#011Speed: 1672.82 samples/sec#011loss=7.872537\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[86] Batch[45] avg_epoch_loss=8.138086\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=86, batch=45 train loss <loss>=8.03980283737\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[86] Batch [45]#011Speed: 965.62 samples/sec#011loss=8.039803\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[86] Batch[50] avg_epoch_loss=8.079332\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=86, batch=50 train loss <loss>=7.53879585266\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[86] Batch [50]#011Speed: 1641.95 samples/sec#011loss=7.538796\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] processed a total of 1644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1313.02809715271, \"sum\": 1313.02809715271, \"min\": 1313.02809715271}}, \"EndTime\": 1577369838.673795, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369837.36027}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1251.94102614 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=86, train loss <loss>=8.01841967839\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[87] Batch[0] avg_epoch_loss=8.072409\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=8.07240867615\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[87] Batch[5] avg_epoch_loss=8.260820\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=8.26081975301\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:18 INFO 140207931545408] Epoch[87] Batch [5]#011Speed: 1663.46 samples/sec#011loss=8.260820\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch[10] avg_epoch_loss=8.239236\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=8.21333475113\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch [10]#011Speed: 1046.20 samples/sec#011loss=8.213335\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch[15] avg_epoch_loss=8.356343\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=87, batch=15 train loss <loss>=8.61397838593\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch [15]#011Speed: 2050.28 samples/sec#011loss=8.613978\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch[20] avg_epoch_loss=8.381813\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=87, batch=20 train loss <loss>=8.46331615448\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch [20]#011Speed: 1028.74 samples/sec#011loss=8.463316\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch[25] avg_epoch_loss=8.229014\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=87, batch=25 train loss <loss>=7.58726148605\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch [25]#011Speed: 2028.43 samples/sec#011loss=7.587261\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch[30] avg_epoch_loss=8.154702\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=87, batch=30 train loss <loss>=7.7682800293\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch [30]#011Speed: 1037.13 samples/sec#011loss=7.768280\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch[35] avg_epoch_loss=8.097908\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=87, batch=35 train loss <loss>=7.74578561783\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch [35]#011Speed: 2079.52 samples/sec#011loss=7.745786\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch[40] avg_epoch_loss=8.099959\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=87, batch=40 train loss <loss>=8.11472187042\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch [40]#011Speed: 934.81 samples/sec#011loss=8.114722\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch[45] avg_epoch_loss=8.100358\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=87, batch=45 train loss <loss>=8.10362911224\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch [45]#011Speed: 1812.27 samples/sec#011loss=8.103629\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch[50] avg_epoch_loss=8.034436\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=87, batch=50 train loss <loss>=7.42796049118\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] Epoch[87] Batch [50]#011Speed: 1442.90 samples/sec#011loss=7.427960\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] processed a total of 1632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1265.4659748077393, \"sum\": 1265.4659748077393, \"min\": 1265.4659748077393}}, \"EndTime\": 1577369839.939823, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369838.673883}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1289.51427553 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] #quality_metric: host=algo-1, epoch=87, train loss <loss>=8.03443643159\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:19 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch[0] avg_epoch_loss=8.597093\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=8.59709262848\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch[5] avg_epoch_loss=8.401225\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=8.40122509003\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch [5]#011Speed: 2022.34 samples/sec#011loss=8.401225\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch[10] avg_epoch_loss=8.342919\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=8.27295227051\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch [10]#011Speed: 930.07 samples/sec#011loss=8.272952\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch[15] avg_epoch_loss=8.375951\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=88, batch=15 train loss <loss>=8.44862098694\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch [15]#011Speed: 1610.58 samples/sec#011loss=8.448621\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch[20] avg_epoch_loss=8.410722\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=88, batch=20 train loss <loss>=8.52198696136\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch [20]#011Speed: 960.08 samples/sec#011loss=8.521987\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch[25] avg_epoch_loss=8.316882\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=88, batch=25 train loss <loss>=7.92275390625\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch [25]#011Speed: 2139.10 samples/sec#011loss=7.922754\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch[30] avg_epoch_loss=8.204913\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=88, batch=30 train loss <loss>=7.62267599106\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch [30]#011Speed: 991.28 samples/sec#011loss=7.622676\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch[35] avg_epoch_loss=8.143662\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] #quality_metric: host=algo-1, epoch=88, batch=35 train loss <loss>=7.7639046669\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:20 INFO 140207931545408] Epoch[88] Batch [35]#011Speed: 1982.04 samples/sec#011loss=7.763905\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[88] Batch[40] avg_epoch_loss=8.106115\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=88, batch=40 train loss <loss>=7.83577957153\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[88] Batch [40]#011Speed: 1005.82 samples/sec#011loss=7.835780\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[88] Batch[45] avg_epoch_loss=8.127853\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=88, batch=45 train loss <loss>=8.30610027313\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[88] Batch [45]#011Speed: 2155.44 samples/sec#011loss=8.306100\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] processed a total of 1598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1264.0109062194824, \"sum\": 1264.0109062194824, \"min\": 1264.0109062194824}}, \"EndTime\": 1577369841.204378, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369839.939909}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1264.09345223 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=88, train loss <loss>=8.06973377228\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[89] Batch[0] avg_epoch_loss=8.365311\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=8.36531066895\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[89] Batch[5] avg_epoch_loss=8.106365\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=8.10636488597\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[89] Batch [5]#011Speed: 2073.62 samples/sec#011loss=8.106365\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[89] Batch[10] avg_epoch_loss=8.201273\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=8.3151638031\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[89] Batch [10]#011Speed: 956.61 samples/sec#011loss=8.315164\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[89] Batch[15] avg_epoch_loss=8.280761\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=89, batch=15 train loss <loss>=8.45563488007\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[89] Batch [15]#011Speed: 1783.33 samples/sec#011loss=8.455635\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[89] Batch[20] avg_epoch_loss=8.268270\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=89, batch=20 train loss <loss>=8.22829904556\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[89] Batch [20]#011Speed: 932.91 samples/sec#011loss=8.228299\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[89] Batch[25] avg_epoch_loss=8.214722\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] #quality_metric: host=algo-1, epoch=89, batch=25 train loss <loss>=7.98981800079\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:21 INFO 140207931545408] Epoch[89] Batch [25]#011Speed: 2037.10 samples/sec#011loss=7.989818\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[89] Batch[30] avg_epoch_loss=8.148004\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=89, batch=30 train loss <loss>=7.80106840134\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[89] Batch [30]#011Speed: 947.75 samples/sec#011loss=7.801068\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[89] Batch[35] avg_epoch_loss=8.080874\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=89, batch=35 train loss <loss>=7.66467418671\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[89] Batch [35]#011Speed: 1650.98 samples/sec#011loss=7.664674\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[89] Batch[40] avg_epoch_loss=8.049766\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=89, batch=40 train loss <loss>=7.82578697205\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[89] Batch [40]#011Speed: 915.56 samples/sec#011loss=7.825787\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[89] Batch[45] avg_epoch_loss=8.064188\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=89, batch=45 train loss <loss>=8.18244457245\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[89] Batch [45]#011Speed: 1638.49 samples/sec#011loss=8.182445\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] processed a total of 1589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1326.465129852295, \"sum\": 1326.465129852295, \"min\": 1326.465129852295}}, \"EndTime\": 1577369842.531364, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369841.204472}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1197.81065684 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=89, train loss <loss>=8.05825539589\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[90] Batch[0] avg_epoch_loss=8.247633\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=8.24763298035\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[90] Batch[5] avg_epoch_loss=8.011554\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=8.01155440013\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[90] Batch [5]#011Speed: 1660.11 samples/sec#011loss=8.011554\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[90] Batch[10] avg_epoch_loss=8.072162\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=8.14489021301\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[90] Batch [10]#011Speed: 928.06 samples/sec#011loss=8.144890\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[90] Batch[15] avg_epoch_loss=8.229520\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] #quality_metric: host=algo-1, epoch=90, batch=15 train loss <loss>=8.57570800781\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:22 INFO 140207931545408] Epoch[90] Batch [15]#011Speed: 2079.65 samples/sec#011loss=8.575708\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch[20] avg_epoch_loss=8.157446\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=90, batch=20 train loss <loss>=7.9268116951\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch [20]#011Speed: 1069.19 samples/sec#011loss=7.926812\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch[25] avg_epoch_loss=8.117908\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=90, batch=25 train loss <loss>=7.95184469223\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch [25]#011Speed: 1928.80 samples/sec#011loss=7.951845\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch[30] avg_epoch_loss=8.030567\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=90, batch=30 train loss <loss>=7.57639503479\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch [30]#011Speed: 890.10 samples/sec#011loss=7.576395\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch[35] avg_epoch_loss=7.985310\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=90, batch=35 train loss <loss>=7.70471487045\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch [35]#011Speed: 2078.36 samples/sec#011loss=7.704715\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch[40] avg_epoch_loss=7.997132\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=90, batch=40 train loss <loss>=8.08225641251\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch [40]#011Speed: 896.20 samples/sec#011loss=8.082256\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch[45] avg_epoch_loss=7.980276\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=90, batch=45 train loss <loss>=7.84205341339\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch [45]#011Speed: 1647.67 samples/sec#011loss=7.842053\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch[50] avg_epoch_loss=7.965241\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=90, batch=50 train loss <loss>=7.82692041397\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[90] Batch [50]#011Speed: 1376.10 samples/sec#011loss=7.826920\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] processed a total of 1609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1321.4540481567383, \"sum\": 1321.4540481567383, \"min\": 1321.4540481567383}}, \"EndTime\": 1577369843.853418, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369842.531443}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1217.47557719 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=90, train loss <loss>=7.96524117975\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] Epoch[91] Batch[0] avg_epoch_loss=8.545980\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:23 INFO 140207931545408] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=8.54598045349\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch[5] avg_epoch_loss=8.350567\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=8.35056726138\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch [5]#011Speed: 1738.72 samples/sec#011loss=8.350567\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch[10] avg_epoch_loss=8.331376\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=8.30834674835\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch [10]#011Speed: 982.34 samples/sec#011loss=8.308347\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch[15] avg_epoch_loss=8.249140\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=91, batch=15 train loss <loss>=8.06822118759\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch [15]#011Speed: 2010.66 samples/sec#011loss=8.068221\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch[20] avg_epoch_loss=8.230486\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=91, batch=20 train loss <loss>=8.17079305649\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch [20]#011Speed: 1033.71 samples/sec#011loss=8.170793\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch[25] avg_epoch_loss=8.185820\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=91, batch=25 train loss <loss>=7.9982216835\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch [25]#011Speed: 2090.41 samples/sec#011loss=7.998222\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch[30] avg_epoch_loss=8.148312\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=91, batch=30 train loss <loss>=7.95327291489\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch [30]#011Speed: 1063.05 samples/sec#011loss=7.953273\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch[35] avg_epoch_loss=8.096111\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=91, batch=35 train loss <loss>=7.7724606514\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch [35]#011Speed: 2095.67 samples/sec#011loss=7.772461\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch[40] avg_epoch_loss=8.055072\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=91, batch=40 train loss <loss>=7.75959482193\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch [40]#011Speed: 1002.51 samples/sec#011loss=7.759595\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch[45] avg_epoch_loss=8.013011\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] #quality_metric: host=algo-1, epoch=91, batch=45 train loss <loss>=7.66811323166\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:24 INFO 140207931545408] Epoch[91] Batch [45]#011Speed: 1832.88 samples/sec#011loss=7.668113\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[91] Batch[50] avg_epoch_loss=8.021833\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=91, batch=50 train loss <loss>=8.10298748016\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[91] Batch [50]#011Speed: 1475.57 samples/sec#011loss=8.102987\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] processed a total of 1626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1241.4040565490723, \"sum\": 1241.4040565490723, \"min\": 1241.4040565490723}}, \"EndTime\": 1577369845.095402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369843.853506}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1309.67114551 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=91, train loss <loss>=8.02183259702\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch[0] avg_epoch_loss=8.228043\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=8.22804260254\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch[5] avg_epoch_loss=8.204076\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=8.20407605171\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch [5]#011Speed: 2054.50 samples/sec#011loss=8.204076\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch[10] avg_epoch_loss=8.291740\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=8.39693613052\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch [10]#011Speed: 808.89 samples/sec#011loss=8.396936\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch[15] avg_epoch_loss=8.445064\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=92, batch=15 train loss <loss>=8.78237857819\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch [15]#011Speed: 2078.38 samples/sec#011loss=8.782379\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch[20] avg_epoch_loss=8.428564\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=92, batch=20 train loss <loss>=8.37576465607\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch [20]#011Speed: 997.21 samples/sec#011loss=8.375765\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch[25] avg_epoch_loss=8.323385\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=92, batch=25 train loss <loss>=7.88163204193\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch [25]#011Speed: 1661.18 samples/sec#011loss=7.881632\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch[30] avg_epoch_loss=8.251739\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] #quality_metric: host=algo-1, epoch=92, batch=30 train loss <loss>=7.87917976379\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:25 INFO 140207931545408] Epoch[92] Batch [30]#011Speed: 968.42 samples/sec#011loss=7.879180\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[92] Batch[35] avg_epoch_loss=8.179210\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=92, batch=35 train loss <loss>=7.72952814102\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[92] Batch [35]#011Speed: 2039.83 samples/sec#011loss=7.729528\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[92] Batch[40] avg_epoch_loss=8.156929\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=92, batch=40 train loss <loss>=7.99650363922\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[92] Batch [40]#011Speed: 1035.91 samples/sec#011loss=7.996504\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[92] Batch[45] avg_epoch_loss=8.152246\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=92, batch=45 train loss <loss>=8.11384906769\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[92] Batch [45]#011Speed: 2080.38 samples/sec#011loss=8.113849\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[92] Batch[50] avg_epoch_loss=8.079356\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=92, batch=50 train loss <loss>=7.40877027512\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[92] Batch [50]#011Speed: 1659.25 samples/sec#011loss=7.408770\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] processed a total of 1643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1296.8220710754395, \"sum\": 1296.8220710754395, \"min\": 1296.8220710754395}}, \"EndTime\": 1577369846.392742, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369845.095488}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1266.81727348 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=92, train loss <loss>=8.10921918429\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[93] Batch[0] avg_epoch_loss=8.335268\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=8.33526802063\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[93] Batch[5] avg_epoch_loss=8.103546\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=8.10354614258\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[93] Batch [5]#011Speed: 1943.78 samples/sec#011loss=8.103546\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[93] Batch[10] avg_epoch_loss=8.278868\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=8.48925495148\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[93] Batch [10]#011Speed: 1100.20 samples/sec#011loss=8.489255\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[93] Batch[15] avg_epoch_loss=8.367767\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=93, batch=15 train loss <loss>=8.56334257126\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[93] Batch [15]#011Speed: 2077.03 samples/sec#011loss=8.563343\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[93] Batch[20] avg_epoch_loss=8.344909\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] #quality_metric: host=algo-1, epoch=93, batch=20 train loss <loss>=8.27176456451\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:26 INFO 140207931545408] Epoch[93] Batch [20]#011Speed: 1059.55 samples/sec#011loss=8.271765\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[93] Batch[25] avg_epoch_loss=8.288879\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=93, batch=25 train loss <loss>=8.05355262756\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[93] Batch [25]#011Speed: 1980.96 samples/sec#011loss=8.053553\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[93] Batch[30] avg_epoch_loss=8.216782\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=93, batch=30 train loss <loss>=7.84187574387\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[93] Batch [30]#011Speed: 1017.68 samples/sec#011loss=7.841876\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[93] Batch[35] avg_epoch_loss=8.165442\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=93, batch=35 train loss <loss>=7.8471362114\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[93] Batch [35]#011Speed: 1655.34 samples/sec#011loss=7.847136\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[93] Batch[40] avg_epoch_loss=8.143730\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=93, batch=40 train loss <loss>=7.98740568161\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[93] Batch [40]#011Speed: 975.09 samples/sec#011loss=7.987406\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[93] Batch[45] avg_epoch_loss=8.121786\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=93, batch=45 train loss <loss>=7.94183931351\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[93] Batch [45]#011Speed: 1730.06 samples/sec#011loss=7.941839\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] processed a total of 1542 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1215.9769535064697, \"sum\": 1215.9769535064697, \"min\": 1215.9769535064697}}, \"EndTime\": 1577369847.609244, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369846.39283}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1267.99108511 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=93, train loss <loss>=8.04613685608\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[94] Batch[0] avg_epoch_loss=8.424108\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=8.42410755157\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[94] Batch[5] avg_epoch_loss=8.158581\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=8.15858093898\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[94] Batch [5]#011Speed: 1780.78 samples/sec#011loss=8.158581\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[94] Batch[10] avg_epoch_loss=8.333312\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=8.5429895401\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:27 INFO 140207931545408] Epoch[94] Batch [10]#011Speed: 963.38 samples/sec#011loss=8.542990\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch[15] avg_epoch_loss=8.435352\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=94, batch=15 train loss <loss>=8.65984077454\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch [15]#011Speed: 1776.38 samples/sec#011loss=8.659841\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch[20] avg_epoch_loss=8.380080\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=94, batch=20 train loss <loss>=8.20320663452\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch [20]#011Speed: 1018.75 samples/sec#011loss=8.203207\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch[25] avg_epoch_loss=8.274495\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=94, batch=25 train loss <loss>=7.83104124069\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch [25]#011Speed: 1886.44 samples/sec#011loss=7.831041\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch[30] avg_epoch_loss=8.213500\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=94, batch=30 train loss <loss>=7.89632749557\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch [30]#011Speed: 870.19 samples/sec#011loss=7.896327\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch[35] avg_epoch_loss=8.159014\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=94, batch=35 train loss <loss>=7.8211974144\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch [35]#011Speed: 1731.96 samples/sec#011loss=7.821197\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch[40] avg_epoch_loss=8.134370\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=94, batch=40 train loss <loss>=7.95692968369\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch [40]#011Speed: 993.52 samples/sec#011loss=7.956930\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch[45] avg_epoch_loss=8.081502\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=94, batch=45 train loss <loss>=7.64798793793\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch [45]#011Speed: 1831.27 samples/sec#011loss=7.647988\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch[50] avg_epoch_loss=8.014252\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=94, batch=50 train loss <loss>=7.39555635452\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] Epoch[94] Batch [50]#011Speed: 1782.85 samples/sec#011loss=7.395556\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] processed a total of 1636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1315.7179355621338, \"sum\": 1315.7179355621338, \"min\": 1315.7179355621338}}, \"EndTime\": 1577369848.925583, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369847.609328}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1243.33297711 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] #quality_metric: host=algo-1, epoch=94, train loss <loss>=7.99519044619\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:28 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch[0] avg_epoch_loss=8.722442\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=8.72244167328\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch[5] avg_epoch_loss=8.280151\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=8.28015112877\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch [5]#011Speed: 2023.55 samples/sec#011loss=8.280151\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch[10] avg_epoch_loss=8.310706\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=8.34737205505\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch [10]#011Speed: 955.77 samples/sec#011loss=8.347372\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch[15] avg_epoch_loss=8.256929\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=95, batch=15 train loss <loss>=8.13861875534\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch [15]#011Speed: 1809.42 samples/sec#011loss=8.138619\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch[20] avg_epoch_loss=8.289868\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=95, batch=20 train loss <loss>=8.39527244568\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch [20]#011Speed: 963.97 samples/sec#011loss=8.395272\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch[25] avg_epoch_loss=8.217154\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=95, batch=25 train loss <loss>=7.91175689697\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch [25]#011Speed: 1891.54 samples/sec#011loss=7.911757\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch[30] avg_epoch_loss=8.152101\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=95, batch=30 train loss <loss>=7.8138258934\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch [30]#011Speed: 1094.78 samples/sec#011loss=7.813826\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch[35] avg_epoch_loss=8.118468\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] #quality_metric: host=algo-1, epoch=95, batch=35 train loss <loss>=7.90994462967\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:29 INFO 140207931545408] Epoch[95] Batch [35]#011Speed: 2082.65 samples/sec#011loss=7.909945\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[95] Batch[40] avg_epoch_loss=8.114212\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=95, batch=40 train loss <loss>=8.08356685638\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[95] Batch [40]#011Speed: 903.59 samples/sec#011loss=8.083567\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[95] Batch[45] avg_epoch_loss=8.067543\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=95, batch=45 train loss <loss>=7.68485393524\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[95] Batch [45]#011Speed: 1817.02 samples/sec#011loss=7.684854\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[95] Batch[50] avg_epoch_loss=8.046113\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=95, batch=50 train loss <loss>=7.84896240234\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[95] Batch [50]#011Speed: 1549.05 samples/sec#011loss=7.848962\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] processed a total of 1650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1284.865140914917, \"sum\": 1284.865140914917, \"min\": 1284.865140914917}}, \"EndTime\": 1577369850.211002, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369848.925647}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1284.04470091 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=95, train loss <loss>=8.04174315929\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[96] Batch[0] avg_epoch_loss=8.525078\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=8.52507781982\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[96] Batch[5] avg_epoch_loss=8.332098\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=8.33209808668\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[96] Batch [5]#011Speed: 1765.33 samples/sec#011loss=8.332098\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[96] Batch[10] avg_epoch_loss=8.243935\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=8.1381398201\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[96] Batch [10]#011Speed: 1754.77 samples/sec#011loss=8.138140\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[96] Batch[15] avg_epoch_loss=8.271407\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=96, batch=15 train loss <loss>=8.33184623718\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[96] Batch [15]#011Speed: 1079.40 samples/sec#011loss=8.331846\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[96] Batch[20] avg_epoch_loss=8.251526\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=96, batch=20 train loss <loss>=8.18790550232\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[96] Batch [20]#011Speed: 844.03 samples/sec#011loss=8.187906\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[96] Batch[25] avg_epoch_loss=8.198396\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] #quality_metric: host=algo-1, epoch=96, batch=25 train loss <loss>=7.97525215149\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:30 INFO 140207931545408] Epoch[96] Batch [25]#011Speed: 1979.34 samples/sec#011loss=7.975252\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[96] Batch[30] avg_epoch_loss=8.140093\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=96, batch=30 train loss <loss>=7.8369178772\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[96] Batch [30]#011Speed: 859.55 samples/sec#011loss=7.836918\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[96] Batch[35] avg_epoch_loss=8.058351\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=96, batch=35 train loss <loss>=7.55154695511\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[96] Batch [35]#011Speed: 1768.03 samples/sec#011loss=7.551547\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[96] Batch[40] avg_epoch_loss=8.033307\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=96, batch=40 train loss <loss>=7.85299024582\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[96] Batch [40]#011Speed: 896.36 samples/sec#011loss=7.852990\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[96] Batch[45] avg_epoch_loss=8.026229\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=96, batch=45 train loss <loss>=7.96819133759\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[96] Batch [45]#011Speed: 1884.90 samples/sec#011loss=7.968191\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[96] Batch[50] avg_epoch_loss=7.968502\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=96, batch=50 train loss <loss>=7.43741559982\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[96] Batch [50]#011Speed: 1420.50 samples/sec#011loss=7.437416\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] processed a total of 1642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1386.1970901489258, \"sum\": 1386.1970901489258, \"min\": 1386.1970901489258}}, \"EndTime\": 1577369851.597737, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369850.211097}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1184.4188112 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=96, train loss <loss>=7.95782684363\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[97] Batch[0] avg_epoch_loss=8.367635\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=8.36763477325\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[97] Batch[5] avg_epoch_loss=8.081743\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=8.08174276352\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[97] Batch [5]#011Speed: 1694.88 samples/sec#011loss=8.081743\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[97] Batch[10] avg_epoch_loss=8.135031\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=8.19897603989\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:31 INFO 140207931545408] Epoch[97] Batch [10]#011Speed: 986.73 samples/sec#011loss=8.198976\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch[15] avg_epoch_loss=8.205975\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=97, batch=15 train loss <loss>=8.36205387115\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch [15]#011Speed: 2095.72 samples/sec#011loss=8.362054\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch[20] avg_epoch_loss=8.200655\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=97, batch=20 train loss <loss>=8.18362846375\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch [20]#011Speed: 919.50 samples/sec#011loss=8.183628\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch[25] avg_epoch_loss=8.155899\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=97, batch=25 train loss <loss>=7.96792564392\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch [25]#011Speed: 2006.75 samples/sec#011loss=7.967926\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch[30] avg_epoch_loss=8.096627\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=97, batch=30 train loss <loss>=7.78841171265\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch [30]#011Speed: 1037.01 samples/sec#011loss=7.788412\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch[35] avg_epoch_loss=8.046405\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=97, batch=35 train loss <loss>=7.73502616882\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch [35]#011Speed: 2089.75 samples/sec#011loss=7.735026\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch[40] avg_epoch_loss=8.017708\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=97, batch=40 train loss <loss>=7.81108922958\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch [40]#011Speed: 989.53 samples/sec#011loss=7.811089\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch[45] avg_epoch_loss=8.007827\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=97, batch=45 train loss <loss>=7.92680778503\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[97] Batch [45]#011Speed: 2083.44 samples/sec#011loss=7.926808\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] processed a total of 1583 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1228.9118766784668, \"sum\": 1228.9118766784668, \"min\": 1228.9118766784668}}, \"EndTime\": 1577369852.82725, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369851.597823}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1288.01172475 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=97, train loss <loss>=7.95611413002\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] Epoch[98] Batch[0] avg_epoch_loss=8.350610\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:32 INFO 140207931545408] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=8.35060977936\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch[5] avg_epoch_loss=8.083185\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=8.08318487803\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch [5]#011Speed: 1917.87 samples/sec#011loss=8.083185\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch[10] avg_epoch_loss=8.163915\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=8.26079206467\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch [10]#011Speed: 1030.10 samples/sec#011loss=8.260792\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch[15] avg_epoch_loss=8.244451\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=98, batch=15 train loss <loss>=8.42162780762\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch [15]#011Speed: 2087.57 samples/sec#011loss=8.421628\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch[20] avg_epoch_loss=8.262164\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=98, batch=20 train loss <loss>=8.31884727478\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch [20]#011Speed: 1029.87 samples/sec#011loss=8.318847\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch[25] avg_epoch_loss=8.209944\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=98, batch=25 train loss <loss>=7.99062223434\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch [25]#011Speed: 1658.93 samples/sec#011loss=7.990622\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch[30] avg_epoch_loss=8.096084\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=98, batch=30 train loss <loss>=7.50400886536\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch [30]#011Speed: 930.23 samples/sec#011loss=7.504009\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch[35] avg_epoch_loss=8.063842\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=98, batch=35 train loss <loss>=7.86394224167\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch [35]#011Speed: 2023.55 samples/sec#011loss=7.863942\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch[40] avg_epoch_loss=8.039254\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=98, batch=40 train loss <loss>=7.86221818924\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch [40]#011Speed: 1013.78 samples/sec#011loss=7.862218\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch[45] avg_epoch_loss=8.043034\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] #quality_metric: host=algo-1, epoch=98, batch=45 train loss <loss>=8.07403287888\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:33 INFO 140207931545408] Epoch[98] Batch [45]#011Speed: 1661.06 samples/sec#011loss=8.074033\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[98] Batch[50] avg_epoch_loss=8.028774\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=98, batch=50 train loss <loss>=7.8975851059\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[98] Batch [50]#011Speed: 1550.75 samples/sec#011loss=7.897585\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] processed a total of 1649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1287.9297733306885, \"sum\": 1287.9297733306885, \"min\": 1287.9297733306885}}, \"EndTime\": 1577369854.115779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369852.827327}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1280.23176383 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=98, train loss <loss>=8.00925623454\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch[0] avg_epoch_loss=7.826241\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=7.82624101639\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch[5] avg_epoch_loss=8.041956\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=8.04195555051\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch [5]#011Speed: 1666.96 samples/sec#011loss=8.041956\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch[10] avg_epoch_loss=8.196145\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=8.3811715126\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch [10]#011Speed: 1023.09 samples/sec#011loss=8.381172\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch[15] avg_epoch_loss=8.257023\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=99, batch=15 train loss <loss>=8.39095439911\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch [15]#011Speed: 1669.88 samples/sec#011loss=8.390954\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch[20] avg_epoch_loss=8.249441\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=99, batch=20 train loss <loss>=8.2251783371\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch [20]#011Speed: 926.19 samples/sec#011loss=8.225178\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch[25] avg_epoch_loss=8.201468\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=99, batch=25 train loss <loss>=7.99998207092\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch [25]#011Speed: 1643.17 samples/sec#011loss=7.999982\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch[30] avg_epoch_loss=8.112417\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] #quality_metric: host=algo-1, epoch=99, batch=30 train loss <loss>=7.64935474396\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:34 INFO 140207931545408] Epoch[99] Batch [30]#011Speed: 935.79 samples/sec#011loss=7.649355\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[99] Batch[35] avg_epoch_loss=8.050954\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=99, batch=35 train loss <loss>=7.66988096237\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[99] Batch [35]#011Speed: 1650.42 samples/sec#011loss=7.669881\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[99] Batch[40] avg_epoch_loss=8.033067\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=99, batch=40 train loss <loss>=7.9042807579\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[99] Batch [40]#011Speed: 933.17 samples/sec#011loss=7.904281\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[99] Batch[45] avg_epoch_loss=8.039021\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=99, batch=45 train loss <loss>=8.08783931732\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[99] Batch [45]#011Speed: 1586.97 samples/sec#011loss=8.087839\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] processed a total of 1573 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1349.6739864349365, \"sum\": 1349.6739864349365, \"min\": 1349.6739864349365}}, \"EndTime\": 1577369855.466048, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369854.115854}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1165.37605599 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=99, train loss <loss>=7.96519002914\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[100] Batch[0] avg_epoch_loss=8.554000\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=8.55399990082\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[100] Batch[5] avg_epoch_loss=8.177811\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=8.1778113842\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[100] Batch [5]#011Speed: 1962.37 samples/sec#011loss=8.177811\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[100] Batch[10] avg_epoch_loss=8.211660\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=8.25227737427\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[100] Batch [10]#011Speed: 902.50 samples/sec#011loss=8.252277\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[100] Batch[15] avg_epoch_loss=8.187593\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] #quality_metric: host=algo-1, epoch=100, batch=15 train loss <loss>=8.13464651108\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:35 INFO 140207931545408] Epoch[100] Batch [15]#011Speed: 1998.52 samples/sec#011loss=8.134647\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[100] Batch[20] avg_epoch_loss=8.188076\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=100, batch=20 train loss <loss>=8.18962087631\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[100] Batch [20]#011Speed: 1081.20 samples/sec#011loss=8.189621\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[100] Batch[25] avg_epoch_loss=8.098313\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=100, batch=25 train loss <loss>=7.72130680084\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[100] Batch [25]#011Speed: 2131.54 samples/sec#011loss=7.721307\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[100] Batch[30] avg_epoch_loss=8.039137\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=100, batch=30 train loss <loss>=7.73142662048\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[100] Batch [30]#011Speed: 954.14 samples/sec#011loss=7.731427\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[100] Batch[35] avg_epoch_loss=8.036663\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=100, batch=35 train loss <loss>=8.02132024765\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[100] Batch [35]#011Speed: 1771.62 samples/sec#011loss=8.021320\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[100] Batch[40] avg_epoch_loss=8.049840\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=100, batch=40 train loss <loss>=8.14471349716\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[100] Batch [40]#011Speed: 1018.18 samples/sec#011loss=8.144713\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[100] Batch[45] avg_epoch_loss=8.024709\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=100, batch=45 train loss <loss>=7.81864023209\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[100] Batch [45]#011Speed: 1748.06 samples/sec#011loss=7.818640\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] processed a total of 1586 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1260.524034500122, \"sum\": 1260.524034500122, \"min\": 1260.524034500122}}, \"EndTime\": 1577369856.727151, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369855.466116}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1258.09312569 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=100, train loss <loss>=7.97506970406\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[101] Batch[0] avg_epoch_loss=8.347422\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=8.34742164612\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[101] Batch[5] avg_epoch_loss=8.255438\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=8.25543777148\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:36 INFO 140207931545408] Epoch[101] Batch [5]#011Speed: 1679.84 samples/sec#011loss=8.255438\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch[10] avg_epoch_loss=8.244533\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=8.23144645691\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch [10]#011Speed: 914.22 samples/sec#011loss=8.231446\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch[15] avg_epoch_loss=8.126265\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=101, batch=15 train loss <loss>=7.86607618332\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch [15]#011Speed: 1779.54 samples/sec#011loss=7.866076\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch[20] avg_epoch_loss=8.198871\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=101, batch=20 train loss <loss>=8.43121109009\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch [20]#011Speed: 1664.67 samples/sec#011loss=8.431211\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch[25] avg_epoch_loss=8.143746\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=101, batch=25 train loss <loss>=7.91222085953\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch [25]#011Speed: 895.32 samples/sec#011loss=7.912221\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch[30] avg_epoch_loss=8.077877\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=101, batch=30 train loss <loss>=7.73535919189\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch [30]#011Speed: 2156.07 samples/sec#011loss=7.735359\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch[35] avg_epoch_loss=8.040810\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=101, batch=35 train loss <loss>=7.81099500656\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch [35]#011Speed: 836.95 samples/sec#011loss=7.810995\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch[40] avg_epoch_loss=8.016847\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=101, batch=40 train loss <loss>=7.84431409836\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch [40]#011Speed: 2054.02 samples/sec#011loss=7.844314\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch[45] avg_epoch_loss=7.982113\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] #quality_metric: host=algo-1, epoch=101, batch=45 train loss <loss>=7.69729499817\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:37 INFO 140207931545408] Epoch[101] Batch [45]#011Speed: 939.39 samples/sec#011loss=7.697295\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[101] Batch[50] avg_epoch_loss=7.974425\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=101, batch=50 train loss <loss>=7.90369386673\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[101] Batch [50]#011Speed: 1739.66 samples/sec#011loss=7.903694\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] processed a total of 1672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1382.8752040863037, \"sum\": 1382.8752040863037, \"min\": 1382.8752040863037}}, \"EndTime\": 1577369858.110582, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369856.727223}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1208.96339654 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=101, train loss <loss>=7.94070049502\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch[0] avg_epoch_loss=8.380635\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=8.38063526154\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch[5] avg_epoch_loss=8.315422\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=8.31542158127\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch [5]#011Speed: 1822.57 samples/sec#011loss=8.315422\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch[10] avg_epoch_loss=8.143481\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=7.93715267181\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch [10]#011Speed: 2110.49 samples/sec#011loss=7.937153\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch[15] avg_epoch_loss=8.212107\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=102, batch=15 train loss <loss>=8.36308374405\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch [15]#011Speed: 832.91 samples/sec#011loss=8.363084\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch[20] avg_epoch_loss=8.312220\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=102, batch=20 train loss <loss>=8.63258361816\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch [20]#011Speed: 1926.09 samples/sec#011loss=8.632584\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch[25] avg_epoch_loss=8.230143\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=102, batch=25 train loss <loss>=7.88542013168\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch [25]#011Speed: 921.06 samples/sec#011loss=7.885420\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch[30] avg_epoch_loss=8.197998\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] #quality_metric: host=algo-1, epoch=102, batch=30 train loss <loss>=8.0308429718\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:38 INFO 140207931545408] Epoch[102] Batch [30]#011Speed: 1974.38 samples/sec#011loss=8.030843\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[102] Batch[35] avg_epoch_loss=8.157715\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=102, batch=35 train loss <loss>=7.90795822144\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[102] Batch [35]#011Speed: 1036.52 samples/sec#011loss=7.907958\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[102] Batch[40] avg_epoch_loss=8.089491\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=102, batch=40 train loss <loss>=7.59828233719\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[102] Batch [40]#011Speed: 1120.72 samples/sec#011loss=7.598282\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[102] Batch[45] avg_epoch_loss=8.083955\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=102, batch=45 train loss <loss>=8.03855695724\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[102] Batch [45]#011Speed: 1533.90 samples/sec#011loss=8.038557\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[102] Batch[50] avg_epoch_loss=8.014426\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=102, batch=50 train loss <loss>=7.3747546196\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[102] Batch [50]#011Speed: 1332.90 samples/sec#011loss=7.374755\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] processed a total of 1606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1316.8652057647705, \"sum\": 1316.8652057647705, \"min\": 1316.8652057647705}}, \"EndTime\": 1577369859.428019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369858.110656}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1219.42142088 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=102, train loss <loss>=8.01442560495\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[103] Batch[0] avg_epoch_loss=8.203303\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=8.2033033371\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[103] Batch[5] avg_epoch_loss=7.990896\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=7.99089630445\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[103] Batch [5]#011Speed: 1586.67 samples/sec#011loss=7.990896\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[103] Batch[10] avg_epoch_loss=8.248624\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=8.55789680481\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[103] Batch [10]#011Speed: 883.50 samples/sec#011loss=8.557897\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[103] Batch[15] avg_epoch_loss=8.341410\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] #quality_metric: host=algo-1, epoch=103, batch=15 train loss <loss>=8.54554100037\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:39 INFO 140207931545408] Epoch[103] Batch [15]#011Speed: 1583.33 samples/sec#011loss=8.545541\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[103] Batch[20] avg_epoch_loss=8.362239\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=103, batch=20 train loss <loss>=8.42888946533\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[103] Batch [20]#011Speed: 982.89 samples/sec#011loss=8.428889\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[103] Batch[25] avg_epoch_loss=8.257470\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=103, batch=25 train loss <loss>=7.81744279861\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[103] Batch [25]#011Speed: 1603.59 samples/sec#011loss=7.817443\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[103] Batch[30] avg_epoch_loss=8.142500\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=103, batch=30 train loss <loss>=7.54465646744\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[103] Batch [30]#011Speed: 908.89 samples/sec#011loss=7.544656\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[103] Batch[35] avg_epoch_loss=8.080565\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=103, batch=35 train loss <loss>=7.69656324387\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[103] Batch [35]#011Speed: 1547.84 samples/sec#011loss=7.696563\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[103] Batch[40] avg_epoch_loss=8.067759\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=103, batch=40 train loss <loss>=7.97556056976\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[103] Batch [40]#011Speed: 870.61 samples/sec#011loss=7.975561\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[103] Batch[45] avg_epoch_loss=8.059494\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=103, batch=45 train loss <loss>=7.99172077179\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[103] Batch [45]#011Speed: 1541.49 samples/sec#011loss=7.991721\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] processed a total of 1565 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1383.9459419250488, \"sum\": 1383.9459419250488, \"min\": 1383.9459419250488}}, \"EndTime\": 1577369860.812539, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369859.428126}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1130.72400187 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=103, train loss <loss>=8.02138972769\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[104] Batch[0] avg_epoch_loss=8.050763\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=8.05076313019\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[104] Batch[5] avg_epoch_loss=7.950004\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=7.95000370344\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:40 INFO 140207931545408] Epoch[104] Batch [5]#011Speed: 1816.88 samples/sec#011loss=7.950004\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch[10] avg_epoch_loss=8.169806\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=8.4335682869\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch [10]#011Speed: 929.15 samples/sec#011loss=8.433568\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch[15] avg_epoch_loss=8.275876\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=104, batch=15 train loss <loss>=8.50922908783\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch [15]#011Speed: 1703.02 samples/sec#011loss=8.509229\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch[20] avg_epoch_loss=8.286528\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=104, batch=20 train loss <loss>=8.32061500549\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch [20]#011Speed: 919.07 samples/sec#011loss=8.320615\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch[25] avg_epoch_loss=8.219353\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=104, batch=25 train loss <loss>=7.937221241\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch [25]#011Speed: 1699.34 samples/sec#011loss=7.937221\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch[30] avg_epoch_loss=8.186562\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=104, batch=30 train loss <loss>=8.01604757309\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch [30]#011Speed: 968.62 samples/sec#011loss=8.016048\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch[35] avg_epoch_loss=8.114795\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=104, batch=35 train loss <loss>=7.66983909607\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch [35]#011Speed: 2051.95 samples/sec#011loss=7.669839\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch[40] avg_epoch_loss=8.097379\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] #quality_metric: host=algo-1, epoch=104, batch=40 train loss <loss>=7.97198066711\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:41 INFO 140207931545408] Epoch[104] Batch [40]#011Speed: 926.44 samples/sec#011loss=7.971981\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[104] Batch[45] avg_epoch_loss=8.112629\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=104, batch=45 train loss <loss>=8.23768501282\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[104] Batch [45]#011Speed: 1619.56 samples/sec#011loss=8.237685\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] processed a total of 1571 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1323.7040042877197, \"sum\": 1323.7040042877197, \"min\": 1323.7040042877197}}, \"EndTime\": 1577369862.136841, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369860.812624}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1186.71904864 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=104, train loss <loss>=8.01679367065\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch[0] avg_epoch_loss=8.473405\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=8.47340488434\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch[5] avg_epoch_loss=8.249289\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=8.24928887685\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch [5]#011Speed: 1687.78 samples/sec#011loss=8.249289\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch[10] avg_epoch_loss=8.220366\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=8.18565940857\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch [10]#011Speed: 961.52 samples/sec#011loss=8.185659\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch[15] avg_epoch_loss=8.273990\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=105, batch=15 train loss <loss>=8.39196300507\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch [15]#011Speed: 1744.27 samples/sec#011loss=8.391963\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch[20] avg_epoch_loss=8.225730\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=105, batch=20 train loss <loss>=8.07129707336\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch [20]#011Speed: 1066.39 samples/sec#011loss=8.071297\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch[25] avg_epoch_loss=8.209021\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=105, batch=25 train loss <loss>=8.1388417244\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch [25]#011Speed: 2142.65 samples/sec#011loss=8.138842\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch[30] avg_epoch_loss=8.128810\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] #quality_metric: host=algo-1, epoch=105, batch=30 train loss <loss>=7.711714077\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:42 INFO 140207931545408] Epoch[105] Batch [30]#011Speed: 845.20 samples/sec#011loss=7.711714\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[105] Batch[35] avg_epoch_loss=8.068634\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=105, batch=35 train loss <loss>=7.69554271698\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[105] Batch [35]#011Speed: 1644.92 samples/sec#011loss=7.695543\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[105] Batch[40] avg_epoch_loss=8.017870\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=105, batch=40 train loss <loss>=7.65236597061\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[105] Batch [40]#011Speed: 980.58 samples/sec#011loss=7.652366\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[105] Batch[45] avg_epoch_loss=7.989884\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=105, batch=45 train loss <loss>=7.760405159\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[105] Batch [45]#011Speed: 1831.54 samples/sec#011loss=7.760405\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[105] Batch[50] avg_epoch_loss=7.971618\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=105, batch=50 train loss <loss>=7.80357208252\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[105] Batch [50]#011Speed: 1372.23 samples/sec#011loss=7.803572\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] processed a total of 1610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1327.2719383239746, \"sum\": 1327.2719383239746, \"min\": 1327.2719383239746}}, \"EndTime\": 1577369863.464689, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369862.136913}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1212.89655023 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=105, train loss <loss>=7.9716184186\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[106] Batch[0] avg_epoch_loss=8.215106\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=8.21510601044\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[106] Batch[5] avg_epoch_loss=8.286744\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=8.28674379985\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[106] Batch [5]#011Speed: 2154.22 samples/sec#011loss=8.286744\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[106] Batch[10] avg_epoch_loss=8.335364\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=8.3937078476\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[106] Batch [10]#011Speed: 976.57 samples/sec#011loss=8.393708\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[106] Batch[15] avg_epoch_loss=8.453382\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] #quality_metric: host=algo-1, epoch=106, batch=15 train loss <loss>=8.71302261353\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:43 INFO 140207931545408] Epoch[106] Batch [15]#011Speed: 1871.39 samples/sec#011loss=8.713023\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[106] Batch[20] avg_epoch_loss=8.402268\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=106, batch=20 train loss <loss>=8.23870325089\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[106] Batch [20]#011Speed: 1055.97 samples/sec#011loss=8.238703\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[106] Batch[25] avg_epoch_loss=8.301996\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=106, batch=25 train loss <loss>=7.88085451126\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[106] Batch [25]#011Speed: 1876.02 samples/sec#011loss=7.880855\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[106] Batch[30] avg_epoch_loss=8.237776\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=106, batch=30 train loss <loss>=7.90382823944\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[106] Batch [30]#011Speed: 1100.07 samples/sec#011loss=7.903828\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[106] Batch[35] avg_epoch_loss=8.173378\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=106, batch=35 train loss <loss>=7.77411432266\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[106] Batch [35]#011Speed: 1677.87 samples/sec#011loss=7.774114\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[106] Batch[40] avg_epoch_loss=8.166096\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=106, batch=40 train loss <loss>=8.11366586685\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[106] Batch [40]#011Speed: 907.04 samples/sec#011loss=8.113666\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[106] Batch[45] avg_epoch_loss=8.122756\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=106, batch=45 train loss <loss>=7.76736822128\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[106] Batch [45]#011Speed: 1666.93 samples/sec#011loss=7.767368\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] processed a total of 1554 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1234.3101501464844, \"sum\": 1234.3101501464844, \"min\": 1234.3101501464844}}, \"EndTime\": 1577369864.69956, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369863.464776}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1258.87665055 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=106, train loss <loss>=8.0826766345\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[107] Batch[0] avg_epoch_loss=8.551945\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=8.55194473267\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[107] Batch[5] avg_epoch_loss=8.245880\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=8.24587980906\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:44 INFO 140207931545408] Epoch[107] Batch [5]#011Speed: 1876.70 samples/sec#011loss=8.245880\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch[10] avg_epoch_loss=8.210703\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=8.16849069595\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch [10]#011Speed: 1069.44 samples/sec#011loss=8.168491\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch[15] avg_epoch_loss=8.271356\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=107, batch=15 train loss <loss>=8.4047914505\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch [15]#011Speed: 2057.66 samples/sec#011loss=8.404791\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch[20] avg_epoch_loss=8.272033\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=107, batch=20 train loss <loss>=8.2742023468\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch [20]#011Speed: 935.79 samples/sec#011loss=8.274202\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch[25] avg_epoch_loss=8.162942\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=107, batch=25 train loss <loss>=7.70475597382\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch [25]#011Speed: 1971.58 samples/sec#011loss=7.704756\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch[30] avg_epoch_loss=8.100755\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=107, batch=30 train loss <loss>=7.77738323212\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch [30]#011Speed: 1047.04 samples/sec#011loss=7.777383\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch[35] avg_epoch_loss=8.054067\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=107, batch=35 train loss <loss>=7.7646021843\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch [35]#011Speed: 1800.22 samples/sec#011loss=7.764602\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch[40] avg_epoch_loss=8.004354\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=107, batch=40 train loss <loss>=7.64642496109\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch [40]#011Speed: 914.22 samples/sec#011loss=7.646425\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch[45] avg_epoch_loss=8.002560\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=107, batch=45 train loss <loss>=7.98784570694\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch [45]#011Speed: 2130.89 samples/sec#011loss=7.987846\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch[50] avg_epoch_loss=7.994372\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=107, batch=50 train loss <loss>=7.91903972626\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] Epoch[107] Batch [50]#011Speed: 1495.29 samples/sec#011loss=7.919040\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] processed a total of 1693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1296.1139678955078, \"sum\": 1296.1139678955078, \"min\": 1296.1139678955078}}, \"EndTime\": 1577369865.996267, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369864.699633}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1306.06814476 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] #quality_metric: host=algo-1, epoch=107, train loss <loss>=7.99416534856\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:45 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch[0] avg_epoch_loss=8.045283\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=8.04528331757\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch[5] avg_epoch_loss=8.394215\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=8.39421463013\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch [5]#011Speed: 2065.50 samples/sec#011loss=8.394215\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch[10] avg_epoch_loss=8.316710\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=8.2237039566\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch [10]#011Speed: 1072.70 samples/sec#011loss=8.223704\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch[15] avg_epoch_loss=8.353874\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=108, batch=15 train loss <loss>=8.43563575745\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch [15]#011Speed: 2086.13 samples/sec#011loss=8.435636\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch[20] avg_epoch_loss=8.286365\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=108, batch=20 train loss <loss>=8.07033443451\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch [20]#011Speed: 1073.24 samples/sec#011loss=8.070334\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch[25] avg_epoch_loss=8.187840\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=108, batch=25 train loss <loss>=7.77403564453\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch [25]#011Speed: 1900.87 samples/sec#011loss=7.774036\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch[30] avg_epoch_loss=8.123989\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=108, batch=30 train loss <loss>=7.79196310043\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch [30]#011Speed: 973.14 samples/sec#011loss=7.791963\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch[35] avg_epoch_loss=8.080689\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] #quality_metric: host=algo-1, epoch=108, batch=35 train loss <loss>=7.81223306656\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:46 INFO 140207931545408] Epoch[108] Batch [35]#011Speed: 1670.04 samples/sec#011loss=7.812233\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[108] Batch[40] avg_epoch_loss=8.057005\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=108, batch=40 train loss <loss>=7.88647632599\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[108] Batch [40]#011Speed: 1041.75 samples/sec#011loss=7.886476\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[108] Batch[45] avg_epoch_loss=7.990568\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=108, batch=45 train loss <loss>=7.44578905106\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[108] Batch [45]#011Speed: 1364.30 samples/sec#011loss=7.445789\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] processed a total of 1513 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1196.4139938354492, \"sum\": 1196.4139938354492, \"min\": 1196.4139938354492}}, \"EndTime\": 1577369867.193289, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369865.996366}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1264.48139218 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=108, train loss <loss>=7.95464476943\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[109] Batch[0] avg_epoch_loss=7.988902\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=7.98890161514\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[109] Batch[5] avg_epoch_loss=8.128469\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=8.12846938769\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[109] Batch [5]#011Speed: 1669.06 samples/sec#011loss=8.128469\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[109] Batch[10] avg_epoch_loss=8.174414\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=8.22954750061\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[109] Batch [10]#011Speed: 942.24 samples/sec#011loss=8.229548\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[109] Batch[15] avg_epoch_loss=8.315027\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=109, batch=15 train loss <loss>=8.6243768692\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[109] Batch [15]#011Speed: 1987.92 samples/sec#011loss=8.624377\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[109] Batch[20] avg_epoch_loss=8.338581\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=109, batch=20 train loss <loss>=8.41395397186\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[109] Batch [20]#011Speed: 950.16 samples/sec#011loss=8.413954\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[109] Batch[25] avg_epoch_loss=8.286719\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] #quality_metric: host=algo-1, epoch=109, batch=25 train loss <loss>=8.06889562607\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:47 INFO 140207931545408] Epoch[109] Batch [25]#011Speed: 1664.65 samples/sec#011loss=8.068896\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[109] Batch[30] avg_epoch_loss=8.205626\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=109, batch=30 train loss <loss>=7.78394556046\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[109] Batch [30]#011Speed: 927.89 samples/sec#011loss=7.783946\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[109] Batch[35] avg_epoch_loss=8.175174\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=109, batch=35 train loss <loss>=7.98636655807\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[109] Batch [35]#011Speed: 2123.54 samples/sec#011loss=7.986367\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[109] Batch[40] avg_epoch_loss=8.118051\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=109, batch=40 train loss <loss>=7.70677146912\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[109] Batch [40]#011Speed: 972.90 samples/sec#011loss=7.706771\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[109] Batch[45] avg_epoch_loss=8.104024\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=109, batch=45 train loss <loss>=7.98900337219\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[109] Batch [45]#011Speed: 1851.19 samples/sec#011loss=7.989003\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[109] Batch[50] avg_epoch_loss=8.036487\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=109, batch=50 train loss <loss>=7.41514472961\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[109] Batch [50]#011Speed: 1399.61 samples/sec#011loss=7.415145\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] processed a total of 1624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1320.9772109985352, \"sum\": 1320.9772109985352, \"min\": 1320.9772109985352}}, \"EndTime\": 1577369868.514816, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369867.193366}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1229.27220109 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=109, train loss <loss>=8.03648714926\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[110] Batch[0] avg_epoch_loss=7.927091\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=7.92709064484\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[110] Batch[5] avg_epoch_loss=8.215845\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=8.21584502856\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[110] Batch [5]#011Speed: 1738.22 samples/sec#011loss=8.215845\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[110] Batch[10] avg_epoch_loss=8.264614\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=8.32313747406\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[110] Batch [10]#011Speed: 940.16 samples/sec#011loss=8.323137\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[110] Batch[15] avg_epoch_loss=8.352106\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] #quality_metric: host=algo-1, epoch=110, batch=15 train loss <loss>=8.54458770752\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:48 INFO 140207931545408] Epoch[110] Batch [15]#011Speed: 1785.59 samples/sec#011loss=8.544588\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch[20] avg_epoch_loss=8.298008\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=110, batch=20 train loss <loss>=8.12489557266\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch [20]#011Speed: 886.67 samples/sec#011loss=8.124896\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch[25] avg_epoch_loss=8.214072\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=110, batch=25 train loss <loss>=7.86154136658\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch [25]#011Speed: 1982.92 samples/sec#011loss=7.861541\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch[30] avg_epoch_loss=8.084827\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=110, batch=30 train loss <loss>=7.41275091171\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch [30]#011Speed: 954.89 samples/sec#011loss=7.412751\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch[35] avg_epoch_loss=8.016342\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=110, batch=35 train loss <loss>=7.59173603058\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch [35]#011Speed: 1770.07 samples/sec#011loss=7.591736\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch[40] avg_epoch_loss=8.001364\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=110, batch=40 train loss <loss>=7.89352560043\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch [40]#011Speed: 1033.03 samples/sec#011loss=7.893526\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch[45] avg_epoch_loss=7.990657\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=110, batch=45 train loss <loss>=7.90285396576\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch [45]#011Speed: 2060.50 samples/sec#011loss=7.902854\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch[50] avg_epoch_loss=7.934696\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=110, batch=50 train loss <loss>=7.4198597908\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[110] Batch [50]#011Speed: 1522.65 samples/sec#011loss=7.419860\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] processed a total of 1636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1320.3520774841309, \"sum\": 1320.3520774841309, \"min\": 1320.3520774841309}}, \"EndTime\": 1577369869.83576, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369868.514898}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1238.93593099 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=110, train loss <loss>=7.90830679123\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] Epoch[111] Batch[0] avg_epoch_loss=7.556292\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:49 INFO 140207931545408] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=7.5562915802\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch[5] avg_epoch_loss=8.092122\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=8.09212199847\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch [5]#011Speed: 1919.41 samples/sec#011loss=8.092122\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch[10] avg_epoch_loss=8.138553\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=8.1942700386\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch [10]#011Speed: 1038.20 samples/sec#011loss=8.194270\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch[15] avg_epoch_loss=8.250339\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=111, batch=15 train loss <loss>=8.49626789093\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch [15]#011Speed: 2098.31 samples/sec#011loss=8.496268\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch[20] avg_epoch_loss=8.230532\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=111, batch=20 train loss <loss>=8.16715173721\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch [20]#011Speed: 1044.60 samples/sec#011loss=8.167152\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch[25] avg_epoch_loss=8.185881\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=111, batch=25 train loss <loss>=7.99834489822\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch [25]#011Speed: 1883.93 samples/sec#011loss=7.998345\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch[30] avg_epoch_loss=8.122106\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=111, batch=30 train loss <loss>=7.79047861099\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch [30]#011Speed: 894.50 samples/sec#011loss=7.790479\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch[35] avg_epoch_loss=8.079370\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=111, batch=35 train loss <loss>=7.81440420151\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch [35]#011Speed: 1924.98 samples/sec#011loss=7.814404\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch[40] avg_epoch_loss=8.073770\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] #quality_metric: host=algo-1, epoch=111, batch=40 train loss <loss>=8.03344984055\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:50 INFO 140207931545408] Epoch[111] Batch [40]#011Speed: 984.17 samples/sec#011loss=8.033450\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[111] Batch[45] avg_epoch_loss=8.025552\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=111, batch=45 train loss <loss>=7.63016386032\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[111] Batch [45]#011Speed: 2092.49 samples/sec#011loss=7.630164\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[111] Batch[50] avg_epoch_loss=7.982399\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=111, batch=50 train loss <loss>=7.58539524078\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[111] Batch [50]#011Speed: 1484.61 samples/sec#011loss=7.585395\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] processed a total of 1618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1283.2579612731934, \"sum\": 1283.2579612731934, \"min\": 1283.2579612731934}}, \"EndTime\": 1577369871.119575, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369869.835844}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1260.73920021 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=111, train loss <loss>=7.98239928601\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch[0] avg_epoch_loss=8.239882\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=8.2398815155\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch[5] avg_epoch_loss=8.099709\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=8.09970943133\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch [5]#011Speed: 1642.73 samples/sec#011loss=8.099709\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch[10] avg_epoch_loss=8.176944\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=8.26962547302\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch [10]#011Speed: 953.00 samples/sec#011loss=8.269625\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch[15] avg_epoch_loss=8.247808\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=112, batch=15 train loss <loss>=8.40370826721\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch [15]#011Speed: 1669.85 samples/sec#011loss=8.403708\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch[20] avg_epoch_loss=8.282460\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=112, batch=20 train loss <loss>=8.39334716797\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch [20]#011Speed: 1048.89 samples/sec#011loss=8.393347\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch[25] avg_epoch_loss=8.218871\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=112, batch=25 train loss <loss>=7.95179538727\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch [25]#011Speed: 2072.51 samples/sec#011loss=7.951795\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch[30] avg_epoch_loss=8.184033\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] #quality_metric: host=algo-1, epoch=112, batch=30 train loss <loss>=8.00287876129\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:51 INFO 140207931545408] Epoch[112] Batch [30]#011Speed: 955.42 samples/sec#011loss=8.002879\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[112] Batch[35] avg_epoch_loss=8.097687\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=112, batch=35 train loss <loss>=7.56234359741\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[112] Batch [35]#011Speed: 2083.63 samples/sec#011loss=7.562344\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[112] Batch[40] avg_epoch_loss=8.063811\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=112, batch=40 train loss <loss>=7.81990232468\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[112] Batch [40]#011Speed: 1008.83 samples/sec#011loss=7.819902\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[112] Batch[45] avg_epoch_loss=8.036515\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=112, batch=45 train loss <loss>=7.81268806458\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[112] Batch [45]#011Speed: 2089.02 samples/sec#011loss=7.812688\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] processed a total of 1578 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1248.4750747680664, \"sum\": 1248.4750747680664, \"min\": 1248.4750747680664}}, \"EndTime\": 1577369872.368606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369871.119647}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1263.82053498 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=112, train loss <loss>=8.05614225388\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[113] Batch[0] avg_epoch_loss=7.730962\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=7.73096179962\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[113] Batch[5] avg_epoch_loss=8.301732\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=8.30173158646\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[113] Batch [5]#011Speed: 2014.74 samples/sec#011loss=8.301732\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[113] Batch[10] avg_epoch_loss=8.226749\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=8.13676939011\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[113] Batch [10]#011Speed: 1085.36 samples/sec#011loss=8.136769\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[113] Batch[15] avg_epoch_loss=8.317804\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=113, batch=15 train loss <loss>=8.51812648773\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[113] Batch [15]#011Speed: 2094.46 samples/sec#011loss=8.518126\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[113] Batch[20] avg_epoch_loss=8.301753\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=113, batch=20 train loss <loss>=8.25038881302\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[113] Batch [20]#011Speed: 1050.94 samples/sec#011loss=8.250389\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[113] Batch[25] avg_epoch_loss=8.207445\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] #quality_metric: host=algo-1, epoch=113, batch=25 train loss <loss>=7.8113535881\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:52 INFO 140207931545408] Epoch[113] Batch [25]#011Speed: 2086.13 samples/sec#011loss=7.811354\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[113] Batch[30] avg_epoch_loss=8.127887\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=113, batch=30 train loss <loss>=7.71418590546\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[113] Batch [30]#011Speed: 1015.59 samples/sec#011loss=7.714186\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[113] Batch[35] avg_epoch_loss=8.082263\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=113, batch=35 train loss <loss>=7.79939489365\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[113] Batch [35]#011Speed: 1665.17 samples/sec#011loss=7.799395\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[113] Batch[40] avg_epoch_loss=8.046768\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=113, batch=40 train loss <loss>=7.79119710922\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[113] Batch [40]#011Speed: 960.51 samples/sec#011loss=7.791197\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[113] Batch[45] avg_epoch_loss=8.025807\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=113, batch=45 train loss <loss>=7.85392847061\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[113] Batch [45]#011Speed: 1838.20 samples/sec#011loss=7.853928\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] processed a total of 1563 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1188.5578632354736, \"sum\": 1188.5578632354736, \"min\": 1188.5578632354736}}, \"EndTime\": 1577369873.557767, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369872.368686}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1314.88844032 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=113, train loss <loss>=8.00096525465\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[114] Batch[0] avg_epoch_loss=8.392447\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=8.39244651794\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[114] Batch[5] avg_epoch_loss=8.198026\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=8.19802586238\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[114] Batch [5]#011Speed: 2058.59 samples/sec#011loss=8.198026\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[114] Batch[10] avg_epoch_loss=8.225132\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=8.25765924454\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[114] Batch [10]#011Speed: 1102.76 samples/sec#011loss=8.257659\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[114] Batch[15] avg_epoch_loss=8.301029\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] #quality_metric: host=algo-1, epoch=114, batch=15 train loss <loss>=8.46800098419\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:53 INFO 140207931545408] Epoch[114] Batch [15]#011Speed: 2066.54 samples/sec#011loss=8.468001\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch[20] avg_epoch_loss=8.262832\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=114, batch=20 train loss <loss>=8.14060115814\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch [20]#011Speed: 956.70 samples/sec#011loss=8.140601\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch[25] avg_epoch_loss=8.222274\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=114, batch=25 train loss <loss>=8.05193223953\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch [25]#011Speed: 1896.19 samples/sec#011loss=8.051932\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch[30] avg_epoch_loss=8.163604\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=114, batch=30 train loss <loss>=7.85852146149\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch [30]#011Speed: 944.85 samples/sec#011loss=7.858521\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch[35] avg_epoch_loss=8.102029\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=114, batch=35 train loss <loss>=7.72026348114\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch [35]#011Speed: 2134.47 samples/sec#011loss=7.720263\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch[40] avg_epoch_loss=8.067195\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=114, batch=40 train loss <loss>=7.81638765335\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch [40]#011Speed: 1033.14 samples/sec#011loss=7.816388\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch[45] avg_epoch_loss=8.021771\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=114, batch=45 train loss <loss>=7.64929590225\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch [45]#011Speed: 2062.68 samples/sec#011loss=7.649296\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch[50] avg_epoch_loss=8.076143\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=114, batch=50 train loss <loss>=8.57636222839\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[114] Batch [50]#011Speed: 1486.73 samples/sec#011loss=8.576362\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] processed a total of 1602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1229.032039642334, \"sum\": 1229.032039642334, \"min\": 1229.032039642334}}, \"EndTime\": 1577369874.787422, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369873.557859}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1303.33231461 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=114, train loss <loss>=8.07614268509\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[115] Batch[0] avg_epoch_loss=7.834095\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=7.83409500122\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[115] Batch[5] avg_epoch_loss=8.076562\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=8.07656232516\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:54 INFO 140207931545408] Epoch[115] Batch [5]#011Speed: 2143.48 samples/sec#011loss=8.076562\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch[10] avg_epoch_loss=8.242223\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=8.4410153389\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch [10]#011Speed: 1049.29 samples/sec#011loss=8.441015\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch[15] avg_epoch_loss=8.326729\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=115, batch=15 train loss <loss>=8.51264305115\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch [15]#011Speed: 2076.25 samples/sec#011loss=8.512643\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch[20] avg_epoch_loss=8.280810\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=115, batch=20 train loss <loss>=8.13387031555\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch [20]#011Speed: 964.08 samples/sec#011loss=8.133870\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch[25] avg_epoch_loss=8.169928\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=115, batch=25 train loss <loss>=7.70422286987\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch [25]#011Speed: 1669.48 samples/sec#011loss=7.704223\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch[30] avg_epoch_loss=8.081121\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=115, batch=30 train loss <loss>=7.61932506561\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch [30]#011Speed: 882.26 samples/sec#011loss=7.619325\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch[35] avg_epoch_loss=8.058569\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=115, batch=35 train loss <loss>=7.91874284744\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch [35]#011Speed: 1814.04 samples/sec#011loss=7.918743\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch[40] avg_epoch_loss=8.045408\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=115, batch=40 train loss <loss>=7.95064840317\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch [40]#011Speed: 993.50 samples/sec#011loss=7.950648\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch[45] avg_epoch_loss=8.037763\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] #quality_metric: host=algo-1, epoch=115, batch=45 train loss <loss>=7.97508029938\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:55 INFO 140207931545408] Epoch[115] Batch [45]#011Speed: 1791.99 samples/sec#011loss=7.975080\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] processed a total of 1526 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1218.8560962677002, \"sum\": 1218.8560962677002, \"min\": 1218.8560962677002}}, \"EndTime\": 1577369876.006872, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369874.787503}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1251.87554293 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=115, train loss <loss>=7.98933764299\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch[0] avg_epoch_loss=7.581474\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=7.58147382736\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch[5] avg_epoch_loss=8.180855\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=8.18085511525\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch [5]#011Speed: 2068.25 samples/sec#011loss=8.180855\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch[10] avg_epoch_loss=8.191530\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=8.20434017181\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch [10]#011Speed: 924.40 samples/sec#011loss=8.204340\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch[15] avg_epoch_loss=8.292460\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=116, batch=15 train loss <loss>=8.5145067215\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch [15]#011Speed: 1684.81 samples/sec#011loss=8.514507\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch[20] avg_epoch_loss=8.268815\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=116, batch=20 train loss <loss>=8.19314842224\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch [20]#011Speed: 968.62 samples/sec#011loss=8.193148\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch[25] avg_epoch_loss=8.210016\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=116, batch=25 train loss <loss>=7.96306171417\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch [25]#011Speed: 1693.93 samples/sec#011loss=7.963062\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch[30] avg_epoch_loss=8.134475\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=116, batch=30 train loss <loss>=7.74166088104\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch [30]#011Speed: 986.83 samples/sec#011loss=7.741661\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch[35] avg_epoch_loss=8.070124\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] #quality_metric: host=algo-1, epoch=116, batch=35 train loss <loss>=7.67115135193\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:56 INFO 140207931545408] Epoch[116] Batch [35]#011Speed: 1669.74 samples/sec#011loss=7.671151\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[116] Batch[40] avg_epoch_loss=8.009689\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=116, batch=40 train loss <loss>=7.57455825806\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[116] Batch [40]#011Speed: 935.96 samples/sec#011loss=7.574558\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[116] Batch[45] avg_epoch_loss=8.035228\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=116, batch=45 train loss <loss>=8.24463949203\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[116] Batch [45]#011Speed: 1721.95 samples/sec#011loss=8.244639\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] processed a total of 1597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1314.267873764038, \"sum\": 1314.267873764038, \"min\": 1314.267873764038}}, \"EndTime\": 1577369877.321722, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369876.006946}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1215.00771054 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=116, train loss <loss>=7.99323903084\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[117] Batch[0] avg_epoch_loss=7.855753\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=7.85575294495\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[117] Batch[5] avg_epoch_loss=7.996549\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=7.9965493679\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[117] Batch [5]#011Speed: 2019.23 samples/sec#011loss=7.996549\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[117] Batch[10] avg_epoch_loss=8.135834\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=8.30297584534\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[117] Batch [10]#011Speed: 1012.34 samples/sec#011loss=8.302976\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[117] Batch[15] avg_epoch_loss=8.292653\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=117, batch=15 train loss <loss>=8.63765335083\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[117] Batch [15]#011Speed: 1611.67 samples/sec#011loss=8.637653\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[117] Batch[20] avg_epoch_loss=8.279326\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=117, batch=20 train loss <loss>=8.2366812706\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[117] Batch [20]#011Speed: 1008.43 samples/sec#011loss=8.236681\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[117] Batch[25] avg_epoch_loss=8.233728\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] #quality_metric: host=algo-1, epoch=117, batch=25 train loss <loss>=8.04221811295\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:57 INFO 140207931545408] Epoch[117] Batch [25]#011Speed: 1888.86 samples/sec#011loss=8.042218\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[117] Batch[30] avg_epoch_loss=8.153515\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=117, batch=30 train loss <loss>=7.73640508652\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[117] Batch [30]#011Speed: 1031.41 samples/sec#011loss=7.736405\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[117] Batch[35] avg_epoch_loss=8.123942\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=117, batch=35 train loss <loss>=7.94058713913\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[117] Batch [35]#011Speed: 1701.00 samples/sec#011loss=7.940587\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[117] Batch[40] avg_epoch_loss=8.095487\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=117, batch=40 train loss <loss>=7.89061079025\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[117] Batch [40]#011Speed: 920.13 samples/sec#011loss=7.890611\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[117] Batch[45] avg_epoch_loss=8.066574\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=117, batch=45 train loss <loss>=7.82949419022\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[117] Batch [45]#011Speed: 1910.50 samples/sec#011loss=7.829494\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[117] Batch[50] avg_epoch_loss=8.025736\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=117, batch=50 train loss <loss>=7.650025177\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[117] Batch [50]#011Speed: 1282.60 samples/sec#011loss=7.650025\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] processed a total of 1654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1326.498031616211, \"sum\": 1326.498031616211, \"min\": 1326.498031616211}}, \"EndTime\": 1577369878.64882, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369877.321796}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1246.75233378 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=117, train loss <loss>=7.99769369455\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[118] Batch[0] avg_epoch_loss=8.194827\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=8.19482707977\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[118] Batch[5] avg_epoch_loss=7.958239\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=7.95823947589\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:58 INFO 140207931545408] Epoch[118] Batch [5]#011Speed: 1664.12 samples/sec#011loss=7.958239\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch[10] avg_epoch_loss=8.053924\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=8.16874637604\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch [10]#011Speed: 940.76 samples/sec#011loss=8.168746\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch[15] avg_epoch_loss=8.182314\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=118, batch=15 train loss <loss>=8.46477136612\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch [15]#011Speed: 1668.04 samples/sec#011loss=8.464771\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch[20] avg_epoch_loss=8.227097\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=118, batch=20 train loss <loss>=8.37040214539\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch [20]#011Speed: 919.68 samples/sec#011loss=8.370402\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch[25] avg_epoch_loss=8.185007\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=118, batch=25 train loss <loss>=8.00823011398\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch [25]#011Speed: 1992.60 samples/sec#011loss=8.008230\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch[30] avg_epoch_loss=8.133597\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=118, batch=30 train loss <loss>=7.8662653923\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch [30]#011Speed: 867.89 samples/sec#011loss=7.866265\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch[35] avg_epoch_loss=8.061184\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=118, batch=35 train loss <loss>=7.61222486496\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch [35]#011Speed: 1639.04 samples/sec#011loss=7.612225\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch[40] avg_epoch_loss=8.022198\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=118, batch=40 train loss <loss>=7.74149837494\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch [40]#011Speed: 990.74 samples/sec#011loss=7.741498\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch[45] avg_epoch_loss=7.996596\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=118, batch=45 train loss <loss>=7.78665771484\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Epoch[118] Batch [45]#011Speed: 2140.81 samples/sec#011loss=7.786658\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] processed a total of 1599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1345.923900604248, \"sum\": 1345.923900604248, \"min\": 1345.923900604248}}, \"EndTime\": 1577369879.995288, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369878.648928}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] #throughput_metric: host=algo-1, train throughput=1187.92986871 records/second\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] #quality_metric: host=algo-1, epoch=118, train loss <loss>=7.98537500381\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:17:59 INFO 140207931545408] Loading parameters from best epoch (78)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 4.822015762329102, \"sum\": 4.822015762329102, \"min\": 4.822015762329102}}, \"EndTime\": 1577369880.000788, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369879.995368}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:00 INFO 140207931545408] stopping training now\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:00 INFO 140207931545408] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:00 INFO 140207931545408] Final loss: 7.90750425937 (occurred at epoch 78)\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:00 INFO 140207931545408] #quality_metric: host=algo-1, train final_loss <loss>=7.90750425937\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:00 INFO 140207931545408] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:00 WARNING 140207931545408] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:00 INFO 140207931545408] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 61.18583679199219, \"sum\": 61.18583679199219, \"min\": 61.18583679199219}}, \"EndTime\": 1577369880.062755, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369880.000837}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:00 INFO 140207931545408] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 87.62598037719727, \"sum\": 87.62598037719727, \"min\": 87.62598037719727}}, \"EndTime\": 1577369880.08915, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369880.062811}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:00 INFO 140207931545408] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:00 INFO 140207931545408] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 4.606008529663086, \"sum\": 4.606008529663086, \"min\": 4.606008529663086}}, \"EndTime\": 1577369880.09384, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369880.089199}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:00 INFO 140207931545408] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:00 INFO 140207931545408] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03814697265625, \"sum\": 0.03814697265625, \"min\": 0.03814697265625}}, \"EndTime\": 1577369880.094568, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369880.093883}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:02 INFO 140207931545408] Number of test batches scored: 10\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/26/2019 14:18:04 INFO 140207931545408] Number of test batches scored: 20\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:07 INFO 140207931545408] Number of test batches scored: 30\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:09 INFO 140207931545408] Number of test batches scored: 40\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:11 INFO 140207931545408] Number of test batches scored: 50\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 12033.082008361816, \"sum\": 12033.082008361816, \"min\": 12033.082008361816}}, \"EndTime\": 1577369892.127624, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369880.094629}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #test_score (algo-1, RMSE): 34806.9344815\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #test_score (algo-1, mean_wQuantileLoss): 0.36249372\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #test_score (algo-1, wQuantileLoss[0.1]): 0.21140136\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #test_score (algo-1, wQuantileLoss[0.2]): 0.35520014\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #test_score (algo-1, wQuantileLoss[0.3]): 0.42490184\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #test_score (algo-1, wQuantileLoss[0.4]): 0.45582867\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #test_score (algo-1, wQuantileLoss[0.5]): 0.4571058\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #test_score (algo-1, wQuantileLoss[0.6]): 0.4367077\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #test_score (algo-1, wQuantileLoss[0.7]): 0.39175165\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #test_score (algo-1, wQuantileLoss[0.8]): 0.3188709\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #test_score (algo-1, wQuantileLoss[0.9]): 0.2106754\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.362493723631\u001b[0m\n",
      "\u001b[34m[12/26/2019 14:18:12 INFO 140207931545408] #quality_metric: host=algo-1, test RMSE <loss>=34806.9344815\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 165444.97394561768, \"sum\": 165444.97394561768, \"min\": 165444.97394561768}, \"setuptime\": {\"count\": 1, \"max\": 9.190082550048828, \"sum\": 9.190082550048828, \"min\": 9.190082550048828}}, \"EndTime\": 1577369892.139054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577369892.12772}\n",
      "\u001b[0m\n",
      "\n",
      "2019-12-26 14:18:22 Uploading - Uploading generated training model\n",
      "2019-12-26 14:18:22 Completed - Training job completed\n",
      "Training seconds: 215\n",
      "Billable seconds: 215\n",
      "CPU times: user 847 ms, sys: 86 ms, total: 933 ms\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\n",
    "    \"train\": \"{}/train/\".format(s3_data_path),\n",
    "    \"test\": \"{}/test/\".format(s3_data_path)\n",
    "}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you pass a test set in this example, accuracy metrics for the forecast are computed and logged (see bottom of the log).\n",
    "You can find the definition of these metrics from [our documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html). You can use these to optimize the parameters and tune your model or use SageMaker's [Automated Model Tuning service](https://aws.amazon.com/blogs/aws/sagemaker-automatic-model-tuning/) to tune the model for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint and predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained model, we can use it to perform predictions by deploying it to an endpoint.\n",
    "\n",
    "**Note: Remember to delete the endpoint after running this experiment. A cell at the very bottom of this notebook will do that: make sure you run it at the end.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query the endpoint and perform predictions, we can define the following utility class: this allows making requests using `pandas.Series` objects rather than raw JSON strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, content_type=sagemaker.content_types.CONTENT_TYPE_JSON, **kwargs)\n",
    "        \n",
    "    def predict(self, ts, cat=None, dynamic_feat=None, \n",
    "                num_samples=100, return_samples=False, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "        \n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "        \n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + 1\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None)\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "        \n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "        \n",
    "        return json.dumps(http_request_data).encode('utf-8')\n",
    "    \n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode('utf-8'))['predictions'][0]\n",
    "        prediction_length = len(next(iter(predictions['quantiles'].values())))\n",
    "        prediction_index = pd.DatetimeIndex(start=prediction_time, freq=freq, periods=prediction_length)        \n",
    "        if return_samples:\n",
    "            dict_of_samples = {'sample_' + str(i): s for i, s in enumerate(predictions['samples'])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(data={**predictions['quantiles'], **dict_of_samples}, index=prediction_index)\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "        \n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]        \n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can deploy the model and create and endpoint that can be queried using our custom DeepARPredictor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    predictor_cls=DeepARPredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions and plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `predictor` object to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  if __name__ == '__main__':\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:19: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:46: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-24</th>\n",
       "      <td>-37.407478</td>\n",
       "      <td>64.938721</td>\n",
       "      <td>12.363743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-25</th>\n",
       "      <td>-37.595280</td>\n",
       "      <td>46.953438</td>\n",
       "      <td>8.149283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-26</th>\n",
       "      <td>-26.169178</td>\n",
       "      <td>58.574799</td>\n",
       "      <td>17.012093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-27</th>\n",
       "      <td>-24.764664</td>\n",
       "      <td>44.080570</td>\n",
       "      <td>10.019235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-28</th>\n",
       "      <td>-24.236549</td>\n",
       "      <td>44.367313</td>\n",
       "      <td>12.105393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-29</th>\n",
       "      <td>-17.952757</td>\n",
       "      <td>54.171425</td>\n",
       "      <td>11.576536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>-7.990780</td>\n",
       "      <td>36.675087</td>\n",
       "      <td>15.293027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.1        0.9        0.5\n",
       "2019-09-24 -37.407478  64.938721  12.363743\n",
       "2019-09-25 -37.595280  46.953438   8.149283\n",
       "2019-09-26 -26.169178  58.574799  17.012093\n",
       "2019-09-27 -24.764664  44.080570  10.019235\n",
       "2019-09-28 -24.236549  44.367313  12.105393\n",
       "2019-09-29 -17.952757  54.171425  11.576536\n",
       "2019-09-30  -7.990780  36.675087  15.293027"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(ts=timeseries[0][start_dataset:end_test-1],quantiles=[0.10, 0.5, 0.90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a plotting function that queries the model and displays the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "    predictor, \n",
    "    target_ts, \n",
    "    cat=None, \n",
    "    dynamic_feat=None, \n",
    "    forecast_date=end_training, \n",
    "    show_samples=False, \n",
    "    plot_history=7 * 12,\n",
    "    confidence=80\n",
    "):\n",
    "    print(\"calling served model to generate predictions starting from {}\".format(str(forecast_date)))\n",
    "    assert(confidence > 50 and confidence < 100)\n",
    "    low_quantile = 0.5 - confidence * 0.005\n",
    "    up_quantile = confidence * 0.005 + 0.5\n",
    "        \n",
    "    # we first construct the argument to call our model\n",
    "    args = {\n",
    "        \"ts\": target_ts[:forecast_date],\n",
    "        \"return_samples\": show_samples,\n",
    "        \"quantiles\": [low_quantile, 0.5, up_quantile],\n",
    "        \"num_samples\": 100\n",
    "    }\n",
    "\n",
    "\n",
    "    if dynamic_feat is not None:\n",
    "        args[\"dynamic_feat\"] = dynamic_feat\n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        ax = plt.subplot(2, 1, 1)\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(20, 6))\n",
    "        ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    if cat is not None:\n",
    "        args[\"cat\"] = cat\n",
    "        ax.text(0.9, 0.9, 'cat = {}'.format(cat), transform=ax.transAxes)\n",
    "\n",
    "    # call the end point to get the prediction\n",
    "    prediction = predictor.predict(**args)\n",
    "\n",
    "    # plot the samples\n",
    "    if show_samples: \n",
    "        for key in prediction.keys():\n",
    "            if \"sample\" in key:\n",
    "                prediction[key].plot(color='lightskyblue', alpha=0.2, label='_nolegend_')\n",
    "                \n",
    "                \n",
    "    # plot the target\n",
    "    target_section = target_ts[forecast_date-plot_history:forecast_date+prediction_length]\n",
    "    target_section.plot(color=\"black\", label='target')\n",
    "    \n",
    "    # plot the confidence interval and the median predicted\n",
    "    ax.fill_between(\n",
    "        prediction[str(low_quantile)].index, \n",
    "        prediction[str(low_quantile)].values, \n",
    "        prediction[str(up_quantile)].values, \n",
    "        color=\"b\", alpha=0.3, label='{}% confidence interval'.format(confidence)\n",
    "    )\n",
    "    prediction[\"0.5\"].plot(color=\"b\", label='P50')\n",
    "    ax.legend(loc=2)    \n",
    "    \n",
    "    # fix the scale as the samples may change it\n",
    "    ax.set_ylim(target_section.min() * 0.5, target_section.max() * 1.5)\n",
    "    \n",
    "    if dynamic_feat is not None:\n",
    "        for i, f in enumerate(dynamic_feat, start=1):\n",
    "            ax = plt.subplot(len(dynamic_feat) * 2, 1, len(dynamic_feat) + i, sharex=ax)\n",
    "            feat_ts = pd.Series(\n",
    "                index=pd.DatetimeIndex(start=target_ts.index[0], freq=target_ts.index.freq, periods=len(f)),\n",
    "                data=f\n",
    "            )\n",
    "            feat_ts[forecast_date-plot_history:forecast_date+prediction_length].plot(ax=ax, color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interact with the function previously defined, to look at the forecast of any customer at any point in (future) time. \n",
    "\n",
    "For each request, the predictions are obtained by calling our served model on the fly.\n",
    "\n",
    "Here we forecast the consumption of an office after week-end (note the lower week-end consumption). \n",
    "You can select any time series and any forecast date, just click on `Run Interact` to generate the predictions from our served endpoint and see the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {'description_width': 'initial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715dc12709ad479ca6b67ae1f2c70a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=120, description='customer_id', max=1603, style=SliderStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "@interact_manual(\n",
    "    customer_id=IntSlider(min=0, max=1603, value=120, style=style), \n",
    "#     forecast_day= prediction_length,\n",
    "    confidence=IntSlider(min=60, max=95, value=80, step=5, style=style),\n",
    "    history_days_plot=IntSlider(min=1, max=50, value=7, style=style),\n",
    "    show_samples=Checkbox(value=False),\n",
    "    continuous_update=False\n",
    ")\n",
    "def plot_interact(customer_id, confidence, history_days_plot, show_samples):\n",
    "    plot(\n",
    "        predictor,\n",
    "        target_ts=timeseries[customer_id],\n",
    "        forecast_date= start_predict -1,#end_training + datetime.timedelta(days=forecast_day),\n",
    "        show_samples=show_samples,\n",
    "        plot_history=history_days_plot,\n",
    "        confidence=confidence\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:19: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:46: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.05 s, sys: 77 ms, total: 5.13 s\n",
      "Wall time: 44.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds = []\n",
    "quantiles=[0.10, 0.5, 0.90]\n",
    "\n",
    "for i, ts_dict in enumerate(timeseries):\n",
    "    ts = ts_dict[start_dataset:end_test-1]\n",
    "    if ts.shape[0] == 0:\n",
    "        preds.append(None)\n",
    "        continue\n",
    "    pred = predictor.predict(ts=ts, quantiles=quantiles)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predict result and label data into a csv for later use\n",
    "df = pd.DataFrame()\n",
    "for i in range(len(timeseries)):\n",
    "    y =  timeseries[i][start_predict:end_predict].fillna(0)\n",
    "    y_hat = preds[i]['0.5']\n",
    "    dd = pd.DataFrame({'store_id':i,'y_label': y, 'y_pred': y_hat})\n",
    "    df = pd.concat([df, dd])\n",
    "df.index.name='date'\n",
    "df.to_csv(\"data/deepar-predict-result.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print sample site stores prediction result, you can print more if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 24\n",
      "RMSE: 1406.6672841322722\n",
      "MAE: 1230.2035016741\n",
      "Target Mean: 5569.585714285714\n",
      "                 y_pred  y_label\n",
      "2019-09-24  4517.583496   7026.0\n",
      "2019-09-25  4354.111328   4043.6\n",
      "2019-09-26  4353.962402   6221.2\n",
      "2019-09-27  4917.299805   5847.8\n",
      "2019-09-28  6354.404785   5126.7\n",
      "2019-09-29  6803.198730   5775.6\n",
      "2019-09-30  4206.744629   4946.2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 31\n",
      "RMSE: 1892.5107264489236\n",
      "MAE: 1665.9226283482142\n",
      "Target Mean: 9007.67142857143\n",
      "                  y_pred  y_label\n",
      "2019-09-24   7729.753906   7383.9\n",
      "2019-09-25   7315.371094   8558.8\n",
      "2019-09-26   6695.611816   9763.9\n",
      "2019-09-27   6124.147461   8243.4\n",
      "2019-09-28   7967.549805   9221.3\n",
      "2019-09-29  11350.946289  10352.9\n",
      "2019-09-30   6896.661621   9529.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 36\n",
      "RMSE: 4986.11005131684\n",
      "MAE: 2990.2407645089293\n",
      "Target Mean: 18153.442857142858\n",
      "                  y_pred  y_label\n",
      "2019-09-24  13588.302734  13646.5\n",
      "2019-09-25  16151.426758  16744.0\n",
      "2019-09-26  16137.608398  15419.9\n",
      "2019-09-27  18191.798828  18162.3\n",
      "2019-09-28  28059.017578  26111.2\n",
      "2019-09-29  26696.355469  15189.3\n",
      "2019-09-30  15722.065430  21800.9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 87\n",
      "RMSE: 10562.167915809518\n",
      "MAE: 8261.332098214287\n",
      "Target Mean: 41728.84428571429\n",
      "                  y_pred   y_label\n",
      "2019-09-24  38413.855469  34817.70\n",
      "2019-09-25  38417.496094  33837.11\n",
      "2019-09-26  39688.996094  32969.10\n",
      "2019-09-27  53255.398438  36843.10\n",
      "2019-09-28  69847.070312  67866.62\n",
      "2019-09-29  60190.601562  39937.69\n",
      "2019-09-30  41543.363281  45830.59\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 s, sys: 726 ms, total: 3.08 s\n",
      "Wall time: 1.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import metrics\n",
    "\n",
    "def show_metrics(sample_sites, target_quantile='0.5'):\n",
    "    for i in sample_sites:  # TODO len(timeseries)\n",
    "        if preds[i] is None:\n",
    "            continue\n",
    "        \n",
    "        s = timeseries[i].fillna(0)\n",
    "        \n",
    "        print(\"i:\", i)\n",
    "        p10 = preds[i]['0.1']\n",
    "        p90 = preds[i]['0.9']\n",
    "        y_label =  timeseries[i][start_predict:end_predict].fillna(0)\n",
    "        y_pred = preds[i][target_quantile]\n",
    "        if y_label.shape[0] != y_pred.shape[0]:\n",
    "            continue\n",
    "        \n",
    "        print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_label, y_pred)))\n",
    "        print(\"MAE:\",metrics.mean_absolute_error(y_label, y_pred))\n",
    "        print(\"Target Mean:\",y_label.mean())\n",
    "        print(pd.DataFrame({'y_pred': y_pred, 'y_label': y_label}))\n",
    "        plt.figure(figsize=(12,6))\n",
    "        s.plot(label='target %s'%str(i))\n",
    "        plt.fill_between(p10.index, p10, p90, color='y', alpha=0.5, label='80% confidence interval')\n",
    "        y_pred.plot(label='prediction median')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "show_metrics(sample_sites, target_quantile='0.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional features\n",
    "\n",
    "We have seen how to prepare a dataset and run DeepAR for a simple example.\n",
    "\n",
    "In addition DeepAR supports the following features:\n",
    "\n",
    "* missing values: DeepAR can handle missing values in the time series during training as well as for inference.\n",
    "* Additional time features: DeepAR provides a set default time series features such as hour of day etc. However, you can provide additional feature time series via the `dynamic_feat` field. \n",
    "* generalize frequencies: any integer multiple of the previously supported base frequencies (minutes `min`, hours `H`, days `D`, weeks `W`, month `M`) are now allowed; e.g., `15min`. We already demonstrated this above by using `1D` frequency.\n",
    "* categories: If your time series belong to different groups (e.g. types of product, regions, etc), this information can be encoded as one or more categorical features using the `cat` field.\n",
    "\n",
    "We will now demonstrate categories and time features support. For this part we will reuse the stores sales dataset, we get categories of the stores from data owner and crawler weather data from http://lishi.tianqi.com/shenzhen as dynamic time series: \n",
    "* weather time series will contain: the high temperature, the low temperature of the day, whether is rainy, whether is sunshine, whether is cloudy;\n",
    "* besides that, we add addtional time series that whether the day is weekend;\n",
    "* categories: 1D array for each target series;\n",
    "\n",
    "dynamic_feat: total 6 dynamic_feat, the high temperature, the low temperature, is_sunshine, is_rain, is_cloudy, is_weekend. As the stores are in the same city, so each store time series will use same dynamic_feat values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read those data as we have prepared in advance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat is stand for category, here it is a one 1d vector for each store time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = pd.read_csv('data/cat.csv', sep=\",\", index_col=0, parse_dates=True)\n",
    "cat_num_timeseries = cat.shape[0]\n",
    "cat_timeseries = []\n",
    "for i in range(cat_num_timeseries):\n",
    "    cat_timeseries.append(cat.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2019-07-10    0\n",
       "2019-07-11    0\n",
       "2019-07-12    0\n",
       "2019-07-13    1\n",
       "2019-07-14    1\n",
       "             ..\n",
       "2019-09-26    0\n",
       "2019-09-27    0\n",
       "2019-09-28    1\n",
       "2019-09-29    1\n",
       "2019-09-30    0\n",
       "Name: is_weekend, Length: 83, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_weekend = pd.read_csv('data/is_weekend.csv', sep=\",\", index_col=0, parse_dates=True)\n",
    "is_weekend_timeseries = is_weekend.iloc[:,0]\n",
    "is_weekend_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('data/shenzhen_weather.csv', sep=\",\", index_col=0, parse_dates=True)\n",
    "w_num_timeseries = weather.shape[1]\n",
    "w_timeseries = []\n",
    "for i in range(w_num_timeseries):\n",
    "    w_timeseries.append(weather.iloc[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  app.launch_new_instance()\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    }
   ],
   "source": [
    "train_dynamic_feat= []\n",
    "for i in range(5):\n",
    "    train_dynamic_feat.append(w_timeseries[i][start_dataset:end_training -1].tolist())\n",
    "train_dynamic_feat.append(is_weekend_timeseries[start_dataset:end_training -1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  app.launch_new_instance()\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    }
   ],
   "source": [
    "test_dynamic_feat= []\n",
    "for i in range(5):\n",
    "    test_dynamic_feat.append(w_timeseries[i][start_dataset:end_test -1].tolist())\n",
    "test_dynamic_feat.append(is_weekend_timeseries[start_dataset:end_test -1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  app.launch_new_instance()\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    }
   ],
   "source": [
    "predict_dynamic_feat= []\n",
    "for i in range(5):\n",
    "    predict_dynamic_feat.append(w_timeseries[i][start_dataset:end_predict -1].tolist())\n",
    "predict_dynamic_feat.append(is_weekend_timeseries[start_dataset:end_predict -1].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DeepAR JSON input format represents each time series as a JSON object. In the case each time series consists of a start time stamp (``start``) and a list of values (``target``)as well as ``dynamic_feat`` for time-series features and ``cat`` for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:9: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n",
      "CPU times: user 439 ms, sys: 3.02 ms, total: 442 ms\n",
      "Wall time: 441 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "training_data_new_features = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": timeseries[i][start_dataset:end_training -1].tolist(),\n",
    "        \"cat\": cat_timeseries[i].tolist(),\n",
    "        \"dynamic_feat\": train_dynamic_feat\n",
    "    }\n",
    "    for i in range(cat_num_timeseries)\n",
    "]\n",
    "print(len(training_data_new_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:8: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n"
     ]
    }
   ],
   "source": [
    "test_data_new_features = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": timeseries[i][start_dataset:end_test -1].tolist(),\n",
    "        \"cat\": cat_timeseries[i].tolist(),\n",
    "        \"dynamic_feat\": test_dynamic_feat\n",
    "    }\n",
    "    for i in range(cat_num_timeseries)\n",
    "]\n",
    "print(len(test_data_new_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_consistency(train_dataset, test_dataset=None):\n",
    "    d = train_dataset[0]\n",
    "    has_dynamic_feat = 'dynamic_feat' in d\n",
    "    if has_dynamic_feat:\n",
    "        num_dynamic_feat = len(d['dynamic_feat'])\n",
    "    has_cat = 'cat' in d\n",
    "    if has_cat:\n",
    "        num_cat = len(d['cat'])\n",
    "    \n",
    "    def check_ds(ds):\n",
    "        for i, d in enumerate(ds):\n",
    "            if has_dynamic_feat:\n",
    "                assert 'dynamic_feat' in d\n",
    "                assert num_dynamic_feat == len(d['dynamic_feat'])\n",
    "                for f in d['dynamic_feat']:\n",
    "                    assert len(d['target']) == len(f)\n",
    "                    \n",
    "            if has_cat:\n",
    "                assert 'cat' in d\n",
    "                assert len(d['cat']) == num_cat\n",
    "    check_ds(train_dataset)\n",
    "    if test_dataset is not None:\n",
    "        \n",
    "        check_ds(test_dataset)\n",
    "        \n",
    "check_dataset_consistency(training_data_new_features, test_data_new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the new train and test data to local disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 224 ms, sys: 13.8 ms, total: 238 ms\n",
      "Wall time: 237 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"data/train_new_features.json\", training_data_new_features)\n",
    "write_dicts_to_file(\"data/test_new_features.json\", test_data_new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the new train and test data to S3 bucket, here we will use new bucket which has a extend name '-new-features' of the bucket name you used in before case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to S3 this may take a few minutes depending on your connection.\n",
      "Overwriting existing file\n",
      "Uploading file to s3://sagemaker-us-west-2-169088282855/tko_ts_workshop-new-features/data/train/train_new_features.json\n",
      "Overwriting existing file\n",
      "Uploading file to s3://sagemaker-us-west-2-169088282855/tko_ts_workshop-new-features/data/test/test_new_features.json\n",
      "CPU times: user 53.9 ms, sys: 1.92 ms, total: 55.9 ms\n",
      "Wall time: 267 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "s3_data_path_new_features = \"s3://{}/{}-new-features/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path_new_features = \"s3://{}/{}-new-features/output\".format(s3_bucket, s3_prefix)\n",
    "\n",
    "print('Uploading to S3 this may take a few minutes depending on your connection.')\n",
    "copy_to_s3(\"data/train_new_features.json\", s3_data_path_new_features + \"/train/train_new_features.json\", override=True)\n",
    "copy_to_s3(\"data/test_new_features.json\", s3_data_path_new_features + \"/test/test_new_features.json\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agagin, let's setup the estimator and hyperparameters, then let's fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-27 02:36:58 Starting - Starting the training job...\n",
      "2019-12-27 02:37:28 Starting - Launching requested ML instances......\n",
      "2019-12-27 02:38:26 Starting - Preparing the instances for training......\n",
      "2019-12-27 02:39:13 Downloading - Downloading input data...\n",
      "2019-12-27 02:39:57 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:39:59 INFO 139649395074880] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:39:59 INFO 139649395074880] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'num_dynamic_feat': u'auto', u'learning_rate': u'5E-4', u'prediction_length': u'7', u'epochs': u'400', u'time_freq': u'1D', u'context_length': u'14', u'mini_batch_size': u'32', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:39:59 INFO 139649395074880] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'32', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'7', u'time_freq': u'1D', u'context_length': u'14', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:39:59 INFO 139649395074880] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train_new_features.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train_new_features.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] [cardinality=auto] Inferred value of cardinality=[4, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] from dataset.\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=6 from dataset.\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] Training set statistics:\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] Real time series\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] number of time series: 1604\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] number of observations: 110676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] mean target length: 69\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] min/mean/max target: 0.0/21018.1296408/1653507.875\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] mean abs(target): 21018.1296408\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] contains missing values: no\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] Test set statistics:\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] Real time series\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] number of time series: 1604\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] number of observations: 121904\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] mean target length: 76\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] min/mean/max target: 0.0/20798.7399189/1653507.875\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] mean abs(target): 20798.7399189\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] contains missing values: no\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] nvidia-smi took: 0.025249004364 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 50.421953201293945, \"sum\": 50.421953201293945, \"min\": 50.421953201293945}}, \"EndTime\": 1577414400.797781, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414400.746494}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:00 INFO 139649395074880] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 144.83189582824707, \"sum\": 144.83189582824707, \"min\": 144.83189582824707}}, \"EndTime\": 1577414400.89145, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414400.797845}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] Epoch[0] Batch[0] avg_epoch_loss=9.139020\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=9.13901996613\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] Epoch[0] Batch[5] avg_epoch_loss=8.924106\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=8.92410580317\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] Epoch[0] Batch [5]#011Speed: 1654.95 samples/sec#011loss=8.924106\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] Epoch[0] Batch[10] avg_epoch_loss=8.761392\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=8.56613540649\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] Epoch[0] Batch [10]#011Speed: 698.02 samples/sec#011loss=8.566135\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] Epoch[0] Batch[15] avg_epoch_loss=8.733415\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=0, batch=15 train loss <loss>=8.67186412811\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] Epoch[0] Batch [15]#011Speed: 1445.80 samples/sec#011loss=8.671864\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] Epoch[0] Batch[20] avg_epoch_loss=8.805969\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=0, batch=20 train loss <loss>=9.03814144135\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] Epoch[0] Batch [20]#011Speed: 676.89 samples/sec#011loss=9.038141\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] Epoch[0] Batch[25] avg_epoch_loss=8.760508\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=0, batch=25 train loss <loss>=8.56957416534\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:01 INFO 139649395074880] Epoch[0] Batch [25]#011Speed: 1416.58 samples/sec#011loss=8.569574\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[0] Batch[30] avg_epoch_loss=8.693357\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=0, batch=30 train loss <loss>=8.3441701889\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[0] Batch [30]#011Speed: 708.28 samples/sec#011loss=8.344170\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[0] Batch[35] avg_epoch_loss=8.579831\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=0, batch=35 train loss <loss>=7.87597284317\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[0] Batch [35]#011Speed: 1546.65 samples/sec#011loss=7.875973\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[0] Batch[40] avg_epoch_loss=8.523917\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=0, batch=40 train loss <loss>=8.12133359909\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[0] Batch [40]#011Speed: 754.84 samples/sec#011loss=8.121334\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[0] Batch[45] avg_epoch_loss=8.492910\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=0, batch=45 train loss <loss>=8.23865451813\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[0] Batch [45]#011Speed: 1582.48 samples/sec#011loss=8.238655\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[0] Batch[50] avg_epoch_loss=8.439643\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=0, batch=50 train loss <loss>=7.94958114624\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[0] Batch [50]#011Speed: 1413.94 samples/sec#011loss=7.949581\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] processed a total of 1609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 1738.664150238037, \"sum\": 1738.664150238037, \"min\": 1738.664150238037}}, \"EndTime\": 1577414402.630261, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414400.891509}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=925.35726165 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=0, train loss <loss>=8.4396425883\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_d997dc77-2614-48c1-82f1-60748430dde5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 21.61407470703125, \"sum\": 21.61407470703125, \"min\": 21.61407470703125}}, \"EndTime\": 1577414402.652472, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414402.630348}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[1] Batch[0] avg_epoch_loss=8.680103\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=8.680103302\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[1] Batch[5] avg_epoch_loss=8.670997\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=8.6709968249\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:02 INFO 139649395074880] Epoch[1] Batch [5]#011Speed: 1526.98 samples/sec#011loss=8.670997\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] Epoch[1] Batch[10] avg_epoch_loss=8.622590\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=8.56450185776\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] Epoch[1] Batch [10]#011Speed: 812.75 samples/sec#011loss=8.564502\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] Epoch[1] Batch[15] avg_epoch_loss=8.676900\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=1, batch=15 train loss <loss>=8.79638233185\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] Epoch[1] Batch [15]#011Speed: 1568.90 samples/sec#011loss=8.796382\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] Epoch[1] Batch[20] avg_epoch_loss=8.634519\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=1, batch=20 train loss <loss>=8.49890098572\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] Epoch[1] Batch [20]#011Speed: 683.12 samples/sec#011loss=8.498901\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] Epoch[1] Batch[25] avg_epoch_loss=8.632929\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=1, batch=25 train loss <loss>=8.62624721527\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] Epoch[1] Batch [25]#011Speed: 1573.01 samples/sec#011loss=8.626247\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] Epoch[1] Batch[30] avg_epoch_loss=8.595513\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=1, batch=30 train loss <loss>=8.40095024109\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] Epoch[1] Batch [30]#011Speed: 672.61 samples/sec#011loss=8.400950\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] Epoch[1] Batch[35] avg_epoch_loss=8.561603\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=1, batch=35 train loss <loss>=8.35136032104\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:03 INFO 139649395074880] Epoch[1] Batch [35]#011Speed: 1550.96 samples/sec#011loss=8.351360\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] Epoch[1] Batch[40] avg_epoch_loss=8.495792\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=1, batch=40 train loss <loss>=8.02195205688\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] Epoch[1] Batch [40]#011Speed: 579.07 samples/sec#011loss=8.021952\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] Epoch[1] Batch[45] avg_epoch_loss=8.439532\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=1, batch=45 train loss <loss>=7.9781996727\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] Epoch[1] Batch [45]#011Speed: 1207.04 samples/sec#011loss=7.978200\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] Epoch[1] Batch[50] avg_epoch_loss=8.390380\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=1, batch=50 train loss <loss>=7.93818635941\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] Epoch[1] Batch [50]#011Speed: 849.51 samples/sec#011loss=7.938186\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] processed a total of 1628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1803.7738800048828, \"sum\": 1803.7738800048828, \"min\": 1803.7738800048828}}, \"EndTime\": 1577414404.456375, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414402.652546}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=902.501574412 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=1, train loss <loss>=8.39038012074\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_920d846b-57e7-4cfa-ac02-6e88bf064e9b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 25.835037231445312, \"sum\": 25.835037231445312, \"min\": 25.835037231445312}}, \"EndTime\": 1577414404.482809, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414404.456443}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] Epoch[2] Batch[0] avg_epoch_loss=8.754738\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=8.754737854\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] Epoch[2] Batch[5] avg_epoch_loss=8.578884\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=8.57888364792\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] Epoch[2] Batch [5]#011Speed: 1248.32 samples/sec#011loss=8.578884\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] Epoch[2] Batch[10] avg_epoch_loss=8.765461\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=8.98935279846\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:04 INFO 139649395074880] Epoch[2] Batch [10]#011Speed: 738.10 samples/sec#011loss=8.989353\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] Epoch[2] Batch[15] avg_epoch_loss=8.826185\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=8.95977745056\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] Epoch[2] Batch [15]#011Speed: 1318.53 samples/sec#011loss=8.959777\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] Epoch[2] Batch[20] avg_epoch_loss=8.750236\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=2, batch=20 train loss <loss>=8.50719852448\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] Epoch[2] Batch [20]#011Speed: 686.65 samples/sec#011loss=8.507199\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] Epoch[2] Batch[25] avg_epoch_loss=8.645129\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=2, batch=25 train loss <loss>=8.20368185043\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] Epoch[2] Batch [25]#011Speed: 1619.86 samples/sec#011loss=8.203682\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] Epoch[2] Batch[30] avg_epoch_loss=8.593976\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=2, batch=30 train loss <loss>=8.32798051834\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] Epoch[2] Batch [30]#011Speed: 816.19 samples/sec#011loss=8.327981\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] Epoch[2] Batch[35] avg_epoch_loss=8.487473\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=2, batch=35 train loss <loss>=7.82715053558\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] Epoch[2] Batch [35]#011Speed: 1590.19 samples/sec#011loss=7.827151\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] Epoch[2] Batch[40] avg_epoch_loss=8.409543\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=2, batch=40 train loss <loss>=7.84844865799\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:05 INFO 139649395074880] Epoch[2] Batch [40]#011Speed: 772.76 samples/sec#011loss=7.848449\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[2] Batch[45] avg_epoch_loss=8.375988\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=2, batch=45 train loss <loss>=8.10083599091\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[2] Batch [45]#011Speed: 1417.91 samples/sec#011loss=8.100836\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[2] Batch[50] avg_epoch_loss=8.350247\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=2, batch=50 train loss <loss>=8.11342906952\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[2] Batch [50]#011Speed: 1060.81 samples/sec#011loss=8.113429\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] processed a total of 1612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1726.362943649292, \"sum\": 1726.362943649292, \"min\": 1726.362943649292}}, \"EndTime\": 1577414406.209333, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414404.482907}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=933.697600553 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=2, train loss <loss>=8.35024664449\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_aa8fe568-ab6c-463b-8f9a-a055e4ae8c64-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 23.94580841064453, \"sum\": 23.94580841064453, \"min\": 23.94580841064453}}, \"EndTime\": 1577414406.233819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414406.209405}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[3] Batch[0] avg_epoch_loss=8.264418\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=8.26441764832\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[3] Batch[5] avg_epoch_loss=8.337442\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=8.33744208018\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[3] Batch [5]#011Speed: 1626.74 samples/sec#011loss=8.337442\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[3] Batch[10] avg_epoch_loss=8.487887\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=8.66842136383\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[3] Batch [10]#011Speed: 716.79 samples/sec#011loss=8.668421\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[3] Batch[15] avg_epoch_loss=8.566004\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=8.7378613472\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[3] Batch [15]#011Speed: 1387.65 samples/sec#011loss=8.737861\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[3] Batch[20] avg_epoch_loss=8.595277\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=3, batch=20 train loss <loss>=8.68895225525\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:06 INFO 139649395074880] Epoch[3] Batch [20]#011Speed: 793.82 samples/sec#011loss=8.688952\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Epoch[3] Batch[25] avg_epoch_loss=8.517217\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=3, batch=25 train loss <loss>=8.18936042786\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Epoch[3] Batch [25]#011Speed: 1506.38 samples/sec#011loss=8.189360\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Epoch[3] Batch[30] avg_epoch_loss=8.455584\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=3, batch=30 train loss <loss>=8.13509635925\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Epoch[3] Batch [30]#011Speed: 787.27 samples/sec#011loss=8.135096\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Epoch[3] Batch[35] avg_epoch_loss=8.410631\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=3, batch=35 train loss <loss>=8.13192176819\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Epoch[3] Batch [35]#011Speed: 1524.68 samples/sec#011loss=8.131922\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Epoch[3] Batch[40] avg_epoch_loss=8.365422\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=3, batch=40 train loss <loss>=8.03991441727\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Epoch[3] Batch [40]#011Speed: 731.71 samples/sec#011loss=8.039914\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Epoch[3] Batch[45] avg_epoch_loss=8.398010\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=3, batch=45 train loss <loss>=8.66523599625\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Epoch[3] Batch [45]#011Speed: 1586.97 samples/sec#011loss=8.665236\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Epoch[3] Batch[50] avg_epoch_loss=8.326155\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=3, batch=50 train loss <loss>=7.66508989334\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Epoch[3] Batch [50]#011Speed: 1250.46 samples/sec#011loss=7.665090\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] processed a total of 1603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1628.1590461730957, \"sum\": 1628.1590461730957, \"min\": 1628.1590461730957}}, \"EndTime\": 1577414407.862092, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414406.233883}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=984.482244609 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=3, train loss <loss>=8.32615532595\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:07 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_6479e6a4-c39a-48ba-8417-374ecad33003-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 25.876998901367188, \"sum\": 25.876998901367188, \"min\": 25.876998901367188}}, \"EndTime\": 1577414407.888509, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414407.862168}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] Epoch[4] Batch[0] avg_epoch_loss=9.012209\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=9.0122089386\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] Epoch[4] Batch[5] avg_epoch_loss=8.572560\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=8.57255999247\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] Epoch[4] Batch [5]#011Speed: 1572.70 samples/sec#011loss=8.572560\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] Epoch[4] Batch[10] avg_epoch_loss=8.470798\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=8.3486825943\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] Epoch[4] Batch [10]#011Speed: 782.73 samples/sec#011loss=8.348683\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] Epoch[4] Batch[15] avg_epoch_loss=8.541022\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=8.69551467896\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] Epoch[4] Batch [15]#011Speed: 1598.98 samples/sec#011loss=8.695515\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] Epoch[4] Batch[20] avg_epoch_loss=8.505520\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=4, batch=20 train loss <loss>=8.39191532135\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] Epoch[4] Batch [20]#011Speed: 707.13 samples/sec#011loss=8.391915\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] Epoch[4] Batch[25] avg_epoch_loss=8.467040\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=4, batch=25 train loss <loss>=8.30542421341\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:08 INFO 139649395074880] Epoch[4] Batch [25]#011Speed: 1406.16 samples/sec#011loss=8.305424\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] Epoch[4] Batch[30] avg_epoch_loss=8.391453\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=4, batch=30 train loss <loss>=7.99840040207\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] Epoch[4] Batch [30]#011Speed: 716.21 samples/sec#011loss=7.998400\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] Epoch[4] Batch[35] avg_epoch_loss=8.362226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=4, batch=35 train loss <loss>=8.18102054596\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] Epoch[4] Batch [35]#011Speed: 1477.08 samples/sec#011loss=8.181021\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] Epoch[4] Batch[40] avg_epoch_loss=8.300942\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=4, batch=40 train loss <loss>=7.85969247818\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] Epoch[4] Batch [40]#011Speed: 762.63 samples/sec#011loss=7.859692\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] Epoch[4] Batch[45] avg_epoch_loss=8.272913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=4, batch=45 train loss <loss>=8.04308166504\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] Epoch[4] Batch [45]#011Speed: 1164.38 samples/sec#011loss=8.043082\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] processed a total of 1554 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1643.8689231872559, \"sum\": 1643.8689231872559, \"min\": 1643.8689231872559}}, \"EndTime\": 1577414409.532497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414407.888574}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=945.264628477 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=4, train loss <loss>=8.2067861557\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_c62aebd4-f0c2-48d2-b74a-116a87dfb3be-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 26.419878005981445, \"sum\": 26.419878005981445, \"min\": 26.419878005981445}}, \"EndTime\": 1577414409.55951, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414409.532576}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] Epoch[5] Batch[0] avg_epoch_loss=7.788921\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=7.78892087936\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] Epoch[5] Batch[5] avg_epoch_loss=8.376042\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=8.37604165077\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:09 INFO 139649395074880] Epoch[5] Batch [5]#011Speed: 1318.05 samples/sec#011loss=8.376042\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch[10] avg_epoch_loss=8.448669\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=8.53582210541\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch [10]#011Speed: 705.81 samples/sec#011loss=8.535822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch[15] avg_epoch_loss=8.336750\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=8.0905292511\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch [15]#011Speed: 1535.10 samples/sec#011loss=8.090529\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch[20] avg_epoch_loss=8.351310\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=5, batch=20 train loss <loss>=8.39790048599\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch [20]#011Speed: 790.00 samples/sec#011loss=8.397900\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch[25] avg_epoch_loss=8.342357\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=5, batch=25 train loss <loss>=8.30475711823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch [25]#011Speed: 1609.21 samples/sec#011loss=8.304757\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch[30] avg_epoch_loss=8.258888\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=5, batch=30 train loss <loss>=7.82484579086\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch [30]#011Speed: 765.69 samples/sec#011loss=7.824846\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch[35] avg_epoch_loss=8.246169\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=5, batch=35 train loss <loss>=8.16731405258\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch [35]#011Speed: 1605.65 samples/sec#011loss=8.167314\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch[40] avg_epoch_loss=8.213174\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=5, batch=40 train loss <loss>=7.97560415268\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:10 INFO 139649395074880] Epoch[5] Batch [40]#011Speed: 803.55 samples/sec#011loss=7.975604\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] Epoch[5] Batch[45] avg_epoch_loss=8.176848\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=5, batch=45 train loss <loss>=7.87898235321\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] Epoch[5] Batch [45]#011Speed: 1533.77 samples/sec#011loss=7.878982\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] processed a total of 1588 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1637.6259326934814, \"sum\": 1637.6259326934814, \"min\": 1637.6259326934814}}, \"EndTime\": 1577414411.197264, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414409.559578}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=969.629363405 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=5, train loss <loss>=8.10664637566\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_7a864ed0-8d0e-44aa-8796-c2a4f0b422cd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.065048217773438, \"sum\": 17.065048217773438, \"min\": 17.065048217773438}}, \"EndTime\": 1577414411.21496, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414411.197338}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] Epoch[6] Batch[0] avg_epoch_loss=8.628199\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=8.62819862366\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] Epoch[6] Batch[5] avg_epoch_loss=8.340158\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=8.34015750885\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] Epoch[6] Batch [5]#011Speed: 1384.61 samples/sec#011loss=8.340158\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] Epoch[6] Batch[10] avg_epoch_loss=8.440858\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=8.561698246\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] Epoch[6] Batch [10]#011Speed: 761.02 samples/sec#011loss=8.561698\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] Epoch[6] Batch[15] avg_epoch_loss=8.525745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=8.7124961853\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] Epoch[6] Batch [15]#011Speed: 1457.17 samples/sec#011loss=8.712496\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] Epoch[6] Batch[20] avg_epoch_loss=8.405269\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=6, batch=20 train loss <loss>=8.01974487305\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:11 INFO 139649395074880] Epoch[6] Batch [20]#011Speed: 808.57 samples/sec#011loss=8.019745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] Epoch[6] Batch[25] avg_epoch_loss=8.420119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=6, batch=25 train loss <loss>=8.48249263763\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] Epoch[6] Batch [25]#011Speed: 1300.72 samples/sec#011loss=8.482493\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] Epoch[6] Batch[30] avg_epoch_loss=8.363569\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=6, batch=30 train loss <loss>=8.06950960159\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] Epoch[6] Batch [30]#011Speed: 784.98 samples/sec#011loss=8.069510\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] Epoch[6] Batch[35] avg_epoch_loss=8.317166\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=6, batch=35 train loss <loss>=8.02946281433\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] Epoch[6] Batch [35]#011Speed: 1554.76 samples/sec#011loss=8.029463\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] Epoch[6] Batch[40] avg_epoch_loss=8.271565\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=6, batch=40 train loss <loss>=7.94324321747\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] Epoch[6] Batch [40]#011Speed: 745.27 samples/sec#011loss=7.943243\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] Epoch[6] Batch[45] avg_epoch_loss=8.223133\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=6, batch=45 train loss <loss>=7.8259850502\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] Epoch[6] Batch [45]#011Speed: 1129.08 samples/sec#011loss=7.825985\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] processed a total of 1555 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1606.6129207611084, \"sum\": 1606.6129207611084, \"min\": 1606.6129207611084}}, \"EndTime\": 1577414412.821682, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414411.21502}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=967.805332043 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=6, train loss <loss>=8.22992214865\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] Epoch[7] Batch[0] avg_epoch_loss=8.251435\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=8.25143527985\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] Epoch[7] Batch[5] avg_epoch_loss=8.247217\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=8.24721654256\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] Epoch[7] Batch [5]#011Speed: 1452.39 samples/sec#011loss=8.247217\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] Epoch[7] Batch[10] avg_epoch_loss=8.303248\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=8.37048530579\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] Epoch[7] Batch [10]#011Speed: 746.54 samples/sec#011loss=8.370485\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] Epoch[7] Batch[15] avg_epoch_loss=8.397701\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=7, batch=15 train loss <loss>=8.60549869537\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] Epoch[7] Batch [15]#011Speed: 1633.02 samples/sec#011loss=8.605499\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] Epoch[7] Batch[20] avg_epoch_loss=8.454182\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=7, batch=20 train loss <loss>=8.63492202759\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] Epoch[7] Batch [20]#011Speed: 763.53 samples/sec#011loss=8.634922\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] Epoch[7] Batch[25] avg_epoch_loss=8.355006\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=7, batch=25 train loss <loss>=7.9384677887\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] Epoch[7] Batch [25]#011Speed: 1551.26 samples/sec#011loss=7.938468\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] Epoch[7] Batch[30] avg_epoch_loss=8.271263\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=7, batch=30 train loss <loss>=7.83579549789\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:13 INFO 139649395074880] Epoch[7] Batch [30]#011Speed: 688.86 samples/sec#011loss=7.835795\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[7] Batch[35] avg_epoch_loss=8.219094\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=7, batch=35 train loss <loss>=7.89565067291\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[7] Batch [35]#011Speed: 1300.99 samples/sec#011loss=7.895651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[7] Batch[40] avg_epoch_loss=8.226496\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=7, batch=40 train loss <loss>=8.27978744507\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[7] Batch [40]#011Speed: 706.62 samples/sec#011loss=8.279787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[7] Batch[45] avg_epoch_loss=8.210927\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=7, batch=45 train loss <loss>=8.08326206207\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[7] Batch [45]#011Speed: 1490.06 samples/sec#011loss=8.083262\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[7] Batch[50] avg_epoch_loss=8.166178\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=7, batch=50 train loss <loss>=7.75448741913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[7] Batch [50]#011Speed: 1352.43 samples/sec#011loss=7.754487\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] processed a total of 1621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1684.7760677337646, \"sum\": 1684.7760677337646, \"min\": 1684.7760677337646}}, \"EndTime\": 1577414414.506985, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414412.821763}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=962.088624658 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=7, train loss <loss>=8.16617811427\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[8] Batch[0] avg_epoch_loss=7.737660\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=7.73765993118\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[8] Batch[5] avg_epoch_loss=8.066033\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=8.0660332044\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[8] Batch [5]#011Speed: 1301.90 samples/sec#011loss=8.066033\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[8] Batch[10] avg_epoch_loss=8.305892\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=8.59372196198\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:14 INFO 139649395074880] Epoch[8] Batch [10]#011Speed: 714.64 samples/sec#011loss=8.593722\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] Epoch[8] Batch[15] avg_epoch_loss=8.329165\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=8, batch=15 train loss <loss>=8.3803647995\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] Epoch[8] Batch [15]#011Speed: 1632.24 samples/sec#011loss=8.380365\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] Epoch[8] Batch[20] avg_epoch_loss=8.415606\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=8, batch=20 train loss <loss>=8.69221687317\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] Epoch[8] Batch [20]#011Speed: 783.89 samples/sec#011loss=8.692217\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] Epoch[8] Batch[25] avg_epoch_loss=8.344536\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=8, batch=25 train loss <loss>=8.04604473114\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] Epoch[8] Batch [25]#011Speed: 1327.02 samples/sec#011loss=8.046045\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] Epoch[8] Batch[30] avg_epoch_loss=8.273846\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=8, batch=30 train loss <loss>=7.90625400543\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] Epoch[8] Batch [30]#011Speed: 786.90 samples/sec#011loss=7.906254\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] Epoch[8] Batch[35] avg_epoch_loss=8.179958\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=8, batch=35 train loss <loss>=7.59785280228\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] Epoch[8] Batch [35]#011Speed: 1591.66 samples/sec#011loss=7.597853\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] Epoch[8] Batch[40] avg_epoch_loss=8.166826\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=8, batch=40 train loss <loss>=8.07227458954\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:15 INFO 139649395074880] Epoch[8] Batch [40]#011Speed: 795.73 samples/sec#011loss=8.072275\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[8] Batch[45] avg_epoch_loss=8.137432\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=8, batch=45 train loss <loss>=7.89640378952\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[8] Batch [45]#011Speed: 1444.39 samples/sec#011loss=7.896404\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[8] Batch[50] avg_epoch_loss=8.078275\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=8, batch=50 train loss <loss>=7.53403291702\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[8] Batch [50]#011Speed: 1122.74 samples/sec#011loss=7.534033\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] processed a total of 1640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1674.9329566955566, \"sum\": 1674.9329566955566, \"min\": 1674.9329566955566}}, \"EndTime\": 1577414416.182496, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414414.507049}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=979.07760874 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=8, train loss <loss>=8.06801632734\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_d86ad10b-107f-4c6a-9137-69ae6542b299-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 26.057004928588867, \"sum\": 26.057004928588867, \"min\": 26.057004928588867}}, \"EndTime\": 1577414416.209089, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414416.182575}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[9] Batch[0] avg_epoch_loss=8.447440\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=8.4474401474\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[9] Batch[5] avg_epoch_loss=8.194430\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=8.19443019231\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[9] Batch [5]#011Speed: 1603.06 samples/sec#011loss=8.194430\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[9] Batch[10] avg_epoch_loss=8.457270\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=8.77267875671\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[9] Batch [10]#011Speed: 822.44 samples/sec#011loss=8.772679\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[9] Batch[15] avg_epoch_loss=8.376542\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=9, batch=15 train loss <loss>=8.19893980026\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[9] Batch [15]#011Speed: 1541.72 samples/sec#011loss=8.198940\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[9] Batch[20] avg_epoch_loss=8.444749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=9, batch=20 train loss <loss>=8.66301193237\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:16 INFO 139649395074880] Epoch[9] Batch [20]#011Speed: 746.33 samples/sec#011loss=8.663012\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] Epoch[9] Batch[25] avg_epoch_loss=8.394060\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=9, batch=25 train loss <loss>=8.18116407394\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] Epoch[9] Batch [25]#011Speed: 1624.50 samples/sec#011loss=8.181164\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] Epoch[9] Batch[30] avg_epoch_loss=8.327508\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=9, batch=30 train loss <loss>=7.981437397\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] Epoch[9] Batch [30]#011Speed: 793.94 samples/sec#011loss=7.981437\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] Epoch[9] Batch[35] avg_epoch_loss=8.281528\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=9, batch=35 train loss <loss>=7.99645357132\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] Epoch[9] Batch [35]#011Speed: 1410.44 samples/sec#011loss=7.996454\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] Epoch[9] Batch[40] avg_epoch_loss=8.250600\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=9, batch=40 train loss <loss>=8.02791929245\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] Epoch[9] Batch [40]#011Speed: 717.72 samples/sec#011loss=8.027919\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] Epoch[9] Batch[45] avg_epoch_loss=8.213436\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=9, batch=45 train loss <loss>=7.90869054794\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] Epoch[9] Batch [45]#011Speed: 1553.90 samples/sec#011loss=7.908691\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] Epoch[9] Batch[50] avg_epoch_loss=8.191242\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=9, batch=50 train loss <loss>=7.98705310822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] Epoch[9] Batch [50]#011Speed: 1082.64 samples/sec#011loss=7.987053\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] processed a total of 1654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1674.957036972046, \"sum\": 1674.957036972046, \"min\": 1674.957036972046}}, \"EndTime\": 1577414417.884152, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414416.209149}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=987.432636845 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=9, train loss <loss>=8.17906583272\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:17 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch[0] avg_epoch_loss=8.410623\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=8.41062259674\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch[5] avg_epoch_loss=8.243241\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=8.24324115117\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch [5]#011Speed: 1344.81 samples/sec#011loss=8.243241\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch[10] avg_epoch_loss=8.297992\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=8.3636920929\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch [10]#011Speed: 756.03 samples/sec#011loss=8.363692\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch[15] avg_epoch_loss=8.363875\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=8.50881919861\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch [15]#011Speed: 1558.82 samples/sec#011loss=8.508819\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch[20] avg_epoch_loss=8.350179\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=10, batch=20 train loss <loss>=8.30635099411\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch [20]#011Speed: 799.43 samples/sec#011loss=8.306351\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch[25] avg_epoch_loss=8.294314\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=10, batch=25 train loss <loss>=8.05968151093\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch [25]#011Speed: 1541.65 samples/sec#011loss=8.059682\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch[30] avg_epoch_loss=8.242399\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=10, batch=30 train loss <loss>=7.97244253159\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:18 INFO 139649395074880] Epoch[10] Batch [30]#011Speed: 736.51 samples/sec#011loss=7.972443\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] Epoch[10] Batch[35] avg_epoch_loss=8.223137\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=10, batch=35 train loss <loss>=8.10371026993\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] Epoch[10] Batch [35]#011Speed: 1334.56 samples/sec#011loss=8.103710\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] Epoch[10] Batch[40] avg_epoch_loss=8.214256\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=10, batch=40 train loss <loss>=8.15031509399\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] Epoch[10] Batch [40]#011Speed: 773.72 samples/sec#011loss=8.150315\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] Epoch[10] Batch[45] avg_epoch_loss=8.234944\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=10, batch=45 train loss <loss>=8.40458192825\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] Epoch[10] Batch [45]#011Speed: 1610.79 samples/sec#011loss=8.404582\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] processed a total of 1572 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1616.9400215148926, \"sum\": 1616.9400215148926, \"min\": 1616.9400215148926}}, \"EndTime\": 1577414419.501639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414417.884219}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=972.13765706 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=10, train loss <loss>=8.18899241447\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] Epoch[11] Batch[0] avg_epoch_loss=8.645432\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=8.64543151855\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] Epoch[11] Batch[5] avg_epoch_loss=8.607984\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=8.60798358917\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] Epoch[11] Batch [5]#011Speed: 1657.84 samples/sec#011loss=8.607984\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] Epoch[11] Batch[10] avg_epoch_loss=8.598046\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=8.586120224\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:19 INFO 139649395074880] Epoch[11] Batch [10]#011Speed: 747.99 samples/sec#011loss=8.586120\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] Epoch[11] Batch[15] avg_epoch_loss=8.526719\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=11, batch=15 train loss <loss>=8.36980056763\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] Epoch[11] Batch [15]#011Speed: 1511.90 samples/sec#011loss=8.369801\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] Epoch[11] Batch[20] avg_epoch_loss=8.558900\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=11, batch=20 train loss <loss>=8.66187782288\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] Epoch[11] Batch [20]#011Speed: 699.66 samples/sec#011loss=8.661878\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] Epoch[11] Batch[25] avg_epoch_loss=8.460144\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=11, batch=25 train loss <loss>=8.0453704834\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] Epoch[11] Batch [25]#011Speed: 1520.32 samples/sec#011loss=8.045370\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] Epoch[11] Batch[30] avg_epoch_loss=8.425207\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=11, batch=30 train loss <loss>=8.24353599548\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] Epoch[11] Batch [30]#011Speed: 794.77 samples/sec#011loss=8.243536\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] Epoch[11] Batch[35] avg_epoch_loss=8.359199\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=11, batch=35 train loss <loss>=7.94995069504\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] Epoch[11] Batch [35]#011Speed: 1506.14 samples/sec#011loss=7.949951\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] Epoch[11] Batch[40] avg_epoch_loss=8.314423\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=11, batch=40 train loss <loss>=7.99203128815\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:20 INFO 139649395074880] Epoch[11] Batch [40]#011Speed: 813.04 samples/sec#011loss=7.992031\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[11] Batch[45] avg_epoch_loss=8.273785\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=11, batch=45 train loss <loss>=7.94055051804\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[11] Batch [45]#011Speed: 1303.99 samples/sec#011loss=7.940551\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[11] Batch[50] avg_epoch_loss=8.264992\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=11, batch=50 train loss <loss>=8.1841003418\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[11] Batch [50]#011Speed: 1054.28 samples/sec#011loss=8.184100\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] processed a total of 1642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1678.5948276519775, \"sum\": 1678.5948276519775, \"min\": 1678.5948276519775}}, \"EndTime\": 1577414421.180809, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414419.501718}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=978.132027462 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=11, train loss <loss>=8.29385018349\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[12] Batch[0] avg_epoch_loss=7.841983\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=7.84198284149\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[12] Batch[5] avg_epoch_loss=8.243849\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=8.24384864171\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[12] Batch [5]#011Speed: 1461.09 samples/sec#011loss=8.243849\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[12] Batch[10] avg_epoch_loss=8.282967\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=8.3299079895\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[12] Batch [10]#011Speed: 736.55 samples/sec#011loss=8.329908\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[12] Batch[15] avg_epoch_loss=8.298093\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=8.33137073517\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[12] Batch [15]#011Speed: 1582.41 samples/sec#011loss=8.331371\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[12] Batch[20] avg_epoch_loss=8.391637\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=12, batch=20 train loss <loss>=8.6909778595\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:21 INFO 139649395074880] Epoch[12] Batch [20]#011Speed: 692.65 samples/sec#011loss=8.690978\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] Epoch[12] Batch[25] avg_epoch_loss=8.285392\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=12, batch=25 train loss <loss>=7.83916292191\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] Epoch[12] Batch [25]#011Speed: 1700.66 samples/sec#011loss=7.839163\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] Epoch[12] Batch[30] avg_epoch_loss=8.222099\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=12, batch=30 train loss <loss>=7.8929772377\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] Epoch[12] Batch [30]#011Speed: 705.83 samples/sec#011loss=7.892977\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] Epoch[12] Batch[35] avg_epoch_loss=8.172040\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=12, batch=35 train loss <loss>=7.86167621613\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] Epoch[12] Batch [35]#011Speed: 1657.98 samples/sec#011loss=7.861676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] Epoch[12] Batch[40] avg_epoch_loss=8.177509\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=12, batch=40 train loss <loss>=8.21688098907\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] Epoch[12] Batch [40]#011Speed: 736.92 samples/sec#011loss=8.216881\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] Epoch[12] Batch[45] avg_epoch_loss=8.178206\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=12, batch=45 train loss <loss>=8.1839266777\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] Epoch[12] Batch [45]#011Speed: 1290.39 samples/sec#011loss=8.183927\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] processed a total of 1597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1669.739007949829, \"sum\": 1669.739007949829, \"min\": 1669.739007949829}}, \"EndTime\": 1577414422.851075, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414421.180887}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=956.373399918 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=12, train loss <loss>=8.1382793045\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] Epoch[13] Batch[0] avg_epoch_loss=7.805979\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=7.80597925186\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch[5] avg_epoch_loss=8.241611\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=8.2416109244\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch [5]#011Speed: 1663.12 samples/sec#011loss=8.241611\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch[10] avg_epoch_loss=8.546008\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=8.91128463745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch [10]#011Speed: 783.09 samples/sec#011loss=8.911285\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch[15] avg_epoch_loss=8.489858\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=13, batch=15 train loss <loss>=8.36632738113\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch [15]#011Speed: 1593.60 samples/sec#011loss=8.366327\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch[20] avg_epoch_loss=8.480471\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=13, batch=20 train loss <loss>=8.450431633\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch [20]#011Speed: 771.31 samples/sec#011loss=8.450432\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch[25] avg_epoch_loss=8.406344\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=13, batch=25 train loss <loss>=8.0950135231\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch [25]#011Speed: 1732.80 samples/sec#011loss=8.095014\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch[30] avg_epoch_loss=8.344784\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=13, batch=30 train loss <loss>=8.02466983795\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch [30]#011Speed: 769.02 samples/sec#011loss=8.024670\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch[35] avg_epoch_loss=8.286047\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=13, batch=35 train loss <loss>=7.92188119888\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:23 INFO 139649395074880] Epoch[13] Batch [35]#011Speed: 1732.46 samples/sec#011loss=7.921881\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[13] Batch[40] avg_epoch_loss=8.270659\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=13, batch=40 train loss <loss>=8.15986270905\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[13] Batch [40]#011Speed: 750.82 samples/sec#011loss=8.159863\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[13] Batch[45] avg_epoch_loss=8.224573\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=13, batch=45 train loss <loss>=7.8466629982\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[13] Batch [45]#011Speed: 1294.76 samples/sec#011loss=7.846663\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[13] Batch[50] avg_epoch_loss=8.149159\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=13, batch=50 train loss <loss>=7.45535326004\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[13] Batch [50]#011Speed: 1309.92 samples/sec#011loss=7.455353\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] processed a total of 1624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1600.4221439361572, \"sum\": 1600.4221439361572, \"min\": 1600.4221439361572}}, \"EndTime\": 1577414424.45205, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414422.851151}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1014.67528632 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=13, train loss <loss>=8.14915885177\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[14] Batch[0] avg_epoch_loss=8.301268\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=8.3012676239\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[14] Batch[5] avg_epoch_loss=8.302802\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=8.3028023243\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[14] Batch [5]#011Speed: 1607.47 samples/sec#011loss=8.302802\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[14] Batch[10] avg_epoch_loss=8.338046\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=8.38033752441\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[14] Batch [10]#011Speed: 763.84 samples/sec#011loss=8.380338\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[14] Batch[15] avg_epoch_loss=8.362502\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=8.41630735397\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:24 INFO 139649395074880] Epoch[14] Batch [15]#011Speed: 1551.12 samples/sec#011loss=8.416307\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] Epoch[14] Batch[20] avg_epoch_loss=8.324436\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=14, batch=20 train loss <loss>=8.20262460709\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] Epoch[14] Batch [20]#011Speed: 805.22 samples/sec#011loss=8.202625\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] Epoch[14] Batch[25] avg_epoch_loss=8.279163\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=14, batch=25 train loss <loss>=8.08901605606\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] Epoch[14] Batch [25]#011Speed: 1532.38 samples/sec#011loss=8.089016\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] Epoch[14] Batch[30] avg_epoch_loss=8.221216\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=14, batch=30 train loss <loss>=7.91988868713\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] Epoch[14] Batch [30]#011Speed: 779.07 samples/sec#011loss=7.919889\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] Epoch[14] Batch[35] avg_epoch_loss=8.181098\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=14, batch=35 train loss <loss>=7.93236713409\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] Epoch[14] Batch [35]#011Speed: 1536.81 samples/sec#011loss=7.932367\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] Epoch[14] Batch[40] avg_epoch_loss=8.150609\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=14, batch=40 train loss <loss>=7.93108959198\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] Epoch[14] Batch [40]#011Speed: 742.60 samples/sec#011loss=7.931090\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] Epoch[14] Batch[45] avg_epoch_loss=8.152622\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=14, batch=45 train loss <loss>=8.16912879944\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:25 INFO 139649395074880] Epoch[14] Batch [45]#011Speed: 1329.30 samples/sec#011loss=8.169129\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] processed a total of 1571 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1603.5881042480469, \"sum\": 1603.5881042480469, \"min\": 1603.5881042480469}}, \"EndTime\": 1577414426.056157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414424.452108}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=979.609117435 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=14, train loss <loss>=8.11025425911\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] Epoch[15] Batch[0] avg_epoch_loss=8.285312\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=8.28531169891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] Epoch[15] Batch[5] avg_epoch_loss=8.343570\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=8.34357023239\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] Epoch[15] Batch [5]#011Speed: 1549.41 samples/sec#011loss=8.343570\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] Epoch[15] Batch[10] avg_epoch_loss=8.453212\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=8.58478145599\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] Epoch[15] Batch [10]#011Speed: 746.84 samples/sec#011loss=8.584781\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] Epoch[15] Batch[15] avg_epoch_loss=8.508910\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=8.63144550323\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] Epoch[15] Batch [15]#011Speed: 1534.30 samples/sec#011loss=8.631446\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] Epoch[15] Batch[20] avg_epoch_loss=8.423718\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=15, batch=20 train loss <loss>=8.15110454559\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] Epoch[15] Batch [20]#011Speed: 809.02 samples/sec#011loss=8.151105\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] Epoch[15] Batch[25] avg_epoch_loss=8.327880\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=15, batch=25 train loss <loss>=7.92535800934\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:26 INFO 139649395074880] Epoch[15] Batch [25]#011Speed: 1293.45 samples/sec#011loss=7.925358\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] Epoch[15] Batch[30] avg_epoch_loss=8.256952\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=15, batch=30 train loss <loss>=7.88812570572\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] Epoch[15] Batch [30]#011Speed: 751.39 samples/sec#011loss=7.888126\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] Epoch[15] Batch[35] avg_epoch_loss=8.216109\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=15, batch=35 train loss <loss>=7.96288738251\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] Epoch[15] Batch [35]#011Speed: 1308.75 samples/sec#011loss=7.962887\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] Epoch[15] Batch[40] avg_epoch_loss=8.203801\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=15, batch=40 train loss <loss>=8.11517839432\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] Epoch[15] Batch [40]#011Speed: 725.70 samples/sec#011loss=8.115178\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] Epoch[15] Batch[45] avg_epoch_loss=8.152603\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=15, batch=45 train loss <loss>=7.73278083801\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] Epoch[15] Batch [45]#011Speed: 1622.93 samples/sec#011loss=7.732781\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] processed a total of 1589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1664.3619537353516, \"sum\": 1664.3619537353516, \"min\": 1664.3619537353516}}, \"EndTime\": 1577414427.72107, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414426.056238}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=954.661682663 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=15, train loss <loss>=8.1289377594\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] Epoch[16] Batch[0] avg_epoch_loss=8.522513\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=8.52251338959\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] Epoch[16] Batch[5] avg_epoch_loss=8.429674\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=8.42967398961\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:27 INFO 139649395074880] Epoch[16] Batch [5]#011Speed: 1330.68 samples/sec#011loss=8.429674\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] Epoch[16] Batch[10] avg_epoch_loss=8.398227\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=8.36049060822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] Epoch[16] Batch [10]#011Speed: 750.79 samples/sec#011loss=8.360491\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] Epoch[16] Batch[15] avg_epoch_loss=8.449518\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=8.56235942841\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] Epoch[16] Batch [15]#011Speed: 1283.83 samples/sec#011loss=8.562359\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] Epoch[16] Batch[20] avg_epoch_loss=8.417557\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=16, batch=20 train loss <loss>=8.31528224945\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] Epoch[16] Batch [20]#011Speed: 725.11 samples/sec#011loss=8.315282\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] Epoch[16] Batch[25] avg_epoch_loss=8.359105\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=16, batch=25 train loss <loss>=8.11360368729\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] Epoch[16] Batch [25]#011Speed: 1350.08 samples/sec#011loss=8.113604\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] Epoch[16] Batch[30] avg_epoch_loss=8.282273\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=16, batch=30 train loss <loss>=7.88274888992\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] Epoch[16] Batch [30]#011Speed: 671.17 samples/sec#011loss=7.882749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] Epoch[16] Batch[35] avg_epoch_loss=8.230739\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=16, batch=35 train loss <loss>=7.91122360229\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:28 INFO 139649395074880] Epoch[16] Batch [35]#011Speed: 1520.94 samples/sec#011loss=7.911224\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] Epoch[16] Batch[40] avg_epoch_loss=8.189906\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=16, batch=40 train loss <loss>=7.89591245651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] Epoch[16] Batch [40]#011Speed: 805.42 samples/sec#011loss=7.895912\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] Epoch[16] Batch[45] avg_epoch_loss=8.132734\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=16, batch=45 train loss <loss>=7.66392126083\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] Epoch[16] Batch [45]#011Speed: 1198.34 samples/sec#011loss=7.663921\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] processed a total of 1550 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1666.2030220031738, \"sum\": 1666.2030220031738, \"min\": 1666.2030220031738}}, \"EndTime\": 1577414429.387864, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414427.721139}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=930.193565594 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=16, train loss <loss>=8.11593305821\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] Epoch[17] Batch[0] avg_epoch_loss=8.827446\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=8.82744598389\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] Epoch[17] Batch[5] avg_epoch_loss=8.347520\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=8.34751955668\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] Epoch[17] Batch [5]#011Speed: 1522.26 samples/sec#011loss=8.347520\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] Epoch[17] Batch[10] avg_epoch_loss=8.454233\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=8.58228931427\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] Epoch[17] Batch [10]#011Speed: 785.80 samples/sec#011loss=8.582289\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] Epoch[17] Batch[15] avg_epoch_loss=8.441901\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=8.41477184296\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:29 INFO 139649395074880] Epoch[17] Batch [15]#011Speed: 1270.73 samples/sec#011loss=8.414772\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] Epoch[17] Batch[20] avg_epoch_loss=8.417040\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=17, batch=20 train loss <loss>=8.33748407364\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] Epoch[17] Batch [20]#011Speed: 782.10 samples/sec#011loss=8.337484\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] Epoch[17] Batch[25] avg_epoch_loss=8.315821\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=17, batch=25 train loss <loss>=7.89069871902\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] Epoch[17] Batch [25]#011Speed: 1648.93 samples/sec#011loss=7.890699\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] Epoch[17] Batch[30] avg_epoch_loss=8.230642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=17, batch=30 train loss <loss>=7.78771076202\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] Epoch[17] Batch [30]#011Speed: 760.45 samples/sec#011loss=7.787711\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] Epoch[17] Batch[35] avg_epoch_loss=8.204273\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=17, batch=35 train loss <loss>=8.04078474045\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] Epoch[17] Batch [35]#011Speed: 748.58 samples/sec#011loss=8.040785\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] Epoch[17] Batch[40] avg_epoch_loss=8.166543\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=17, batch=40 train loss <loss>=7.89489326477\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] Epoch[17] Batch [40]#011Speed: 1529.83 samples/sec#011loss=7.894893\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] Epoch[17] Batch[45] avg_epoch_loss=8.125913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=17, batch=45 train loss <loss>=7.79274158478\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] Epoch[17] Batch [45]#011Speed: 1106.97 samples/sec#011loss=7.792742\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] processed a total of 1512 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1579.2229175567627, \"sum\": 1579.2229175567627, \"min\": 1579.2229175567627}}, \"EndTime\": 1577414430.967634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414429.387945}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=957.362525565 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=17, train loss <loss>=8.0881109635\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:30 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] Epoch[18] Batch[0] avg_epoch_loss=8.245764\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=8.24576377869\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] Epoch[18] Batch[5] avg_epoch_loss=8.367303\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=8.36730289459\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] Epoch[18] Batch [5]#011Speed: 1303.71 samples/sec#011loss=8.367303\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] Epoch[18] Batch[10] avg_epoch_loss=8.442865\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=8.53354053497\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] Epoch[18] Batch [10]#011Speed: 734.13 samples/sec#011loss=8.533541\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] Epoch[18] Batch[15] avg_epoch_loss=8.555393\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=18, batch=15 train loss <loss>=8.80295314789\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] Epoch[18] Batch [15]#011Speed: 1322.80 samples/sec#011loss=8.802953\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] Epoch[18] Batch[20] avg_epoch_loss=8.510947\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=18, batch=20 train loss <loss>=8.3687204361\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] Epoch[18] Batch [20]#011Speed: 759.81 samples/sec#011loss=8.368720\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] Epoch[18] Batch[25] avg_epoch_loss=8.424750\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=18, batch=25 train loss <loss>=8.06272411346\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:31 INFO 139649395074880] Epoch[18] Batch [25]#011Speed: 1332.23 samples/sec#011loss=8.062724\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[18] Batch[30] avg_epoch_loss=8.362783\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=18, batch=30 train loss <loss>=8.04055080414\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[18] Batch [30]#011Speed: 749.35 samples/sec#011loss=8.040551\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[18] Batch[35] avg_epoch_loss=8.307170\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=18, batch=35 train loss <loss>=7.96236858368\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[18] Batch [35]#011Speed: 1335.29 samples/sec#011loss=7.962369\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[18] Batch[40] avg_epoch_loss=8.291182\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=18, batch=40 train loss <loss>=8.17606754303\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[18] Batch [40]#011Speed: 706.71 samples/sec#011loss=8.176068\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[18] Batch[45] avg_epoch_loss=8.279689\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=18, batch=45 train loss <loss>=8.18544816971\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[18] Batch [45]#011Speed: 1404.22 samples/sec#011loss=8.185448\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[18] Batch[50] avg_epoch_loss=8.154304\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=18, batch=50 train loss <loss>=7.00076684952\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[18] Batch [50]#011Speed: 1152.71 samples/sec#011loss=7.000767\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] processed a total of 1602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1735.0881099700928, \"sum\": 1735.0881099700928, \"min\": 1735.0881099700928}}, \"EndTime\": 1577414432.703283, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414430.967714}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=923.224248023 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=18, train loss <loss>=8.15430428\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[19] Batch[0] avg_epoch_loss=8.187108\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=8.18710803986\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[19] Batch[5] avg_epoch_loss=8.184780\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=8.1847799619\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:32 INFO 139649395074880] Epoch[19] Batch [5]#011Speed: 1390.96 samples/sec#011loss=8.184780\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] Epoch[19] Batch[10] avg_epoch_loss=8.345016\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=8.53729906082\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] Epoch[19] Batch [10]#011Speed: 798.93 samples/sec#011loss=8.537299\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] Epoch[19] Batch[15] avg_epoch_loss=8.448640\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=19, batch=15 train loss <loss>=8.67661342621\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] Epoch[19] Batch [15]#011Speed: 1618.82 samples/sec#011loss=8.676613\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] Epoch[19] Batch[20] avg_epoch_loss=8.403772\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=19, batch=20 train loss <loss>=8.26019458771\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] Epoch[19] Batch [20]#011Speed: 723.93 samples/sec#011loss=8.260195\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] Epoch[19] Batch[25] avg_epoch_loss=8.332553\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=19, batch=25 train loss <loss>=8.03343515396\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] Epoch[19] Batch [25]#011Speed: 1619.71 samples/sec#011loss=8.033435\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] Epoch[19] Batch[30] avg_epoch_loss=8.267128\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=19, batch=30 train loss <loss>=7.92691488266\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] Epoch[19] Batch [30]#011Speed: 719.68 samples/sec#011loss=7.926915\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] Epoch[19] Batch[35] avg_epoch_loss=8.197500\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=19, batch=35 train loss <loss>=7.7658033371\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:33 INFO 139649395074880] Epoch[19] Batch [35]#011Speed: 1497.31 samples/sec#011loss=7.765803\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[19] Batch[40] avg_epoch_loss=8.163000\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=19, batch=40 train loss <loss>=7.91460533142\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[19] Batch [40]#011Speed: 751.14 samples/sec#011loss=7.914605\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[19] Batch[45] avg_epoch_loss=8.151037\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=19, batch=45 train loss <loss>=8.0529419899\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[19] Batch [45]#011Speed: 1737.36 samples/sec#011loss=8.052942\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[19] Batch[50] avg_epoch_loss=8.084402\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=19, batch=50 train loss <loss>=7.4713561058\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[19] Batch [50]#011Speed: 1179.13 samples/sec#011loss=7.471356\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] processed a total of 1602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1646.2059020996094, \"sum\": 1646.2059020996094, \"min\": 1646.2059020996094}}, \"EndTime\": 1577414434.350015, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414432.703382}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=973.079431834 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=19, train loss <loss>=8.0844019441\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[20] Batch[0] avg_epoch_loss=8.524511\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=8.52451133728\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[20] Batch[5] avg_epoch_loss=8.178301\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=8.17830053965\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[20] Batch [5]#011Speed: 1505.74 samples/sec#011loss=8.178301\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[20] Batch[10] avg_epoch_loss=8.199999\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=8.22603645325\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[20] Batch [10]#011Speed: 708.76 samples/sec#011loss=8.226036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[20] Batch[15] avg_epoch_loss=8.286026\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=20, batch=15 train loss <loss>=8.47528457642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:34 INFO 139649395074880] Epoch[20] Batch [15]#011Speed: 1605.78 samples/sec#011loss=8.475285\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch[20] avg_epoch_loss=8.266702\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=20, batch=20 train loss <loss>=8.20486688614\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch [20]#011Speed: 786.45 samples/sec#011loss=8.204867\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch[25] avg_epoch_loss=8.207949\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=20, batch=25 train loss <loss>=7.96118793488\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch [25]#011Speed: 1502.39 samples/sec#011loss=7.961188\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch[30] avg_epoch_loss=8.147319\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=20, batch=30 train loss <loss>=7.83204021454\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch [30]#011Speed: 781.91 samples/sec#011loss=7.832040\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch[35] avg_epoch_loss=8.127043\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=20, batch=35 train loss <loss>=8.0013343811\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch [35]#011Speed: 1723.71 samples/sec#011loss=8.001334\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch[40] avg_epoch_loss=8.086523\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=20, batch=40 train loss <loss>=7.79477968216\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch [40]#011Speed: 732.61 samples/sec#011loss=7.794780\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch[45] avg_epoch_loss=8.063997\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=20, batch=45 train loss <loss>=7.87928152084\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch [45]#011Speed: 1561.31 samples/sec#011loss=7.879282\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch[50] avg_epoch_loss=8.053976\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=20, batch=50 train loss <loss>=7.961784935\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:35 INFO 139649395074880] Epoch[20] Batch [50]#011Speed: 1156.89 samples/sec#011loss=7.961785\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] processed a total of 1669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1664.8681163787842, \"sum\": 1664.8681163787842, \"min\": 1664.8681163787842}}, \"EndTime\": 1577414436.015419, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414434.350095}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1002.41692295 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=20, train loss <loss>=8.04527015506\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_d06706f6-9228-4388-a805-a414dd6504dc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 24.801969528198242, \"sum\": 24.801969528198242, \"min\": 24.801969528198242}}, \"EndTime\": 1577414436.04075, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414436.015492}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] Epoch[21] Batch[0] avg_epoch_loss=7.952514\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=7.95251369476\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] Epoch[21] Batch[5] avg_epoch_loss=8.221119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=8.22111868858\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] Epoch[21] Batch [5]#011Speed: 1407.56 samples/sec#011loss=8.221119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] Epoch[21] Batch[10] avg_epoch_loss=8.265753\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=8.31931476593\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] Epoch[21] Batch [10]#011Speed: 781.70 samples/sec#011loss=8.319315\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] Epoch[21] Batch[15] avg_epoch_loss=8.302328\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=21, batch=15 train loss <loss>=8.38279294968\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] Epoch[21] Batch [15]#011Speed: 1673.64 samples/sec#011loss=8.382793\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] Epoch[21] Batch[20] avg_epoch_loss=8.270969\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=21, batch=20 train loss <loss>=8.17061891556\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] Epoch[21] Batch [20]#011Speed: 799.92 samples/sec#011loss=8.170619\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] Epoch[21] Batch[25] avg_epoch_loss=8.244429\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=21, batch=25 train loss <loss>=8.13295917511\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:36 INFO 139649395074880] Epoch[21] Batch [25]#011Speed: 1342.54 samples/sec#011loss=8.132959\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] Epoch[21] Batch[30] avg_epoch_loss=8.165368\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=21, batch=30 train loss <loss>=7.75425081253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] Epoch[21] Batch [30]#011Speed: 729.49 samples/sec#011loss=7.754251\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] Epoch[21] Batch[35] avg_epoch_loss=8.125561\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=21, batch=35 train loss <loss>=7.87876081467\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] Epoch[21] Batch [35]#011Speed: 1345.92 samples/sec#011loss=7.878761\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] Epoch[21] Batch[40] avg_epoch_loss=8.076022\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=21, batch=40 train loss <loss>=7.71933870316\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] Epoch[21] Batch [40]#011Speed: 735.42 samples/sec#011loss=7.719339\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] Epoch[21] Batch[45] avg_epoch_loss=8.076112\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=21, batch=45 train loss <loss>=8.07684755325\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] Epoch[21] Batch [45]#011Speed: 1390.95 samples/sec#011loss=8.076848\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] Epoch[21] Batch[50] avg_epoch_loss=8.050645\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=21, batch=50 train loss <loss>=7.81635227203\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] Epoch[21] Batch [50]#011Speed: 1247.60 samples/sec#011loss=7.816352\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] processed a total of 1650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1694.1978931427002, \"sum\": 1694.1978931427002, \"min\": 1694.1978931427002}}, \"EndTime\": 1577414437.735068, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414436.040814}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=973.850119483 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=21, train loss <loss>=8.01896272256\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_f88dbf99-c5f2-44fb-8b83-3be6f7993ab8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.912864685058594, \"sum\": 17.912864685058594, \"min\": 17.912864685058594}}, \"EndTime\": 1577414437.753653, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414437.735137}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] Epoch[22] Batch[0] avg_epoch_loss=8.042968\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=8.04296779633\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch[5] avg_epoch_loss=8.249219\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=8.2492193381\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch [5]#011Speed: 1278.26 samples/sec#011loss=8.249219\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch[10] avg_epoch_loss=8.416967\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=8.61826381683\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch [10]#011Speed: 671.28 samples/sec#011loss=8.618264\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch[15] avg_epoch_loss=8.406100\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=22, batch=15 train loss <loss>=8.38219232559\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch [15]#011Speed: 1714.91 samples/sec#011loss=8.382192\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch[20] avg_epoch_loss=8.298459\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=22, batch=20 train loss <loss>=7.95400857925\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch [20]#011Speed: 762.77 samples/sec#011loss=7.954009\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch[25] avg_epoch_loss=8.274057\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=22, batch=25 train loss <loss>=8.17156734467\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch [25]#011Speed: 1580.53 samples/sec#011loss=8.171567\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch[30] avg_epoch_loss=8.198320\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=22, batch=30 train loss <loss>=7.80448904037\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch [30]#011Speed: 693.27 samples/sec#011loss=7.804489\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch[35] avg_epoch_loss=8.140317\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=22, batch=35 train loss <loss>=7.78069505692\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:38 INFO 139649395074880] Epoch[22] Batch [35]#011Speed: 1578.44 samples/sec#011loss=7.780695\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] Epoch[22] Batch[40] avg_epoch_loss=8.119765\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=22, batch=40 train loss <loss>=7.97179489136\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] Epoch[22] Batch [40]#011Speed: 724.59 samples/sec#011loss=7.971795\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] Epoch[22] Batch[45] avg_epoch_loss=8.079342\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=22, batch=45 train loss <loss>=7.74787664413\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] Epoch[22] Batch [45]#011Speed: 1325.15 samples/sec#011loss=7.747877\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] Epoch[22] Batch[50] avg_epoch_loss=7.990510\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=22, batch=50 train loss <loss>=7.17324771881\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] Epoch[22] Batch [50]#011Speed: 1057.21 samples/sec#011loss=7.173248\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] processed a total of 1613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1717.1249389648438, \"sum\": 1717.1249389648438, \"min\": 1717.1249389648438}}, \"EndTime\": 1577414439.470905, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414437.753724}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=939.309497846 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=22, train loss <loss>=7.99050966899\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_b268d4c3-d62d-4b20-809e-7bd078237a06-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.3799991607666, \"sum\": 17.3799991607666, \"min\": 17.3799991607666}}, \"EndTime\": 1577414439.48888, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414439.470964}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] Epoch[23] Batch[0] avg_epoch_loss=8.586586\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=8.58658599854\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] Epoch[23] Batch[5] avg_epoch_loss=8.275255\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=8.27525472641\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] Epoch[23] Batch [5]#011Speed: 1703.03 samples/sec#011loss=8.275255\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] Epoch[23] Batch[10] avg_epoch_loss=8.332448\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=8.40107936859\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:39 INFO 139649395074880] Epoch[23] Batch [10]#011Speed: 794.02 samples/sec#011loss=8.401079\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch[15] avg_epoch_loss=8.477643\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=23, batch=15 train loss <loss>=8.79707260132\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch [15]#011Speed: 1679.46 samples/sec#011loss=8.797073\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch[20] avg_epoch_loss=8.445276\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=23, batch=20 train loss <loss>=8.34170246124\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch [20]#011Speed: 680.72 samples/sec#011loss=8.341702\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch[25] avg_epoch_loss=8.377176\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=23, batch=25 train loss <loss>=8.09115304947\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch [25]#011Speed: 1676.61 samples/sec#011loss=8.091153\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch[30] avg_epoch_loss=8.305423\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=23, batch=30 train loss <loss>=7.93230791092\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch [30]#011Speed: 769.62 samples/sec#011loss=7.932308\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch[35] avg_epoch_loss=8.227888\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=23, batch=35 train loss <loss>=7.74717473984\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch [35]#011Speed: 1633.94 samples/sec#011loss=7.747175\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch[40] avg_epoch_loss=8.202893\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=23, batch=40 train loss <loss>=8.0229262352\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch [40]#011Speed: 743.00 samples/sec#011loss=8.022926\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch[45] avg_epoch_loss=8.192958\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=23, batch=45 train loss <loss>=8.11149301529\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:40 INFO 139649395074880] Epoch[23] Batch [45]#011Speed: 1594.42 samples/sec#011loss=8.111493\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[23] Batch[50] avg_epoch_loss=8.119885\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=23, batch=50 train loss <loss>=7.44761638641\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[23] Batch [50]#011Speed: 1185.32 samples/sec#011loss=7.447616\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] processed a total of 1622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1604.6679019927979, \"sum\": 1604.6679019927979, \"min\": 1604.6679019927979}}, \"EndTime\": 1577414441.093643, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414439.488931}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1010.73422286 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=23, train loss <loss>=8.11988543529\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[24] Batch[0] avg_epoch_loss=7.602927\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=7.60292720795\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[24] Batch[5] avg_epoch_loss=8.301254\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=8.30125379562\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[24] Batch [5]#011Speed: 1708.31 samples/sec#011loss=8.301254\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[24] Batch[10] avg_epoch_loss=8.403559\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=8.52632465363\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[24] Batch [10]#011Speed: 793.00 samples/sec#011loss=8.526325\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[24] Batch[15] avg_epoch_loss=8.491409\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=24, batch=15 train loss <loss>=8.68467960358\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[24] Batch [15]#011Speed: 1583.11 samples/sec#011loss=8.684680\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[24] Batch[20] avg_epoch_loss=8.414840\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=24, batch=20 train loss <loss>=8.16981859207\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[24] Batch [20]#011Speed: 731.43 samples/sec#011loss=8.169819\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[24] Batch[25] avg_epoch_loss=8.287270\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=24, batch=25 train loss <loss>=7.75147867203\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:41 INFO 139649395074880] Epoch[24] Batch [25]#011Speed: 1554.14 samples/sec#011loss=7.751479\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] Epoch[24] Batch[30] avg_epoch_loss=8.227607\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=24, batch=30 train loss <loss>=7.91735668182\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] Epoch[24] Batch [30]#011Speed: 694.80 samples/sec#011loss=7.917357\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] Epoch[24] Batch[35] avg_epoch_loss=8.170710\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=24, batch=35 train loss <loss>=7.81794996262\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] Epoch[24] Batch [35]#011Speed: 1691.39 samples/sec#011loss=7.817950\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] Epoch[24] Batch[40] avg_epoch_loss=8.148639\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=24, batch=40 train loss <loss>=7.98972730637\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] Epoch[24] Batch [40]#011Speed: 789.26 samples/sec#011loss=7.989727\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] Epoch[24] Batch[45] avg_epoch_loss=8.127252\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=24, batch=45 train loss <loss>=7.95187444687\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] Epoch[24] Batch [45]#011Speed: 1397.16 samples/sec#011loss=7.951874\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] processed a total of 1589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1606.7979335784912, \"sum\": 1606.7979335784912, \"min\": 1606.7979335784912}}, \"EndTime\": 1577414442.700931, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414441.09372}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=988.854977956 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=24, train loss <loss>=8.07825727463\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] Epoch[25] Batch[0] avg_epoch_loss=8.357693\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=8.35769271851\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] Epoch[25] Batch[5] avg_epoch_loss=8.474137\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=8.47413651148\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:42 INFO 139649395074880] Epoch[25] Batch [5]#011Speed: 1524.55 samples/sec#011loss=8.474137\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] Epoch[25] Batch[10] avg_epoch_loss=8.275304\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=8.03670406342\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] Epoch[25] Batch [10]#011Speed: 745.49 samples/sec#011loss=8.036704\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] Epoch[25] Batch[15] avg_epoch_loss=8.360397\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=25, batch=15 train loss <loss>=8.54760322571\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] Epoch[25] Batch [15]#011Speed: 1320.93 samples/sec#011loss=8.547603\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] Epoch[25] Batch[20] avg_epoch_loss=8.303668\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=25, batch=20 train loss <loss>=8.12213478088\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] Epoch[25] Batch [20]#011Speed: 764.37 samples/sec#011loss=8.122135\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] Epoch[25] Batch[25] avg_epoch_loss=8.234091\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=25, batch=25 train loss <loss>=7.94186553955\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] Epoch[25] Batch [25]#011Speed: 1310.48 samples/sec#011loss=7.941866\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] Epoch[25] Batch[30] avg_epoch_loss=8.179456\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=25, batch=30 train loss <loss>=7.89535732269\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] Epoch[25] Batch [30]#011Speed: 745.72 samples/sec#011loss=7.895357\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] Epoch[25] Batch[35] avg_epoch_loss=8.110366\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=25, batch=35 train loss <loss>=7.68200769424\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:43 INFO 139649395074880] Epoch[25] Batch [35]#011Speed: 1576.82 samples/sec#011loss=7.682008\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] Epoch[25] Batch[40] avg_epoch_loss=8.103456\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=25, batch=40 train loss <loss>=8.05370645523\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] Epoch[25] Batch [40]#011Speed: 790.86 samples/sec#011loss=8.053706\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] Epoch[25] Batch[45] avg_epoch_loss=8.080444\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=25, batch=45 train loss <loss>=7.89174489975\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] Epoch[25] Batch [45]#011Speed: 1376.64 samples/sec#011loss=7.891745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] Epoch[25] Batch[50] avg_epoch_loss=7.951354\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=25, batch=50 train loss <loss>=6.76371917725\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] Epoch[25] Batch [50]#011Speed: 1135.03 samples/sec#011loss=6.763719\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] processed a total of 1602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1714.440107345581, \"sum\": 1714.440107345581, \"min\": 1714.440107345581}}, \"EndTime\": 1577414444.415892, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414442.701007}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=934.356982903 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=25, train loss <loss>=7.95135362476\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_1d633c00-a0ae-4533-acdc-1d4bf045680b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 26.03888511657715, \"sum\": 26.03888511657715, \"min\": 26.03888511657715}}, \"EndTime\": 1577414444.442455, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414444.415967}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] Epoch[26] Batch[0] avg_epoch_loss=8.138142\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=8.13814163208\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] Epoch[26] Batch[5] avg_epoch_loss=8.417070\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=8.41706975301\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] Epoch[26] Batch [5]#011Speed: 1628.60 samples/sec#011loss=8.417070\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] Epoch[26] Batch[10] avg_epoch_loss=8.359845\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=8.29117584229\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:44 INFO 139649395074880] Epoch[26] Batch [10]#011Speed: 689.85 samples/sec#011loss=8.291176\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch[15] avg_epoch_loss=8.435538\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=26, batch=15 train loss <loss>=8.60206184387\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch [15]#011Speed: 1504.44 samples/sec#011loss=8.602062\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch[20] avg_epoch_loss=8.405473\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=26, batch=20 train loss <loss>=8.30926322937\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch [20]#011Speed: 788.64 samples/sec#011loss=8.309263\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch[25] avg_epoch_loss=8.307413\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=26, batch=25 train loss <loss>=7.8955616951\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch [25]#011Speed: 1596.44 samples/sec#011loss=7.895562\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch[30] avg_epoch_loss=8.224036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=26, batch=30 train loss <loss>=7.79047622681\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch [30]#011Speed: 810.43 samples/sec#011loss=7.790476\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch[35] avg_epoch_loss=8.147433\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=26, batch=35 train loss <loss>=7.67249794006\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch [35]#011Speed: 1665.61 samples/sec#011loss=7.672498\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch[40] avg_epoch_loss=8.127296\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=26, batch=40 train loss <loss>=7.98230905533\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch [40]#011Speed: 772.99 samples/sec#011loss=7.982309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch[45] avg_epoch_loss=8.109087\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=26, batch=45 train loss <loss>=7.95976724625\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:45 INFO 139649395074880] Epoch[26] Batch [45]#011Speed: 1676.67 samples/sec#011loss=7.959767\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[26] Batch[50] avg_epoch_loss=8.049817\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=26, batch=50 train loss <loss>=7.50453882217\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[26] Batch [50]#011Speed: 1292.53 samples/sec#011loss=7.504539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] processed a total of 1621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1603.2800674438477, \"sum\": 1603.2800674438477, \"min\": 1603.2800674438477}}, \"EndTime\": 1577414446.045852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414444.44252}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1010.98359474 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=26, train loss <loss>=8.04981721616\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[27] Batch[0] avg_epoch_loss=8.186317\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=8.18631744385\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[27] Batch[5] avg_epoch_loss=8.338003\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=8.33800315857\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[27] Batch [5]#011Speed: 1477.23 samples/sec#011loss=8.338003\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[27] Batch[10] avg_epoch_loss=8.362351\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=8.39156808853\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[27] Batch [10]#011Speed: 732.39 samples/sec#011loss=8.391568\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[27] Batch[15] avg_epoch_loss=8.294383\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=27, batch=15 train loss <loss>=8.14485530853\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[27] Batch [15]#011Speed: 1724.73 samples/sec#011loss=8.144855\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[27] Batch[20] avg_epoch_loss=8.255593\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=27, batch=20 train loss <loss>=8.13146162033\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[27] Batch [20]#011Speed: 796.31 samples/sec#011loss=8.131462\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[27] Batch[25] avg_epoch_loss=8.205827\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=27, batch=25 train loss <loss>=7.99681215286\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:46 INFO 139649395074880] Epoch[27] Batch [25]#011Speed: 1716.55 samples/sec#011loss=7.996812\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] Epoch[27] Batch[30] avg_epoch_loss=8.105822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=27, batch=30 train loss <loss>=7.58579378128\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] Epoch[27] Batch [30]#011Speed: 715.92 samples/sec#011loss=7.585794\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] Epoch[27] Batch[35] avg_epoch_loss=8.066870\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=27, batch=35 train loss <loss>=7.82537050247\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] Epoch[27] Batch [35]#011Speed: 1455.40 samples/sec#011loss=7.825371\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] Epoch[27] Batch[40] avg_epoch_loss=8.035713\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=27, batch=40 train loss <loss>=7.8113776207\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] Epoch[27] Batch [40]#011Speed: 771.28 samples/sec#011loss=7.811378\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] Epoch[27] Batch[45] avg_epoch_loss=8.012295\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=27, batch=45 train loss <loss>=7.82027025223\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] Epoch[27] Batch [45]#011Speed: 1705.23 samples/sec#011loss=7.820270\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] processed a total of 1588 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1601.046085357666, \"sum\": 1601.046085357666, \"min\": 1601.046085357666}}, \"EndTime\": 1577414447.647389, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414446.045927}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=991.784029468 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=27, train loss <loss>=8.00965559006\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] Epoch[28] Batch[0] avg_epoch_loss=8.535275\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=8.53527545929\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] Epoch[28] Batch[5] avg_epoch_loss=8.254862\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=8.25486175219\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:47 INFO 139649395074880] Epoch[28] Batch [5]#011Speed: 1465.58 samples/sec#011loss=8.254862\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] Epoch[28] Batch[10] avg_epoch_loss=8.298551\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=8.35097827911\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] Epoch[28] Batch [10]#011Speed: 715.76 samples/sec#011loss=8.350978\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] Epoch[28] Batch[15] avg_epoch_loss=8.365818\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=28, batch=15 train loss <loss>=8.51380462646\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] Epoch[28] Batch [15]#011Speed: 1620.85 samples/sec#011loss=8.513805\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] Epoch[28] Batch[20] avg_epoch_loss=8.382693\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=28, batch=20 train loss <loss>=8.43669395447\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] Epoch[28] Batch [20]#011Speed: 791.22 samples/sec#011loss=8.436694\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] Epoch[28] Batch[25] avg_epoch_loss=8.314091\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=28, batch=25 train loss <loss>=8.02596082687\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] Epoch[28] Batch [25]#011Speed: 1399.52 samples/sec#011loss=8.025961\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] Epoch[28] Batch[30] avg_epoch_loss=8.232029\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=28, batch=30 train loss <loss>=7.80530939102\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] Epoch[28] Batch [30]#011Speed: 765.26 samples/sec#011loss=7.805309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] Epoch[28] Batch[35] avg_epoch_loss=8.180239\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=28, batch=35 train loss <loss>=7.85914087296\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:48 INFO 139649395074880] Epoch[28] Batch [35]#011Speed: 1729.78 samples/sec#011loss=7.859141\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[28] Batch[40] avg_epoch_loss=8.164387\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=28, batch=40 train loss <loss>=8.05025005341\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[28] Batch [40]#011Speed: 780.09 samples/sec#011loss=8.050250\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[28] Batch[45] avg_epoch_loss=8.162564\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=28, batch=45 train loss <loss>=8.14761724472\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[28] Batch [45]#011Speed: 1724.62 samples/sec#011loss=8.147617\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[28] Batch[50] avg_epoch_loss=8.107908\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=28, batch=50 train loss <loss>=7.60506877899\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[28] Batch [50]#011Speed: 1169.49 samples/sec#011loss=7.605069\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] processed a total of 1645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1637.5539302825928, \"sum\": 1637.5539302825928, \"min\": 1637.5539302825928}}, \"EndTime\": 1577414449.28553, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414447.647463}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1004.4783326 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=28, train loss <loss>=8.09478624967\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[29] Batch[0] avg_epoch_loss=8.731832\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=8.7318315506\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[29] Batch[5] avg_epoch_loss=8.490598\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=8.49059788386\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[29] Batch [5]#011Speed: 1509.05 samples/sec#011loss=8.490598\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[29] Batch[10] avg_epoch_loss=8.379818\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=8.24688310623\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[29] Batch [10]#011Speed: 752.91 samples/sec#011loss=8.246883\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[29] Batch[15] avg_epoch_loss=8.452254\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=29, batch=15 train loss <loss>=8.61161327362\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:49 INFO 139649395074880] Epoch[29] Batch [15]#011Speed: 1546.73 samples/sec#011loss=8.611613\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] Epoch[29] Batch[20] avg_epoch_loss=8.396286\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=29, batch=20 train loss <loss>=8.2171875\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] Epoch[29] Batch [20]#011Speed: 772.06 samples/sec#011loss=8.217187\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] Epoch[29] Batch[25] avg_epoch_loss=8.323814\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=29, batch=25 train loss <loss>=8.01943082809\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] Epoch[29] Batch [25]#011Speed: 1571.48 samples/sec#011loss=8.019431\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] Epoch[29] Batch[30] avg_epoch_loss=8.253505\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=29, batch=30 train loss <loss>=7.8878988266\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] Epoch[29] Batch [30]#011Speed: 763.80 samples/sec#011loss=7.887899\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] Epoch[29] Batch[35] avg_epoch_loss=8.191908\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=29, batch=35 train loss <loss>=7.81000347137\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] Epoch[29] Batch [35]#011Speed: 1488.93 samples/sec#011loss=7.810003\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] Epoch[29] Batch[40] avg_epoch_loss=8.179205\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=29, batch=40 train loss <loss>=8.08774871826\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] Epoch[29] Batch [40]#011Speed: 702.78 samples/sec#011loss=8.087749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] Epoch[29] Batch[45] avg_epoch_loss=8.155382\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=29, batch=45 train loss <loss>=7.9600271225\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] Epoch[29] Batch [45]#011Speed: 1554.74 samples/sec#011loss=7.960027\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] processed a total of 1596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1618.0548667907715, \"sum\": 1618.0548667907715, \"min\": 1618.0548667907715}}, \"EndTime\": 1577414450.9041, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414449.285607}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=986.298742865 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=29, train loss <loss>=8.10843120575\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:50 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch[0] avg_epoch_loss=8.326457\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=8.32645702362\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch[5] avg_epoch_loss=8.144451\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=8.14445066452\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch [5]#011Speed: 1575.61 samples/sec#011loss=8.144451\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch[10] avg_epoch_loss=8.215597\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=8.30097179413\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch [10]#011Speed: 777.63 samples/sec#011loss=8.300972\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch[15] avg_epoch_loss=8.247968\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=30, batch=15 train loss <loss>=8.31918439865\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch [15]#011Speed: 1542.75 samples/sec#011loss=8.319184\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch[20] avg_epoch_loss=8.231204\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=30, batch=20 train loss <loss>=8.17756185532\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch [20]#011Speed: 811.01 samples/sec#011loss=8.177562\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch[25] avg_epoch_loss=8.176594\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=30, batch=25 train loss <loss>=7.94722967148\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch [25]#011Speed: 1559.99 samples/sec#011loss=7.947230\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch[30] avg_epoch_loss=8.119099\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=30, batch=30 train loss <loss>=7.82012529373\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:51 INFO 139649395074880] Epoch[30] Batch [30]#011Speed: 712.98 samples/sec#011loss=7.820125\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] Epoch[30] Batch[35] avg_epoch_loss=8.077378\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=30, batch=35 train loss <loss>=7.81870718002\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] Epoch[30] Batch [35]#011Speed: 1650.27 samples/sec#011loss=7.818707\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] Epoch[30] Batch[40] avg_epoch_loss=8.086391\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=30, batch=40 train loss <loss>=8.15128726959\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] Epoch[30] Batch [40]#011Speed: 763.64 samples/sec#011loss=8.151287\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] Epoch[30] Batch[45] avg_epoch_loss=8.095548\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=30, batch=45 train loss <loss>=8.17062940598\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] Epoch[30] Batch [45]#011Speed: 1741.82 samples/sec#011loss=8.170629\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] processed a total of 1591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1556.9829940795898, \"sum\": 1556.9829940795898, \"min\": 1556.9829940795898}}, \"EndTime\": 1577414452.461681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414450.90418}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1021.77448909 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=30, train loss <loss>=8.07430599213\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] Epoch[31] Batch[0] avg_epoch_loss=8.402443\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=8.40244293213\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] Epoch[31] Batch[5] avg_epoch_loss=8.099171\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=8.09917068481\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] Epoch[31] Batch [5]#011Speed: 1544.52 samples/sec#011loss=8.099171\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] Epoch[31] Batch[10] avg_epoch_loss=8.274192\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=8.48421707153\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:52 INFO 139649395074880] Epoch[31] Batch [10]#011Speed: 755.98 samples/sec#011loss=8.484217\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch[15] avg_epoch_loss=8.350381\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=31, batch=15 train loss <loss>=8.51799755096\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch [15]#011Speed: 1482.66 samples/sec#011loss=8.517998\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch[20] avg_epoch_loss=8.362214\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=31, batch=20 train loss <loss>=8.40007915497\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch [20]#011Speed: 772.78 samples/sec#011loss=8.400079\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch[25] avg_epoch_loss=8.271996\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=31, batch=25 train loss <loss>=7.89308271408\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch [25]#011Speed: 1498.70 samples/sec#011loss=7.893083\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch[30] avg_epoch_loss=8.205015\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=31, batch=30 train loss <loss>=7.85671453476\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch [30]#011Speed: 772.01 samples/sec#011loss=7.856715\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch[35] avg_epoch_loss=8.154783\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=31, batch=35 train loss <loss>=7.84334306717\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch [35]#011Speed: 1548.60 samples/sec#011loss=7.843343\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch[40] avg_epoch_loss=8.150255\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=31, batch=40 train loss <loss>=8.11765146255\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch [40]#011Speed: 659.85 samples/sec#011loss=8.117651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch[45] avg_epoch_loss=8.144283\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=31, batch=45 train loss <loss>=8.09530897141\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:53 INFO 139649395074880] Epoch[31] Batch [45]#011Speed: 1508.07 samples/sec#011loss=8.095309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[31] Batch[50] avg_epoch_loss=8.102093\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=31, batch=50 train loss <loss>=7.71395263672\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[31] Batch [50]#011Speed: 1369.86 samples/sec#011loss=7.713953\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] processed a total of 1626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1644.0210342407227, \"sum\": 1644.0210342407227, \"min\": 1644.0210342407227}}, \"EndTime\": 1577414454.106213, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414452.461759}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=988.972896532 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=31, train loss <loss>=8.10209333195\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[32] Batch[0] avg_epoch_loss=8.502571\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=8.50257110596\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[32] Batch[5] avg_epoch_loss=8.235500\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=8.23549969991\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[32] Batch [5]#011Speed: 1700.34 samples/sec#011loss=8.235500\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[32] Batch[10] avg_epoch_loss=8.262634\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=8.295195961\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[32] Batch [10]#011Speed: 789.66 samples/sec#011loss=8.295196\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[32] Batch[15] avg_epoch_loss=8.310863\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=32, batch=15 train loss <loss>=8.41696519852\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[32] Batch [15]#011Speed: 1697.99 samples/sec#011loss=8.416965\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[32] Batch[20] avg_epoch_loss=8.229356\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=32, batch=20 train loss <loss>=7.96853532791\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[32] Batch [20]#011Speed: 778.64 samples/sec#011loss=7.968535\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[32] Batch[25] avg_epoch_loss=8.182717\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=32, batch=25 train loss <loss>=7.98682975769\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:54 INFO 139649395074880] Epoch[32] Batch [25]#011Speed: 1651.49 samples/sec#011loss=7.986830\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[32] Batch[30] avg_epoch_loss=8.118638\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=32, batch=30 train loss <loss>=7.78542737961\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[32] Batch [30]#011Speed: 792.27 samples/sec#011loss=7.785427\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[32] Batch[35] avg_epoch_loss=8.073913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=32, batch=35 train loss <loss>=7.79661798477\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[32] Batch [35]#011Speed: 1506.17 samples/sec#011loss=7.796618\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[32] Batch[40] avg_epoch_loss=8.033126\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=32, batch=40 train loss <loss>=7.73946142197\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[32] Batch [40]#011Speed: 789.97 samples/sec#011loss=7.739461\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[32] Batch[45] avg_epoch_loss=8.037320\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=32, batch=45 train loss <loss>=8.07171173096\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[32] Batch [45]#011Speed: 1714.83 samples/sec#011loss=8.071712\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[32] Batch[50] avg_epoch_loss=8.027068\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=32, batch=50 train loss <loss>=7.93274707794\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[32] Batch [50]#011Speed: 1118.32 samples/sec#011loss=7.932747\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] processed a total of 1629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1599.5681285858154, \"sum\": 1599.5681285858154, \"min\": 1599.5681285858154}}, \"EndTime\": 1577414455.70627, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414454.106289}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1018.33052082 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=32, train loss <loss>=8.02706779218\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[33] Batch[0] avg_epoch_loss=8.575644\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=8.5756444931\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[33] Batch[5] avg_epoch_loss=8.570292\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=8.57029247284\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:55 INFO 139649395074880] Epoch[33] Batch [5]#011Speed: 1539.36 samples/sec#011loss=8.570292\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] Epoch[33] Batch[10] avg_epoch_loss=8.407732\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=8.21265954971\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] Epoch[33] Batch [10]#011Speed: 791.26 samples/sec#011loss=8.212660\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] Epoch[33] Batch[15] avg_epoch_loss=8.459784\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=33, batch=15 train loss <loss>=8.57429771423\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] Epoch[33] Batch [15]#011Speed: 1540.69 samples/sec#011loss=8.574298\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] Epoch[33] Batch[20] avg_epoch_loss=8.499647\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=33, batch=20 train loss <loss>=8.62720832825\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] Epoch[33] Batch [20]#011Speed: 793.07 samples/sec#011loss=8.627208\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] Epoch[33] Batch[25] avg_epoch_loss=8.369930\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=33, batch=25 train loss <loss>=7.82511777878\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] Epoch[33] Batch [25]#011Speed: 1552.13 samples/sec#011loss=7.825118\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] Epoch[33] Batch[30] avg_epoch_loss=8.320444\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=33, batch=30 train loss <loss>=8.06311998367\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] Epoch[33] Batch [30]#011Speed: 790.43 samples/sec#011loss=8.063120\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] Epoch[33] Batch[35] avg_epoch_loss=8.275721\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=33, batch=35 train loss <loss>=7.99843492508\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:56 INFO 139649395074880] Epoch[33] Batch [35]#011Speed: 1564.96 samples/sec#011loss=7.998435\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[33] Batch[40] avg_epoch_loss=8.213252\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=33, batch=40 train loss <loss>=7.76347780228\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[33] Batch [40]#011Speed: 750.78 samples/sec#011loss=7.763478\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[33] Batch[45] avg_epoch_loss=8.191200\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=33, batch=45 train loss <loss>=8.01037168503\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[33] Batch [45]#011Speed: 1437.23 samples/sec#011loss=8.010372\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[33] Batch[50] avg_epoch_loss=8.113126\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=33, batch=50 train loss <loss>=7.39484195709\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[33] Batch [50]#011Speed: 1188.15 samples/sec#011loss=7.394842\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] processed a total of 1621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1617.2161102294922, \"sum\": 1617.2161102294922, \"min\": 1617.2161102294922}}, \"EndTime\": 1577414457.323979, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414455.706345}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1002.27281973 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=33, train loss <loss>=8.11312555799\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[34] Batch[0] avg_epoch_loss=8.113389\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=8.1133890152\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[34] Batch[5] avg_epoch_loss=8.421413\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=8.42141326269\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[34] Batch [5]#011Speed: 1643.37 samples/sec#011loss=8.421413\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[34] Batch[10] avg_epoch_loss=8.422155\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=8.42304477692\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[34] Batch [10]#011Speed: 790.45 samples/sec#011loss=8.423045\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[34] Batch[15] avg_epoch_loss=8.483406\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=34, batch=15 train loss <loss>=8.61815700531\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:57 INFO 139649395074880] Epoch[34] Batch [15]#011Speed: 1552.78 samples/sec#011loss=8.618157\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] Epoch[34] Batch[20] avg_epoch_loss=8.360738\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=34, batch=20 train loss <loss>=7.96820268631\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] Epoch[34] Batch [20]#011Speed: 750.40 samples/sec#011loss=7.968203\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] Epoch[34] Batch[25] avg_epoch_loss=8.268570\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=34, batch=25 train loss <loss>=7.88146467209\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] Epoch[34] Batch [25]#011Speed: 1702.85 samples/sec#011loss=7.881465\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] Epoch[34] Batch[30] avg_epoch_loss=8.234814\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=34, batch=30 train loss <loss>=8.05927906036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] Epoch[34] Batch [30]#011Speed: 775.67 samples/sec#011loss=8.059279\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] Epoch[34] Batch[35] avg_epoch_loss=8.202754\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=34, batch=35 train loss <loss>=8.00398683548\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] Epoch[34] Batch [35]#011Speed: 1453.53 samples/sec#011loss=8.003987\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] Epoch[34] Batch[40] avg_epoch_loss=8.189023\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=34, batch=40 train loss <loss>=8.09015741348\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] Epoch[34] Batch [40]#011Speed: 710.09 samples/sec#011loss=8.090157\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] Epoch[34] Batch[45] avg_epoch_loss=8.171386\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=34, batch=45 train loss <loss>=8.02676382065\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] Epoch[34] Batch [45]#011Speed: 1612.68 samples/sec#011loss=8.026764\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] processed a total of 1593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1582.9119682312012, \"sum\": 1582.9119682312012, \"min\": 1582.9119682312012}}, \"EndTime\": 1577414458.907383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414457.324053}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1006.30124066 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=34, train loss <loss>=8.12606603622\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:58 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch[0] avg_epoch_loss=8.418468\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=8.41846752167\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch[5] avg_epoch_loss=8.397165\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=8.39716545741\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch [5]#011Speed: 1552.58 samples/sec#011loss=8.397165\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch[10] avg_epoch_loss=8.408060\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=8.42113304138\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch [10]#011Speed: 761.59 samples/sec#011loss=8.421133\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch[15] avg_epoch_loss=8.343821\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=35, batch=15 train loss <loss>=8.20249519348\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch [15]#011Speed: 1508.79 samples/sec#011loss=8.202495\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch[20] avg_epoch_loss=8.303726\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=35, batch=20 train loss <loss>=8.17542333603\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch [20]#011Speed: 751.36 samples/sec#011loss=8.175423\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch[25] avg_epoch_loss=8.226020\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=35, batch=25 train loss <loss>=7.89965343475\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch [25]#011Speed: 1720.00 samples/sec#011loss=7.899653\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch[30] avg_epoch_loss=8.133313\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=35, batch=30 train loss <loss>=7.65123615265\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:40:59 INFO 139649395074880] Epoch[35] Batch [30]#011Speed: 771.43 samples/sec#011loss=7.651236\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[35] Batch[35] avg_epoch_loss=8.087414\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=35, batch=35 train loss <loss>=7.80284290314\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[35] Batch [35]#011Speed: 1646.68 samples/sec#011loss=7.802843\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[35] Batch[40] avg_epoch_loss=8.072106\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=35, batch=40 train loss <loss>=7.9618897438\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[35] Batch [40]#011Speed: 706.93 samples/sec#011loss=7.961890\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[35] Batch[45] avg_epoch_loss=8.047913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=35, batch=45 train loss <loss>=7.84952526093\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[35] Batch [45]#011Speed: 1630.49 samples/sec#011loss=7.849525\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] processed a total of 1517 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1545.9251403808594, \"sum\": 1545.9251403808594, \"min\": 1545.9251403808594}}, \"EndTime\": 1577414460.453833, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414458.907461}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=981.217247069 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=35, train loss <loss>=7.95499961575\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[36] Batch[0] avg_epoch_loss=7.940705\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=7.94070529938\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[36] Batch[5] avg_epoch_loss=8.165451\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=8.1654513677\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[36] Batch [5]#011Speed: 1649.91 samples/sec#011loss=8.165451\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[36] Batch[10] avg_epoch_loss=8.277395\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=8.41172790527\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[36] Batch [10]#011Speed: 740.80 samples/sec#011loss=8.411728\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[36] Batch[15] avg_epoch_loss=8.277306\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=36, batch=15 train loss <loss>=8.27710828781\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:00 INFO 139649395074880] Epoch[36] Batch [15]#011Speed: 1550.72 samples/sec#011loss=8.277108\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] Epoch[36] Batch[20] avg_epoch_loss=8.237922\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=36, batch=20 train loss <loss>=8.11189441681\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] Epoch[36] Batch [20]#011Speed: 750.29 samples/sec#011loss=8.111894\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] Epoch[36] Batch[25] avg_epoch_loss=8.148995\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=36, batch=25 train loss <loss>=7.77550354004\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] Epoch[36] Batch [25]#011Speed: 1542.36 samples/sec#011loss=7.775504\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] Epoch[36] Batch[30] avg_epoch_loss=8.113684\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=36, batch=30 train loss <loss>=7.93006696701\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] Epoch[36] Batch [30]#011Speed: 726.06 samples/sec#011loss=7.930067\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] Epoch[36] Batch[35] avg_epoch_loss=8.091110\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=36, batch=35 train loss <loss>=7.95115060806\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] Epoch[36] Batch [35]#011Speed: 1603.51 samples/sec#011loss=7.951151\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] Epoch[36] Batch[40] avg_epoch_loss=8.091517\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=36, batch=40 train loss <loss>=8.09444932938\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] Epoch[36] Batch [40]#011Speed: 780.85 samples/sec#011loss=8.094449\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] Epoch[36] Batch[45] avg_epoch_loss=8.108671\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=36, batch=45 train loss <loss>=8.24932880402\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:01 INFO 139649395074880] Epoch[36] Batch [45]#011Speed: 1730.87 samples/sec#011loss=8.249329\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] processed a total of 1563 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1557.0881366729736, \"sum\": 1557.0881366729736, \"min\": 1557.0881366729736}}, \"EndTime\": 1577414462.011439, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414460.453912}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1003.72082105 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=36, train loss <loss>=8.08742797618\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] Epoch[37] Batch[0] avg_epoch_loss=8.095545\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=8.09554481506\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] Epoch[37] Batch[5] avg_epoch_loss=8.234580\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=8.23457972209\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] Epoch[37] Batch [5]#011Speed: 1524.32 samples/sec#011loss=8.234580\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] Epoch[37] Batch[10] avg_epoch_loss=8.240783\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=8.24822635651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] Epoch[37] Batch [10]#011Speed: 761.02 samples/sec#011loss=8.248226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] Epoch[37] Batch[15] avg_epoch_loss=8.298841\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=37, batch=15 train loss <loss>=8.42656879425\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] Epoch[37] Batch [15]#011Speed: 1449.26 samples/sec#011loss=8.426569\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] Epoch[37] Batch[20] avg_epoch_loss=8.249104\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=37, batch=20 train loss <loss>=8.08994522095\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] Epoch[37] Batch [20]#011Speed: 758.75 samples/sec#011loss=8.089945\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] Epoch[37] Batch[25] avg_epoch_loss=8.182780\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=37, batch=25 train loss <loss>=7.90422039032\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:02 INFO 139649395074880] Epoch[37] Batch [25]#011Speed: 1632.40 samples/sec#011loss=7.904220\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[37] Batch[30] avg_epoch_loss=8.131571\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=37, batch=30 train loss <loss>=7.86528596878\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[37] Batch [30]#011Speed: 695.23 samples/sec#011loss=7.865286\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[37] Batch[35] avg_epoch_loss=8.092491\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=37, batch=35 train loss <loss>=7.85019111633\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[37] Batch [35]#011Speed: 1511.10 samples/sec#011loss=7.850191\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[37] Batch[40] avg_epoch_loss=8.055410\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=37, batch=40 train loss <loss>=7.78843221664\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[37] Batch [40]#011Speed: 1639.38 samples/sec#011loss=7.788432\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[37] Batch[45] avg_epoch_loss=8.071798\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=37, batch=45 train loss <loss>=8.20617446899\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[37] Batch [45]#011Speed: 733.66 samples/sec#011loss=8.206174\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[37] Batch[50] avg_epoch_loss=8.086039\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=37, batch=50 train loss <loss>=8.21705675125\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[37] Batch [50]#011Speed: 1533.42 samples/sec#011loss=8.217057\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] processed a total of 1674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1673.1140613555908, \"sum\": 1673.1140613555908, \"min\": 1673.1140613555908}}, \"EndTime\": 1577414463.685109, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414462.01152}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1000.46079819 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=37, train loss <loss>=7.99615145629\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[38] Batch[0] avg_epoch_loss=8.529056\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=8.5290555954\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[38] Batch[5] avg_epoch_loss=8.270634\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=8.27063377698\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:03 INFO 139649395074880] Epoch[38] Batch [5]#011Speed: 1673.53 samples/sec#011loss=8.270634\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] Epoch[38] Batch[10] avg_epoch_loss=8.253978\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=8.23399124146\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] Epoch[38] Batch [10]#011Speed: 712.61 samples/sec#011loss=8.233991\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] Epoch[38] Batch[15] avg_epoch_loss=8.242672\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=38, batch=15 train loss <loss>=8.21779937744\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] Epoch[38] Batch [15]#011Speed: 1496.25 samples/sec#011loss=8.217799\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] Epoch[38] Batch[20] avg_epoch_loss=8.216290\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=38, batch=20 train loss <loss>=8.13186511993\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] Epoch[38] Batch [20]#011Speed: 764.23 samples/sec#011loss=8.131865\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] Epoch[38] Batch[25] avg_epoch_loss=8.113813\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=38, batch=25 train loss <loss>=7.68341064453\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] Epoch[38] Batch [25]#011Speed: 1580.45 samples/sec#011loss=7.683411\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] Epoch[38] Batch[30] avg_epoch_loss=8.068284\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=38, batch=30 train loss <loss>=7.83153123856\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] Epoch[38] Batch [30]#011Speed: 751.28 samples/sec#011loss=7.831531\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] Epoch[38] Batch[35] avg_epoch_loss=8.051006\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=38, batch=35 train loss <loss>=7.94388465881\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:04 INFO 139649395074880] Epoch[38] Batch [35]#011Speed: 1480.26 samples/sec#011loss=7.943885\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] Epoch[38] Batch[40] avg_epoch_loss=8.042834\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=38, batch=40 train loss <loss>=7.98399381638\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] Epoch[38] Batch [40]#011Speed: 727.14 samples/sec#011loss=7.983994\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] Epoch[38] Batch[45] avg_epoch_loss=8.011724\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=38, batch=45 train loss <loss>=7.75662021637\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] Epoch[38] Batch [45]#011Speed: 1343.28 samples/sec#011loss=7.756620\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] processed a total of 1581 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1642.4999237060547, \"sum\": 1642.4999237060547, \"min\": 1642.4999237060547}}, \"EndTime\": 1577414465.328146, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414463.685189}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=962.490899205 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=38, train loss <loss>=7.96069687843\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] Epoch[39] Batch[0] avg_epoch_loss=8.207727\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=8.20772743225\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] Epoch[39] Batch[5] avg_epoch_loss=8.440952\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=8.44095222155\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] Epoch[39] Batch [5]#011Speed: 1561.25 samples/sec#011loss=8.440952\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] Epoch[39] Batch[10] avg_epoch_loss=8.426892\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=8.4100194931\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] Epoch[39] Batch [10]#011Speed: 737.58 samples/sec#011loss=8.410019\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] Epoch[39] Batch[15] avg_epoch_loss=8.342046\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=39, batch=15 train loss <loss>=8.15538492203\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:05 INFO 139649395074880] Epoch[39] Batch [15]#011Speed: 1725.94 samples/sec#011loss=8.155385\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch[20] avg_epoch_loss=8.332597\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=39, batch=20 train loss <loss>=8.30236186981\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch [20]#011Speed: 731.12 samples/sec#011loss=8.302362\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch[25] avg_epoch_loss=8.244363\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=39, batch=25 train loss <loss>=7.87377614975\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch [25]#011Speed: 1636.11 samples/sec#011loss=7.873776\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch[30] avg_epoch_loss=8.186370\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=39, batch=30 train loss <loss>=7.8848107338\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch [30]#011Speed: 767.05 samples/sec#011loss=7.884811\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch[35] avg_epoch_loss=8.143653\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=39, batch=35 train loss <loss>=7.87880430222\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch [35]#011Speed: 1525.45 samples/sec#011loss=7.878804\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch[40] avg_epoch_loss=8.103930\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=39, batch=40 train loss <loss>=7.81792268753\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch [40]#011Speed: 784.19 samples/sec#011loss=7.817923\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch[45] avg_epoch_loss=8.071861\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=39, batch=45 train loss <loss>=7.80889692307\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch [45]#011Speed: 1567.35 samples/sec#011loss=7.808897\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch[50] avg_epoch_loss=8.002658\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=39, batch=50 train loss <loss>=7.36599569321\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] Epoch[39] Batch [50]#011Speed: 1266.36 samples/sec#011loss=7.365996\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] processed a total of 1604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1610.9211444854736, \"sum\": 1610.9211444854736, \"min\": 1610.9211444854736}}, \"EndTime\": 1577414466.939587, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414465.328223}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=995.635679755 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=39, train loss <loss>=8.00265837651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:06 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] Epoch[40] Batch[0] avg_epoch_loss=8.227333\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=8.22733306885\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] Epoch[40] Batch[5] avg_epoch_loss=8.317660\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=8.31766017278\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] Epoch[40] Batch [5]#011Speed: 1507.91 samples/sec#011loss=8.317660\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] Epoch[40] Batch[10] avg_epoch_loss=8.324324\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=8.33232135773\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] Epoch[40] Batch [10]#011Speed: 788.73 samples/sec#011loss=8.332321\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] Epoch[40] Batch[15] avg_epoch_loss=8.360998\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=40, batch=15 train loss <loss>=8.441680336\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] Epoch[40] Batch [15]#011Speed: 1464.42 samples/sec#011loss=8.441680\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] Epoch[40] Batch[20] avg_epoch_loss=8.355150\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=40, batch=20 train loss <loss>=8.33643407822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] Epoch[40] Batch [20]#011Speed: 730.75 samples/sec#011loss=8.336434\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] Epoch[40] Batch[25] avg_epoch_loss=8.279759\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=40, batch=25 train loss <loss>=7.96312093735\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:07 INFO 139649395074880] Epoch[40] Batch [25]#011Speed: 1661.18 samples/sec#011loss=7.963121\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[40] Batch[30] avg_epoch_loss=8.216838\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=40, batch=30 train loss <loss>=7.88964490891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[40] Batch [30]#011Speed: 768.59 samples/sec#011loss=7.889645\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[40] Batch[35] avg_epoch_loss=8.147565\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=40, batch=35 train loss <loss>=7.71807165146\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[40] Batch [35]#011Speed: 1584.66 samples/sec#011loss=7.718072\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[40] Batch[40] avg_epoch_loss=8.109358\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=40, batch=40 train loss <loss>=7.83427038193\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[40] Batch [40]#011Speed: 778.81 samples/sec#011loss=7.834270\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[40] Batch[45] avg_epoch_loss=8.068212\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=40, batch=45 train loss <loss>=7.73081579208\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[40] Batch [45]#011Speed: 1725.31 samples/sec#011loss=7.730816\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] processed a total of 1592 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1576.3061046600342, \"sum\": 1576.3061046600342, \"min\": 1576.3061046600342}}, \"EndTime\": 1577414468.516454, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414466.93966}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1009.88509449 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=40, train loss <loss>=8.01729409218\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[41] Batch[0] avg_epoch_loss=8.494713\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=8.49471282959\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[41] Batch[5] avg_epoch_loss=8.087689\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=8.08768908183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[41] Batch [5]#011Speed: 1625.94 samples/sec#011loss=8.087689\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[41] Batch[10] avg_epoch_loss=8.207926\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=8.35221099854\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:08 INFO 139649395074880] Epoch[41] Batch [10]#011Speed: 755.80 samples/sec#011loss=8.352211\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch[15] avg_epoch_loss=8.275142\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=41, batch=15 train loss <loss>=8.42301588058\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch [15]#011Speed: 1598.71 samples/sec#011loss=8.423016\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch[20] avg_epoch_loss=8.310530\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=41, batch=20 train loss <loss>=8.42377243042\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch [20]#011Speed: 771.43 samples/sec#011loss=8.423772\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch[25] avg_epoch_loss=8.250467\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=41, batch=25 train loss <loss>=7.99820251465\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch [25]#011Speed: 1460.19 samples/sec#011loss=7.998203\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch[30] avg_epoch_loss=8.169376\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=41, batch=30 train loss <loss>=7.747701931\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch [30]#011Speed: 779.59 samples/sec#011loss=7.747702\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch[35] avg_epoch_loss=8.118493\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=41, batch=35 train loss <loss>=7.80301980972\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch [35]#011Speed: 1728.78 samples/sec#011loss=7.803020\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch[40] avg_epoch_loss=8.085545\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=41, batch=40 train loss <loss>=7.84831562042\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch [40]#011Speed: 733.86 samples/sec#011loss=7.848316\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch[45] avg_epoch_loss=8.070231\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=41, batch=45 train loss <loss>=7.94465522766\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:09 INFO 139649395074880] Epoch[41] Batch [45]#011Speed: 1517.90 samples/sec#011loss=7.944655\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] processed a total of 1585 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1599.992036819458, \"sum\": 1599.992036819458, \"min\": 1599.992036819458}}, \"EndTime\": 1577414470.116965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414468.51653}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=990.560555646 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=41, train loss <loss>=8.03844157219\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] Epoch[42] Batch[0] avg_epoch_loss=8.499758\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=8.49975776672\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] Epoch[42] Batch[5] avg_epoch_loss=8.109747\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=8.1097471714\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] Epoch[42] Batch [5]#011Speed: 1615.33 samples/sec#011loss=8.109747\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] Epoch[42] Batch[10] avg_epoch_loss=8.169127\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=8.24038257599\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] Epoch[42] Batch [10]#011Speed: 780.95 samples/sec#011loss=8.240383\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] Epoch[42] Batch[15] avg_epoch_loss=8.347417\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=42, batch=15 train loss <loss>=8.7396566391\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] Epoch[42] Batch [15]#011Speed: 1540.79 samples/sec#011loss=8.739657\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] Epoch[42] Batch[20] avg_epoch_loss=8.340338\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=42, batch=20 train loss <loss>=8.31768217087\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] Epoch[42] Batch [20]#011Speed: 764.96 samples/sec#011loss=8.317682\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] Epoch[42] Batch[25] avg_epoch_loss=8.254372\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=42, batch=25 train loss <loss>=7.89331712723\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:10 INFO 139649395074880] Epoch[42] Batch [25]#011Speed: 1537.00 samples/sec#011loss=7.893317\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[42] Batch[30] avg_epoch_loss=8.192723\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=42, batch=30 train loss <loss>=7.87214975357\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[42] Batch [30]#011Speed: 792.17 samples/sec#011loss=7.872150\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[42] Batch[35] avg_epoch_loss=8.159545\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=42, batch=35 train loss <loss>=7.95383968353\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[42] Batch [35]#011Speed: 1473.23 samples/sec#011loss=7.953840\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[42] Batch[40] avg_epoch_loss=8.132223\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=42, batch=40 train loss <loss>=7.93550157547\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[42] Batch [40]#011Speed: 750.39 samples/sec#011loss=7.935502\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[42] Batch[45] avg_epoch_loss=8.094598\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=42, batch=45 train loss <loss>=7.78607139587\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[42] Batch [45]#011Speed: 1541.57 samples/sec#011loss=7.786071\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[42] Batch[50] avg_epoch_loss=8.061549\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=42, batch=50 train loss <loss>=7.75750598907\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[42] Batch [50]#011Speed: 1204.35 samples/sec#011loss=7.757506\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] processed a total of 1632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1631.8690776824951, \"sum\": 1631.8690776824951, \"min\": 1631.8690776824951}}, \"EndTime\": 1577414471.749364, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414470.117041}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1000.01404352 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=42, train loss <loss>=8.06154936435\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[43] Batch[0] avg_epoch_loss=7.892124\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=7.89212417603\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[43] Batch[5] avg_epoch_loss=8.169314\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=8.16931374868\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:11 INFO 139649395074880] Epoch[43] Batch [5]#011Speed: 1685.84 samples/sec#011loss=8.169314\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] Epoch[43] Batch[10] avg_epoch_loss=8.059678\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=7.92811403275\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] Epoch[43] Batch [10]#011Speed: 819.84 samples/sec#011loss=7.928114\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] Epoch[43] Batch[15] avg_epoch_loss=8.121977\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=43, batch=15 train loss <loss>=8.25903635025\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] Epoch[43] Batch [15]#011Speed: 1502.05 samples/sec#011loss=8.259036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] Epoch[43] Batch[20] avg_epoch_loss=8.234056\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=43, batch=20 train loss <loss>=8.5927072525\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] Epoch[43] Batch [20]#011Speed: 801.39 samples/sec#011loss=8.592707\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] Epoch[43] Batch[25] avg_epoch_loss=8.130948\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=43, batch=25 train loss <loss>=7.69789381027\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] Epoch[43] Batch [25]#011Speed: 1543.61 samples/sec#011loss=7.697894\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] Epoch[43] Batch[30] avg_epoch_loss=8.112243\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=43, batch=30 train loss <loss>=8.01497688293\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] Epoch[43] Batch [30]#011Speed: 648.78 samples/sec#011loss=8.014977\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] Epoch[43] Batch[35] avg_epoch_loss=8.106289\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=43, batch=35 train loss <loss>=8.06937265396\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:12 INFO 139649395074880] Epoch[43] Batch [35]#011Speed: 1402.24 samples/sec#011loss=8.069373\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] Epoch[43] Batch[40] avg_epoch_loss=8.087961\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=43, batch=40 train loss <loss>=7.95600318909\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] Epoch[43] Batch [40]#011Speed: 732.08 samples/sec#011loss=7.956003\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] Epoch[43] Batch[45] avg_epoch_loss=8.102034\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=43, batch=45 train loss <loss>=8.21742935181\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] Epoch[43] Batch [45]#011Speed: 1319.12 samples/sec#011loss=8.217429\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] Epoch[43] Batch[50] avg_epoch_loss=8.068607\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=43, batch=50 train loss <loss>=7.76108379364\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] Epoch[43] Batch [50]#011Speed: 1234.50 samples/sec#011loss=7.761084\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] processed a total of 1660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1687.4780654907227, \"sum\": 1687.4780654907227, \"min\": 1687.4780654907227}}, \"EndTime\": 1577414473.437331, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414471.749438}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=983.651865903 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=43, train loss <loss>=8.05811703205\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] Epoch[44] Batch[0] avg_epoch_loss=8.167040\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=8.16703987122\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] Epoch[44] Batch[5] avg_epoch_loss=8.273106\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=8.27310625712\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] Epoch[44] Batch [5]#011Speed: 1567.48 samples/sec#011loss=8.273106\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] Epoch[44] Batch[10] avg_epoch_loss=8.207572\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=8.12893190384\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:13 INFO 139649395074880] Epoch[44] Batch [10]#011Speed: 743.77 samples/sec#011loss=8.128932\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch[15] avg_epoch_loss=8.301955\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=44, batch=15 train loss <loss>=8.50959587097\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch [15]#011Speed: 1548.54 samples/sec#011loss=8.509596\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch[20] avg_epoch_loss=8.304296\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=44, batch=20 train loss <loss>=8.31178808212\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch [20]#011Speed: 779.65 samples/sec#011loss=8.311788\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch[25] avg_epoch_loss=8.247005\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=44, batch=25 train loss <loss>=8.00638256073\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch [25]#011Speed: 1465.27 samples/sec#011loss=8.006383\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch[30] avg_epoch_loss=8.182004\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=44, batch=30 train loss <loss>=7.84399662018\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch [30]#011Speed: 811.61 samples/sec#011loss=7.843997\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch[35] avg_epoch_loss=8.119572\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=44, batch=35 train loss <loss>=7.73249912262\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch [35]#011Speed: 1479.30 samples/sec#011loss=7.732499\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch[40] avg_epoch_loss=8.084068\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=44, batch=40 train loss <loss>=7.82843742371\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch [40]#011Speed: 740.27 samples/sec#011loss=7.828437\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch[45] avg_epoch_loss=8.057913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=44, batch=45 train loss <loss>=7.84344301224\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:14 INFO 139649395074880] Epoch[44] Batch [45]#011Speed: 1515.98 samples/sec#011loss=7.843443\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] processed a total of 1586 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1636.307954788208, \"sum\": 1636.307954788208, \"min\": 1636.307954788208}}, \"EndTime\": 1577414475.074156, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414473.437408}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=969.195468964 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=44, train loss <loss>=8.05778247833\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] Epoch[45] Batch[0] avg_epoch_loss=8.762793\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=8.76279258728\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] Epoch[45] Batch[5] avg_epoch_loss=8.215873\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=8.2158733209\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] Epoch[45] Batch [5]#011Speed: 1423.92 samples/sec#011loss=8.215873\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] Epoch[45] Batch[10] avg_epoch_loss=8.127638\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=8.02175502777\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] Epoch[45] Batch [10]#011Speed: 796.85 samples/sec#011loss=8.021755\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] Epoch[45] Batch[15] avg_epoch_loss=8.176191\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=45, batch=15 train loss <loss>=8.28300914764\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] Epoch[45] Batch [15]#011Speed: 1546.16 samples/sec#011loss=8.283009\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] Epoch[45] Batch[20] avg_epoch_loss=8.243661\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=45, batch=20 train loss <loss>=8.45956363678\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] Epoch[45] Batch [20]#011Speed: 793.67 samples/sec#011loss=8.459564\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] Epoch[45] Batch[25] avg_epoch_loss=8.162443\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=45, batch=25 train loss <loss>=7.82132883072\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:15 INFO 139649395074880] Epoch[45] Batch [25]#011Speed: 1446.75 samples/sec#011loss=7.821329\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[45] Batch[30] avg_epoch_loss=8.109299\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=45, batch=30 train loss <loss>=7.8329492569\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[45] Batch [30]#011Speed: 706.47 samples/sec#011loss=7.832949\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[45] Batch[35] avg_epoch_loss=8.065456\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=45, batch=35 train loss <loss>=7.79363098145\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[45] Batch [35]#011Speed: 1546.85 samples/sec#011loss=7.793631\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[45] Batch[40] avg_epoch_loss=8.051869\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=45, batch=40 train loss <loss>=7.954043293\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[45] Batch [40]#011Speed: 779.70 samples/sec#011loss=7.954043\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[45] Batch[45] avg_epoch_loss=8.051086\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=45, batch=45 train loss <loss>=8.04466323853\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[45] Batch [45]#011Speed: 1496.39 samples/sec#011loss=8.044663\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[45] Batch[50] avg_epoch_loss=7.970713\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=45, batch=50 train loss <loss>=7.23127775192\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[45] Batch [50]#011Speed: 1290.28 samples/sec#011loss=7.231278\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] processed a total of 1620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1620.5909252166748, \"sum\": 1620.5909252166748, \"min\": 1620.5909252166748}}, \"EndTime\": 1577414476.695342, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414475.07422}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=999.554044218 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=45, train loss <loss>=7.97071266174\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[46] Batch[0] avg_epoch_loss=8.387724\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=8.38772392273\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[46] Batch[5] avg_epoch_loss=8.215098\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=8.2150982221\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:16 INFO 139649395074880] Epoch[46] Batch [5]#011Speed: 1652.57 samples/sec#011loss=8.215098\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] Epoch[46] Batch[10] avg_epoch_loss=8.214436\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=8.21364135742\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] Epoch[46] Batch [10]#011Speed: 809.91 samples/sec#011loss=8.213641\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] Epoch[46] Batch[15] avg_epoch_loss=8.238448\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=46, batch=15 train loss <loss>=8.29127531052\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] Epoch[46] Batch [15]#011Speed: 1608.31 samples/sec#011loss=8.291275\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] Epoch[46] Batch[20] avg_epoch_loss=8.204440\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=46, batch=20 train loss <loss>=8.09561243057\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] Epoch[46] Batch [20]#011Speed: 684.98 samples/sec#011loss=8.095612\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] Epoch[46] Batch[25] avg_epoch_loss=8.155338\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=46, batch=25 train loss <loss>=7.94911279678\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] Epoch[46] Batch [25]#011Speed: 1724.25 samples/sec#011loss=7.949113\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] Epoch[46] Batch[30] avg_epoch_loss=8.118881\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=46, batch=30 train loss <loss>=7.92930202484\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] Epoch[46] Batch [30]#011Speed: 734.86 samples/sec#011loss=7.929302\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] Epoch[46] Batch[35] avg_epoch_loss=8.088537\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=46, batch=35 train loss <loss>=7.90040512085\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:17 INFO 139649395074880] Epoch[46] Batch [35]#011Speed: 1700.25 samples/sec#011loss=7.900405\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[46] Batch[40] avg_epoch_loss=8.044044\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=46, batch=40 train loss <loss>=7.72369422913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[46] Batch [40]#011Speed: 750.94 samples/sec#011loss=7.723694\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[46] Batch[45] avg_epoch_loss=8.019019\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=46, batch=45 train loss <loss>=7.81381072998\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[46] Batch [45]#011Speed: 1432.19 samples/sec#011loss=7.813811\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[46] Batch[50] avg_epoch_loss=7.977197\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=46, batch=50 train loss <loss>=7.59244184494\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[46] Batch [50]#011Speed: 1157.14 samples/sec#011loss=7.592442\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] processed a total of 1657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1650.3148078918457, \"sum\": 1650.3148078918457, \"min\": 1650.3148078918457}}, \"EndTime\": 1577414478.346167, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414476.695418}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1003.99051997 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=46, train loss <loss>=7.95720529556\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[47] Batch[0] avg_epoch_loss=8.239777\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=8.23977661133\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[47] Batch[5] avg_epoch_loss=8.139867\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=8.13986730576\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[47] Batch [5]#011Speed: 1644.80 samples/sec#011loss=8.139867\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[47] Batch[10] avg_epoch_loss=8.204106\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=8.28119258881\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[47] Batch [10]#011Speed: 747.35 samples/sec#011loss=8.281193\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[47] Batch[15] avg_epoch_loss=8.331309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=47, batch=15 train loss <loss>=8.61115550995\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:18 INFO 139649395074880] Epoch[47] Batch [15]#011Speed: 1628.07 samples/sec#011loss=8.611156\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] Epoch[47] Batch[20] avg_epoch_loss=8.304032\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=47, batch=20 train loss <loss>=8.21674413681\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] Epoch[47] Batch [20]#011Speed: 755.74 samples/sec#011loss=8.216744\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] Epoch[47] Batch[25] avg_epoch_loss=8.229164\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=47, batch=25 train loss <loss>=7.91472072601\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] Epoch[47] Batch [25]#011Speed: 1392.83 samples/sec#011loss=7.914721\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] Epoch[47] Batch[30] avg_epoch_loss=8.145426\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=47, batch=30 train loss <loss>=7.7099858284\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] Epoch[47] Batch [30]#011Speed: 795.28 samples/sec#011loss=7.709986\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] Epoch[47] Batch[35] avg_epoch_loss=8.076446\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=47, batch=35 train loss <loss>=7.64876976013\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] Epoch[47] Batch [35]#011Speed: 1554.54 samples/sec#011loss=7.648770\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] Epoch[47] Batch[40] avg_epoch_loss=8.073337\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=47, batch=40 train loss <loss>=8.05095252991\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] Epoch[47] Batch [40]#011Speed: 789.05 samples/sec#011loss=8.050953\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] Epoch[47] Batch[45] avg_epoch_loss=8.076585\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=47, batch=45 train loss <loss>=8.10321903229\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] Epoch[47] Batch [45]#011Speed: 1392.41 samples/sec#011loss=8.103219\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] processed a total of 1552 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1567.3251152038574, \"sum\": 1567.3251152038574, \"min\": 1567.3251152038574}}, \"EndTime\": 1577414479.91394, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414478.346234}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=990.151329691 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=47, train loss <loss>=8.03715353596\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:19 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch[0] avg_epoch_loss=8.366917\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=8.36691665649\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch[5] avg_epoch_loss=8.256406\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=8.25640583038\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch [5]#011Speed: 1454.57 samples/sec#011loss=8.256406\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch[10] avg_epoch_loss=8.181821\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=8.09232025146\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch [10]#011Speed: 780.05 samples/sec#011loss=8.092320\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch[15] avg_epoch_loss=8.201545\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=48, batch=15 train loss <loss>=8.24493780136\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch [15]#011Speed: 1352.09 samples/sec#011loss=8.244938\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch[20] avg_epoch_loss=8.182559\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=48, batch=20 train loss <loss>=8.12180271149\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch [20]#011Speed: 767.38 samples/sec#011loss=8.121803\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch[25] avg_epoch_loss=8.107369\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=48, batch=25 train loss <loss>=7.79157352448\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch [25]#011Speed: 1733.91 samples/sec#011loss=7.791574\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch[30] avg_epoch_loss=8.048587\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=48, batch=30 train loss <loss>=7.74292011261\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:20 INFO 139649395074880] Epoch[48] Batch [30]#011Speed: 807.07 samples/sec#011loss=7.742920\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] Epoch[48] Batch[35] avg_epoch_loss=8.030861\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=48, batch=35 train loss <loss>=7.92095909119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] Epoch[48] Batch [35]#011Speed: 1636.59 samples/sec#011loss=7.920959\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] Epoch[48] Batch[40] avg_epoch_loss=8.031865\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=48, batch=40 train loss <loss>=8.03909473419\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] Epoch[48] Batch [40]#011Speed: 684.82 samples/sec#011loss=8.039095\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] Epoch[48] Batch[45] avg_epoch_loss=8.020490\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=48, batch=45 train loss <loss>=7.92720851898\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] Epoch[48] Batch [45]#011Speed: 1442.94 samples/sec#011loss=7.927209\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] processed a total of 1565 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1599.9162197113037, \"sum\": 1599.9162197113037, \"min\": 1599.9162197113037}}, \"EndTime\": 1577414481.514404, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414479.914018}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=978.107859867 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=48, train loss <loss>=7.99797520346\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] Epoch[49] Batch[0] avg_epoch_loss=8.759404\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=8.75940418243\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] Epoch[49] Batch[5] avg_epoch_loss=8.496706\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=8.49670584997\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] Epoch[49] Batch [5]#011Speed: 1302.59 samples/sec#011loss=8.496706\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] Epoch[49] Batch[10] avg_epoch_loss=8.456036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=8.40723152161\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:21 INFO 139649395074880] Epoch[49] Batch [10]#011Speed: 798.92 samples/sec#011loss=8.407232\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] Epoch[49] Batch[15] avg_epoch_loss=8.460390\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=49, batch=15 train loss <loss>=8.46997032166\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] Epoch[49] Batch [15]#011Speed: 1343.80 samples/sec#011loss=8.469970\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] Epoch[49] Batch[20] avg_epoch_loss=8.500715\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=49, batch=20 train loss <loss>=8.62975416183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] Epoch[49] Batch [20]#011Speed: 677.66 samples/sec#011loss=8.629754\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] Epoch[49] Batch[25] avg_epoch_loss=8.356917\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=49, batch=25 train loss <loss>=7.75296573639\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] Epoch[49] Batch [25]#011Speed: 1619.52 samples/sec#011loss=7.752966\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] Epoch[49] Batch[30] avg_epoch_loss=8.250282\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=49, batch=30 train loss <loss>=7.69577941895\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] Epoch[49] Batch [30]#011Speed: 768.70 samples/sec#011loss=7.695779\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] Epoch[49] Batch[35] avg_epoch_loss=8.210181\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=49, batch=35 train loss <loss>=7.96155824661\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] Epoch[49] Batch [35]#011Speed: 1657.17 samples/sec#011loss=7.961558\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] Epoch[49] Batch[40] avg_epoch_loss=8.116217\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=49, batch=40 train loss <loss>=7.43967475891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:22 INFO 139649395074880] Epoch[49] Batch [40]#011Speed: 778.94 samples/sec#011loss=7.439675\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[49] Batch[45] avg_epoch_loss=8.084613\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=49, batch=45 train loss <loss>=7.82546062469\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[49] Batch [45]#011Speed: 1466.21 samples/sec#011loss=7.825461\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[49] Batch[50] avg_epoch_loss=8.013119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=49, batch=50 train loss <loss>=7.35537080765\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[49] Batch [50]#011Speed: 1028.53 samples/sec#011loss=7.355371\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] processed a total of 1646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1710.439920425415, \"sum\": 1710.439920425415, \"min\": 1710.439920425415}}, \"EndTime\": 1577414483.225421, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414481.514478}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=962.264096643 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=49, train loss <loss>=8.05525417511\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[50] Batch[0] avg_epoch_loss=8.501291\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=8.50129127502\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[50] Batch[5] avg_epoch_loss=8.382608\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=8.38260769844\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[50] Batch [5]#011Speed: 1355.66 samples/sec#011loss=8.382608\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[50] Batch[10] avg_epoch_loss=8.279036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=8.15475063324\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[50] Batch [10]#011Speed: 741.46 samples/sec#011loss=8.154751\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[50] Batch[15] avg_epoch_loss=8.324337\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=50, batch=15 train loss <loss>=8.42399950027\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[50] Batch [15]#011Speed: 1580.51 samples/sec#011loss=8.424000\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[50] Batch[20] avg_epoch_loss=8.286313\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=50, batch=20 train loss <loss>=8.16463365555\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:23 INFO 139649395074880] Epoch[50] Batch [20]#011Speed: 783.22 samples/sec#011loss=8.164634\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] Epoch[50] Batch[25] avg_epoch_loss=8.183860\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=50, batch=25 train loss <loss>=7.75356149673\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] Epoch[50] Batch [25]#011Speed: 1545.79 samples/sec#011loss=7.753561\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] Epoch[50] Batch[30] avg_epoch_loss=8.143173\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=50, batch=30 train loss <loss>=7.93159542084\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] Epoch[50] Batch [30]#011Speed: 770.70 samples/sec#011loss=7.931595\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] Epoch[50] Batch[35] avg_epoch_loss=8.076613\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=50, batch=35 train loss <loss>=7.66394309998\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] Epoch[50] Batch [35]#011Speed: 1498.16 samples/sec#011loss=7.663943\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] Epoch[50] Batch[40] avg_epoch_loss=8.047765\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=50, batch=40 train loss <loss>=7.84006175995\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] Epoch[50] Batch [40]#011Speed: 761.55 samples/sec#011loss=7.840062\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] Epoch[50] Batch[45] avg_epoch_loss=8.025298\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=50, batch=45 train loss <loss>=7.84106960297\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] Epoch[50] Batch [45]#011Speed: 1677.85 samples/sec#011loss=7.841070\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] processed a total of 1577 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1626.021146774292, \"sum\": 1626.021146774292, \"min\": 1626.021146774292}}, \"EndTime\": 1577414484.852022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414483.225492}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=969.78539508 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=50, train loss <loss>=8.08356977463\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] Epoch[51] Batch[0] avg_epoch_loss=8.094481\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=8.09448051453\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] Epoch[51] Batch[5] avg_epoch_loss=8.304437\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=8.30443676313\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] Epoch[51] Batch [5]#011Speed: 1354.28 samples/sec#011loss=8.304437\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] Epoch[51] Batch[10] avg_epoch_loss=8.204315\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=8.08416919708\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] Epoch[51] Batch [10]#011Speed: 1477.50 samples/sec#011loss=8.084169\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] Epoch[51] Batch[15] avg_epoch_loss=8.287862\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=51, batch=15 train loss <loss>=8.47166633606\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] Epoch[51] Batch [15]#011Speed: 728.58 samples/sec#011loss=8.471666\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] Epoch[51] Batch[20] avg_epoch_loss=8.307199\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=51, batch=20 train loss <loss>=8.36907520294\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] Epoch[51] Batch [20]#011Speed: 704.10 samples/sec#011loss=8.369075\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] Epoch[51] Batch[25] avg_epoch_loss=8.209897\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=51, batch=25 train loss <loss>=7.80122709274\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] Epoch[51] Batch [25]#011Speed: 1688.64 samples/sec#011loss=7.801227\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] Epoch[51] Batch[30] avg_epoch_loss=8.136680\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=51, batch=30 train loss <loss>=7.75595140457\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:25 INFO 139649395074880] Epoch[51] Batch [30]#011Speed: 785.03 samples/sec#011loss=7.755951\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[51] Batch[35] avg_epoch_loss=8.064548\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=51, batch=35 train loss <loss>=7.6173324585\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[51] Batch [35]#011Speed: 1733.56 samples/sec#011loss=7.617332\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[51] Batch[40] avg_epoch_loss=8.034781\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=51, batch=40 train loss <loss>=7.82045478821\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[51] Batch [40]#011Speed: 808.88 samples/sec#011loss=7.820455\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[51] Batch[45] avg_epoch_loss=8.022392\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=51, batch=45 train loss <loss>=7.92080249786\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[51] Batch [45]#011Speed: 1598.53 samples/sec#011loss=7.920802\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[51] Batch[50] avg_epoch_loss=7.969558\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=51, batch=50 train loss <loss>=7.48349351883\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[51] Batch [50]#011Speed: 1374.73 samples/sec#011loss=7.483494\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] processed a total of 1631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1622.406005859375, \"sum\": 1622.406005859375, \"min\": 1622.406005859375}}, \"EndTime\": 1577414486.474963, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414484.852099}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1005.23014931 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=51, train loss <loss>=7.96955849143\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[52] Batch[0] avg_epoch_loss=8.297477\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=8.29747676849\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[52] Batch[5] avg_epoch_loss=8.296682\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=8.29668172201\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[52] Batch [5]#011Speed: 1707.27 samples/sec#011loss=8.296682\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[52] Batch[10] avg_epoch_loss=8.217723\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=8.12297229767\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[52] Batch [10]#011Speed: 777.81 samples/sec#011loss=8.122972\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[52] Batch[15] avg_epoch_loss=8.178904\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=52, batch=15 train loss <loss>=8.09350233078\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:26 INFO 139649395074880] Epoch[52] Batch [15]#011Speed: 1727.34 samples/sec#011loss=8.093502\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] Epoch[52] Batch[20] avg_epoch_loss=8.182224\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=52, batch=20 train loss <loss>=8.19284801483\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] Epoch[52] Batch [20]#011Speed: 728.09 samples/sec#011loss=8.192848\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] Epoch[52] Batch[25] avg_epoch_loss=8.111236\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=52, batch=25 train loss <loss>=7.81308908463\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] Epoch[52] Batch [25]#011Speed: 1614.97 samples/sec#011loss=7.813089\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] Epoch[52] Batch[30] avg_epoch_loss=8.076868\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=52, batch=30 train loss <loss>=7.89815359116\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] Epoch[52] Batch [30]#011Speed: 725.16 samples/sec#011loss=7.898154\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] Epoch[52] Batch[35] avg_epoch_loss=8.053666\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=52, batch=35 train loss <loss>=7.90981311798\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] Epoch[52] Batch [35]#011Speed: 1325.18 samples/sec#011loss=7.909813\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] Epoch[52] Batch[40] avg_epoch_loss=8.031203\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=52, batch=40 train loss <loss>=7.86946706772\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] Epoch[52] Batch [40]#011Speed: 804.87 samples/sec#011loss=7.869467\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] Epoch[52] Batch[45] avg_epoch_loss=8.016270\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=52, batch=45 train loss <loss>=7.89381723404\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:27 INFO 139649395074880] Epoch[52] Batch [45]#011Speed: 1300.59 samples/sec#011loss=7.893817\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[52] Batch[50] avg_epoch_loss=7.953366\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=52, batch=50 train loss <loss>=7.37465019226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[52] Batch [50]#011Speed: 1054.07 samples/sec#011loss=7.374650\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] processed a total of 1625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1656.3599109649658, \"sum\": 1656.3599109649658, \"min\": 1656.3599109649658}}, \"EndTime\": 1577414488.131847, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414486.475039}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=981.001733082 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=52, train loss <loss>=7.95336578407\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[53] Batch[0] avg_epoch_loss=8.427284\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=8.42728424072\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[53] Batch[5] avg_epoch_loss=8.456859\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=8.45685903231\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[53] Batch [5]#011Speed: 1597.86 samples/sec#011loss=8.456859\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[53] Batch[10] avg_epoch_loss=8.279939\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=8.06763401031\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[53] Batch [10]#011Speed: 744.65 samples/sec#011loss=8.067634\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[53] Batch[15] avg_epoch_loss=8.330326\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=53, batch=15 train loss <loss>=8.44117717743\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[53] Batch [15]#011Speed: 1583.44 samples/sec#011loss=8.441177\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[53] Batch[20] avg_epoch_loss=8.314966\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=53, batch=20 train loss <loss>=8.26581687927\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[53] Batch [20]#011Speed: 813.64 samples/sec#011loss=8.265817\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[53] Batch[25] avg_epoch_loss=8.234450\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=53, batch=25 train loss <loss>=7.89627952576\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:28 INFO 139649395074880] Epoch[53] Batch [25]#011Speed: 1496.78 samples/sec#011loss=7.896280\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] Epoch[53] Batch[30] avg_epoch_loss=8.184033\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=53, batch=30 train loss <loss>=7.92186384201\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] Epoch[53] Batch [30]#011Speed: 698.60 samples/sec#011loss=7.921864\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] Epoch[53] Batch[35] avg_epoch_loss=8.141379\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=53, batch=35 train loss <loss>=7.87692842484\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] Epoch[53] Batch [35]#011Speed: 1664.26 samples/sec#011loss=7.876928\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] Epoch[53] Batch[40] avg_epoch_loss=8.102680\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=53, batch=40 train loss <loss>=7.82404918671\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] Epoch[53] Batch [40]#011Speed: 669.89 samples/sec#011loss=7.824049\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] Epoch[53] Batch[45] avg_epoch_loss=8.089135\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=53, batch=45 train loss <loss>=7.97805843353\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] Epoch[53] Batch [45]#011Speed: 1619.33 samples/sec#011loss=7.978058\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] Epoch[53] Batch[50] avg_epoch_loss=8.059772\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=53, batch=50 train loss <loss>=7.78963384628\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] Epoch[53] Batch [50]#011Speed: 1446.24 samples/sec#011loss=7.789634\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] processed a total of 1644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1653.8898944854736, \"sum\": 1653.8898944854736, \"min\": 1653.8898944854736}}, \"EndTime\": 1577414489.78623, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414488.131923}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=993.952878223 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=53, train loss <loss>=8.02402921823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] Epoch[54] Batch[0] avg_epoch_loss=8.240642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=8.24064159393\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch[5] avg_epoch_loss=8.115219\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=8.11521887779\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch [5]#011Speed: 1604.67 samples/sec#011loss=8.115219\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch[10] avg_epoch_loss=8.246751\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=8.40458936691\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch [10]#011Speed: 832.69 samples/sec#011loss=8.404589\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch[15] avg_epoch_loss=8.219333\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=54, batch=15 train loss <loss>=8.15901422501\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch [15]#011Speed: 1415.68 samples/sec#011loss=8.159014\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch[20] avg_epoch_loss=8.188836\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=54, batch=20 train loss <loss>=8.09124526978\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch [20]#011Speed: 720.58 samples/sec#011loss=8.091245\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch[25] avg_epoch_loss=8.140681\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=54, batch=25 train loss <loss>=7.9384311676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch [25]#011Speed: 1554.82 samples/sec#011loss=7.938431\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch[30] avg_epoch_loss=8.096926\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=54, batch=30 train loss <loss>=7.86939754486\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch [30]#011Speed: 767.91 samples/sec#011loss=7.869398\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch[35] avg_epoch_loss=8.031754\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=54, batch=35 train loss <loss>=7.62768716812\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:30 INFO 139649395074880] Epoch[54] Batch [35]#011Speed: 1676.62 samples/sec#011loss=7.627687\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] Epoch[54] Batch[40] avg_epoch_loss=8.029803\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=54, batch=40 train loss <loss>=8.01575546265\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] Epoch[54] Batch [40]#011Speed: 727.98 samples/sec#011loss=8.015755\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] Epoch[54] Batch[45] avg_epoch_loss=8.009647\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=54, batch=45 train loss <loss>=7.84436655045\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] Epoch[54] Batch [45]#011Speed: 1661.63 samples/sec#011loss=7.844367\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] processed a total of 1556 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1586.1341953277588, \"sum\": 1586.1341953277588, \"min\": 1586.1341953277588}}, \"EndTime\": 1577414491.37288, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414489.786307}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=980.936017146 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=54, train loss <loss>=7.9654368965\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] Epoch[55] Batch[0] avg_epoch_loss=7.999343\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=7.9993429184\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] Epoch[55] Batch[5] avg_epoch_loss=8.172750\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=8.1727502346\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] Epoch[55] Batch [5]#011Speed: 1656.09 samples/sec#011loss=8.172750\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] Epoch[55] Batch[10] avg_epoch_loss=8.070679\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=7.94819374084\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] Epoch[55] Batch [10]#011Speed: 807.07 samples/sec#011loss=7.948194\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] Epoch[55] Batch[15] avg_epoch_loss=8.153455\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=55, batch=15 train loss <loss>=8.33556156158\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:31 INFO 139649395074880] Epoch[55] Batch [15]#011Speed: 1710.28 samples/sec#011loss=8.335562\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Epoch[55] Batch[20] avg_epoch_loss=8.134440\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=55, batch=20 train loss <loss>=8.07359113693\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Epoch[55] Batch [20]#011Speed: 790.64 samples/sec#011loss=8.073591\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Epoch[55] Batch[25] avg_epoch_loss=8.081123\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=55, batch=25 train loss <loss>=7.85719366074\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Epoch[55] Batch [25]#011Speed: 1673.96 samples/sec#011loss=7.857194\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Epoch[55] Batch[30] avg_epoch_loss=8.029316\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=55, batch=30 train loss <loss>=7.75991859436\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Epoch[55] Batch [30]#011Speed: 766.45 samples/sec#011loss=7.759919\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Epoch[55] Batch[35] avg_epoch_loss=7.985932\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=55, batch=35 train loss <loss>=7.71695413589\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Epoch[55] Batch [35]#011Speed: 1532.92 samples/sec#011loss=7.716954\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Epoch[55] Batch[40] avg_epoch_loss=7.986357\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=55, batch=40 train loss <loss>=7.989412117\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Epoch[55] Batch [40]#011Speed: 732.59 samples/sec#011loss=7.989412\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Epoch[55] Batch[45] avg_epoch_loss=7.966126\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=55, batch=45 train loss <loss>=7.80023670197\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Epoch[55] Batch [45]#011Speed: 1728.85 samples/sec#011loss=7.800237\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] processed a total of 1533 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1507.3800086975098, \"sum\": 1507.3800086975098, \"min\": 1507.3800086975098}}, \"EndTime\": 1577414492.880783, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414491.372945}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1016.92077534 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=55, train loss <loss>=7.90630286932\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:32 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_358f98c6-584a-4c76-a4c2-0f20e60cccd2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 25.93708038330078, \"sum\": 25.93708038330078, \"min\": 25.93708038330078}}, \"EndTime\": 1577414492.907277, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414492.88086}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch[0] avg_epoch_loss=8.064532\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=8.06453227997\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch[5] avg_epoch_loss=7.936642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=7.93664185206\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch [5]#011Speed: 1378.91 samples/sec#011loss=7.936642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch[10] avg_epoch_loss=8.169459\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=8.44883918762\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch [10]#011Speed: 786.91 samples/sec#011loss=8.448839\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch[15] avg_epoch_loss=8.285020\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=56, batch=15 train loss <loss>=8.53925533295\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch [15]#011Speed: 1468.75 samples/sec#011loss=8.539255\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch[20] avg_epoch_loss=8.339895\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=56, batch=20 train loss <loss>=8.51549339294\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch [20]#011Speed: 805.32 samples/sec#011loss=8.515493\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch[25] avg_epoch_loss=8.286052\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=56, batch=25 train loss <loss>=8.05991334915\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch [25]#011Speed: 1637.11 samples/sec#011loss=8.059913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch[30] avg_epoch_loss=8.191138\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=56, batch=30 train loss <loss>=7.69758434296\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:33 INFO 139649395074880] Epoch[56] Batch [30]#011Speed: 689.42 samples/sec#011loss=7.697584\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] Epoch[56] Batch[35] avg_epoch_loss=8.143388\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=56, batch=35 train loss <loss>=7.84733610153\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] Epoch[56] Batch [35]#011Speed: 1335.72 samples/sec#011loss=7.847336\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] Epoch[56] Batch[40] avg_epoch_loss=8.083636\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=56, batch=40 train loss <loss>=7.65342102051\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] Epoch[56] Batch [40]#011Speed: 698.11 samples/sec#011loss=7.653421\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] Epoch[56] Batch[45] avg_epoch_loss=8.056342\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=56, batch=45 train loss <loss>=7.83253107071\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] Epoch[56] Batch [45]#011Speed: 1659.89 samples/sec#011loss=7.832531\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] Epoch[56] Batch[50] avg_epoch_loss=8.038095\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=56, batch=50 train loss <loss>=7.87022094727\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] Epoch[56] Batch [50]#011Speed: 1160.45 samples/sec#011loss=7.870221\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] processed a total of 1662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1695.2788829803467, \"sum\": 1695.2788829803467, \"min\": 1695.2788829803467}}, \"EndTime\": 1577414494.602692, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414492.907361}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=980.304873094 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=56, train loss <loss>=8.03861688651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] Epoch[57] Batch[0] avg_epoch_loss=8.154436\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=8.15443611145\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] Epoch[57] Batch[5] avg_epoch_loss=7.994458\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=7.99445764224\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:34 INFO 139649395074880] Epoch[57] Batch [5]#011Speed: 1275.54 samples/sec#011loss=7.994458\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch[10] avg_epoch_loss=8.166041\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=8.37194023132\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch [10]#011Speed: 763.37 samples/sec#011loss=8.371940\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch[15] avg_epoch_loss=8.283123\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=57, batch=15 train loss <loss>=8.54070396423\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch [15]#011Speed: 1720.76 samples/sec#011loss=8.540704\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch[20] avg_epoch_loss=8.277166\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=57, batch=20 train loss <loss>=8.25810432434\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch [20]#011Speed: 826.66 samples/sec#011loss=8.258104\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch[25] avg_epoch_loss=8.249118\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=57, batch=25 train loss <loss>=8.13131599426\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch [25]#011Speed: 1571.74 samples/sec#011loss=8.131316\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch[30] avg_epoch_loss=8.166269\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=57, batch=30 train loss <loss>=7.73545684814\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch [30]#011Speed: 812.54 samples/sec#011loss=7.735457\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch[35] avg_epoch_loss=8.147132\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=57, batch=35 train loss <loss>=8.02848186493\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch [35]#011Speed: 1345.42 samples/sec#011loss=8.028482\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch[40] avg_epoch_loss=8.105514\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=57, batch=40 train loss <loss>=7.80586280823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:35 INFO 139649395074880] Epoch[57] Batch [40]#011Speed: 716.80 samples/sec#011loss=7.805863\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[57] Batch[45] avg_epoch_loss=8.069714\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=57, batch=45 train loss <loss>=7.77615795135\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[57] Batch [45]#011Speed: 1714.71 samples/sec#011loss=7.776158\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[57] Batch[50] avg_epoch_loss=8.052238\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=57, batch=50 train loss <loss>=7.89145174026\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[57] Batch [50]#011Speed: 1128.39 samples/sec#011loss=7.891452\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] processed a total of 1627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1631.856918334961, \"sum\": 1631.856918334961, \"min\": 1631.856918334961}}, \"EndTime\": 1577414496.235065, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414494.60277}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=996.954644412 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=57, train loss <loss>=8.05223773508\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[58] Batch[0] avg_epoch_loss=8.277683\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=8.27768325806\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[58] Batch[5] avg_epoch_loss=8.133965\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=8.1339653333\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[58] Batch [5]#011Speed: 1527.71 samples/sec#011loss=8.133965\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[58] Batch[10] avg_epoch_loss=8.138988\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=8.14501543045\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[58] Batch [10]#011Speed: 786.05 samples/sec#011loss=8.145015\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[58] Batch[15] avg_epoch_loss=8.178488\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=58, batch=15 train loss <loss>=8.26538925171\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[58] Batch [15]#011Speed: 1570.51 samples/sec#011loss=8.265389\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[58] Batch[20] avg_epoch_loss=8.184794\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=58, batch=20 train loss <loss>=8.20497169495\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:36 INFO 139649395074880] Epoch[58] Batch [20]#011Speed: 783.65 samples/sec#011loss=8.204972\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[58] Batch[25] avg_epoch_loss=8.174987\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=58, batch=25 train loss <loss>=8.13379955292\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[58] Batch [25]#011Speed: 1610.65 samples/sec#011loss=8.133800\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[58] Batch[30] avg_epoch_loss=8.157660\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=58, batch=30 train loss <loss>=8.06755847931\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[58] Batch [30]#011Speed: 773.60 samples/sec#011loss=8.067558\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[58] Batch[35] avg_epoch_loss=8.130792\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=58, batch=35 train loss <loss>=7.96421279907\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[58] Batch [35]#011Speed: 1618.35 samples/sec#011loss=7.964213\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[58] Batch[40] avg_epoch_loss=8.109442\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=58, batch=40 train loss <loss>=7.95571632385\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[58] Batch [40]#011Speed: 710.81 samples/sec#011loss=7.955716\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[58] Batch[45] avg_epoch_loss=8.034480\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=58, batch=45 train loss <loss>=7.41978988647\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[58] Batch [45]#011Speed: 1726.22 samples/sec#011loss=7.419790\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[58] Batch[50] avg_epoch_loss=8.005956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=58, batch=50 train loss <loss>=7.74354038239\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[58] Batch [50]#011Speed: 1220.87 samples/sec#011loss=7.743540\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] processed a total of 1656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1611.5500926971436, \"sum\": 1611.5500926971436, \"min\": 1611.5500926971436}}, \"EndTime\": 1577414497.847144, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414496.235142}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1027.50881186 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=58, train loss <loss>=7.98939638871\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] Epoch[59] Batch[0] avg_epoch_loss=7.531922\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=7.53192234039\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] Epoch[59] Batch[5] avg_epoch_loss=8.287082\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=8.28708187739\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] Epoch[59] Batch [5]#011Speed: 1647.68 samples/sec#011loss=8.287082\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] Epoch[59] Batch[10] avg_epoch_loss=8.248162\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=8.20145797729\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] Epoch[59] Batch [10]#011Speed: 742.30 samples/sec#011loss=8.201458\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] Epoch[59] Batch[15] avg_epoch_loss=8.238151\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=59, batch=15 train loss <loss>=8.21612825394\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] Epoch[59] Batch [15]#011Speed: 1570.69 samples/sec#011loss=8.216128\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] Epoch[59] Batch[20] avg_epoch_loss=8.274925\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=59, batch=20 train loss <loss>=8.39260044098\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] Epoch[59] Batch [20]#011Speed: 773.46 samples/sec#011loss=8.392600\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] Epoch[59] Batch[25] avg_epoch_loss=8.222418\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=59, batch=25 train loss <loss>=8.00188732147\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] Epoch[59] Batch [25]#011Speed: 1666.51 samples/sec#011loss=8.001887\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] Epoch[59] Batch[30] avg_epoch_loss=8.167253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=59, batch=30 train loss <loss>=7.88039722443\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:38 INFO 139649395074880] Epoch[59] Batch [30]#011Speed: 805.84 samples/sec#011loss=7.880397\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] Epoch[59] Batch[35] avg_epoch_loss=8.094603\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=59, batch=35 train loss <loss>=7.64417171478\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] Epoch[59] Batch [35]#011Speed: 1671.54 samples/sec#011loss=7.644172\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] Epoch[59] Batch[40] avg_epoch_loss=8.034973\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=59, batch=40 train loss <loss>=7.60563659668\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] Epoch[59] Batch [40]#011Speed: 736.37 samples/sec#011loss=7.605637\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] Epoch[59] Batch[45] avg_epoch_loss=8.030455\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=59, batch=45 train loss <loss>=7.99340600967\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] Epoch[59] Batch [45]#011Speed: 1477.24 samples/sec#011loss=7.993406\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] processed a total of 1580 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1577.1279335021973, \"sum\": 1577.1279335021973, \"min\": 1577.1279335021973}}, \"EndTime\": 1577414499.424823, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414497.847226}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1001.75186697 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=59, train loss <loss>=8.01012821198\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] Epoch[60] Batch[0] avg_epoch_loss=7.814982\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=7.81498241425\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] Epoch[60] Batch[5] avg_epoch_loss=8.389369\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=8.38936948776\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] Epoch[60] Batch [5]#011Speed: 1614.73 samples/sec#011loss=8.389369\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] Epoch[60] Batch[10] avg_epoch_loss=8.298797\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=8.19011011124\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:39 INFO 139649395074880] Epoch[60] Batch [10]#011Speed: 695.00 samples/sec#011loss=8.190110\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch[15] avg_epoch_loss=8.214573\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=60, batch=15 train loss <loss>=8.02927894592\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch [15]#011Speed: 1451.31 samples/sec#011loss=8.029279\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch[20] avg_epoch_loss=8.274730\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=60, batch=20 train loss <loss>=8.46723480225\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch [20]#011Speed: 781.14 samples/sec#011loss=8.467235\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch[25] avg_epoch_loss=8.203843\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=60, batch=25 train loss <loss>=7.90611448288\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch [25]#011Speed: 1619.11 samples/sec#011loss=7.906114\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch[30] avg_epoch_loss=8.169944\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=60, batch=30 train loss <loss>=7.99366960526\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch [30]#011Speed: 794.57 samples/sec#011loss=7.993670\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch[35] avg_epoch_loss=8.124251\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=60, batch=35 train loss <loss>=7.84095621109\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch [35]#011Speed: 1698.10 samples/sec#011loss=7.840956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch[40] avg_epoch_loss=8.092710\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=60, batch=40 train loss <loss>=7.86561059952\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch [40]#011Speed: 759.10 samples/sec#011loss=7.865611\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch[45] avg_epoch_loss=8.101093\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=60, batch=45 train loss <loss>=8.16983671188\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:40 INFO 139649395074880] Epoch[60] Batch [45]#011Speed: 1587.50 samples/sec#011loss=8.169837\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[60] Batch[50] avg_epoch_loss=7.996455\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=60, batch=50 train loss <loss>=7.03378677368\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[60] Batch [50]#011Speed: 1187.28 samples/sec#011loss=7.033787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] processed a total of 1615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1631.7839622497559, \"sum\": 1631.7839622497559, \"min\": 1631.7839622497559}}, \"EndTime\": 1577414501.057097, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414499.424898}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=989.648267152 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=60, train loss <loss>=7.99645506167\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[61] Batch[0] avg_epoch_loss=8.186450\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=8.18645000458\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[61] Batch[5] avg_epoch_loss=8.431183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=8.43118302027\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[61] Batch [5]#011Speed: 1454.45 samples/sec#011loss=8.431183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[61] Batch[10] avg_epoch_loss=8.340823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=8.23239202499\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[61] Batch [10]#011Speed: 777.68 samples/sec#011loss=8.232392\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[61] Batch[15] avg_epoch_loss=8.348615\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=61, batch=15 train loss <loss>=8.36575660706\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[61] Batch [15]#011Speed: 1657.72 samples/sec#011loss=8.365757\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[61] Batch[20] avg_epoch_loss=8.356068\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=61, batch=20 train loss <loss>=8.37991762161\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[61] Batch [20]#011Speed: 760.42 samples/sec#011loss=8.379918\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[61] Batch[25] avg_epoch_loss=8.291823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=61, batch=25 train loss <loss>=8.021991539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:41 INFO 139649395074880] Epoch[61] Batch [25]#011Speed: 1682.23 samples/sec#011loss=8.021992\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[61] Batch[30] avg_epoch_loss=8.216271\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=61, batch=30 train loss <loss>=7.82340202332\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[61] Batch [30]#011Speed: 808.49 samples/sec#011loss=7.823402\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[61] Batch[35] avg_epoch_loss=8.134412\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=61, batch=35 train loss <loss>=7.62688894272\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[61] Batch [35]#011Speed: 1306.24 samples/sec#011loss=7.626889\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[61] Batch[40] avg_epoch_loss=8.133642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=61, batch=40 train loss <loss>=8.12809791565\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[61] Batch [40]#011Speed: 774.99 samples/sec#011loss=8.128098\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[61] Batch[45] avg_epoch_loss=8.159361\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=61, batch=45 train loss <loss>=8.37025032043\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[61] Batch [45]#011Speed: 1664.08 samples/sec#011loss=8.370250\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[61] Batch[50] avg_epoch_loss=8.107951\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=61, batch=50 train loss <loss>=7.63498620987\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[61] Batch [50]#011Speed: 1306.73 samples/sec#011loss=7.634986\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] processed a total of 1631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1595.4949855804443, \"sum\": 1595.4949855804443, \"min\": 1595.4949855804443}}, \"EndTime\": 1577414502.653077, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414501.057173}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1022.18470752 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=61, train loss <loss>=8.10795125774\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[62] Batch[0] avg_epoch_loss=8.019615\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=8.01961517334\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[62] Batch[5] avg_epoch_loss=8.315073\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=8.31507285436\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:42 INFO 139649395074880] Epoch[62] Batch [5]#011Speed: 1543.09 samples/sec#011loss=8.315073\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] Epoch[62] Batch[10] avg_epoch_loss=8.315473\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=8.31595249176\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] Epoch[62] Batch [10]#011Speed: 792.79 samples/sec#011loss=8.315952\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] Epoch[62] Batch[15] avg_epoch_loss=8.332112\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=62, batch=15 train loss <loss>=8.36871862411\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] Epoch[62] Batch [15]#011Speed: 1285.45 samples/sec#011loss=8.368719\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] Epoch[62] Batch[20] avg_epoch_loss=8.299473\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=62, batch=20 train loss <loss>=8.19502792358\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] Epoch[62] Batch [20]#011Speed: 768.39 samples/sec#011loss=8.195028\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] Epoch[62] Batch[25] avg_epoch_loss=8.206973\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=62, batch=25 train loss <loss>=7.81847429276\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] Epoch[62] Batch [25]#011Speed: 1517.49 samples/sec#011loss=7.818474\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] Epoch[62] Batch[30] avg_epoch_loss=8.149173\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=62, batch=30 train loss <loss>=7.84860877991\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] Epoch[62] Batch [30]#011Speed: 822.72 samples/sec#011loss=7.848609\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] Epoch[62] Batch[35] avg_epoch_loss=8.087701\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=62, batch=35 train loss <loss>=7.70658063889\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:43 INFO 139649395074880] Epoch[62] Batch [35]#011Speed: 1565.31 samples/sec#011loss=7.706581\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[62] Batch[40] avg_epoch_loss=8.023836\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=62, batch=40 train loss <loss>=7.56400489807\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[62] Batch [40]#011Speed: 789.44 samples/sec#011loss=7.564005\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[62] Batch[45] avg_epoch_loss=8.028893\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=62, batch=45 train loss <loss>=8.07036008835\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[62] Batch [45]#011Speed: 1703.41 samples/sec#011loss=8.070360\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] processed a total of 1547 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1561.1560344696045, \"sum\": 1561.1560344696045, \"min\": 1561.1560344696045}}, \"EndTime\": 1577414504.214779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414502.65315}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=990.860762478 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=62, train loss <loss>=7.98330861695\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[63] Batch[0] avg_epoch_loss=7.926956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=7.92695617676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[63] Batch[5] avg_epoch_loss=8.272903\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=8.27290344238\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[63] Batch [5]#011Speed: 1665.14 samples/sec#011loss=8.272903\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[63] Batch[10] avg_epoch_loss=8.297270\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=8.3265089035\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[63] Batch [10]#011Speed: 760.91 samples/sec#011loss=8.326509\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[63] Batch[15] avg_epoch_loss=8.332333\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=63, batch=15 train loss <loss>=8.40947122574\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[63] Batch [15]#011Speed: 1511.63 samples/sec#011loss=8.409471\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[63] Batch[20] avg_epoch_loss=8.323781\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=63, batch=20 train loss <loss>=8.29641551971\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:44 INFO 139649395074880] Epoch[63] Batch [20]#011Speed: 792.16 samples/sec#011loss=8.296416\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] Epoch[63] Batch[25] avg_epoch_loss=8.229010\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=63, batch=25 train loss <loss>=7.83097229004\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] Epoch[63] Batch [25]#011Speed: 1628.76 samples/sec#011loss=7.830972\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] Epoch[63] Batch[30] avg_epoch_loss=8.191948\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=63, batch=30 train loss <loss>=7.99922266006\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] Epoch[63] Batch [30]#011Speed: 739.25 samples/sec#011loss=7.999223\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] Epoch[63] Batch[35] avg_epoch_loss=8.124361\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=63, batch=35 train loss <loss>=7.70532636642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] Epoch[63] Batch [35]#011Speed: 1540.33 samples/sec#011loss=7.705326\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] Epoch[63] Batch[40] avg_epoch_loss=8.087059\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=63, batch=40 train loss <loss>=7.81848526001\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] Epoch[63] Batch [40]#011Speed: 761.22 samples/sec#011loss=7.818485\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] Epoch[63] Batch[45] avg_epoch_loss=8.073302\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=63, batch=45 train loss <loss>=7.96049642563\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] Epoch[63] Batch [45]#011Speed: 1653.53 samples/sec#011loss=7.960496\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] Epoch[63] Batch[50] avg_epoch_loss=8.065286\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=63, batch=50 train loss <loss>=7.99153490067\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] Epoch[63] Batch [50]#011Speed: 1739.89 samples/sec#011loss=7.991535\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] processed a total of 1713 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1663.012981414795, \"sum\": 1663.012981414795, \"min\": 1663.012981414795}}, \"EndTime\": 1577414505.878299, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414504.214856}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1030.00228684 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=63, train loss <loss>=8.00532739251\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:45 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch[0] avg_epoch_loss=8.157094\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=8.15709400177\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch[5] avg_epoch_loss=8.194028\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=8.19402805964\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch [5]#011Speed: 1550.69 samples/sec#011loss=8.194028\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch[10] avg_epoch_loss=8.336636\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=8.50776462555\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch [10]#011Speed: 704.55 samples/sec#011loss=8.507765\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch[15] avg_epoch_loss=8.300470\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=64, batch=15 train loss <loss>=8.22090549469\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch [15]#011Speed: 1653.49 samples/sec#011loss=8.220905\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch[20] avg_epoch_loss=8.355691\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=64, batch=20 train loss <loss>=8.53239841461\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch [20]#011Speed: 797.13 samples/sec#011loss=8.532398\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch[25] avg_epoch_loss=8.288822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=64, batch=25 train loss <loss>=8.00797319412\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch [25]#011Speed: 1702.36 samples/sec#011loss=8.007973\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch[30] avg_epoch_loss=8.202623\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=64, batch=30 train loss <loss>=7.754388237\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:46 INFO 139649395074880] Epoch[64] Batch [30]#011Speed: 779.52 samples/sec#011loss=7.754388\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] Epoch[64] Batch[35] avg_epoch_loss=8.174035\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=64, batch=35 train loss <loss>=7.99678659439\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] Epoch[64] Batch [35]#011Speed: 1540.58 samples/sec#011loss=7.996787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] Epoch[64] Batch[40] avg_epoch_loss=8.132415\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=64, batch=40 train loss <loss>=7.83275527954\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] Epoch[64] Batch [40]#011Speed: 739.10 samples/sec#011loss=7.832755\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] Epoch[64] Batch[45] avg_epoch_loss=8.101060\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=64, batch=45 train loss <loss>=7.84395027161\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] Epoch[64] Batch [45]#011Speed: 1741.65 samples/sec#011loss=7.843950\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] processed a total of 1587 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1562.1960163116455, \"sum\": 1562.1960163116455, \"min\": 1562.1960163116455}}, \"EndTime\": 1577414507.441038, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414505.878356}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1015.8021393 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=64, train loss <loss>=8.04693407059\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] Epoch[65] Batch[0] avg_epoch_loss=7.681425\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=7.68142461777\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] Epoch[65] Batch[5] avg_epoch_loss=8.003310\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=8.00330988566\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] Epoch[65] Batch [5]#011Speed: 1410.70 samples/sec#011loss=8.003310\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] Epoch[65] Batch[10] avg_epoch_loss=8.096078\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=8.20740070343\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:47 INFO 139649395074880] Epoch[65] Batch [10]#011Speed: 756.47 samples/sec#011loss=8.207401\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch[15] avg_epoch_loss=8.260265\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=65, batch=15 train loss <loss>=8.62147579193\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch [15]#011Speed: 1340.36 samples/sec#011loss=8.621476\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch[20] avg_epoch_loss=8.254787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=65, batch=20 train loss <loss>=8.23725709915\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch [20]#011Speed: 772.21 samples/sec#011loss=8.237257\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch[25] avg_epoch_loss=8.169027\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=65, batch=25 train loss <loss>=7.80883293152\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch [25]#011Speed: 1526.37 samples/sec#011loss=7.808833\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch[30] avg_epoch_loss=8.098859\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=65, batch=30 train loss <loss>=7.73398971558\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch [30]#011Speed: 731.47 samples/sec#011loss=7.733990\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch[35] avg_epoch_loss=8.084463\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=65, batch=35 train loss <loss>=7.9952038765\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch [35]#011Speed: 1513.92 samples/sec#011loss=7.995204\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch[40] avg_epoch_loss=8.071792\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=65, batch=40 train loss <loss>=7.98056573868\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch [40]#011Speed: 761.74 samples/sec#011loss=7.980566\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch[45] avg_epoch_loss=8.081456\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=65, batch=45 train loss <loss>=8.16069564819\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:48 INFO 139649395074880] Epoch[65] Batch [45]#011Speed: 1669.97 samples/sec#011loss=8.160696\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] Epoch[65] Batch[50] avg_epoch_loss=8.060296\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=65, batch=50 train loss <loss>=7.86562662125\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] Epoch[65] Batch [50]#011Speed: 1130.16 samples/sec#011loss=7.865627\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] processed a total of 1609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1659.2340469360352, \"sum\": 1659.2340469360352, \"min\": 1659.2340469360352}}, \"EndTime\": 1577414509.100856, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414507.441118}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=969.659766801 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=65, train loss <loss>=8.06029607735\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] Epoch[66] Batch[0] avg_epoch_loss=7.971878\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=7.97187757492\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] Epoch[66] Batch[5] avg_epoch_loss=8.381328\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=8.38132802645\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] Epoch[66] Batch [5]#011Speed: 1499.17 samples/sec#011loss=8.381328\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] Epoch[66] Batch[10] avg_epoch_loss=8.308269\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=8.22059822083\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] Epoch[66] Batch [10]#011Speed: 725.06 samples/sec#011loss=8.220598\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] Epoch[66] Batch[15] avg_epoch_loss=8.369323\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=66, batch=15 train loss <loss>=8.50364103317\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] Epoch[66] Batch [15]#011Speed: 1335.54 samples/sec#011loss=8.503641\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] Epoch[66] Batch[20] avg_epoch_loss=8.354868\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=66, batch=20 train loss <loss>=8.30861225128\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:49 INFO 139649395074880] Epoch[66] Batch [20]#011Speed: 764.30 samples/sec#011loss=8.308612\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[66] Batch[25] avg_epoch_loss=8.257255\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=66, batch=25 train loss <loss>=7.84727897644\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[66] Batch [25]#011Speed: 1323.98 samples/sec#011loss=7.847279\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[66] Batch[30] avg_epoch_loss=8.205179\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=66, batch=30 train loss <loss>=7.9343875885\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[66] Batch [30]#011Speed: 737.78 samples/sec#011loss=7.934388\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[66] Batch[35] avg_epoch_loss=8.126936\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=66, batch=35 train loss <loss>=7.64182834625\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[66] Batch [35]#011Speed: 1727.30 samples/sec#011loss=7.641828\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[66] Batch[40] avg_epoch_loss=8.162065\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=66, batch=40 train loss <loss>=8.41499538422\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[66] Batch [40]#011Speed: 754.04 samples/sec#011loss=8.414995\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[66] Batch[45] avg_epoch_loss=8.138283\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=66, batch=45 train loss <loss>=7.94327116013\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[66] Batch [45]#011Speed: 1548.00 samples/sec#011loss=7.943271\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[66] Batch[50] avg_epoch_loss=8.047798\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=66, batch=50 train loss <loss>=7.21533021927\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[66] Batch [50]#011Speed: 1077.24 samples/sec#011loss=7.215330\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] processed a total of 1608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1700.4399299621582, \"sum\": 1700.4399299621582, \"min\": 1700.4399299621582}}, \"EndTime\": 1577414510.801792, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414509.10093}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=945.575856753 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=66, train loss <loss>=8.04779772665\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] Epoch[67] Batch[0] avg_epoch_loss=8.551455\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=8.55145454407\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch[5] avg_epoch_loss=8.218924\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=8.21892436345\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch [5]#011Speed: 1651.70 samples/sec#011loss=8.218924\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch[10] avg_epoch_loss=8.173868\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=8.11979980469\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch [10]#011Speed: 1592.04 samples/sec#011loss=8.119800\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch[15] avg_epoch_loss=8.192411\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=67, batch=15 train loss <loss>=8.23320646286\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch [15]#011Speed: 743.57 samples/sec#011loss=8.233206\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch[20] avg_epoch_loss=8.272680\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=67, batch=20 train loss <loss>=8.52953929901\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch [20]#011Speed: 1711.50 samples/sec#011loss=8.529539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch[25] avg_epoch_loss=8.188094\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=67, batch=25 train loss <loss>=7.83283262253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch [25]#011Speed: 778.86 samples/sec#011loss=7.832833\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch[30] avg_epoch_loss=8.120978\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=67, batch=30 train loss <loss>=7.77197885513\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch [30]#011Speed: 1726.34 samples/sec#011loss=7.771979\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch[35] avg_epoch_loss=8.041911\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=67, batch=35 train loss <loss>=7.55169286728\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:51 INFO 139649395074880] Epoch[67] Batch [35]#011Speed: 775.87 samples/sec#011loss=7.551693\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[67] Batch[40] avg_epoch_loss=8.024229\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=67, batch=40 train loss <loss>=7.89692249298\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[67] Batch [40]#011Speed: 827.96 samples/sec#011loss=7.896922\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[67] Batch[45] avg_epoch_loss=8.019308\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=67, batch=45 train loss <loss>=7.97894954681\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[67] Batch [45]#011Speed: 1581.72 samples/sec#011loss=7.978950\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[67] Batch[50] avg_epoch_loss=7.985040\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=67, batch=50 train loss <loss>=7.66977367401\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[67] Batch [50]#011Speed: 1335.62 samples/sec#011loss=7.669774\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] processed a total of 1645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1602.1881103515625, \"sum\": 1602.1881103515625, \"min\": 1602.1881103515625}}, \"EndTime\": 1577414512.404495, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414510.801869}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1026.66130592 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=67, train loss <loss>=7.95778379991\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[68] Batch[0] avg_epoch_loss=8.307937\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=8.3079366684\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[68] Batch[5] avg_epoch_loss=8.250673\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=8.25067257881\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[68] Batch [5]#011Speed: 1458.68 samples/sec#011loss=8.250673\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[68] Batch[10] avg_epoch_loss=8.237484\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=8.22165803909\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[68] Batch [10]#011Speed: 815.18 samples/sec#011loss=8.221658\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[68] Batch[15] avg_epoch_loss=8.264907\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=68, batch=15 train loss <loss>=8.32523612976\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:52 INFO 139649395074880] Epoch[68] Batch [15]#011Speed: 1682.53 samples/sec#011loss=8.325236\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] Epoch[68] Batch[20] avg_epoch_loss=8.234540\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=68, batch=20 train loss <loss>=8.13736610413\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] Epoch[68] Batch [20]#011Speed: 738.31 samples/sec#011loss=8.137366\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] Epoch[68] Batch[25] avg_epoch_loss=8.171263\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=68, batch=25 train loss <loss>=7.90550022125\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] Epoch[68] Batch [25]#011Speed: 1352.36 samples/sec#011loss=7.905500\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] Epoch[68] Batch[30] avg_epoch_loss=8.122837\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=68, batch=30 train loss <loss>=7.87102022171\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] Epoch[68] Batch [30]#011Speed: 742.21 samples/sec#011loss=7.871020\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] Epoch[68] Batch[35] avg_epoch_loss=8.037036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=68, batch=35 train loss <loss>=7.50506782532\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] Epoch[68] Batch [35]#011Speed: 1370.71 samples/sec#011loss=7.505068\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] Epoch[68] Batch[40] avg_epoch_loss=8.027681\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=68, batch=40 train loss <loss>=7.96033086777\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] Epoch[68] Batch [40]#011Speed: 809.55 samples/sec#011loss=7.960331\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] Epoch[68] Batch[45] avg_epoch_loss=7.991117\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=68, batch=45 train loss <loss>=7.69128961563\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] Epoch[68] Batch [45]#011Speed: 1335.16 samples/sec#011loss=7.691290\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] processed a total of 1507 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1562.1411800384521, \"sum\": 1562.1411800384521, \"min\": 1562.1411800384521}}, \"EndTime\": 1577414513.967171, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414512.404555}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=964.626307152 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=68, train loss <loss>=7.94733859102\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:53 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] Epoch[69] Batch[0] avg_epoch_loss=7.846425\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=7.84642505646\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] Epoch[69] Batch[5] avg_epoch_loss=8.021909\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=8.02190883954\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] Epoch[69] Batch [5]#011Speed: 1302.49 samples/sec#011loss=8.021909\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] Epoch[69] Batch[10] avg_epoch_loss=8.159278\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=8.32412128448\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] Epoch[69] Batch [10]#011Speed: 762.46 samples/sec#011loss=8.324121\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] Epoch[69] Batch[15] avg_epoch_loss=8.340933\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=69, batch=15 train loss <loss>=8.74057254791\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] Epoch[69] Batch [15]#011Speed: 1545.09 samples/sec#011loss=8.740573\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] Epoch[69] Batch[20] avg_epoch_loss=8.345703\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=69, batch=20 train loss <loss>=8.36096658707\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] Epoch[69] Batch [20]#011Speed: 722.53 samples/sec#011loss=8.360967\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] Epoch[69] Batch[25] avg_epoch_loss=8.275316\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=69, batch=25 train loss <loss>=7.97969055176\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:54 INFO 139649395074880] Epoch[69] Batch [25]#011Speed: 1260.51 samples/sec#011loss=7.979691\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] Epoch[69] Batch[30] avg_epoch_loss=8.192004\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=69, batch=30 train loss <loss>=7.75878620148\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] Epoch[69] Batch [30]#011Speed: 765.83 samples/sec#011loss=7.758786\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] Epoch[69] Batch[35] avg_epoch_loss=8.123476\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=69, batch=35 train loss <loss>=7.69859733582\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] Epoch[69] Batch [35]#011Speed: 1706.06 samples/sec#011loss=7.698597\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] Epoch[69] Batch[40] avg_epoch_loss=8.118185\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=69, batch=40 train loss <loss>=8.08009166718\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] Epoch[69] Batch [40]#011Speed: 783.04 samples/sec#011loss=8.080092\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] Epoch[69] Batch[45] avg_epoch_loss=8.107245\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=69, batch=45 train loss <loss>=8.01753559113\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] Epoch[69] Batch [45]#011Speed: 1716.61 samples/sec#011loss=8.017536\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] processed a total of 1585 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1625.3738403320312, \"sum\": 1625.3738403320312, \"min\": 1625.3738403320312}}, \"EndTime\": 1577414515.593147, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414513.967256}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=975.093049323 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=69, train loss <loss>=8.08047913551\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] Epoch[70] Batch[0] avg_epoch_loss=8.237465\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=8.23746490479\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] Epoch[70] Batch[5] avg_epoch_loss=8.164811\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=8.16481097539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:55 INFO 139649395074880] Epoch[70] Batch [5]#011Speed: 1646.61 samples/sec#011loss=8.164811\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch[10] avg_epoch_loss=8.185114\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=8.2094783783\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch [10]#011Speed: 816.83 samples/sec#011loss=8.209478\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch[15] avg_epoch_loss=8.290666\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=70, batch=15 train loss <loss>=8.52288093567\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch [15]#011Speed: 1740.19 samples/sec#011loss=8.522881\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch[20] avg_epoch_loss=8.217691\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=70, batch=20 train loss <loss>=7.98417081833\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch [20]#011Speed: 742.13 samples/sec#011loss=7.984171\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch[25] avg_epoch_loss=8.139270\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=70, batch=25 train loss <loss>=7.80989971161\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch [25]#011Speed: 1739.96 samples/sec#011loss=7.809900\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch[30] avg_epoch_loss=8.082021\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=70, batch=30 train loss <loss>=7.78432607651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch [30]#011Speed: 794.19 samples/sec#011loss=7.784326\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch[35] avg_epoch_loss=8.040004\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=70, batch=35 train loss <loss>=7.77949762344\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch [35]#011Speed: 1564.79 samples/sec#011loss=7.779498\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch[40] avg_epoch_loss=8.011974\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=70, batch=40 train loss <loss>=7.81015996933\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:56 INFO 139649395074880] Epoch[70] Batch [40]#011Speed: 798.89 samples/sec#011loss=7.810160\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[70] Batch[45] avg_epoch_loss=8.002254\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=70, batch=45 train loss <loss>=7.92254619598\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[70] Batch [45]#011Speed: 1556.30 samples/sec#011loss=7.922546\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] processed a total of 1524 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1481.6279411315918, \"sum\": 1481.6279411315918, \"min\": 1481.6279411315918}}, \"EndTime\": 1577414517.075302, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414515.593225}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1028.51357397 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=70, train loss <loss>=7.98218385379\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[71] Batch[0] avg_epoch_loss=8.427375\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=8.42737483978\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[71] Batch[5] avg_epoch_loss=8.240734\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=8.24073441823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[71] Batch [5]#011Speed: 1702.60 samples/sec#011loss=8.240734\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[71] Batch[10] avg_epoch_loss=8.327123\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=8.4307882309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[71] Batch [10]#011Speed: 805.64 samples/sec#011loss=8.430788\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[71] Batch[15] avg_epoch_loss=8.439265\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=71, batch=15 train loss <loss>=8.68597736359\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[71] Batch [15]#011Speed: 1624.15 samples/sec#011loss=8.685977\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[71] Batch[20] avg_epoch_loss=8.404327\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=71, batch=20 train loss <loss>=8.29252824783\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[71] Batch [20]#011Speed: 721.83 samples/sec#011loss=8.292528\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[71] Batch[25] avg_epoch_loss=8.274394\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=71, batch=25 train loss <loss>=7.72867298126\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:57 INFO 139649395074880] Epoch[71] Batch [25]#011Speed: 1719.18 samples/sec#011loss=7.728673\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[71] Batch[30] avg_epoch_loss=8.233169\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=71, batch=30 train loss <loss>=8.01879796982\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[71] Batch [30]#011Speed: 811.25 samples/sec#011loss=8.018798\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[71] Batch[35] avg_epoch_loss=8.150169\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=71, batch=35 train loss <loss>=7.6355676651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[71] Batch [35]#011Speed: 1718.12 samples/sec#011loss=7.635568\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[71] Batch[40] avg_epoch_loss=8.123260\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=71, batch=40 train loss <loss>=7.92952222824\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[71] Batch [40]#011Speed: 694.45 samples/sec#011loss=7.929522\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[71] Batch[45] avg_epoch_loss=8.074806\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=71, batch=45 train loss <loss>=7.67748250961\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[71] Batch [45]#011Speed: 1618.31 samples/sec#011loss=7.677483\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[71] Batch[50] avg_epoch_loss=8.052572\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=71, batch=50 train loss <loss>=7.84802093506\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[71] Batch [50]#011Speed: 1086.38 samples/sec#011loss=7.848021\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] processed a total of 1639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1623.3751773834229, \"sum\": 1623.3751773834229, \"min\": 1623.3751773834229}}, \"EndTime\": 1577414518.699231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414517.075385}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1009.5647014 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=71, train loss <loss>=8.03632751795\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[72] Batch[0] avg_epoch_loss=8.390173\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=8.39017295837\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[72] Batch[5] avg_epoch_loss=8.244200\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=8.24419983228\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:58 INFO 139649395074880] Epoch[72] Batch [5]#011Speed: 1444.03 samples/sec#011loss=8.244200\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] Epoch[72] Batch[10] avg_epoch_loss=8.233517\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=8.22069835663\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] Epoch[72] Batch [10]#011Speed: 742.22 samples/sec#011loss=8.220698\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] Epoch[72] Batch[15] avg_epoch_loss=8.254554\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=72, batch=15 train loss <loss>=8.30083427429\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] Epoch[72] Batch [15]#011Speed: 1352.61 samples/sec#011loss=8.300834\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] Epoch[72] Batch[20] avg_epoch_loss=8.338157\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=72, batch=20 train loss <loss>=8.60568647385\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] Epoch[72] Batch [20]#011Speed: 777.70 samples/sec#011loss=8.605686\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] Epoch[72] Batch[25] avg_epoch_loss=8.204454\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=72, batch=25 train loss <loss>=7.64290370941\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] Epoch[72] Batch [25]#011Speed: 1654.04 samples/sec#011loss=7.642904\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] Epoch[72] Batch[30] avg_epoch_loss=8.147209\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=72, batch=30 train loss <loss>=7.84953336716\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] Epoch[72] Batch [30]#011Speed: 698.04 samples/sec#011loss=7.849533\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] Epoch[72] Batch[35] avg_epoch_loss=8.115787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=72, batch=35 train loss <loss>=7.92097158432\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:41:59 INFO 139649395074880] Epoch[72] Batch [35]#011Speed: 1638.20 samples/sec#011loss=7.920972\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[72] Batch[40] avg_epoch_loss=8.068427\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=72, batch=40 train loss <loss>=7.72743282318\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[72] Batch [40]#011Speed: 751.51 samples/sec#011loss=7.727433\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[72] Batch[45] avg_epoch_loss=8.064166\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=72, batch=45 train loss <loss>=8.02923088074\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[72] Batch [45]#011Speed: 1696.60 samples/sec#011loss=8.029231\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[72] Batch[50] avg_epoch_loss=8.009934\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=72, batch=50 train loss <loss>=7.51099452972\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[72] Batch [50]#011Speed: 1214.05 samples/sec#011loss=7.510995\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] processed a total of 1649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1659.656047821045, \"sum\": 1659.656047821045, \"min\": 1659.656047821045}}, \"EndTime\": 1577414520.359459, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414518.699291}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=993.506289777 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=72, train loss <loss>=8.00120641635\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[73] Batch[0] avg_epoch_loss=7.650351\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=7.65035104752\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[73] Batch[5] avg_epoch_loss=7.973510\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=7.97350978851\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[73] Batch [5]#011Speed: 1423.28 samples/sec#011loss=7.973510\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[73] Batch[10] avg_epoch_loss=8.223739\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=8.52401409149\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[73] Batch [10]#011Speed: 698.76 samples/sec#011loss=8.524014\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[73] Batch[15] avg_epoch_loss=8.350151\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=73, batch=15 train loss <loss>=8.6282585144\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:00 INFO 139649395074880] Epoch[73] Batch [15]#011Speed: 1536.38 samples/sec#011loss=8.628259\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] Epoch[73] Batch[20] avg_epoch_loss=8.260845\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=73, batch=20 train loss <loss>=7.97506637573\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] Epoch[73] Batch [20]#011Speed: 761.59 samples/sec#011loss=7.975066\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] Epoch[73] Batch[25] avg_epoch_loss=8.176758\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=73, batch=25 train loss <loss>=7.82359046936\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] Epoch[73] Batch [25]#011Speed: 1704.01 samples/sec#011loss=7.823590\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] Epoch[73] Batch[30] avg_epoch_loss=8.115193\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=73, batch=30 train loss <loss>=7.79505262375\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] Epoch[73] Batch [30]#011Speed: 703.02 samples/sec#011loss=7.795053\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] Epoch[73] Batch[35] avg_epoch_loss=7.986574\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=73, batch=35 train loss <loss>=7.18913946152\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] Epoch[73] Batch [35]#011Speed: 1332.30 samples/sec#011loss=7.189139\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] Epoch[73] Batch[40] avg_epoch_loss=7.969700\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=73, batch=40 train loss <loss>=7.84820928574\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] Epoch[73] Batch [40]#011Speed: 769.20 samples/sec#011loss=7.848209\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] Epoch[73] Batch[45] avg_epoch_loss=7.947745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=73, batch=45 train loss <loss>=7.76771535873\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:01 INFO 139649395074880] Epoch[73] Batch [45]#011Speed: 1564.93 samples/sec#011loss=7.767715\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[73] Batch[50] avg_epoch_loss=7.872629\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=73, batch=50 train loss <loss>=7.18155612946\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[73] Batch [50]#011Speed: 1439.21 samples/sec#011loss=7.181556\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] processed a total of 1604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1644.6139812469482, \"sum\": 1644.6139812469482, \"min\": 1644.6139812469482}}, \"EndTime\": 1577414522.004625, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414520.359543}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=975.245616176 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=73, train loss <loss>=7.87262882906\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_b64f0415-b1be-4f8b-be83-df6dfdbd04f0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 21.23403549194336, \"sum\": 21.23403549194336, \"min\": 21.23403549194336}}, \"EndTime\": 1577414522.026424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414522.004694}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[74] Batch[0] avg_epoch_loss=8.435485\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=8.43548488617\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[74] Batch[5] avg_epoch_loss=8.141145\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=8.14114459356\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[74] Batch [5]#011Speed: 1559.85 samples/sec#011loss=8.141145\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[74] Batch[10] avg_epoch_loss=8.325644\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=8.54704322815\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[74] Batch [10]#011Speed: 765.93 samples/sec#011loss=8.547043\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[74] Batch[15] avg_epoch_loss=8.339838\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=74, batch=15 train loss <loss>=8.37106628418\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[74] Batch [15]#011Speed: 1351.23 samples/sec#011loss=8.371066\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[74] Batch[20] avg_epoch_loss=8.313788\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=74, batch=20 train loss <loss>=8.23042831421\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[74] Batch [20]#011Speed: 708.89 samples/sec#011loss=8.230428\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[74] Batch[25] avg_epoch_loss=8.221411\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=74, batch=25 train loss <loss>=7.83342494965\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:02 INFO 139649395074880] Epoch[74] Batch [25]#011Speed: 1299.44 samples/sec#011loss=7.833425\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] Epoch[74] Batch[30] avg_epoch_loss=8.129999\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=74, batch=30 train loss <loss>=7.65465459824\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] Epoch[74] Batch [30]#011Speed: 834.17 samples/sec#011loss=7.654655\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] Epoch[74] Batch[35] avg_epoch_loss=8.101257\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=74, batch=35 train loss <loss>=7.92306070328\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] Epoch[74] Batch [35]#011Speed: 1550.40 samples/sec#011loss=7.923061\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] Epoch[74] Batch[40] avg_epoch_loss=8.044033\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=74, batch=40 train loss <loss>=7.63201770782\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] Epoch[74] Batch [40]#011Speed: 669.11 samples/sec#011loss=7.632018\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] Epoch[74] Batch[45] avg_epoch_loss=7.987570\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=74, batch=45 train loss <loss>=7.52457132339\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] Epoch[74] Batch [45]#011Speed: 1553.34 samples/sec#011loss=7.524571\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] processed a total of 1576 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1669.2190170288086, \"sum\": 1669.2190170288086, \"min\": 1669.2190170288086}}, \"EndTime\": 1577414523.695739, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414522.026466}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=944.090195419 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=74, train loss <loss>=7.91198737144\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] Epoch[75] Batch[0] avg_epoch_loss=7.603159\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=7.60315895081\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] Epoch[75] Batch[5] avg_epoch_loss=8.354748\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=8.35474761327\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:03 INFO 139649395074880] Epoch[75] Batch [5]#011Speed: 1406.49 samples/sec#011loss=8.354748\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] Epoch[75] Batch[10] avg_epoch_loss=8.285164\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=8.20166320801\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] Epoch[75] Batch [10]#011Speed: 1377.71 samples/sec#011loss=8.201663\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] Epoch[75] Batch[15] avg_epoch_loss=8.240469\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=75, batch=15 train loss <loss>=8.1421412468\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] Epoch[75] Batch [15]#011Speed: 744.60 samples/sec#011loss=8.142141\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] Epoch[75] Batch[20] avg_epoch_loss=8.204458\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=75, batch=20 train loss <loss>=8.08922300339\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] Epoch[75] Batch [20]#011Speed: 768.46 samples/sec#011loss=8.089223\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] Epoch[75] Batch[25] avg_epoch_loss=8.093415\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=75, batch=25 train loss <loss>=7.62703332901\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] Epoch[75] Batch [25]#011Speed: 1549.45 samples/sec#011loss=7.627033\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] Epoch[75] Batch[30] avg_epoch_loss=8.059458\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=75, batch=30 train loss <loss>=7.88288192749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] Epoch[75] Batch [30]#011Speed: 725.28 samples/sec#011loss=7.882882\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] Epoch[75] Batch[35] avg_epoch_loss=8.021031\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=75, batch=35 train loss <loss>=7.78278541565\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:04 INFO 139649395074880] Epoch[75] Batch [35]#011Speed: 1429.78 samples/sec#011loss=7.782785\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[75] Batch[40] avg_epoch_loss=7.992126\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=75, batch=40 train loss <loss>=7.78400430679\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[75] Batch [40]#011Speed: 764.79 samples/sec#011loss=7.784004\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[75] Batch[45] avg_epoch_loss=7.980255\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=75, batch=45 train loss <loss>=7.88291873932\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[75] Batch [45]#011Speed: 1531.92 samples/sec#011loss=7.882919\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[75] Batch[50] avg_epoch_loss=7.942399\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=75, batch=50 train loss <loss>=7.59412460327\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[75] Batch [50]#011Speed: 1217.09 samples/sec#011loss=7.594125\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] processed a total of 1623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1672.611951828003, \"sum\": 1672.611951828003, \"min\": 1672.611951828003}}, \"EndTime\": 1577414525.368875, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414523.695818}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=970.278887808 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=75, train loss <loss>=7.94239930546\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[76] Batch[0] avg_epoch_loss=8.232968\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=8.23296833038\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[76] Batch[5] avg_epoch_loss=8.153842\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=8.15384181341\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[76] Batch [5]#011Speed: 1343.32 samples/sec#011loss=8.153842\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[76] Batch[10] avg_epoch_loss=8.292320\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=8.4584941864\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[76] Batch [10]#011Speed: 722.62 samples/sec#011loss=8.458494\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[76] Batch[15] avg_epoch_loss=8.253928\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=76, batch=15 train loss <loss>=8.16946372986\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:05 INFO 139649395074880] Epoch[76] Batch [15]#011Speed: 1466.24 samples/sec#011loss=8.169464\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch[20] avg_epoch_loss=8.279430\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=76, batch=20 train loss <loss>=8.36103610992\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch [20]#011Speed: 1574.68 samples/sec#011loss=8.361036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch[25] avg_epoch_loss=8.216904\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=76, batch=25 train loss <loss>=7.95429821014\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch [25]#011Speed: 804.71 samples/sec#011loss=7.954298\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch[30] avg_epoch_loss=8.150452\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=76, batch=30 train loss <loss>=7.80489854813\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch [30]#011Speed: 1560.87 samples/sec#011loss=7.804899\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch[35] avg_epoch_loss=8.090822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=76, batch=35 train loss <loss>=7.72111568451\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch [35]#011Speed: 830.59 samples/sec#011loss=7.721116\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch[40] avg_epoch_loss=8.039401\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=76, batch=40 train loss <loss>=7.66917009354\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch [40]#011Speed: 1701.06 samples/sec#011loss=7.669170\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch[45] avg_epoch_loss=8.015247\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=76, batch=45 train loss <loss>=7.8171831131\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch [45]#011Speed: 770.69 samples/sec#011loss=7.817183\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch[50] avg_epoch_loss=8.009399\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=76, batch=50 train loss <loss>=7.95559711456\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:06 INFO 139649395074880] Epoch[76] Batch [50]#011Speed: 1301.64 samples/sec#011loss=7.955597\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] processed a total of 1684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1640.3789520263672, \"sum\": 1640.3789520263672, \"min\": 1640.3789520263672}}, \"EndTime\": 1577414527.009806, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414525.368948}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1026.53386735 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=76, train loss <loss>=8.01944526636\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] Epoch[77] Batch[0] avg_epoch_loss=8.241827\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=8.24182701111\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] Epoch[77] Batch[5] avg_epoch_loss=8.201337\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=8.20133733749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] Epoch[77] Batch [5]#011Speed: 1546.98 samples/sec#011loss=8.201337\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] Epoch[77] Batch[10] avg_epoch_loss=8.240299\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=8.28705205917\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] Epoch[77] Batch [10]#011Speed: 788.66 samples/sec#011loss=8.287052\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] Epoch[77] Batch[15] avg_epoch_loss=8.255213\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=77, batch=15 train loss <loss>=8.28802547455\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] Epoch[77] Batch [15]#011Speed: 1380.02 samples/sec#011loss=8.288025\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] Epoch[77] Batch[20] avg_epoch_loss=8.262480\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=77, batch=20 train loss <loss>=8.28573503494\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] Epoch[77] Batch [20]#011Speed: 756.85 samples/sec#011loss=8.285735\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] Epoch[77] Batch[25] avg_epoch_loss=8.110967\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=77, batch=25 train loss <loss>=7.47461128235\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:07 INFO 139649395074880] Epoch[77] Batch [25]#011Speed: 1274.65 samples/sec#011loss=7.474611\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] Epoch[77] Batch[30] avg_epoch_loss=8.088968\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=77, batch=30 train loss <loss>=7.97457370758\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] Epoch[77] Batch [30]#011Speed: 705.05 samples/sec#011loss=7.974574\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] Epoch[77] Batch[35] avg_epoch_loss=8.062963\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=77, batch=35 train loss <loss>=7.90173397064\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] Epoch[77] Batch [35]#011Speed: 1527.87 samples/sec#011loss=7.901734\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] Epoch[77] Batch[40] avg_epoch_loss=8.029604\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=77, batch=40 train loss <loss>=7.78942041397\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] Epoch[77] Batch [40]#011Speed: 771.00 samples/sec#011loss=7.789420\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] Epoch[77] Batch[45] avg_epoch_loss=7.984710\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=77, batch=45 train loss <loss>=7.61657781601\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] Epoch[77] Batch [45]#011Speed: 1554.47 samples/sec#011loss=7.616578\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] processed a total of 1598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1633.8889598846436, \"sum\": 1633.8889598846436, \"min\": 1633.8889598846436}}, \"EndTime\": 1577414528.644195, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414527.009865}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=977.974845355 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=77, train loss <loss>=7.97437418938\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] Epoch[78] Batch[0] avg_epoch_loss=8.158137\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=8.15813732147\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] Epoch[78] Batch[5] avg_epoch_loss=8.214752\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=8.21475243568\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:08 INFO 139649395074880] Epoch[78] Batch [5]#011Speed: 1381.96 samples/sec#011loss=8.214752\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] Epoch[78] Batch[10] avg_epoch_loss=8.151314\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=8.07518863678\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] Epoch[78] Batch [10]#011Speed: 700.10 samples/sec#011loss=8.075189\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] Epoch[78] Batch[15] avg_epoch_loss=8.223575\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=78, batch=15 train loss <loss>=8.38254947662\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] Epoch[78] Batch [15]#011Speed: 1719.32 samples/sec#011loss=8.382549\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] Epoch[78] Batch[20] avg_epoch_loss=8.277843\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=78, batch=20 train loss <loss>=8.45149831772\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] Epoch[78] Batch [20]#011Speed: 777.10 samples/sec#011loss=8.451498\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] Epoch[78] Batch[25] avg_epoch_loss=8.202341\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=78, batch=25 train loss <loss>=7.88523235321\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] Epoch[78] Batch [25]#011Speed: 1531.52 samples/sec#011loss=7.885232\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] Epoch[78] Batch[30] avg_epoch_loss=8.135642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=78, batch=30 train loss <loss>=7.78880653381\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] Epoch[78] Batch [30]#011Speed: 818.02 samples/sec#011loss=7.788807\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] Epoch[78] Batch[35] avg_epoch_loss=8.078576\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=78, batch=35 train loss <loss>=7.72476997375\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:09 INFO 139649395074880] Epoch[78] Batch [35]#011Speed: 1542.84 samples/sec#011loss=7.724770\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[78] Batch[40] avg_epoch_loss=8.052616\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=78, batch=40 train loss <loss>=7.86570672989\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[78] Batch [40]#011Speed: 764.53 samples/sec#011loss=7.865707\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[78] Batch[45] avg_epoch_loss=8.047435\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=78, batch=45 train loss <loss>=8.00495014191\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[78] Batch [45]#011Speed: 1702.98 samples/sec#011loss=8.004950\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[78] Batch[50] avg_epoch_loss=7.986040\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=78, batch=50 train loss <loss>=7.42120132446\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[78] Batch [50]#011Speed: 1212.47 samples/sec#011loss=7.421201\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] processed a total of 1652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1638.1101608276367, \"sum\": 1638.1101608276367, \"min\": 1638.1101608276367}}, \"EndTime\": 1577414530.282846, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414528.64426}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1008.41152446 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=78, train loss <loss>=7.98027575933\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[79] Batch[0] avg_epoch_loss=7.879014\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=7.8790140152\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[79] Batch[5] avg_epoch_loss=8.239182\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=8.23918199539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[79] Batch [5]#011Speed: 1554.62 samples/sec#011loss=8.239182\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[79] Batch[10] avg_epoch_loss=8.247090\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=8.25657978058\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[79] Batch [10]#011Speed: 781.19 samples/sec#011loss=8.256580\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[79] Batch[15] avg_epoch_loss=8.337283\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=79, batch=15 train loss <loss>=8.53570747375\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:10 INFO 139649395074880] Epoch[79] Batch [15]#011Speed: 1540.79 samples/sec#011loss=8.535707\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch[20] avg_epoch_loss=8.321549\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=79, batch=20 train loss <loss>=8.27120084763\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch [20]#011Speed: 747.86 samples/sec#011loss=8.271201\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch[25] avg_epoch_loss=8.220979\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=79, batch=25 train loss <loss>=7.79858312607\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch [25]#011Speed: 1572.45 samples/sec#011loss=7.798583\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch[30] avg_epoch_loss=8.159137\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=79, batch=30 train loss <loss>=7.83755702972\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch [30]#011Speed: 777.43 samples/sec#011loss=7.837557\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch[35] avg_epoch_loss=8.098858\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=79, batch=35 train loss <loss>=7.72512798309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch [35]#011Speed: 1561.69 samples/sec#011loss=7.725128\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch[40] avg_epoch_loss=8.089568\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=79, batch=40 train loss <loss>=8.02267923355\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch [40]#011Speed: 770.64 samples/sec#011loss=8.022679\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch[45] avg_epoch_loss=8.046315\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=79, batch=45 train loss <loss>=7.6916431427\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch [45]#011Speed: 1542.47 samples/sec#011loss=7.691643\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch[50] avg_epoch_loss=8.023288\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=79, batch=50 train loss <loss>=7.81144418716\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] Epoch[79] Batch [50]#011Speed: 1286.39 samples/sec#011loss=7.811444\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] processed a total of 1634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1638.659954071045, \"sum\": 1638.659954071045, \"min\": 1638.659954071045}}, \"EndTime\": 1577414531.922061, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414530.282921}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=997.088056928 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=79, train loss <loss>=7.95815010254\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:11 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch[0] avg_epoch_loss=8.347759\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=8.34775924683\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch[5] avg_epoch_loss=8.233828\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=8.23382814725\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch [5]#011Speed: 1509.09 samples/sec#011loss=8.233828\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch[10] avg_epoch_loss=8.250283\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=8.27002983093\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch [10]#011Speed: 807.13 samples/sec#011loss=8.270030\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch[15] avg_epoch_loss=8.353147\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=80, batch=15 train loss <loss>=8.57944717407\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch [15]#011Speed: 1548.51 samples/sec#011loss=8.579447\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch[20] avg_epoch_loss=8.300767\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=80, batch=20 train loss <loss>=8.13315067291\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch [20]#011Speed: 788.95 samples/sec#011loss=8.133151\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch[25] avg_epoch_loss=8.229036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=80, batch=25 train loss <loss>=7.92776470184\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch [25]#011Speed: 1290.26 samples/sec#011loss=7.927765\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch[30] avg_epoch_loss=8.123253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=80, batch=30 train loss <loss>=7.57317972183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:12 INFO 139649395074880] Epoch[80] Batch [30]#011Speed: 813.37 samples/sec#011loss=7.573180\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] Epoch[80] Batch[35] avg_epoch_loss=8.100304\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=80, batch=35 train loss <loss>=7.95802621841\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] Epoch[80] Batch [35]#011Speed: 1363.82 samples/sec#011loss=7.958026\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] Epoch[80] Batch[40] avg_epoch_loss=8.032278\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=80, batch=40 train loss <loss>=7.54248695374\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] Epoch[80] Batch [40]#011Speed: 734.81 samples/sec#011loss=7.542487\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] Epoch[80] Batch[45] avg_epoch_loss=7.971982\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=80, batch=45 train loss <loss>=7.47755594254\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] Epoch[80] Batch [45]#011Speed: 1282.38 samples/sec#011loss=7.477556\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] processed a total of 1584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1654.3200016021729, \"sum\": 1654.3200016021729, \"min\": 1654.3200016021729}}, \"EndTime\": 1577414533.576893, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414531.922137}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=957.432395069 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=80, train loss <loss>=7.94865097046\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] Epoch[81] Batch[0] avg_epoch_loss=8.275046\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=8.27504634857\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] Epoch[81] Batch[5] avg_epoch_loss=8.084798\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=8.08479849497\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:13 INFO 139649395074880] Epoch[81] Batch [5]#011Speed: 1287.28 samples/sec#011loss=8.084798\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] Epoch[81] Batch[10] avg_epoch_loss=8.066957\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=8.04554796219\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] Epoch[81] Batch [10]#011Speed: 736.68 samples/sec#011loss=8.045548\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] Epoch[81] Batch[15] avg_epoch_loss=8.138578\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=81, batch=15 train loss <loss>=8.29614486694\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] Epoch[81] Batch [15]#011Speed: 1325.85 samples/sec#011loss=8.296145\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] Epoch[81] Batch[20] avg_epoch_loss=8.184212\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=81, batch=20 train loss <loss>=8.33023853302\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] Epoch[81] Batch [20]#011Speed: 740.25 samples/sec#011loss=8.330239\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] Epoch[81] Batch[25] avg_epoch_loss=8.143745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=81, batch=25 train loss <loss>=7.97378444672\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] Epoch[81] Batch [25]#011Speed: 1311.20 samples/sec#011loss=7.973784\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] Epoch[81] Batch[30] avg_epoch_loss=8.078484\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=81, batch=30 train loss <loss>=7.73912878036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] Epoch[81] Batch [30]#011Speed: 745.79 samples/sec#011loss=7.739129\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] Epoch[81] Batch[35] avg_epoch_loss=8.012802\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=81, batch=35 train loss <loss>=7.60556869507\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:14 INFO 139649395074880] Epoch[81] Batch [35]#011Speed: 1293.75 samples/sec#011loss=7.605569\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[81] Batch[40] avg_epoch_loss=7.980134\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=81, batch=40 train loss <loss>=7.74492759705\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[81] Batch [40]#011Speed: 829.20 samples/sec#011loss=7.744928\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[81] Batch[45] avg_epoch_loss=8.012828\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=81, batch=45 train loss <loss>=8.28091945648\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[81] Batch [45]#011Speed: 1620.91 samples/sec#011loss=8.280919\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[81] Batch[50] avg_epoch_loss=7.970897\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=81, batch=50 train loss <loss>=7.58513565063\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[81] Batch [50]#011Speed: 1413.34 samples/sec#011loss=7.585136\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] processed a total of 1641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1688.5888576507568, \"sum\": 1688.5888576507568, \"min\": 1688.5888576507568}}, \"EndTime\": 1577414535.266025, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414533.576961}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=971.75975349 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=81, train loss <loss>=7.91516335194\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[82] Batch[0] avg_epoch_loss=7.684089\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=7.68408870697\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[82] Batch[5] avg_epoch_loss=8.049069\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=8.04906900724\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[82] Batch [5]#011Speed: 1547.91 samples/sec#011loss=8.049069\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[82] Batch[10] avg_epoch_loss=8.196355\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=8.37309875488\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[82] Batch [10]#011Speed: 801.21 samples/sec#011loss=8.373099\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[82] Batch[15] avg_epoch_loss=8.237331\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=82, batch=15 train loss <loss>=8.32747859955\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:15 INFO 139649395074880] Epoch[82] Batch [15]#011Speed: 1477.06 samples/sec#011loss=8.327479\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch[20] avg_epoch_loss=8.235205\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=82, batch=20 train loss <loss>=8.2283993721\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch [20]#011Speed: 785.34 samples/sec#011loss=8.228399\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch[25] avg_epoch_loss=8.192019\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=82, batch=25 train loss <loss>=8.01064147949\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch [25]#011Speed: 1321.91 samples/sec#011loss=8.010641\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch[30] avg_epoch_loss=8.090433\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=82, batch=30 train loss <loss>=7.56218566895\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch [30]#011Speed: 722.33 samples/sec#011loss=7.562186\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch[35] avg_epoch_loss=8.017685\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=82, batch=35 train loss <loss>=7.56664562225\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch [35]#011Speed: 1330.33 samples/sec#011loss=7.566646\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch[40] avg_epoch_loss=8.001481\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=82, batch=40 train loss <loss>=7.88481464386\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch [40]#011Speed: 745.24 samples/sec#011loss=7.884815\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch[45] avg_epoch_loss=7.997064\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=82, batch=45 train loss <loss>=7.96083803177\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch [45]#011Speed: 1315.29 samples/sec#011loss=7.960838\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch[50] avg_epoch_loss=7.930219\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=82, batch=50 train loss <loss>=7.31525363922\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] Epoch[82] Batch [50]#011Speed: 1258.40 samples/sec#011loss=7.315254\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] processed a total of 1618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1676.7208576202393, \"sum\": 1676.7208576202393, \"min\": 1676.7208576202393}}, \"EndTime\": 1577414536.943198, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414535.266092}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=964.915500307 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=82, train loss <loss>=7.93021947262\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:16 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] Epoch[83] Batch[0] avg_epoch_loss=8.462766\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=8.46276569366\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] Epoch[83] Batch[5] avg_epoch_loss=8.318498\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=8.31849797567\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] Epoch[83] Batch [5]#011Speed: 1559.53 samples/sec#011loss=8.318498\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] Epoch[83] Batch[10] avg_epoch_loss=8.254587\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=8.17789363861\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] Epoch[83] Batch [10]#011Speed: 803.79 samples/sec#011loss=8.177894\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] Epoch[83] Batch[15] avg_epoch_loss=8.416140\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=83, batch=15 train loss <loss>=8.77155647278\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] Epoch[83] Batch [15]#011Speed: 1299.69 samples/sec#011loss=8.771556\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] Epoch[83] Batch[20] avg_epoch_loss=8.361769\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=83, batch=20 train loss <loss>=8.18778104782\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] Epoch[83] Batch [20]#011Speed: 716.82 samples/sec#011loss=8.187781\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] Epoch[83] Batch[25] avg_epoch_loss=8.268171\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=83, batch=25 train loss <loss>=7.87505846024\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:17 INFO 139649395074880] Epoch[83] Batch [25]#011Speed: 1334.14 samples/sec#011loss=7.875058\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] Epoch[83] Batch[30] avg_epoch_loss=8.156570\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=83, batch=30 train loss <loss>=7.57624959946\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] Epoch[83] Batch [30]#011Speed: 764.82 samples/sec#011loss=7.576250\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] Epoch[83] Batch[35] avg_epoch_loss=8.086482\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=83, batch=35 train loss <loss>=7.65193347931\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] Epoch[83] Batch [35]#011Speed: 1354.34 samples/sec#011loss=7.651933\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] Epoch[83] Batch[40] avg_epoch_loss=8.055029\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=83, batch=40 train loss <loss>=7.82857036591\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] Epoch[83] Batch [40]#011Speed: 753.55 samples/sec#011loss=7.828570\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] Epoch[83] Batch[45] avg_epoch_loss=8.032348\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=83, batch=45 train loss <loss>=7.84635896683\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] Epoch[83] Batch [45]#011Speed: 1093.40 samples/sec#011loss=7.846359\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] processed a total of 1526 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1624.9940395355225, \"sum\": 1624.9940395355225, \"min\": 1624.9940395355225}}, \"EndTime\": 1577414538.568753, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414536.943271}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=939.020849743 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=83, train loss <loss>=7.9740378956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] Epoch[84] Batch[0] avg_epoch_loss=8.407157\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=8.40715694427\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] Epoch[84] Batch[5] avg_epoch_loss=8.046878\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=8.04687833786\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:18 INFO 139649395074880] Epoch[84] Batch [5]#011Speed: 1293.95 samples/sec#011loss=8.046878\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch[10] avg_epoch_loss=8.195846\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=8.37460651398\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch [10]#011Speed: 781.72 samples/sec#011loss=8.374607\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch[15] avg_epoch_loss=8.323120\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=84, batch=15 train loss <loss>=8.603125\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch [15]#011Speed: 1481.89 samples/sec#011loss=8.603125\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch[20] avg_epoch_loss=8.267523\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=84, batch=20 train loss <loss>=8.08961200714\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch [20]#011Speed: 813.62 samples/sec#011loss=8.089612\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch[25] avg_epoch_loss=8.199897\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=84, batch=25 train loss <loss>=7.91586475372\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch [25]#011Speed: 1657.91 samples/sec#011loss=7.915865\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch[30] avg_epoch_loss=8.136863\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=84, batch=30 train loss <loss>=7.80908899307\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch [30]#011Speed: 780.06 samples/sec#011loss=7.809089\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch[35] avg_epoch_loss=8.069075\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=84, batch=35 train loss <loss>=7.64878759384\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch [35]#011Speed: 1419.64 samples/sec#011loss=7.648788\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch[40] avg_epoch_loss=8.072175\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=84, batch=40 train loss <loss>=8.09449367523\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:19 INFO 139649395074880] Epoch[84] Batch [40]#011Speed: 750.12 samples/sec#011loss=8.094494\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] Epoch[84] Batch[45] avg_epoch_loss=8.039497\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=84, batch=45 train loss <loss>=7.77153768539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] Epoch[84] Batch [45]#011Speed: 1112.38 samples/sec#011loss=7.771538\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] processed a total of 1535 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1581.5601348876953, \"sum\": 1581.5601348876953, \"min\": 1581.5601348876953}}, \"EndTime\": 1577414540.150847, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414538.568822}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=970.503571486 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=84, train loss <loss>=8.01771745086\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] Epoch[85] Batch[0] avg_epoch_loss=8.001253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=8.00125312805\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] Epoch[85] Batch[5] avg_epoch_loss=8.172122\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=8.17212160428\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] Epoch[85] Batch [5]#011Speed: 1240.94 samples/sec#011loss=8.172122\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] Epoch[85] Batch[10] avg_epoch_loss=8.195003\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=8.2224609375\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] Epoch[85] Batch [10]#011Speed: 713.51 samples/sec#011loss=8.222461\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] Epoch[85] Batch[15] avg_epoch_loss=8.224727\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=85, batch=15 train loss <loss>=8.29011869431\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] Epoch[85] Batch [15]#011Speed: 1272.06 samples/sec#011loss=8.290119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] Epoch[85] Batch[20] avg_epoch_loss=8.184899\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=85, batch=20 train loss <loss>=8.0574505806\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:20 INFO 139649395074880] Epoch[85] Batch [20]#011Speed: 752.37 samples/sec#011loss=8.057451\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] Epoch[85] Batch[25] avg_epoch_loss=8.092226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=85, batch=25 train loss <loss>=7.70300149918\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] Epoch[85] Batch [25]#011Speed: 1543.17 samples/sec#011loss=7.703001\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] Epoch[85] Batch[30] avg_epoch_loss=8.059786\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=85, batch=30 train loss <loss>=7.89109249115\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] Epoch[85] Batch [30]#011Speed: 727.21 samples/sec#011loss=7.891092\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] Epoch[85] Batch[35] avg_epoch_loss=8.031171\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=85, batch=35 train loss <loss>=7.85376157761\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] Epoch[85] Batch [35]#011Speed: 1263.32 samples/sec#011loss=7.853762\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] Epoch[85] Batch[40] avg_epoch_loss=7.989291\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=85, batch=40 train loss <loss>=7.68775577545\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] Epoch[85] Batch [40]#011Speed: 722.84 samples/sec#011loss=7.687756\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] Epoch[85] Batch[45] avg_epoch_loss=7.985001\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=85, batch=45 train loss <loss>=7.9498213768\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] Epoch[85] Batch [45]#011Speed: 1513.66 samples/sec#011loss=7.949821\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] processed a total of 1555 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1685.3160858154297, \"sum\": 1685.3160858154297, \"min\": 1685.3160858154297}}, \"EndTime\": 1577414541.836741, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414540.15091}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=922.626374909 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=85, train loss <loss>=7.9437283983\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] Epoch[86] Batch[0] avg_epoch_loss=8.601048\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=8.60104751587\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] Epoch[86] Batch[5] avg_epoch_loss=8.336933\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=8.3369325002\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] Epoch[86] Batch [5]#011Speed: 1582.26 samples/sec#011loss=8.336933\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] Epoch[86] Batch[10] avg_epoch_loss=8.252560\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=8.15131196976\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] Epoch[86] Batch [10]#011Speed: 724.00 samples/sec#011loss=8.151312\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] Epoch[86] Batch[15] avg_epoch_loss=8.388452\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=86, batch=15 train loss <loss>=8.6874162674\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] Epoch[86] Batch [15]#011Speed: 1281.16 samples/sec#011loss=8.687416\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] Epoch[86] Batch[20] avg_epoch_loss=8.390212\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=86, batch=20 train loss <loss>=8.39584503174\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] Epoch[86] Batch [20]#011Speed: 759.85 samples/sec#011loss=8.395845\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] Epoch[86] Batch[25] avg_epoch_loss=8.273422\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=86, batch=25 train loss <loss>=7.78290262222\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] Epoch[86] Batch [25]#011Speed: 1571.08 samples/sec#011loss=7.782903\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] Epoch[86] Batch[30] avg_epoch_loss=8.210314\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=86, batch=30 train loss <loss>=7.88215475082\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:22 INFO 139649395074880] Epoch[86] Batch [30]#011Speed: 795.01 samples/sec#011loss=7.882155\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[86] Batch[35] avg_epoch_loss=8.139513\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=86, batch=35 train loss <loss>=7.70054645538\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[86] Batch [35]#011Speed: 1562.99 samples/sec#011loss=7.700546\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[86] Batch[40] avg_epoch_loss=8.072350\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=86, batch=40 train loss <loss>=7.5887717247\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[86] Batch [40]#011Speed: 798.21 samples/sec#011loss=7.588772\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[86] Batch[45] avg_epoch_loss=8.068381\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=86, batch=45 train loss <loss>=8.0358332634\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[86] Batch [45]#011Speed: 1557.75 samples/sec#011loss=8.035833\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[86] Batch[50] avg_epoch_loss=8.025951\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=86, batch=50 train loss <loss>=7.63559989929\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[86] Batch [50]#011Speed: 1284.22 samples/sec#011loss=7.635600\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] processed a total of 1615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1613.7988567352295, \"sum\": 1613.7988567352295, \"min\": 1613.7988567352295}}, \"EndTime\": 1577414543.451054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414541.836799}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1000.67791643 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=86, train loss <loss>=8.02595107696\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[87] Batch[0] avg_epoch_loss=7.980108\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=7.98010778427\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[87] Batch[5] avg_epoch_loss=7.925651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=7.92565067609\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[87] Batch [5]#011Speed: 1569.89 samples/sec#011loss=7.925651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[87] Batch[10] avg_epoch_loss=8.049667\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=8.19848556519\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:23 INFO 139649395074880] Epoch[87] Batch [10]#011Speed: 779.23 samples/sec#011loss=8.198486\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch[15] avg_epoch_loss=8.191589\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=87, batch=15 train loss <loss>=8.50381908417\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch [15]#011Speed: 1732.87 samples/sec#011loss=8.503819\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch[20] avg_epoch_loss=8.179151\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=87, batch=20 train loss <loss>=8.13935031891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch [20]#011Speed: 768.27 samples/sec#011loss=8.139350\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch[25] avg_epoch_loss=8.094767\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=87, batch=25 train loss <loss>=7.74035377502\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch [25]#011Speed: 1524.49 samples/sec#011loss=7.740354\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch[30] avg_epoch_loss=8.018894\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=87, batch=30 train loss <loss>=7.62435131073\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch [30]#011Speed: 728.17 samples/sec#011loss=7.624351\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch[35] avg_epoch_loss=7.997027\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=87, batch=35 train loss <loss>=7.86145181656\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch [35]#011Speed: 1521.53 samples/sec#011loss=7.861452\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch[40] avg_epoch_loss=8.001326\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=87, batch=40 train loss <loss>=8.03228111267\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch [40]#011Speed: 801.48 samples/sec#011loss=8.032281\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch[45] avg_epoch_loss=8.006822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=87, batch=45 train loss <loss>=8.05188922882\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:24 INFO 139649395074880] Epoch[87] Batch [45]#011Speed: 1563.84 samples/sec#011loss=8.051889\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] processed a total of 1561 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1581.761121749878, \"sum\": 1581.761121749878, \"min\": 1581.761121749878}}, \"EndTime\": 1577414545.033319, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414543.451127}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=986.803581384 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=87, train loss <loss>=7.94482368352\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] Epoch[88] Batch[0] avg_epoch_loss=8.154809\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=8.15480899811\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] Epoch[88] Batch[5] avg_epoch_loss=8.355171\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=8.35517088572\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] Epoch[88] Batch [5]#011Speed: 1326.78 samples/sec#011loss=8.355171\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] Epoch[88] Batch[10] avg_epoch_loss=8.252961\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=8.13030853271\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] Epoch[88] Batch [10]#011Speed: 730.31 samples/sec#011loss=8.130309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] Epoch[88] Batch[15] avg_epoch_loss=8.363074\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=88, batch=15 train loss <loss>=8.60532436371\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] Epoch[88] Batch [15]#011Speed: 1316.45 samples/sec#011loss=8.605324\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] Epoch[88] Batch[20] avg_epoch_loss=8.328010\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=88, batch=20 train loss <loss>=8.21580514908\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] Epoch[88] Batch [20]#011Speed: 723.09 samples/sec#011loss=8.215805\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] Epoch[88] Batch[25] avg_epoch_loss=8.210513\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=88, batch=25 train loss <loss>=7.71702623367\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:25 INFO 139649395074880] Epoch[88] Batch [25]#011Speed: 1343.66 samples/sec#011loss=7.717026\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] Epoch[88] Batch[30] avg_epoch_loss=8.123268\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=88, batch=30 train loss <loss>=7.66959314346\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] Epoch[88] Batch [30]#011Speed: 803.45 samples/sec#011loss=7.669593\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] Epoch[88] Batch[35] avg_epoch_loss=8.072691\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=88, batch=35 train loss <loss>=7.75911617279\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] Epoch[88] Batch [35]#011Speed: 1360.53 samples/sec#011loss=7.759116\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] Epoch[88] Batch[40] avg_epoch_loss=8.056762\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=88, batch=40 train loss <loss>=7.94206695557\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] Epoch[88] Batch [40]#011Speed: 737.37 samples/sec#011loss=7.942067\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] Epoch[88] Batch[45] avg_epoch_loss=8.051449\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=88, batch=45 train loss <loss>=8.00788631439\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] Epoch[88] Batch [45]#011Speed: 1338.54 samples/sec#011loss=8.007886\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] processed a total of 1581 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1696.8278884887695, \"sum\": 1696.8278884887695, \"min\": 1696.8278884887695}}, \"EndTime\": 1577414546.730727, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414545.033394}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=931.67639421 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=88, train loss <loss>=7.98626371384\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] Epoch[89] Batch[0] avg_epoch_loss=7.724873\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=7.72487258911\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] Epoch[89] Batch[5] avg_epoch_loss=8.132441\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=8.13244136175\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:26 INFO 139649395074880] Epoch[89] Batch [5]#011Speed: 1494.85 samples/sec#011loss=8.132441\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] Epoch[89] Batch[10] avg_epoch_loss=8.252174\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=8.39585313797\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] Epoch[89] Batch [10]#011Speed: 805.31 samples/sec#011loss=8.395853\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] Epoch[89] Batch[15] avg_epoch_loss=8.268527\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=89, batch=15 train loss <loss>=8.30450487137\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] Epoch[89] Batch [15]#011Speed: 1564.59 samples/sec#011loss=8.304505\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] Epoch[89] Batch[20] avg_epoch_loss=8.279224\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=89, batch=20 train loss <loss>=8.31345252991\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] Epoch[89] Batch [20]#011Speed: 816.94 samples/sec#011loss=8.313453\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] Epoch[89] Batch[25] avg_epoch_loss=8.175091\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=89, batch=25 train loss <loss>=7.73773288727\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] Epoch[89] Batch [25]#011Speed: 1566.53 samples/sec#011loss=7.737733\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] Epoch[89] Batch[30] avg_epoch_loss=8.130234\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=89, batch=30 train loss <loss>=7.89697666168\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] Epoch[89] Batch [30]#011Speed: 805.41 samples/sec#011loss=7.896977\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] Epoch[89] Batch[35] avg_epoch_loss=8.065313\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=89, batch=35 train loss <loss>=7.66280431747\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:27 INFO 139649395074880] Epoch[89] Batch [35]#011Speed: 1540.58 samples/sec#011loss=7.662804\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[89] Batch[40] avg_epoch_loss=8.037350\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=89, batch=40 train loss <loss>=7.83601398468\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[89] Batch [40]#011Speed: 796.14 samples/sec#011loss=7.836014\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[89] Batch[45] avg_epoch_loss=8.030918\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=89, batch=45 train loss <loss>=7.97817640305\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[89] Batch [45]#011Speed: 1345.94 samples/sec#011loss=7.978176\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[89] Batch[50] avg_epoch_loss=7.993593\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=89, batch=50 train loss <loss>=7.65020360947\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[89] Batch [50]#011Speed: 1074.59 samples/sec#011loss=7.650204\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] processed a total of 1620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1603.909969329834, \"sum\": 1603.909969329834, \"min\": 1603.909969329834}}, \"EndTime\": 1577414548.335196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414546.730802}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1009.97125164 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=89, train loss <loss>=7.9935929448\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[90] Batch[0] avg_epoch_loss=7.865635\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=7.86563491821\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[90] Batch[5] avg_epoch_loss=8.153303\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=8.15330314636\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[90] Batch [5]#011Speed: 1490.05 samples/sec#011loss=8.153303\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[90] Batch[10] avg_epoch_loss=8.199832\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=8.25566635132\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[90] Batch [10]#011Speed: 787.69 samples/sec#011loss=8.255666\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[90] Batch[15] avg_epoch_loss=8.181083\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=90, batch=15 train loss <loss>=8.13983592987\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:28 INFO 139649395074880] Epoch[90] Batch [15]#011Speed: 1536.50 samples/sec#011loss=8.139836\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] Epoch[90] Batch[20] avg_epoch_loss=8.156743\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=90, batch=20 train loss <loss>=8.07885274887\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] Epoch[90] Batch [20]#011Speed: 827.73 samples/sec#011loss=8.078853\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] Epoch[90] Batch[25] avg_epoch_loss=8.130911\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=90, batch=25 train loss <loss>=8.0224196434\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] Epoch[90] Batch [25]#011Speed: 1538.12 samples/sec#011loss=8.022420\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] Epoch[90] Batch[30] avg_epoch_loss=8.050133\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=90, batch=30 train loss <loss>=7.63008623123\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] Epoch[90] Batch [30]#011Speed: 817.80 samples/sec#011loss=7.630086\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] Epoch[90] Batch[35] avg_epoch_loss=8.000415\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=90, batch=35 train loss <loss>=7.6921661377\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] Epoch[90] Batch [35]#011Speed: 1500.39 samples/sec#011loss=7.692166\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] Epoch[90] Batch[40] avg_epoch_loss=7.998722\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=90, batch=40 train loss <loss>=7.98652992249\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] Epoch[90] Batch [40]#011Speed: 725.06 samples/sec#011loss=7.986530\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] Epoch[90] Batch[45] avg_epoch_loss=7.980604\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=90, batch=45 train loss <loss>=7.83204059601\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] Epoch[90] Batch [45]#011Speed: 1331.41 samples/sec#011loss=7.832041\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] processed a total of 1567 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1578.0961513519287, \"sum\": 1578.0961513519287, \"min\": 1578.0961513519287}}, \"EndTime\": 1577414549.913784, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414548.335257}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=992.912093437 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=90, train loss <loss>=7.94371381098\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:29 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch[0] avg_epoch_loss=8.380032\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=8.38003158569\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch[5] avg_epoch_loss=8.071362\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=8.07136170069\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch [5]#011Speed: 1471.44 samples/sec#011loss=8.071362\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch[10] avg_epoch_loss=8.110300\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=8.15702667236\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch [10]#011Speed: 757.15 samples/sec#011loss=8.157027\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch[15] avg_epoch_loss=8.216177\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=91, batch=15 train loss <loss>=8.44910488129\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch [15]#011Speed: 1474.04 samples/sec#011loss=8.449105\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch[20] avg_epoch_loss=8.169415\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=91, batch=20 train loss <loss>=8.01977586746\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch [20]#011Speed: 784.19 samples/sec#011loss=8.019776\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch[25] avg_epoch_loss=8.097055\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=91, batch=25 train loss <loss>=7.79314374924\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch [25]#011Speed: 1564.33 samples/sec#011loss=7.793144\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch[30] avg_epoch_loss=8.022037\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=91, batch=30 train loss <loss>=7.63194704056\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:30 INFO 139649395074880] Epoch[91] Batch [30]#011Speed: 817.48 samples/sec#011loss=7.631947\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] Epoch[91] Batch[35] avg_epoch_loss=7.998018\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=91, batch=35 train loss <loss>=7.8490978241\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] Epoch[91] Batch [35]#011Speed: 1473.24 samples/sec#011loss=7.849098\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] Epoch[91] Batch[40] avg_epoch_loss=8.005326\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=91, batch=40 train loss <loss>=8.05794706345\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] Epoch[91] Batch [40]#011Speed: 716.96 samples/sec#011loss=8.057947\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] Epoch[91] Batch[45] avg_epoch_loss=7.987749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=91, batch=45 train loss <loss>=7.84361248016\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] Epoch[91] Batch [45]#011Speed: 1297.55 samples/sec#011loss=7.843612\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] processed a total of 1573 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1626.3630390167236, \"sum\": 1626.3630390167236, \"min\": 1626.3630390167236}}, \"EndTime\": 1577414551.540673, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414549.913842}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=967.128615038 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=91, train loss <loss>=7.91117171288\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] Epoch[92] Batch[0] avg_epoch_loss=7.943225\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=7.94322538376\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] Epoch[92] Batch[5] avg_epoch_loss=8.054026\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=8.05402628581\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] Epoch[92] Batch [5]#011Speed: 1335.69 samples/sec#011loss=8.054026\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] Epoch[92] Batch[10] avg_epoch_loss=8.167930\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=8.30461463928\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:31 INFO 139649395074880] Epoch[92] Batch [10]#011Speed: 801.50 samples/sec#011loss=8.304615\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] Epoch[92] Batch[15] avg_epoch_loss=8.295283\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=92, batch=15 train loss <loss>=8.57545909882\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] Epoch[92] Batch [15]#011Speed: 1562.91 samples/sec#011loss=8.575459\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] Epoch[92] Batch[20] avg_epoch_loss=8.244758\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=92, batch=20 train loss <loss>=8.08307695389\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] Epoch[92] Batch [20]#011Speed: 742.07 samples/sec#011loss=8.083077\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] Epoch[92] Batch[25] avg_epoch_loss=8.149270\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=92, batch=25 train loss <loss>=7.74822101593\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] Epoch[92] Batch [25]#011Speed: 1499.14 samples/sec#011loss=7.748221\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] Epoch[92] Batch[30] avg_epoch_loss=8.091749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=92, batch=30 train loss <loss>=7.79263963699\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] Epoch[92] Batch [30]#011Speed: 792.87 samples/sec#011loss=7.792640\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] Epoch[92] Batch[35] avg_epoch_loss=8.030168\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=92, batch=35 train loss <loss>=7.64836444855\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] Epoch[92] Batch [35]#011Speed: 1567.40 samples/sec#011loss=7.648364\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] Epoch[92] Batch[40] avg_epoch_loss=8.005574\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=92, batch=40 train loss <loss>=7.82849855423\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:32 INFO 139649395074880] Epoch[92] Batch [40]#011Speed: 739.70 samples/sec#011loss=7.828499\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] Epoch[92] Batch[45] avg_epoch_loss=8.031905\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=92, batch=45 train loss <loss>=8.24781599045\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] Epoch[92] Batch [45]#011Speed: 1517.77 samples/sec#011loss=8.247816\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] processed a total of 1561 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1585.007905960083, \"sum\": 1585.007905960083, \"min\": 1585.007905960083}}, \"EndTime\": 1577414553.126241, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414551.54074}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=984.789138259 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=92, train loss <loss>=7.94457000616\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] Epoch[93] Batch[0] avg_epoch_loss=7.909575\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=7.9095749855\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] Epoch[93] Batch[5] avg_epoch_loss=8.179033\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=8.17903296153\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] Epoch[93] Batch [5]#011Speed: 1444.07 samples/sec#011loss=8.179033\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] Epoch[93] Batch[10] avg_epoch_loss=8.173931\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=8.16780900955\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] Epoch[93] Batch [10]#011Speed: 716.41 samples/sec#011loss=8.167809\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] Epoch[93] Batch[15] avg_epoch_loss=8.210977\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=93, batch=15 train loss <loss>=8.29247808456\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] Epoch[93] Batch [15]#011Speed: 1664.15 samples/sec#011loss=8.292478\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] Epoch[93] Batch[20] avg_epoch_loss=8.221450\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=93, batch=20 train loss <loss>=8.25496263504\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:33 INFO 139649395074880] Epoch[93] Batch [20]#011Speed: 762.49 samples/sec#011loss=8.254963\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[93] Batch[25] avg_epoch_loss=8.179399\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=93, batch=25 train loss <loss>=8.00278739929\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[93] Batch [25]#011Speed: 1340.92 samples/sec#011loss=8.002787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[93] Batch[30] avg_epoch_loss=8.091689\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=93, batch=30 train loss <loss>=7.63559503555\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[93] Batch [30]#011Speed: 783.53 samples/sec#011loss=7.635595\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[93] Batch[35] avg_epoch_loss=8.079130\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=93, batch=35 train loss <loss>=8.00126132965\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[93] Batch [35]#011Speed: 1262.70 samples/sec#011loss=8.001261\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[93] Batch[40] avg_epoch_loss=8.031362\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=93, batch=40 train loss <loss>=7.687433815\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[93] Batch [40]#011Speed: 790.14 samples/sec#011loss=7.687434\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[93] Batch[45] avg_epoch_loss=8.005539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=93, batch=45 train loss <loss>=7.79379272461\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[93] Batch [45]#011Speed: 1316.81 samples/sec#011loss=7.793793\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[93] Batch[50] avg_epoch_loss=7.996473\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=93, batch=50 train loss <loss>=7.91306066513\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[93] Batch [50]#011Speed: 981.03 samples/sec#011loss=7.913061\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] processed a total of 1643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1723.484992980957, \"sum\": 1723.484992980957, \"min\": 1723.484992980957}}, \"EndTime\": 1577414554.850257, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414553.126307}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=953.240228454 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=93, train loss <loss>=7.98059899073\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] Epoch[94] Batch[0] avg_epoch_loss=7.853285\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=7.85328483582\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] Epoch[94] Batch[5] avg_epoch_loss=8.105763\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=8.10576279958\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] Epoch[94] Batch [5]#011Speed: 1303.47 samples/sec#011loss=8.105763\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] Epoch[94] Batch[10] avg_epoch_loss=8.198119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=8.30894632339\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] Epoch[94] Batch [10]#011Speed: 825.69 samples/sec#011loss=8.308946\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] Epoch[94] Batch[15] avg_epoch_loss=8.316016\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=94, batch=15 train loss <loss>=8.575390625\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] Epoch[94] Batch [15]#011Speed: 1520.36 samples/sec#011loss=8.575391\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] Epoch[94] Batch[20] avg_epoch_loss=8.289965\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=94, batch=20 train loss <loss>=8.20660209656\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] Epoch[94] Batch [20]#011Speed: 759.62 samples/sec#011loss=8.206602\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] Epoch[94] Batch[25] avg_epoch_loss=8.214216\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=94, batch=25 train loss <loss>=7.89606924057\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] Epoch[94] Batch [25]#011Speed: 1330.01 samples/sec#011loss=7.896069\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] Epoch[94] Batch[30] avg_epoch_loss=8.165694\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=94, batch=30 train loss <loss>=7.91337718964\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:35 INFO 139649395074880] Epoch[94] Batch [30]#011Speed: 735.20 samples/sec#011loss=7.913377\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] Epoch[94] Batch[35] avg_epoch_loss=8.078748\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=94, batch=35 train loss <loss>=7.53968353271\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] Epoch[94] Batch [35]#011Speed: 1297.47 samples/sec#011loss=7.539684\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] Epoch[94] Batch[40] avg_epoch_loss=8.063189\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=94, batch=40 train loss <loss>=7.95116539001\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] Epoch[94] Batch [40]#011Speed: 771.03 samples/sec#011loss=7.951165\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] Epoch[94] Batch[45] avg_epoch_loss=8.007477\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=94, batch=45 train loss <loss>=7.55063409805\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] Epoch[94] Batch [45]#011Speed: 1257.48 samples/sec#011loss=7.550634\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] processed a total of 1541 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1619.9660301208496, \"sum\": 1619.9660301208496, \"min\": 1619.9660301208496}}, \"EndTime\": 1577414556.470641, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414554.850329}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=951.194038259 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=94, train loss <loss>=7.98902225494\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] Epoch[95] Batch[0] avg_epoch_loss=8.595615\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=8.59561538696\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] Epoch[95] Batch[5] avg_epoch_loss=8.310875\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=8.31087470055\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] Epoch[95] Batch [5]#011Speed: 1537.10 samples/sec#011loss=8.310875\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] Epoch[95] Batch[10] avg_epoch_loss=8.169179\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=7.99914398193\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:36 INFO 139649395074880] Epoch[95] Batch [10]#011Speed: 733.36 samples/sec#011loss=7.999144\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch[15] avg_epoch_loss=8.165901\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=95, batch=15 train loss <loss>=8.15869083405\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch [15]#011Speed: 1385.34 samples/sec#011loss=8.158691\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch[20] avg_epoch_loss=8.160707\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=95, batch=20 train loss <loss>=8.14408483505\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch [20]#011Speed: 810.92 samples/sec#011loss=8.144085\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch[25] avg_epoch_loss=8.058472\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=95, batch=25 train loss <loss>=7.62908639908\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch [25]#011Speed: 1551.86 samples/sec#011loss=7.629086\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch[30] avg_epoch_loss=8.020300\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=95, batch=30 train loss <loss>=7.82180242538\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch [30]#011Speed: 823.46 samples/sec#011loss=7.821802\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch[35] avg_epoch_loss=7.947801\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=95, batch=35 train loss <loss>=7.49831142426\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch [35]#011Speed: 1328.14 samples/sec#011loss=7.498311\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch[40] avg_epoch_loss=7.937770\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=95, batch=40 train loss <loss>=7.86554460526\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch [40]#011Speed: 717.96 samples/sec#011loss=7.865545\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch[45] avg_epoch_loss=7.939760\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=95, batch=45 train loss <loss>=7.95608072281\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:37 INFO 139649395074880] Epoch[95] Batch [45]#011Speed: 1306.27 samples/sec#011loss=7.956081\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] processed a total of 1592 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1627.263069152832, \"sum\": 1627.263069152832, \"min\": 1627.263069152832}}, \"EndTime\": 1577414558.098449, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414556.470715}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=978.26662 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=95, train loss <loss>=7.90257548332\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] Epoch[96] Batch[0] avg_epoch_loss=7.968970\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=7.96897029877\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] Epoch[96] Batch[5] avg_epoch_loss=7.993873\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=7.99387280146\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] Epoch[96] Batch [5]#011Speed: 1450.97 samples/sec#011loss=7.993873\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] Epoch[96] Batch[10] avg_epoch_loss=8.041309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=8.09823303223\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] Epoch[96] Batch [10]#011Speed: 736.40 samples/sec#011loss=8.098233\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] Epoch[96] Batch[15] avg_epoch_loss=8.269347\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=96, batch=15 train loss <loss>=8.77103157043\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] Epoch[96] Batch [15]#011Speed: 1414.90 samples/sec#011loss=8.771032\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] Epoch[96] Batch[20] avg_epoch_loss=8.315284\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=96, batch=20 train loss <loss>=8.4622800827\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:38 INFO 139649395074880] Epoch[96] Batch [20]#011Speed: 676.18 samples/sec#011loss=8.462280\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[96] Batch[25] avg_epoch_loss=8.215376\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=96, batch=25 train loss <loss>=7.7957649231\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[96] Batch [25]#011Speed: 1530.95 samples/sec#011loss=7.795765\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[96] Batch[30] avg_epoch_loss=8.145153\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=96, batch=30 train loss <loss>=7.77999382019\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[96] Batch [30]#011Speed: 810.41 samples/sec#011loss=7.779994\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[96] Batch[35] avg_epoch_loss=8.055789\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=96, batch=35 train loss <loss>=7.50172901154\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[96] Batch [35]#011Speed: 1628.61 samples/sec#011loss=7.501729\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[96] Batch[40] avg_epoch_loss=8.036692\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=96, batch=40 train loss <loss>=7.8991938591\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[96] Batch [40]#011Speed: 827.66 samples/sec#011loss=7.899194\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[96] Batch[45] avg_epoch_loss=7.988380\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=96, batch=45 train loss <loss>=7.59222316742\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[96] Batch [45]#011Speed: 1526.28 samples/sec#011loss=7.592223\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] processed a total of 1594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1619.001865386963, \"sum\": 1619.001865386963, \"min\": 1619.001865386963}}, \"EndTime\": 1577414559.717987, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414558.098517}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=984.501272572 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=96, train loss <loss>=7.95928483009\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[97] Batch[0] avg_epoch_loss=8.140713\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=8.14071273804\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[97] Batch[5] avg_epoch_loss=8.094904\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=8.09490434329\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:39 INFO 139649395074880] Epoch[97] Batch [5]#011Speed: 1433.77 samples/sec#011loss=8.094904\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] Epoch[97] Batch[10] avg_epoch_loss=8.117818\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=8.14531545639\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] Epoch[97] Batch [10]#011Speed: 721.17 samples/sec#011loss=8.145315\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] Epoch[97] Batch[15] avg_epoch_loss=8.278203\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=97, batch=15 train loss <loss>=8.63104934692\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] Epoch[97] Batch [15]#011Speed: 1322.47 samples/sec#011loss=8.631049\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] Epoch[97] Batch[20] avg_epoch_loss=8.190560\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=97, batch=20 train loss <loss>=7.91010341644\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] Epoch[97] Batch [20]#011Speed: 780.98 samples/sec#011loss=7.910103\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] Epoch[97] Batch[25] avg_epoch_loss=8.071195\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=97, batch=25 train loss <loss>=7.56986083984\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] Epoch[97] Batch [25]#011Speed: 1288.03 samples/sec#011loss=7.569861\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] Epoch[97] Batch[30] avg_epoch_loss=8.022831\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=97, batch=30 train loss <loss>=7.77133760452\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] Epoch[97] Batch [30]#011Speed: 749.32 samples/sec#011loss=7.771338\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] Epoch[97] Batch[35] avg_epoch_loss=7.954262\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=97, batch=35 train loss <loss>=7.52913799286\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:40 INFO 139649395074880] Epoch[97] Batch [35]#011Speed: 1577.77 samples/sec#011loss=7.529138\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] Epoch[97] Batch[40] avg_epoch_loss=7.934329\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=97, batch=40 train loss <loss>=7.79080562592\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] Epoch[97] Batch [40]#011Speed: 731.39 samples/sec#011loss=7.790806\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] Epoch[97] Batch[45] avg_epoch_loss=7.937737\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=97, batch=45 train loss <loss>=7.96568946838\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] Epoch[97] Batch [45]#011Speed: 1328.44 samples/sec#011loss=7.965689\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] processed a total of 1572 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1676.8910884857178, \"sum\": 1676.8910884857178, \"min\": 1676.8910884857178}}, \"EndTime\": 1577414561.395435, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414559.718049}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=937.398829191 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=97, train loss <loss>=7.88838359833\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] Epoch[98] Batch[0] avg_epoch_loss=9.192928\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=9.19292831421\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] Epoch[98] Batch[5] avg_epoch_loss=8.482747\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=8.4827466011\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] Epoch[98] Batch [5]#011Speed: 1466.68 samples/sec#011loss=8.482747\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] Epoch[98] Batch[10] avg_epoch_loss=8.338355\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=8.16508607864\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] Epoch[98] Batch [10]#011Speed: 662.10 samples/sec#011loss=8.165086\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] Epoch[98] Batch[15] avg_epoch_loss=8.335788\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=98, batch=15 train loss <loss>=8.33013820648\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:41 INFO 139649395074880] Epoch[98] Batch [15]#011Speed: 1307.75 samples/sec#011loss=8.330138\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] Epoch[98] Batch[20] avg_epoch_loss=8.232895\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=98, batch=20 train loss <loss>=7.90363941193\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] Epoch[98] Batch [20]#011Speed: 752.71 samples/sec#011loss=7.903639\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] Epoch[98] Batch[25] avg_epoch_loss=8.187374\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=98, batch=25 train loss <loss>=7.99618349075\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] Epoch[98] Batch [25]#011Speed: 1303.84 samples/sec#011loss=7.996183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] Epoch[98] Batch[30] avg_epoch_loss=8.134448\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=98, batch=30 train loss <loss>=7.85923213959\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] Epoch[98] Batch [30]#011Speed: 712.35 samples/sec#011loss=7.859232\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] Epoch[98] Batch[35] avg_epoch_loss=8.074226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=98, batch=35 train loss <loss>=7.70084886551\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] Epoch[98] Batch [35]#011Speed: 1562.18 samples/sec#011loss=7.700849\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] Epoch[98] Batch[40] avg_epoch_loss=8.024067\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=98, batch=40 train loss <loss>=7.66292152405\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] Epoch[98] Batch [40]#011Speed: 804.70 samples/sec#011loss=7.662922\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] Epoch[98] Batch[45] avg_epoch_loss=7.992500\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=98, batch=45 train loss <loss>=7.73365697861\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:42 INFO 139649395074880] Epoch[98] Batch [45]#011Speed: 1374.03 samples/sec#011loss=7.733657\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] processed a total of 1599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1701.714038848877, \"sum\": 1701.714038848877, \"min\": 1701.714038848877}}, \"EndTime\": 1577414563.097732, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414561.395494}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=939.57685803 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=98, train loss <loss>=7.98509986877\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] Epoch[99] Batch[0] avg_epoch_loss=8.295624\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=8.2956237793\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] Epoch[99] Batch[5] avg_epoch_loss=8.017342\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=8.01734201113\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] Epoch[99] Batch [5]#011Speed: 1360.81 samples/sec#011loss=8.017342\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] Epoch[99] Batch[10] avg_epoch_loss=8.019234\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=8.02150382996\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] Epoch[99] Batch [10]#011Speed: 780.86 samples/sec#011loss=8.021504\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] Epoch[99] Batch[15] avg_epoch_loss=8.027648\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=99, batch=15 train loss <loss>=8.04615850449\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] Epoch[99] Batch [15]#011Speed: 1303.78 samples/sec#011loss=8.046159\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] Epoch[99] Batch[20] avg_epoch_loss=8.001846\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=99, batch=20 train loss <loss>=7.91928129196\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] Epoch[99] Batch [20]#011Speed: 743.14 samples/sec#011loss=7.919281\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] Epoch[99] Batch[25] avg_epoch_loss=7.981738\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=99, batch=25 train loss <loss>=7.89728345871\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:43 INFO 139649395074880] Epoch[99] Batch [25]#011Speed: 1509.55 samples/sec#011loss=7.897283\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] Epoch[99] Batch[30] avg_epoch_loss=7.958939\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=99, batch=30 train loss <loss>=7.84038133621\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] Epoch[99] Batch [30]#011Speed: 768.62 samples/sec#011loss=7.840381\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] Epoch[99] Batch[35] avg_epoch_loss=7.917271\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=99, batch=35 train loss <loss>=7.65893096924\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] Epoch[99] Batch [35]#011Speed: 1550.69 samples/sec#011loss=7.658931\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] Epoch[99] Batch[40] avg_epoch_loss=7.921880\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=99, batch=40 train loss <loss>=7.95506258011\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] Epoch[99] Batch [40]#011Speed: 784.06 samples/sec#011loss=7.955063\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] Epoch[99] Batch[45] avg_epoch_loss=7.932727\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=99, batch=45 train loss <loss>=8.02167243958\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] Epoch[99] Batch [45]#011Speed: 1304.57 samples/sec#011loss=8.021672\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] Epoch[99] Batch[50] avg_epoch_loss=7.906647\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=99, batch=50 train loss <loss>=7.66671352386\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] Epoch[99] Batch [50]#011Speed: 1153.08 samples/sec#011loss=7.666714\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] processed a total of 1629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1671.7510223388672, \"sum\": 1671.7510223388672, \"min\": 1671.7510223388672}}, \"EndTime\": 1577414564.770052, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414563.09781}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=974.363894015 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=99, train loss <loss>=7.90664689681\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] Epoch[100] Batch[0] avg_epoch_loss=8.036875\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=8.03687477112\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch[5] avg_epoch_loss=8.282664\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=8.28266429901\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch [5]#011Speed: 1508.65 samples/sec#011loss=8.282664\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch[10] avg_epoch_loss=8.286816\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=8.29179773331\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch [10]#011Speed: 770.41 samples/sec#011loss=8.291798\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch[15] avg_epoch_loss=8.371803\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=100, batch=15 train loss <loss>=8.55877571106\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch [15]#011Speed: 1576.45 samples/sec#011loss=8.558776\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch[20] avg_epoch_loss=8.375390\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=100, batch=20 train loss <loss>=8.38686714172\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch [20]#011Speed: 771.93 samples/sec#011loss=8.386867\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch[25] avg_epoch_loss=8.238896\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=100, batch=25 train loss <loss>=7.66562404633\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch [25]#011Speed: 1500.95 samples/sec#011loss=7.665624\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch[30] avg_epoch_loss=8.155326\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=100, batch=30 train loss <loss>=7.7207608223\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch [30]#011Speed: 799.18 samples/sec#011loss=7.720761\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch[35] avg_epoch_loss=8.086633\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=100, batch=35 train loss <loss>=7.66073417664\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:45 INFO 139649395074880] Epoch[100] Batch [35]#011Speed: 1565.53 samples/sec#011loss=7.660734\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[100] Batch[40] avg_epoch_loss=8.033204\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=100, batch=40 train loss <loss>=7.64851713181\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[100] Batch [40]#011Speed: 723.36 samples/sec#011loss=7.648517\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[100] Batch[45] avg_epoch_loss=8.032924\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=100, batch=45 train loss <loss>=8.0306224823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[100] Batch [45]#011Speed: 1341.08 samples/sec#011loss=8.030622\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[100] Batch[50] avg_epoch_loss=7.997992\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=100, batch=50 train loss <loss>=7.67662582397\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[100] Batch [50]#011Speed: 1218.28 samples/sec#011loss=7.676626\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] processed a total of 1609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1634.922981262207, \"sum\": 1634.922981262207, \"min\": 1634.922981262207}}, \"EndTime\": 1577414566.405506, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414564.770124}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=984.073757173 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=100, train loss <loss>=7.99799237532\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[101] Batch[0] avg_epoch_loss=7.525759\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=7.52575922012\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[101] Batch[5] avg_epoch_loss=8.109276\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=8.10927613576\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[101] Batch [5]#011Speed: 1334.59 samples/sec#011loss=8.109276\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[101] Batch[10] avg_epoch_loss=8.301426\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=8.5320069313\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[101] Batch [10]#011Speed: 753.98 samples/sec#011loss=8.532007\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[101] Batch[15] avg_epoch_loss=8.297688\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=101, batch=15 train loss <loss>=8.28946371078\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:46 INFO 139649395074880] Epoch[101] Batch [15]#011Speed: 1352.11 samples/sec#011loss=8.289464\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] Epoch[101] Batch[20] avg_epoch_loss=8.241605\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=101, batch=20 train loss <loss>=8.06213989258\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] Epoch[101] Batch [20]#011Speed: 727.74 samples/sec#011loss=8.062140\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] Epoch[101] Batch[25] avg_epoch_loss=8.182847\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=101, batch=25 train loss <loss>=7.93606204987\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] Epoch[101] Batch [25]#011Speed: 1312.43 samples/sec#011loss=7.936062\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] Epoch[101] Batch[30] avg_epoch_loss=8.101110\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=101, batch=30 train loss <loss>=7.6760761261\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] Epoch[101] Batch [30]#011Speed: 780.78 samples/sec#011loss=7.676076\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] Epoch[101] Batch[35] avg_epoch_loss=8.070958\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=101, batch=35 train loss <loss>=7.88402042389\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] Epoch[101] Batch [35]#011Speed: 1549.85 samples/sec#011loss=7.884020\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] Epoch[101] Batch[40] avg_epoch_loss=8.030745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=101, batch=40 train loss <loss>=7.74120855331\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] Epoch[101] Batch [40]#011Speed: 814.66 samples/sec#011loss=7.741209\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] Epoch[101] Batch[45] avg_epoch_loss=7.983061\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=101, batch=45 train loss <loss>=7.59205341339\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:47 INFO 139649395074880] Epoch[101] Batch [45]#011Speed: 1326.17 samples/sec#011loss=7.592053\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] Epoch[101] Batch[50] avg_epoch_loss=7.991914\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=101, batch=50 train loss <loss>=8.07336463928\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] Epoch[101] Batch [50]#011Speed: 1077.88 samples/sec#011loss=8.073365\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] processed a total of 1612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1691.5810108184814, \"sum\": 1691.5810108184814, \"min\": 1691.5810108184814}}, \"EndTime\": 1577414568.097649, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414566.405583}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=952.897307451 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=101, train loss <loss>=7.9919144219\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] Epoch[102] Batch[0] avg_epoch_loss=7.866461\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=7.86646080017\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] Epoch[102] Batch[5] avg_epoch_loss=8.361817\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=8.3618165652\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] Epoch[102] Batch [5]#011Speed: 1313.31 samples/sec#011loss=8.361817\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] Epoch[102] Batch[10] avg_epoch_loss=8.237718\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=8.08879995346\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] Epoch[102] Batch [10]#011Speed: 757.43 samples/sec#011loss=8.088800\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] Epoch[102] Batch[15] avg_epoch_loss=8.273526\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=102, batch=15 train loss <loss>=8.35230293274\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] Epoch[102] Batch [15]#011Speed: 1230.95 samples/sec#011loss=8.352303\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] Epoch[102] Batch[20] avg_epoch_loss=8.273815\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=102, batch=20 train loss <loss>=8.27474117279\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:48 INFO 139649395074880] Epoch[102] Batch [20]#011Speed: 749.36 samples/sec#011loss=8.274741\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[102] Batch[25] avg_epoch_loss=8.120737\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=102, batch=25 train loss <loss>=7.47780675888\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[102] Batch [25]#011Speed: 1580.23 samples/sec#011loss=7.477807\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[102] Batch[30] avg_epoch_loss=8.055751\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=102, batch=30 train loss <loss>=7.717827034\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[102] Batch [30]#011Speed: 786.74 samples/sec#011loss=7.717827\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[102] Batch[35] avg_epoch_loss=8.005159\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=102, batch=35 train loss <loss>=7.69148988724\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[102] Batch [35]#011Speed: 1553.17 samples/sec#011loss=7.691490\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[102] Batch[40] avg_epoch_loss=7.971920\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=102, batch=40 train loss <loss>=7.73259506226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[102] Batch [40]#011Speed: 795.21 samples/sec#011loss=7.732595\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[102] Batch[45] avg_epoch_loss=7.974254\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=102, batch=45 train loss <loss>=7.99339561462\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[102] Batch [45]#011Speed: 1544.64 samples/sec#011loss=7.993396\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[102] Batch[50] avg_epoch_loss=7.941913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=102, batch=50 train loss <loss>=7.64437227249\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[102] Batch [50]#011Speed: 1428.52 samples/sec#011loss=7.644372\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] processed a total of 1632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1629.5511722564697, \"sum\": 1629.5511722564697, \"min\": 1629.5511722564697}}, \"EndTime\": 1577414569.727719, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414568.097719}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1001.43580272 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=102, train loss <loss>=7.94191280066\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[103] Batch[0] avg_epoch_loss=8.645359\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=8.64535903931\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[103] Batch[5] avg_epoch_loss=8.341238\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=8.34123826027\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:49 INFO 139649395074880] Epoch[103] Batch [5]#011Speed: 1723.95 samples/sec#011loss=8.341238\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] Epoch[103] Batch[10] avg_epoch_loss=8.268350\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=8.18088436127\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] Epoch[103] Batch [10]#011Speed: 699.47 samples/sec#011loss=8.180884\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] Epoch[103] Batch[15] avg_epoch_loss=8.287141\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=103, batch=15 train loss <loss>=8.32847957611\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] Epoch[103] Batch [15]#011Speed: 1549.77 samples/sec#011loss=8.328480\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] Epoch[103] Batch[20] avg_epoch_loss=8.288213\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=103, batch=20 train loss <loss>=8.29164552689\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] Epoch[103] Batch [20]#011Speed: 797.07 samples/sec#011loss=8.291646\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] Epoch[103] Batch[25] avg_epoch_loss=8.187459\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=103, batch=25 train loss <loss>=7.76429290771\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] Epoch[103] Batch [25]#011Speed: 1414.03 samples/sec#011loss=7.764293\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] Epoch[103] Batch[30] avg_epoch_loss=8.135941\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=103, batch=30 train loss <loss>=7.8680475235\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] Epoch[103] Batch [30]#011Speed: 786.56 samples/sec#011loss=7.868048\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] Epoch[103] Batch[35] avg_epoch_loss=8.078660\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=103, batch=35 train loss <loss>=7.72351551056\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:50 INFO 139649395074880] Epoch[103] Batch [35]#011Speed: 1557.77 samples/sec#011loss=7.723516\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[103] Batch[40] avg_epoch_loss=8.066004\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=103, batch=40 train loss <loss>=7.97487783432\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[103] Batch [40]#011Speed: 782.12 samples/sec#011loss=7.974878\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[103] Batch[45] avg_epoch_loss=8.026285\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=103, batch=45 train loss <loss>=7.70059738159\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[103] Batch [45]#011Speed: 1590.02 samples/sec#011loss=7.700597\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[103] Batch[50] avg_epoch_loss=7.978285\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=103, batch=50 train loss <loss>=7.53667879105\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[103] Batch [50]#011Speed: 1493.30 samples/sec#011loss=7.536679\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] processed a total of 1601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1579.2760848999023, \"sum\": 1579.2760848999023, \"min\": 1579.2760848999023}}, \"EndTime\": 1577414571.307556, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414569.727795}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1013.68445552 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=103, train loss <loss>=7.97828483582\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[104] Batch[0] avg_epoch_loss=7.801344\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=7.80134391785\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[104] Batch[5] avg_epoch_loss=7.958116\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=7.95811573664\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[104] Batch [5]#011Speed: 1554.17 samples/sec#011loss=7.958116\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[104] Batch[10] avg_epoch_loss=8.006552\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=8.06467609406\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[104] Batch [10]#011Speed: 768.07 samples/sec#011loss=8.064676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[104] Batch[15] avg_epoch_loss=8.119749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=104, batch=15 train loss <loss>=8.36878223419\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:51 INFO 139649395074880] Epoch[104] Batch [15]#011Speed: 1377.82 samples/sec#011loss=8.368782\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] Epoch[104] Batch[20] avg_epoch_loss=8.145215\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=104, batch=20 train loss <loss>=8.22670488358\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] Epoch[104] Batch [20]#011Speed: 713.18 samples/sec#011loss=8.226705\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] Epoch[104] Batch[25] avg_epoch_loss=8.034818\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=104, batch=25 train loss <loss>=7.57115325928\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] Epoch[104] Batch [25]#011Speed: 1563.58 samples/sec#011loss=7.571153\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] Epoch[104] Batch[30] avg_epoch_loss=8.019652\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=104, batch=30 train loss <loss>=7.94078512192\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] Epoch[104] Batch [30]#011Speed: 766.60 samples/sec#011loss=7.940785\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] Epoch[104] Batch[35] avg_epoch_loss=7.974379\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=104, batch=35 train loss <loss>=7.69368658066\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] Epoch[104] Batch [35]#011Speed: 1556.44 samples/sec#011loss=7.693687\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] Epoch[104] Batch[40] avg_epoch_loss=7.953508\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=104, batch=40 train loss <loss>=7.80323667526\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] Epoch[104] Batch [40]#011Speed: 809.65 samples/sec#011loss=7.803237\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] Epoch[104] Batch[45] avg_epoch_loss=7.934964\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=104, batch=45 train loss <loss>=7.78290319443\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] Epoch[104] Batch [45]#011Speed: 1602.19 samples/sec#011loss=7.782903\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] processed a total of 1592 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1617.5389289855957, \"sum\": 1617.5389289855957, \"min\": 1617.5389289855957}}, \"EndTime\": 1577414572.925592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414571.307632}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=984.137698736 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=104, train loss <loss>=7.89542924881\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:52 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch[0] avg_epoch_loss=7.276930\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=7.27693033218\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch[5] avg_epoch_loss=7.895277\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=7.89527726173\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch [5]#011Speed: 1485.99 samples/sec#011loss=7.895277\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch[10] avg_epoch_loss=7.957713\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=8.03263587952\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch [10]#011Speed: 749.20 samples/sec#011loss=8.032636\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch[15] avg_epoch_loss=8.001771\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=105, batch=15 train loss <loss>=8.09869813919\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch [15]#011Speed: 1655.54 samples/sec#011loss=8.098698\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch[20] avg_epoch_loss=7.904016\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=105, batch=20 train loss <loss>=7.59119977951\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch [20]#011Speed: 752.13 samples/sec#011loss=7.591200\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch[25] avg_epoch_loss=7.884200\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=105, batch=25 train loss <loss>=7.80097484589\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch [25]#011Speed: 1427.59 samples/sec#011loss=7.800975\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch[30] avg_epoch_loss=7.907779\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=105, batch=30 train loss <loss>=8.03039131165\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:53 INFO 139649395074880] Epoch[105] Batch [30]#011Speed: 799.67 samples/sec#011loss=8.030391\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] Epoch[105] Batch[35] avg_epoch_loss=7.901571\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=105, batch=35 train loss <loss>=7.86307973862\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] Epoch[105] Batch [35]#011Speed: 1545.76 samples/sec#011loss=7.863080\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] Epoch[105] Batch[40] avg_epoch_loss=7.843346\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=105, batch=40 train loss <loss>=7.42412776947\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] Epoch[105] Batch [40]#011Speed: 791.30 samples/sec#011loss=7.424128\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] Epoch[105] Batch[45] avg_epoch_loss=7.806546\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=105, batch=45 train loss <loss>=7.50478410721\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] Epoch[105] Batch [45]#011Speed: 1211.62 samples/sec#011loss=7.504784\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] processed a total of 1547 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1562.0219707489014, \"sum\": 1562.0219707489014, \"min\": 1562.0219707489014}}, \"EndTime\": 1577414574.488191, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414572.925673}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=990.315731894 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=105, train loss <loss>=7.84355345551\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_352d67d8-0b3b-4ca8-99f3-348a151811ee-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 21.47817611694336, \"sum\": 21.47817611694336, \"min\": 21.47817611694336}}, \"EndTime\": 1577414574.510296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414574.488265}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] Epoch[106] Batch[0] avg_epoch_loss=8.336811\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=8.33681106567\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] Epoch[106] Batch[5] avg_epoch_loss=8.247081\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=8.24708072344\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] Epoch[106] Batch [5]#011Speed: 1493.04 samples/sec#011loss=8.247081\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] Epoch[106] Batch[10] avg_epoch_loss=8.281174\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=8.3220864296\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:54 INFO 139649395074880] Epoch[106] Batch [10]#011Speed: 804.51 samples/sec#011loss=8.322086\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] Epoch[106] Batch[15] avg_epoch_loss=8.323699\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=106, batch=15 train loss <loss>=8.41725492477\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] Epoch[106] Batch [15]#011Speed: 1349.71 samples/sec#011loss=8.417255\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] Epoch[106] Batch[20] avg_epoch_loss=8.222643\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=106, batch=20 train loss <loss>=7.89926042557\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] Epoch[106] Batch [20]#011Speed: 741.07 samples/sec#011loss=7.899260\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] Epoch[106] Batch[25] avg_epoch_loss=8.149977\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=106, batch=25 train loss <loss>=7.84477968216\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] Epoch[106] Batch [25]#011Speed: 1310.24 samples/sec#011loss=7.844780\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] Epoch[106] Batch[30] avg_epoch_loss=8.126703\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=106, batch=30 train loss <loss>=8.00568056107\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] Epoch[106] Batch [30]#011Speed: 768.66 samples/sec#011loss=8.005681\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] Epoch[106] Batch[35] avg_epoch_loss=8.071085\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=106, batch=35 train loss <loss>=7.72625131607\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] Epoch[106] Batch [35]#011Speed: 1494.81 samples/sec#011loss=7.726251\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] Epoch[106] Batch[40] avg_epoch_loss=8.059815\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=106, batch=40 train loss <loss>=7.97867259979\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:55 INFO 139649395074880] Epoch[106] Batch [40]#011Speed: 777.20 samples/sec#011loss=7.978673\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] Epoch[106] Batch[45] avg_epoch_loss=8.040068\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=106, batch=45 train loss <loss>=7.87814083099\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] Epoch[106] Batch [45]#011Speed: 1573.73 samples/sec#011loss=7.878141\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] processed a total of 1517 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1566.0288333892822, \"sum\": 1566.0288333892822, \"min\": 1566.0288333892822}}, \"EndTime\": 1577414576.076446, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414574.510364}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=968.621027255 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=106, train loss <loss>=7.97877185543\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] Epoch[107] Batch[0] avg_epoch_loss=7.868547\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=7.86854743958\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] Epoch[107] Batch[5] avg_epoch_loss=8.307036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=8.30703560511\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] Epoch[107] Batch [5]#011Speed: 1342.11 samples/sec#011loss=8.307036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] Epoch[107] Batch[10] avg_epoch_loss=8.234456\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=8.14736156464\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] Epoch[107] Batch [10]#011Speed: 747.77 samples/sec#011loss=8.147362\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] Epoch[107] Batch[15] avg_epoch_loss=8.352603\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=107, batch=15 train loss <loss>=8.61252441406\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] Epoch[107] Batch [15]#011Speed: 1302.94 samples/sec#011loss=8.612524\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] Epoch[107] Batch[20] avg_epoch_loss=8.369042\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=107, batch=20 train loss <loss>=8.42164897919\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:56 INFO 139649395074880] Epoch[107] Batch [20]#011Speed: 661.11 samples/sec#011loss=8.421649\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[107] Batch[25] avg_epoch_loss=8.291729\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=107, batch=25 train loss <loss>=7.96701517105\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[107] Batch [25]#011Speed: 1561.40 samples/sec#011loss=7.967015\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[107] Batch[30] avg_epoch_loss=8.235725\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=107, batch=30 train loss <loss>=7.94450149536\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[107] Batch [30]#011Speed: 804.59 samples/sec#011loss=7.944501\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[107] Batch[35] avg_epoch_loss=8.179418\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=107, batch=35 train loss <loss>=7.83031387329\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[107] Batch [35]#011Speed: 1470.83 samples/sec#011loss=7.830314\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[107] Batch[40] avg_epoch_loss=8.138512\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=107, batch=40 train loss <loss>=7.84398775101\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[107] Batch [40]#011Speed: 790.03 samples/sec#011loss=7.843988\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[107] Batch[45] avg_epoch_loss=8.098469\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=107, batch=45 train loss <loss>=7.77012166977\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[107] Batch [45]#011Speed: 1561.62 samples/sec#011loss=7.770122\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[107] Batch[50] avg_epoch_loss=7.981929\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=107, batch=50 train loss <loss>=6.9097574234\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[107] Batch [50]#011Speed: 1246.03 samples/sec#011loss=6.909757\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] processed a total of 1616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1672.3098754882812, \"sum\": 1672.3098754882812, \"min\": 1672.3098754882812}}, \"EndTime\": 1577414577.749317, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414576.076526}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=966.259344018 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=107, train loss <loss>=7.98192892823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[108] Batch[0] avg_epoch_loss=8.094505\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=8.09450531006\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[108] Batch[5] avg_epoch_loss=8.377886\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=8.37788565954\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:57 INFO 139649395074880] Epoch[108] Batch [5]#011Speed: 1553.14 samples/sec#011loss=8.377886\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] Epoch[108] Batch[10] avg_epoch_loss=8.323658\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=8.25858383179\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] Epoch[108] Batch [10]#011Speed: 713.22 samples/sec#011loss=8.258584\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] Epoch[108] Batch[15] avg_epoch_loss=8.395607\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=108, batch=15 train loss <loss>=8.55389661789\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] Epoch[108] Batch [15]#011Speed: 1333.62 samples/sec#011loss=8.553897\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] Epoch[108] Batch[20] avg_epoch_loss=8.383822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=108, batch=20 train loss <loss>=8.34611082077\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] Epoch[108] Batch [20]#011Speed: 732.79 samples/sec#011loss=8.346111\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] Epoch[108] Batch[25] avg_epoch_loss=8.245026\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=108, batch=25 train loss <loss>=7.66207876205\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] Epoch[108] Batch [25]#011Speed: 1297.19 samples/sec#011loss=7.662079\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] Epoch[108] Batch[30] avg_epoch_loss=8.129647\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=108, batch=30 train loss <loss>=7.52967557907\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:58 INFO 139649395074880] Epoch[108] Batch [30]#011Speed: 602.50 samples/sec#011loss=7.529676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[108] Batch[35] avg_epoch_loss=8.069485\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=108, batch=35 train loss <loss>=7.69648036957\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[108] Batch [35]#011Speed: 1334.10 samples/sec#011loss=7.696480\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[108] Batch[40] avg_epoch_loss=8.053878\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=108, batch=40 train loss <loss>=7.94151315689\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[108] Batch [40]#011Speed: 715.61 samples/sec#011loss=7.941513\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[108] Batch[45] avg_epoch_loss=8.016547\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=108, batch=45 train loss <loss>=7.71043376923\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[108] Batch [45]#011Speed: 1696.06 samples/sec#011loss=7.710434\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[108] Batch[50] avg_epoch_loss=7.936042\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=108, batch=50 train loss <loss>=7.19538888931\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[108] Batch [50]#011Speed: 1156.16 samples/sec#011loss=7.195389\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] processed a total of 1617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1749.600887298584, \"sum\": 1749.600887298584, \"min\": 1749.600887298584}}, \"EndTime\": 1577414579.499462, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414577.749398}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=924.154738586 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=108, train loss <loss>=7.93604162628\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[109] Batch[0] avg_epoch_loss=8.189027\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=8.18902683258\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[109] Batch[5] avg_epoch_loss=8.179910\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=8.17990954717\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[109] Batch [5]#011Speed: 1500.09 samples/sec#011loss=8.179910\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[109] Batch[10] avg_epoch_loss=8.282982\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=8.40666942596\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:42:59 INFO 139649395074880] Epoch[109] Batch [10]#011Speed: 766.48 samples/sec#011loss=8.406669\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] Epoch[109] Batch[15] avg_epoch_loss=8.296334\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=109, batch=15 train loss <loss>=8.32570743561\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] Epoch[109] Batch [15]#011Speed: 1329.95 samples/sec#011loss=8.325707\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] Epoch[109] Batch[20] avg_epoch_loss=8.289787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=109, batch=20 train loss <loss>=8.2688378334\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] Epoch[109] Batch [20]#011Speed: 697.51 samples/sec#011loss=8.268838\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] Epoch[109] Batch[25] avg_epoch_loss=8.212883\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=109, batch=25 train loss <loss>=7.88988418579\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] Epoch[109] Batch [25]#011Speed: 1590.72 samples/sec#011loss=7.889884\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] Epoch[109] Batch[30] avg_epoch_loss=8.173198\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=109, batch=30 train loss <loss>=7.96683568954\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] Epoch[109] Batch [30]#011Speed: 726.15 samples/sec#011loss=7.966836\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] Epoch[109] Batch[35] avg_epoch_loss=8.095215\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=109, batch=35 train loss <loss>=7.61172304153\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] Epoch[109] Batch [35]#011Speed: 1627.29 samples/sec#011loss=7.611723\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] Epoch[109] Batch[40] avg_epoch_loss=8.035319\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=109, batch=40 train loss <loss>=7.60407066345\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:00 INFO 139649395074880] Epoch[109] Batch [40]#011Speed: 721.19 samples/sec#011loss=7.604071\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] Epoch[109] Batch[45] avg_epoch_loss=8.055535\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=109, batch=45 train loss <loss>=8.2213051796\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] Epoch[109] Batch [45]#011Speed: 1297.57 samples/sec#011loss=8.221305\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] processed a total of 1579 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1658.930778503418, \"sum\": 1658.930778503418, \"min\": 1658.930778503418}}, \"EndTime\": 1577414581.158865, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414579.499534}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=951.753605431 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=109, train loss <loss>=8.00510277748\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] Epoch[110] Batch[0] avg_epoch_loss=8.574661\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=8.57466125488\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] Epoch[110] Batch[5] avg_epoch_loss=8.242625\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=8.24262515704\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] Epoch[110] Batch [5]#011Speed: 1458.32 samples/sec#011loss=8.242625\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] Epoch[110] Batch[10] avg_epoch_loss=8.188471\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=8.12348527908\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] Epoch[110] Batch [10]#011Speed: 683.27 samples/sec#011loss=8.123485\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] Epoch[110] Batch[15] avg_epoch_loss=8.272304\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=110, batch=15 train loss <loss>=8.45673656464\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] Epoch[110] Batch [15]#011Speed: 1485.07 samples/sec#011loss=8.456737\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] Epoch[110] Batch[20] avg_epoch_loss=8.340665\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=110, batch=20 train loss <loss>=8.5594209671\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:01 INFO 139649395074880] Epoch[110] Batch [20]#011Speed: 811.23 samples/sec#011loss=8.559421\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[110] Batch[25] avg_epoch_loss=8.201397\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=110, batch=25 train loss <loss>=7.61646986008\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[110] Batch [25]#011Speed: 1353.45 samples/sec#011loss=7.616470\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[110] Batch[30] avg_epoch_loss=8.129343\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=110, batch=30 train loss <loss>=7.75466127396\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[110] Batch [30]#011Speed: 776.78 samples/sec#011loss=7.754661\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[110] Batch[35] avg_epoch_loss=8.078953\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=110, batch=35 train loss <loss>=7.76653900146\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[110] Batch [35]#011Speed: 1400.45 samples/sec#011loss=7.766539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[110] Batch[40] avg_epoch_loss=8.044416\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=110, batch=40 train loss <loss>=7.79574604034\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[110] Batch [40]#011Speed: 728.42 samples/sec#011loss=7.795746\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[110] Batch[45] avg_epoch_loss=8.047872\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=110, batch=45 train loss <loss>=8.07620868683\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[110] Batch [45]#011Speed: 1321.65 samples/sec#011loss=8.076209\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[110] Batch[50] avg_epoch_loss=7.972044\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=110, batch=50 train loss <loss>=7.27443523407\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[110] Batch [50]#011Speed: 1216.59 samples/sec#011loss=7.274435\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] processed a total of 1614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1699.429988861084, \"sum\": 1699.429988861084, \"min\": 1699.429988861084}}, \"EndTime\": 1577414582.858849, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414581.158942}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=949.668789868 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=110, train loss <loss>=7.97204442118\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] Epoch[111] Batch[0] avg_epoch_loss=7.718221\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=7.71822071075\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] Epoch[111] Batch[5] avg_epoch_loss=8.158485\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=8.15848469734\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] Epoch[111] Batch [5]#011Speed: 1575.28 samples/sec#011loss=8.158485\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] Epoch[111] Batch[10] avg_epoch_loss=8.350359\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=8.58060722351\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] Epoch[111] Batch [10]#011Speed: 760.12 samples/sec#011loss=8.580607\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] Epoch[111] Batch[15] avg_epoch_loss=8.396880\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=111, batch=15 train loss <loss>=8.49922637939\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] Epoch[111] Batch [15]#011Speed: 1595.98 samples/sec#011loss=8.499226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] Epoch[111] Batch[20] avg_epoch_loss=8.371288\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=111, batch=20 train loss <loss>=8.28939361572\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] Epoch[111] Batch [20]#011Speed: 766.91 samples/sec#011loss=8.289394\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] Epoch[111] Batch[25] avg_epoch_loss=8.283586\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=111, batch=25 train loss <loss>=7.91523742676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] Epoch[111] Batch [25]#011Speed: 1453.64 samples/sec#011loss=7.915237\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] Epoch[111] Batch[30] avg_epoch_loss=8.176579\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=111, batch=30 train loss <loss>=7.62014284134\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:03 INFO 139649395074880] Epoch[111] Batch [30]#011Speed: 719.59 samples/sec#011loss=7.620143\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] Epoch[111] Batch[35] avg_epoch_loss=8.105214\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=111, batch=35 train loss <loss>=7.66274900436\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] Epoch[111] Batch [35]#011Speed: 1638.34 samples/sec#011loss=7.662749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] Epoch[111] Batch[40] avg_epoch_loss=8.067427\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=111, batch=40 train loss <loss>=7.79536466599\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] Epoch[111] Batch [40]#011Speed: 763.86 samples/sec#011loss=7.795365\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] Epoch[111] Batch[45] avg_epoch_loss=8.050034\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=111, batch=45 train loss <loss>=7.90740556717\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] Epoch[111] Batch [45]#011Speed: 1441.49 samples/sec#011loss=7.907406\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] processed a total of 1599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1618.358850479126, \"sum\": 1618.358850479126, \"min\": 1618.358850479126}}, \"EndTime\": 1577414584.477752, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414582.858923}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=987.965782141 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=111, train loss <loss>=8.00976726532\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] Epoch[112] Batch[0] avg_epoch_loss=8.340235\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=8.34023475647\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] Epoch[112] Batch[5] avg_epoch_loss=8.239590\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=8.23959000905\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] Epoch[112] Batch [5]#011Speed: 1399.13 samples/sec#011loss=8.239590\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] Epoch[112] Batch[10] avg_epoch_loss=8.190642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=8.13190364838\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:04 INFO 139649395074880] Epoch[112] Batch [10]#011Speed: 763.43 samples/sec#011loss=8.131904\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] Epoch[112] Batch[15] avg_epoch_loss=8.315640\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=112, batch=15 train loss <loss>=8.59063720703\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] Epoch[112] Batch [15]#011Speed: 1357.16 samples/sec#011loss=8.590637\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] Epoch[112] Batch[20] avg_epoch_loss=8.251876\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=112, batch=20 train loss <loss>=8.04783058167\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] Epoch[112] Batch [20]#011Speed: 690.17 samples/sec#011loss=8.047831\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] Epoch[112] Batch[25] avg_epoch_loss=8.169448\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=112, batch=25 train loss <loss>=7.82324771881\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] Epoch[112] Batch [25]#011Speed: 1556.07 samples/sec#011loss=7.823248\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] Epoch[112] Batch[30] avg_epoch_loss=8.085124\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=112, batch=30 train loss <loss>=7.64664163589\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] Epoch[112] Batch [30]#011Speed: 735.46 samples/sec#011loss=7.646642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] Epoch[112] Batch[35] avg_epoch_loss=8.034884\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=112, batch=35 train loss <loss>=7.72339429855\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] Epoch[112] Batch [35]#011Speed: 1305.95 samples/sec#011loss=7.723394\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] Epoch[112] Batch[40] avg_epoch_loss=8.050074\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=112, batch=40 train loss <loss>=8.15944356918\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:05 INFO 139649395074880] Epoch[112] Batch [40]#011Speed: 747.47 samples/sec#011loss=8.159444\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] Epoch[112] Batch[45] avg_epoch_loss=8.036815\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=112, batch=45 train loss <loss>=7.92809228897\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] Epoch[112] Batch [45]#011Speed: 1314.84 samples/sec#011loss=7.928092\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] processed a total of 1550 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1670.8259582519531, \"sum\": 1670.8259582519531, \"min\": 1670.8259582519531}}, \"EndTime\": 1577414586.149156, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414584.477833}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=927.635519186 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=112, train loss <loss>=8.03768140443\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] Epoch[113] Batch[0] avg_epoch_loss=8.490950\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=8.49094963074\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] Epoch[113] Batch[5] avg_epoch_loss=8.082323\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=8.08232323329\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] Epoch[113] Batch [5]#011Speed: 1451.89 samples/sec#011loss=8.082323\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] Epoch[113] Batch[10] avg_epoch_loss=8.010669\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=7.9246846199\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] Epoch[113] Batch [10]#011Speed: 769.20 samples/sec#011loss=7.924685\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] Epoch[113] Batch[15] avg_epoch_loss=8.167642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=113, batch=15 train loss <loss>=8.51298065186\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] Epoch[113] Batch [15]#011Speed: 1415.62 samples/sec#011loss=8.512981\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] Epoch[113] Batch[20] avg_epoch_loss=8.122258\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=113, batch=20 train loss <loss>=7.9770321846\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:06 INFO 139649395074880] Epoch[113] Batch [20]#011Speed: 789.91 samples/sec#011loss=7.977032\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[113] Batch[25] avg_epoch_loss=8.059350\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=113, batch=25 train loss <loss>=7.79513292313\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[113] Batch [25]#011Speed: 1565.54 samples/sec#011loss=7.795133\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[113] Batch[30] avg_epoch_loss=8.032703\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=113, batch=30 train loss <loss>=7.89413776398\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[113] Batch [30]#011Speed: 806.49 samples/sec#011loss=7.894138\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[113] Batch[35] avg_epoch_loss=8.010055\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=113, batch=35 train loss <loss>=7.86964273453\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[113] Batch [35]#011Speed: 1360.93 samples/sec#011loss=7.869643\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[113] Batch[40] avg_epoch_loss=7.981907\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=113, batch=40 train loss <loss>=7.77923765182\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[113] Batch [40]#011Speed: 744.14 samples/sec#011loss=7.779238\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[113] Batch[45] avg_epoch_loss=7.940972\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=113, batch=45 train loss <loss>=7.60530872345\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[113] Batch [45]#011Speed: 1657.29 samples/sec#011loss=7.605309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[113] Batch[50] avg_epoch_loss=7.876510\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=113, batch=50 train loss <loss>=7.2834526062\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[113] Batch [50]#011Speed: 1132.28 samples/sec#011loss=7.283453\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] processed a total of 1610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1635.556936264038, \"sum\": 1635.556936264038, \"min\": 1635.556936264038}}, \"EndTime\": 1577414587.785245, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414586.149215}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=984.306731309 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=113, train loss <loss>=7.8765095823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] Epoch[114] Batch[0] avg_epoch_loss=8.130287\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=8.13028717041\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch[5] avg_epoch_loss=8.064539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=8.0645386378\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch [5]#011Speed: 1463.92 samples/sec#011loss=8.064539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch[10] avg_epoch_loss=8.091808\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=8.1245308876\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch [10]#011Speed: 745.34 samples/sec#011loss=8.124531\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch[15] avg_epoch_loss=8.254046\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=114, batch=15 train loss <loss>=8.61096839905\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch [15]#011Speed: 1537.39 samples/sec#011loss=8.610968\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch[20] avg_epoch_loss=8.132037\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=114, batch=20 train loss <loss>=7.74160814285\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch [20]#011Speed: 775.59 samples/sec#011loss=7.741608\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch[25] avg_epoch_loss=8.079571\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=114, batch=25 train loss <loss>=7.85921354294\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch [25]#011Speed: 1425.94 samples/sec#011loss=7.859214\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch[30] avg_epoch_loss=7.998187\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=114, batch=30 train loss <loss>=7.57499132156\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch [30]#011Speed: 720.85 samples/sec#011loss=7.574991\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch[35] avg_epoch_loss=7.943967\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=114, batch=35 train loss <loss>=7.60780096054\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:08 INFO 139649395074880] Epoch[114] Batch [35]#011Speed: 1295.06 samples/sec#011loss=7.607801\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] Epoch[114] Batch[40] avg_epoch_loss=7.947084\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=114, batch=40 train loss <loss>=7.96952857971\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] Epoch[114] Batch [40]#011Speed: 689.68 samples/sec#011loss=7.969529\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] Epoch[114] Batch[45] avg_epoch_loss=7.959569\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=114, batch=45 train loss <loss>=8.06194286346\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] Epoch[114] Batch [45]#011Speed: 1549.59 samples/sec#011loss=8.061943\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] processed a total of 1557 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1639.9710178375244, \"sum\": 1639.9710178375244, \"min\": 1639.9710178375244}}, \"EndTime\": 1577414589.42576, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414587.785322}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=949.346846978 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=114, train loss <loss>=7.8678252843\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] Epoch[115] Batch[0] avg_epoch_loss=8.526112\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=8.52611160278\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] Epoch[115] Batch[5] avg_epoch_loss=8.138418\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=8.13841756185\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] Epoch[115] Batch [5]#011Speed: 1440.20 samples/sec#011loss=8.138418\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] Epoch[115] Batch[10] avg_epoch_loss=8.104748\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=8.06434373856\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] Epoch[115] Batch [10]#011Speed: 1532.99 samples/sec#011loss=8.064344\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] Epoch[115] Batch[15] avg_epoch_loss=8.139573\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=115, batch=15 train loss <loss>=8.21618728638\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:09 INFO 139649395074880] Epoch[115] Batch [15]#011Speed: 809.30 samples/sec#011loss=8.216187\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] Epoch[115] Batch[20] avg_epoch_loss=8.263791\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=115, batch=20 train loss <loss>=8.66129131317\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] Epoch[115] Batch [20]#011Speed: 1360.78 samples/sec#011loss=8.661291\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] Epoch[115] Batch[25] avg_epoch_loss=8.181499\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=115, batch=25 train loss <loss>=7.83587083817\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] Epoch[115] Batch [25]#011Speed: 721.05 samples/sec#011loss=7.835871\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] Epoch[115] Batch[30] avg_epoch_loss=8.120929\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=115, batch=30 train loss <loss>=7.80596265793\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] Epoch[115] Batch [30]#011Speed: 732.25 samples/sec#011loss=7.805963\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] Epoch[115] Batch[35] avg_epoch_loss=8.064239\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=115, batch=35 train loss <loss>=7.71276187897\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] Epoch[115] Batch [35]#011Speed: 1544.09 samples/sec#011loss=7.712762\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] Epoch[115] Batch[40] avg_epoch_loss=7.985485\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=115, batch=40 train loss <loss>=7.41845998764\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] Epoch[115] Batch [40]#011Speed: 728.25 samples/sec#011loss=7.418460\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] Epoch[115] Batch[45] avg_epoch_loss=7.964669\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=115, batch=45 train loss <loss>=7.79397163391\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:10 INFO 139649395074880] Epoch[115] Batch [45]#011Speed: 1376.58 samples/sec#011loss=7.793972\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[115] Batch[50] avg_epoch_loss=7.970619\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=115, batch=50 train loss <loss>=8.0253613472\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[115] Batch [50]#011Speed: 1223.63 samples/sec#011loss=8.025361\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] processed a total of 1673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1720.6060886383057, \"sum\": 1720.6060886383057, \"min\": 1720.6060886383057}}, \"EndTime\": 1577414591.146919, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414589.425827}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=972.265641861 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=115, train loss <loss>=7.98046746344\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[116] Batch[0] avg_epoch_loss=7.969891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=7.96989059448\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[116] Batch[5] avg_epoch_loss=7.987887\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=7.98788738251\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[116] Batch [5]#011Speed: 1498.42 samples/sec#011loss=7.987887\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[116] Batch[10] avg_epoch_loss=8.180403\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=8.41142234802\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[116] Batch [10]#011Speed: 757.76 samples/sec#011loss=8.411422\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[116] Batch[15] avg_epoch_loss=8.256365\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=116, batch=15 train loss <loss>=8.42348165512\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[116] Batch [15]#011Speed: 1690.13 samples/sec#011loss=8.423482\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[116] Batch[20] avg_epoch_loss=8.224297\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=116, batch=20 train loss <loss>=8.12167682648\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[116] Batch [20]#011Speed: 795.08 samples/sec#011loss=8.121677\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[116] Batch[25] avg_epoch_loss=8.148093\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=116, batch=25 train loss <loss>=7.82803583145\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:11 INFO 139649395074880] Epoch[116] Batch [25]#011Speed: 1583.00 samples/sec#011loss=7.828036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] Epoch[116] Batch[30] avg_epoch_loss=8.110639\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=116, batch=30 train loss <loss>=7.91588039398\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] Epoch[116] Batch [30]#011Speed: 796.67 samples/sec#011loss=7.915880\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] Epoch[116] Batch[35] avg_epoch_loss=8.030307\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=116, batch=35 train loss <loss>=7.53224496841\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] Epoch[116] Batch [35]#011Speed: 1398.71 samples/sec#011loss=7.532245\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] Epoch[116] Batch[40] avg_epoch_loss=7.989566\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=116, batch=40 train loss <loss>=7.69623231888\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] Epoch[116] Batch [40]#011Speed: 744.78 samples/sec#011loss=7.696232\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] Epoch[116] Batch[45] avg_epoch_loss=7.977770\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=116, batch=45 train loss <loss>=7.88104448318\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] Epoch[116] Batch [45]#011Speed: 1548.78 samples/sec#011loss=7.881044\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] processed a total of 1563 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1556.3969612121582, \"sum\": 1556.3969612121582, \"min\": 1556.3969612121582}}, \"EndTime\": 1577414592.703905, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414591.146999}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1004.17467871 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=116, train loss <loss>=7.92097390428\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] Epoch[117] Batch[0] avg_epoch_loss=7.996061\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=7.99606132507\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] Epoch[117] Batch[5] avg_epoch_loss=8.181143\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=8.18114296595\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:12 INFO 139649395074880] Epoch[117] Batch [5]#011Speed: 1565.53 samples/sec#011loss=8.181143\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] Epoch[117] Batch[10] avg_epoch_loss=8.140212\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=8.09109392166\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] Epoch[117] Batch [10]#011Speed: 790.64 samples/sec#011loss=8.091094\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] Epoch[117] Batch[15] avg_epoch_loss=8.157714\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=117, batch=15 train loss <loss>=8.19621772766\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] Epoch[117] Batch [15]#011Speed: 1363.38 samples/sec#011loss=8.196218\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] Epoch[117] Batch[20] avg_epoch_loss=8.109651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=117, batch=20 train loss <loss>=7.95585079193\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] Epoch[117] Batch [20]#011Speed: 724.97 samples/sec#011loss=7.955851\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] Epoch[117] Batch[25] avg_epoch_loss=8.090621\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=117, batch=25 train loss <loss>=8.0106959343\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] Epoch[117] Batch [25]#011Speed: 1324.11 samples/sec#011loss=8.010696\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] Epoch[117] Batch[30] avg_epoch_loss=8.071841\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=117, batch=30 train loss <loss>=7.97418489456\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] Epoch[117] Batch [30]#011Speed: 752.05 samples/sec#011loss=7.974185\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] Epoch[117] Batch[35] avg_epoch_loss=8.008404\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=117, batch=35 train loss <loss>=7.61509065628\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:13 INFO 139649395074880] Epoch[117] Batch [35]#011Speed: 1263.15 samples/sec#011loss=7.615091\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[117] Batch[40] avg_epoch_loss=7.954820\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=117, batch=40 train loss <loss>=7.56902017593\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[117] Batch [40]#011Speed: 747.35 samples/sec#011loss=7.569020\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[117] Batch[45] avg_epoch_loss=7.964456\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=117, batch=45 train loss <loss>=8.04347038269\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[117] Batch [45]#011Speed: 1468.13 samples/sec#011loss=8.043470\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[117] Batch[50] avg_epoch_loss=7.949990\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=117, batch=50 train loss <loss>=7.81690444946\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[117] Batch [50]#011Speed: 1136.82 samples/sec#011loss=7.816904\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] processed a total of 1630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1686.4521503448486, \"sum\": 1686.4521503448486, \"min\": 1686.4521503448486}}, \"EndTime\": 1577414594.390873, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414592.703974}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=966.471161927 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=117, train loss <loss>=7.94999024447\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[118] Batch[0] avg_epoch_loss=8.235991\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=8.23599147797\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[118] Batch[5] avg_epoch_loss=8.193570\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=8.19356973966\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[118] Batch [5]#011Speed: 1556.83 samples/sec#011loss=8.193570\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[118] Batch[10] avg_epoch_loss=8.155294\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=8.10936412811\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[118] Batch [10]#011Speed: 747.98 samples/sec#011loss=8.109364\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[118] Batch[15] avg_epoch_loss=8.273016\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=118, batch=15 train loss <loss>=8.53200397491\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:14 INFO 139649395074880] Epoch[118] Batch [15]#011Speed: 1345.70 samples/sec#011loss=8.532004\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] Epoch[118] Batch[20] avg_epoch_loss=8.213941\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=118, batch=20 train loss <loss>=8.02489862442\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] Epoch[118] Batch [20]#011Speed: 725.00 samples/sec#011loss=8.024899\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] Epoch[118] Batch[25] avg_epoch_loss=8.131482\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=118, batch=25 train loss <loss>=7.7851556778\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] Epoch[118] Batch [25]#011Speed: 1305.18 samples/sec#011loss=7.785156\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] Epoch[118] Batch[30] avg_epoch_loss=8.078285\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=118, batch=30 train loss <loss>=7.8016579628\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] Epoch[118] Batch [30]#011Speed: 738.23 samples/sec#011loss=7.801658\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] Epoch[118] Batch[35] avg_epoch_loss=7.994472\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=118, batch=35 train loss <loss>=7.47483587265\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] Epoch[118] Batch [35]#011Speed: 1508.97 samples/sec#011loss=7.474836\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] Epoch[118] Batch[40] avg_epoch_loss=7.965627\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=118, batch=40 train loss <loss>=7.7579416275\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] Epoch[118] Batch [40]#011Speed: 840.66 samples/sec#011loss=7.757942\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] Epoch[118] Batch[45] avg_epoch_loss=7.928121\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=118, batch=45 train loss <loss>=7.6205739975\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:15 INFO 139649395074880] Epoch[118] Batch [45]#011Speed: 1100.21 samples/sec#011loss=7.620574\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] processed a total of 1526 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1608.7961196899414, \"sum\": 1608.7961196899414, \"min\": 1608.7961196899414}}, \"EndTime\": 1577414596.000207, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414594.390933}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=948.473509162 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=118, train loss <loss>=7.89833144347\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] Epoch[119] Batch[0] avg_epoch_loss=8.488563\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=8.48856258392\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] Epoch[119] Batch[5] avg_epoch_loss=8.201220\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=8.2012201945\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] Epoch[119] Batch [5]#011Speed: 1478.92 samples/sec#011loss=8.201220\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] Epoch[119] Batch[10] avg_epoch_loss=8.072804\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=7.91870555878\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] Epoch[119] Batch [10]#011Speed: 775.86 samples/sec#011loss=7.918706\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] Epoch[119] Batch[15] avg_epoch_loss=8.260915\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=119, batch=15 train loss <loss>=8.67475738525\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] Epoch[119] Batch [15]#011Speed: 1344.59 samples/sec#011loss=8.674757\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] Epoch[119] Batch[20] avg_epoch_loss=8.250568\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=119, batch=20 train loss <loss>=8.21745786667\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] Epoch[119] Batch [20]#011Speed: 745.92 samples/sec#011loss=8.217458\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] Epoch[119] Batch[25] avg_epoch_loss=8.178161\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=119, batch=25 train loss <loss>=7.87405366898\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:16 INFO 139649395074880] Epoch[119] Batch [25]#011Speed: 1309.11 samples/sec#011loss=7.874054\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[119] Batch[30] avg_epoch_loss=8.114769\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=119, batch=30 train loss <loss>=7.78513154984\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[119] Batch [30]#011Speed: 749.63 samples/sec#011loss=7.785132\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[119] Batch[35] avg_epoch_loss=8.065010\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=119, batch=35 train loss <loss>=7.75649938583\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[119] Batch [35]#011Speed: 1542.42 samples/sec#011loss=7.756499\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[119] Batch[40] avg_epoch_loss=8.010960\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=119, batch=40 train loss <loss>=7.62180042267\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[119] Batch [40]#011Speed: 829.50 samples/sec#011loss=7.621800\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[119] Batch[45] avg_epoch_loss=8.006742\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=119, batch=45 train loss <loss>=7.97215909958\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[119] Batch [45]#011Speed: 1536.20 samples/sec#011loss=7.972159\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[119] Batch[50] avg_epoch_loss=7.954161\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=119, batch=50 train loss <loss>=7.47041416168\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[119] Batch [50]#011Speed: 1200.73 samples/sec#011loss=7.470414\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] processed a total of 1668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1690.796136856079, \"sum\": 1690.796136856079, \"min\": 1690.796136856079}}, \"EndTime\": 1577414597.691563, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414596.000276}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=986.451023668 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=119, train loss <loss>=7.92218156131\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[120] Batch[0] avg_epoch_loss=8.166059\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=8.16605949402\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[120] Batch[5] avg_epoch_loss=8.310187\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=8.31018702189\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:17 INFO 139649395074880] Epoch[120] Batch [5]#011Speed: 1362.20 samples/sec#011loss=8.310187\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] Epoch[120] Batch[10] avg_epoch_loss=8.170497\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=8.00286884308\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] Epoch[120] Batch [10]#011Speed: 810.70 samples/sec#011loss=8.002869\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] Epoch[120] Batch[15] avg_epoch_loss=8.177837\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=120, batch=15 train loss <loss>=8.19398412704\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] Epoch[120] Batch [15]#011Speed: 1477.60 samples/sec#011loss=8.193984\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] Epoch[120] Batch[20] avg_epoch_loss=8.122508\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=120, batch=20 train loss <loss>=7.94545660019\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] Epoch[120] Batch [20]#011Speed: 781.41 samples/sec#011loss=7.945457\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] Epoch[120] Batch[25] avg_epoch_loss=8.041215\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=120, batch=25 train loss <loss>=7.69978370667\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] Epoch[120] Batch [25]#011Speed: 1328.65 samples/sec#011loss=7.699784\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] Epoch[120] Batch[30] avg_epoch_loss=7.972292\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=120, batch=30 train loss <loss>=7.61389131546\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] Epoch[120] Batch [30]#011Speed: 771.29 samples/sec#011loss=7.613891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] Epoch[120] Batch[35] avg_epoch_loss=7.926225\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=120, batch=35 train loss <loss>=7.64061288834\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:18 INFO 139649395074880] Epoch[120] Batch [35]#011Speed: 1408.36 samples/sec#011loss=7.640613\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] Epoch[120] Batch[40] avg_epoch_loss=7.927429\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=120, batch=40 train loss <loss>=7.9360991478\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] Epoch[120] Batch [40]#011Speed: 772.52 samples/sec#011loss=7.936099\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] Epoch[120] Batch[45] avg_epoch_loss=7.890595\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=120, batch=45 train loss <loss>=7.58855628967\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] Epoch[120] Batch [45]#011Speed: 1557.92 samples/sec#011loss=7.588556\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] processed a total of 1556 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1595.4508781433105, \"sum\": 1595.4508781433105, \"min\": 1595.4508781433105}}, \"EndTime\": 1577414599.287582, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414597.691641}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=975.19770029 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=120, train loss <loss>=7.83803745192\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_f73548f4-acb5-4323-88c7-34809ec32190-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.217967987060547, \"sum\": 19.217967987060547, \"min\": 19.217967987060547}}, \"EndTime\": 1577414599.307426, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414599.287666}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] Epoch[121] Batch[0] avg_epoch_loss=7.850124\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=7.85012435913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] Epoch[121] Batch[5] avg_epoch_loss=8.215867\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=8.21586736043\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] Epoch[121] Batch [5]#011Speed: 1531.79 samples/sec#011loss=8.215867\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] Epoch[121] Batch[10] avg_epoch_loss=8.233377\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=8.25438804626\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] Epoch[121] Batch [10]#011Speed: 749.31 samples/sec#011loss=8.254388\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] Epoch[121] Batch[15] avg_epoch_loss=8.284133\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=121, batch=15 train loss <loss>=8.39579563141\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:19 INFO 139649395074880] Epoch[121] Batch [15]#011Speed: 1724.21 samples/sec#011loss=8.395796\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch[20] avg_epoch_loss=8.228729\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=121, batch=20 train loss <loss>=8.05143527985\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch [20]#011Speed: 782.27 samples/sec#011loss=8.051435\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch[25] avg_epoch_loss=8.116518\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=121, batch=25 train loss <loss>=7.64523382187\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch [25]#011Speed: 1498.02 samples/sec#011loss=7.645234\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch[30] avg_epoch_loss=8.042224\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=121, batch=30 train loss <loss>=7.65589523315\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch [30]#011Speed: 668.94 samples/sec#011loss=7.655895\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch[35] avg_epoch_loss=7.997961\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=121, batch=35 train loss <loss>=7.7235291481\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch [35]#011Speed: 1428.32 samples/sec#011loss=7.723529\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch[40] avg_epoch_loss=7.996333\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=121, batch=40 train loss <loss>=7.98461055756\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch [40]#011Speed: 799.74 samples/sec#011loss=7.984611\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch[45] avg_epoch_loss=8.006095\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=121, batch=45 train loss <loss>=8.08614177704\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch [45]#011Speed: 1552.13 samples/sec#011loss=8.086142\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch[50] avg_epoch_loss=7.942096\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=121, batch=50 train loss <loss>=7.35330982208\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] Epoch[121] Batch [50]#011Speed: 1286.26 samples/sec#011loss=7.353310\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] processed a total of 1634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1650.2811908721924, \"sum\": 1650.2811908721924, \"min\": 1650.2811908721924}}, \"EndTime\": 1577414600.957846, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414599.307507}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=990.078508029 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=121, train loss <loss>=7.85000659869\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:20 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] Epoch[122] Batch[0] avg_epoch_loss=8.177748\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=8.17774772644\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] Epoch[122] Batch[5] avg_epoch_loss=8.213127\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=8.21312745412\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] Epoch[122] Batch [5]#011Speed: 1513.91 samples/sec#011loss=8.213127\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] Epoch[122] Batch[10] avg_epoch_loss=8.334661\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=8.48050060272\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] Epoch[122] Batch [10]#011Speed: 771.46 samples/sec#011loss=8.480501\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] Epoch[122] Batch[15] avg_epoch_loss=8.368855\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=122, batch=15 train loss <loss>=8.44408168793\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] Epoch[122] Batch [15]#011Speed: 1450.16 samples/sec#011loss=8.444082\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] Epoch[122] Batch[20] avg_epoch_loss=8.281006\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=122, batch=20 train loss <loss>=7.9998919487\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] Epoch[122] Batch [20]#011Speed: 794.79 samples/sec#011loss=7.999892\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] Epoch[122] Batch[25] avg_epoch_loss=8.181674\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=122, batch=25 train loss <loss>=7.76447687149\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:21 INFO 139649395074880] Epoch[122] Batch [25]#011Speed: 1498.60 samples/sec#011loss=7.764477\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[122] Batch[30] avg_epoch_loss=8.073805\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=122, batch=30 train loss <loss>=7.51288747787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[122] Batch [30]#011Speed: 811.46 samples/sec#011loss=7.512887\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[122] Batch[35] avg_epoch_loss=8.034767\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=122, batch=35 train loss <loss>=7.7927283287\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[122] Batch [35]#011Speed: 1740.89 samples/sec#011loss=7.792728\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[122] Batch[40] avg_epoch_loss=8.009445\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=122, batch=40 train loss <loss>=7.82713289261\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[122] Batch [40]#011Speed: 825.13 samples/sec#011loss=7.827133\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[122] Batch[45] avg_epoch_loss=7.973103\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=122, batch=45 train loss <loss>=7.67509880066\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[122] Batch [45]#011Speed: 1527.78 samples/sec#011loss=7.675099\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[122] Batch[50] avg_epoch_loss=7.972414\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=122, batch=50 train loss <loss>=7.96606798172\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[122] Batch [50]#011Speed: 1129.91 samples/sec#011loss=7.966068\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] processed a total of 1603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1582.664966583252, \"sum\": 1582.664966583252, \"min\": 1582.664966583252}}, \"EndTime\": 1577414602.541049, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414600.957908}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1012.77826856 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=122, train loss <loss>=7.97241368013\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[123] Batch[0] avg_epoch_loss=8.294146\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=8.29414558411\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[123] Batch[5] avg_epoch_loss=8.190971\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=8.19097065926\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[123] Batch [5]#011Speed: 1557.94 samples/sec#011loss=8.190971\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[123] Batch[10] avg_epoch_loss=8.106038\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=8.0041182518\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:22 INFO 139649395074880] Epoch[123] Batch [10]#011Speed: 812.14 samples/sec#011loss=8.004118\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] Epoch[123] Batch[15] avg_epoch_loss=8.209848\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=123, batch=15 train loss <loss>=8.43822965622\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] Epoch[123] Batch [15]#011Speed: 1550.72 samples/sec#011loss=8.438230\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] Epoch[123] Batch[20] avg_epoch_loss=8.217308\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=123, batch=20 train loss <loss>=8.24117984772\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] Epoch[123] Batch [20]#011Speed: 778.00 samples/sec#011loss=8.241180\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] Epoch[123] Batch[25] avg_epoch_loss=8.178959\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=123, batch=25 train loss <loss>=8.01789455414\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] Epoch[123] Batch [25]#011Speed: 1303.03 samples/sec#011loss=8.017895\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] Epoch[123] Batch[30] avg_epoch_loss=8.116703\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=123, batch=30 train loss <loss>=7.79297084808\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] Epoch[123] Batch [30]#011Speed: 765.59 samples/sec#011loss=7.792971\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] Epoch[123] Batch[35] avg_epoch_loss=8.108935\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=123, batch=35 train loss <loss>=8.06077613831\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] Epoch[123] Batch [35]#011Speed: 1277.41 samples/sec#011loss=8.060776\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] Epoch[123] Batch[40] avg_epoch_loss=8.061735\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=123, batch=40 train loss <loss>=7.72189655304\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:23 INFO 139649395074880] Epoch[123] Batch [40]#011Speed: 725.36 samples/sec#011loss=7.721897\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] Epoch[123] Batch[45] avg_epoch_loss=8.014119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=123, batch=45 train loss <loss>=7.62366361618\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] Epoch[123] Batch [45]#011Speed: 1447.99 samples/sec#011loss=7.623664\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] processed a total of 1593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1634.8540782928467, \"sum\": 1634.8540782928467, \"min\": 1634.8540782928467}}, \"EndTime\": 1577414604.17644, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414602.541121}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=974.331539155 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=123, train loss <loss>=7.97529336929\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] Epoch[124] Batch[0] avg_epoch_loss=8.354417\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=8.35441684723\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] Epoch[124] Batch[5] avg_epoch_loss=8.376824\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=8.37682429949\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] Epoch[124] Batch [5]#011Speed: 1393.30 samples/sec#011loss=8.376824\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] Epoch[124] Batch[10] avg_epoch_loss=8.293299\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=8.19306764603\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] Epoch[124] Batch [10]#011Speed: 759.76 samples/sec#011loss=8.193068\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] Epoch[124] Batch[15] avg_epoch_loss=8.373273\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=124, batch=15 train loss <loss>=8.54921607971\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] Epoch[124] Batch [15]#011Speed: 1480.84 samples/sec#011loss=8.549216\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] Epoch[124] Batch[20] avg_epoch_loss=8.350453\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=124, batch=20 train loss <loss>=8.27743053436\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:24 INFO 139649395074880] Epoch[124] Batch [20]#011Speed: 778.04 samples/sec#011loss=8.277431\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[124] Batch[25] avg_epoch_loss=8.247842\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=124, batch=25 train loss <loss>=7.81687393188\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[124] Batch [25]#011Speed: 1533.29 samples/sec#011loss=7.816874\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[124] Batch[30] avg_epoch_loss=8.163956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=124, batch=30 train loss <loss>=7.72775068283\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[124] Batch [30]#011Speed: 769.26 samples/sec#011loss=7.727751\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[124] Batch[35] avg_epoch_loss=8.102312\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=124, batch=35 train loss <loss>=7.72011814117\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[124] Batch [35]#011Speed: 1332.51 samples/sec#011loss=7.720118\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[124] Batch[40] avg_epoch_loss=8.051753\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=124, batch=40 train loss <loss>=7.68772678375\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[124] Batch [40]#011Speed: 722.82 samples/sec#011loss=7.687727\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[124] Batch[45] avg_epoch_loss=8.004726\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=124, batch=45 train loss <loss>=7.61910667419\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[124] Batch [45]#011Speed: 1537.78 samples/sec#011loss=7.619107\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[124] Batch[50] avg_epoch_loss=7.977339\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=124, batch=50 train loss <loss>=7.72538061142\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[124] Batch [50]#011Speed: 1187.58 samples/sec#011loss=7.725381\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] processed a total of 1653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1683.3140850067139, \"sum\": 1683.3140850067139, \"min\": 1683.3140850067139}}, \"EndTime\": 1577414605.860277, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414604.176517}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=981.932597 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=124, train loss <loss>=7.95336612371\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] Epoch[125] Batch[0] avg_epoch_loss=8.683764\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=8.68376350403\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] Epoch[125] Batch[5] avg_epoch_loss=8.227010\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=8.22700969378\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] Epoch[125] Batch [5]#011Speed: 1664.07 samples/sec#011loss=8.227010\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] Epoch[125] Batch[10] avg_epoch_loss=8.177410\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=8.11789121628\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] Epoch[125] Batch [10]#011Speed: 819.30 samples/sec#011loss=8.117891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] Epoch[125] Batch[15] avg_epoch_loss=8.287419\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=125, batch=15 train loss <loss>=8.52943649292\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] Epoch[125] Batch [15]#011Speed: 1592.96 samples/sec#011loss=8.529436\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] Epoch[125] Batch[20] avg_epoch_loss=8.241424\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=125, batch=20 train loss <loss>=8.09424142838\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] Epoch[125] Batch [20]#011Speed: 753.38 samples/sec#011loss=8.094241\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] Epoch[125] Batch[25] avg_epoch_loss=8.138019\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=125, batch=25 train loss <loss>=7.70371723175\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] Epoch[125] Batch [25]#011Speed: 1612.84 samples/sec#011loss=7.703717\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] Epoch[125] Batch[30] avg_epoch_loss=8.050901\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=125, batch=30 train loss <loss>=7.59788799286\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:26 INFO 139649395074880] Epoch[125] Batch [30]#011Speed: 772.79 samples/sec#011loss=7.597888\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[125] Batch[35] avg_epoch_loss=8.004974\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=125, batch=35 train loss <loss>=7.72022914886\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[125] Batch [35]#011Speed: 1335.54 samples/sec#011loss=7.720229\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[125] Batch[40] avg_epoch_loss=7.975505\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=125, batch=40 train loss <loss>=7.76332588196\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[125] Batch [40]#011Speed: 729.76 samples/sec#011loss=7.763326\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[125] Batch[45] avg_epoch_loss=7.987072\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=125, batch=45 train loss <loss>=8.08192367554\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[125] Batch [45]#011Speed: 1281.07 samples/sec#011loss=8.081924\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[125] Batch[50] avg_epoch_loss=7.978606\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=125, batch=50 train loss <loss>=7.90072078705\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[125] Batch [50]#011Speed: 1080.47 samples/sec#011loss=7.900721\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] processed a total of 1657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1677.1390438079834, \"sum\": 1677.1390438079834, \"min\": 1677.1390438079834}}, \"EndTime\": 1577414607.537939, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414605.860343}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=987.925596142 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=125, train loss <loss>=7.95985020124\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[126] Batch[0] avg_epoch_loss=7.970887\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=7.97088718414\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[126] Batch[5] avg_epoch_loss=7.983253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=7.98325292269\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[126] Batch [5]#011Speed: 1408.73 samples/sec#011loss=7.983253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[126] Batch[10] avg_epoch_loss=8.016912\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=8.05730381012\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:27 INFO 139649395074880] Epoch[126] Batch [10]#011Speed: 1679.43 samples/sec#011loss=8.057304\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] Epoch[126] Batch[15] avg_epoch_loss=8.097910\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=126, batch=15 train loss <loss>=8.27610359192\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] Epoch[126] Batch [15]#011Speed: 723.27 samples/sec#011loss=8.276104\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] Epoch[126] Batch[20] avg_epoch_loss=8.153067\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=126, batch=20 train loss <loss>=8.32956886292\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] Epoch[126] Batch [20]#011Speed: 1552.89 samples/sec#011loss=8.329569\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] Epoch[126] Batch[25] avg_epoch_loss=8.072448\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=126, batch=25 train loss <loss>=7.73384876251\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] Epoch[126] Batch [25]#011Speed: 713.79 samples/sec#011loss=7.733849\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] Epoch[126] Batch[30] avg_epoch_loss=8.010710\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=126, batch=30 train loss <loss>=7.68967618942\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] Epoch[126] Batch [30]#011Speed: 802.63 samples/sec#011loss=7.689676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] Epoch[126] Batch[35] avg_epoch_loss=7.979602\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=126, batch=35 train loss <loss>=7.78672790527\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] Epoch[126] Batch [35]#011Speed: 1556.69 samples/sec#011loss=7.786728\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] Epoch[126] Batch[40] avg_epoch_loss=7.992095\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=126, batch=40 train loss <loss>=8.08204669952\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:28 INFO 139649395074880] Epoch[126] Batch [40]#011Speed: 766.60 samples/sec#011loss=8.082047\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[126] Batch[45] avg_epoch_loss=7.987941\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=126, batch=45 train loss <loss>=7.95387783051\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[126] Batch [45]#011Speed: 1299.91 samples/sec#011loss=7.953878\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[126] Batch[50] avg_epoch_loss=7.941037\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=126, batch=50 train loss <loss>=7.50952367783\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[126] Batch [50]#011Speed: 1271.72 samples/sec#011loss=7.509524\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] processed a total of 1657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1678.9069175720215, \"sum\": 1678.9069175720215, \"min\": 1678.9069175720215}}, \"EndTime\": 1577414609.217395, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414607.538019}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=986.884688634 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=126, train loss <loss>=7.92954283494\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[127] Batch[0] avg_epoch_loss=8.575026\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=8.57502555847\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[127] Batch[5] avg_epoch_loss=8.183659\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=8.18365915616\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[127] Batch [5]#011Speed: 1420.33 samples/sec#011loss=8.183659\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[127] Batch[10] avg_epoch_loss=8.154094\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=8.11861562729\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[127] Batch [10]#011Speed: 788.09 samples/sec#011loss=8.118616\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[127] Batch[15] avg_epoch_loss=8.151282\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=127, batch=15 train loss <loss>=8.14509725571\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[127] Batch [15]#011Speed: 1576.76 samples/sec#011loss=8.145097\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[127] Batch[20] avg_epoch_loss=8.185262\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=127, batch=20 train loss <loss>=8.29399528503\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:29 INFO 139649395074880] Epoch[127] Batch [20]#011Speed: 798.17 samples/sec#011loss=8.293995\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] Epoch[127] Batch[25] avg_epoch_loss=8.080319\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=127, batch=25 train loss <loss>=7.63956203461\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] Epoch[127] Batch [25]#011Speed: 1330.73 samples/sec#011loss=7.639562\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] Epoch[127] Batch[30] avg_epoch_loss=8.024334\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=127, batch=30 train loss <loss>=7.73320951462\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] Epoch[127] Batch [30]#011Speed: 811.06 samples/sec#011loss=7.733210\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] Epoch[127] Batch[35] avg_epoch_loss=7.999536\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=127, batch=35 train loss <loss>=7.84578905106\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] Epoch[127] Batch [35]#011Speed: 1519.27 samples/sec#011loss=7.845789\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] Epoch[127] Batch[40] avg_epoch_loss=8.005870\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=127, batch=40 train loss <loss>=8.05147752762\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] Epoch[127] Batch [40]#011Speed: 804.00 samples/sec#011loss=8.051478\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] Epoch[127] Batch[45] avg_epoch_loss=7.988270\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=127, batch=45 train loss <loss>=7.84395036697\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] Epoch[127] Batch [45]#011Speed: 1398.71 samples/sec#011loss=7.843950\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] processed a total of 1568 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1574.0327835083008, \"sum\": 1574.0327835083008, \"min\": 1574.0327835083008}}, \"EndTime\": 1577414610.791944, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414609.217474}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=996.096243769 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=127, train loss <loss>=7.94542153028\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] Epoch[128] Batch[0] avg_epoch_loss=8.068855\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=8.06885528564\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch[5] avg_epoch_loss=8.101357\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=8.10135730108\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch [5]#011Speed: 1621.04 samples/sec#011loss=8.101357\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch[10] avg_epoch_loss=8.088054\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=8.0720911026\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch [10]#011Speed: 788.53 samples/sec#011loss=8.072091\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch[15] avg_epoch_loss=8.232011\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=128, batch=15 train loss <loss>=8.54871454239\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch [15]#011Speed: 1657.82 samples/sec#011loss=8.548715\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch[20] avg_epoch_loss=8.240184\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=128, batch=20 train loss <loss>=8.2663392067\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch [20]#011Speed: 731.59 samples/sec#011loss=8.266339\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch[25] avg_epoch_loss=8.185617\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=128, batch=25 train loss <loss>=7.95643491745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch [25]#011Speed: 1550.06 samples/sec#011loss=7.956435\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch[30] avg_epoch_loss=8.123804\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=128, batch=30 train loss <loss>=7.80237569809\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch [30]#011Speed: 767.43 samples/sec#011loss=7.802376\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch[35] avg_epoch_loss=8.032462\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=128, batch=35 train loss <loss>=7.46614103317\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:31 INFO 139649395074880] Epoch[128] Batch [35]#011Speed: 1667.06 samples/sec#011loss=7.466141\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] Epoch[128] Batch[40] avg_epoch_loss=7.997127\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=128, batch=40 train loss <loss>=7.74271373749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] Epoch[128] Batch [40]#011Speed: 753.79 samples/sec#011loss=7.742714\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] Epoch[128] Batch[45] avg_epoch_loss=7.974114\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=128, batch=45 train loss <loss>=7.78540782928\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] Epoch[128] Batch [45]#011Speed: 1623.92 samples/sec#011loss=7.785408\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] processed a total of 1579 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1578.3770084381104, \"sum\": 1578.3770084381104, \"min\": 1578.3770084381104}}, \"EndTime\": 1577414612.370876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414610.792021}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1000.32187292 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=128, train loss <loss>=7.90303596497\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] Epoch[129] Batch[0] avg_epoch_loss=8.520873\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=8.52087306976\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] Epoch[129] Batch[5] avg_epoch_loss=8.342723\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=8.34272313118\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] Epoch[129] Batch [5]#011Speed: 1510.49 samples/sec#011loss=8.342723\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] Epoch[129] Batch[10] avg_epoch_loss=8.195492\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=8.01881523132\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] Epoch[129] Batch [10]#011Speed: 779.53 samples/sec#011loss=8.018815\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] Epoch[129] Batch[15] avg_epoch_loss=8.291121\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=129, batch=15 train loss <loss>=8.50150279999\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:32 INFO 139649395074880] Epoch[129] Batch [15]#011Speed: 1623.46 samples/sec#011loss=8.501503\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] Epoch[129] Batch[20] avg_epoch_loss=8.235431\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=129, batch=20 train loss <loss>=8.05722579956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] Epoch[129] Batch [20]#011Speed: 762.86 samples/sec#011loss=8.057226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] Epoch[129] Batch[25] avg_epoch_loss=8.161755\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=129, batch=25 train loss <loss>=7.85231285095\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] Epoch[129] Batch [25]#011Speed: 1650.12 samples/sec#011loss=7.852313\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] Epoch[129] Batch[30] avg_epoch_loss=8.065611\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=129, batch=30 train loss <loss>=7.56566143036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] Epoch[129] Batch [30]#011Speed: 719.28 samples/sec#011loss=7.565661\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] Epoch[129] Batch[35] avg_epoch_loss=8.052820\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=129, batch=35 train loss <loss>=7.97351970673\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] Epoch[129] Batch [35]#011Speed: 1640.09 samples/sec#011loss=7.973520\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] Epoch[129] Batch[40] avg_epoch_loss=8.014513\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=129, batch=40 train loss <loss>=7.73869905472\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] Epoch[129] Batch [40]#011Speed: 673.92 samples/sec#011loss=7.738699\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] Epoch[129] Batch[45] avg_epoch_loss=7.999765\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=129, batch=45 train loss <loss>=7.87883338928\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] Epoch[129] Batch [45]#011Speed: 1540.01 samples/sec#011loss=7.878833\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] processed a total of 1568 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1606.1780452728271, \"sum\": 1606.1780452728271, \"min\": 1606.1780452728271}}, \"EndTime\": 1577414613.97762, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414612.370956}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=976.157038436 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=129, train loss <loss>=7.95515208342\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:33 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] Epoch[130] Batch[0] avg_epoch_loss=8.149365\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=8.14936542511\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] Epoch[130] Batch[5] avg_epoch_loss=8.256158\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=8.2561583519\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] Epoch[130] Batch [5]#011Speed: 1476.30 samples/sec#011loss=8.256158\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] Epoch[130] Batch[10] avg_epoch_loss=8.132954\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=7.98510875702\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] Epoch[130] Batch [10]#011Speed: 698.98 samples/sec#011loss=7.985109\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] Epoch[130] Batch[15] avg_epoch_loss=8.205958\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=130, batch=15 train loss <loss>=8.36656532288\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] Epoch[130] Batch [15]#011Speed: 1337.00 samples/sec#011loss=8.366565\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] Epoch[130] Batch[20] avg_epoch_loss=8.206105\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=130, batch=20 train loss <loss>=8.20657558441\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] Epoch[130] Batch [20]#011Speed: 717.05 samples/sec#011loss=8.206576\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] Epoch[130] Batch[25] avg_epoch_loss=8.132392\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=130, batch=25 train loss <loss>=7.82279834747\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:34 INFO 139649395074880] Epoch[130] Batch [25]#011Speed: 1619.89 samples/sec#011loss=7.822798\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[130] Batch[30] avg_epoch_loss=8.054066\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=130, batch=30 train loss <loss>=7.64676942825\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[130] Batch [30]#011Speed: 793.36 samples/sec#011loss=7.646769\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[130] Batch[35] avg_epoch_loss=8.010183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=130, batch=35 train loss <loss>=7.73811340332\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[130] Batch [35]#011Speed: 1633.70 samples/sec#011loss=7.738113\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[130] Batch[40] avg_epoch_loss=7.988307\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=130, batch=40 train loss <loss>=7.83079547882\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[130] Batch [40]#011Speed: 770.57 samples/sec#011loss=7.830795\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[130] Batch[45] avg_epoch_loss=7.950862\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=130, batch=45 train loss <loss>=7.64381170273\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[130] Batch [45]#011Speed: 1297.20 samples/sec#011loss=7.643812\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[130] Batch[50] avg_epoch_loss=8.023924\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=130, batch=50 train loss <loss>=8.69609670639\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[130] Batch [50]#011Speed: 1156.53 samples/sec#011loss=8.696097\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] processed a total of 1602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1699.289083480835, \"sum\": 1699.289083480835, \"min\": 1699.289083480835}}, \"EndTime\": 1577414615.677461, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414613.977703}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=942.684492247 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=130, train loss <loss>=8.02392399545\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[131] Batch[0] avg_epoch_loss=8.365961\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=8.36596107483\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[131] Batch[5] avg_epoch_loss=8.406211\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=8.40621066093\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:35 INFO 139649395074880] Epoch[131] Batch [5]#011Speed: 1523.82 samples/sec#011loss=8.406211\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] Epoch[131] Batch[10] avg_epoch_loss=8.317267\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=8.2105348587\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] Epoch[131] Batch [10]#011Speed: 799.87 samples/sec#011loss=8.210535\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] Epoch[131] Batch[15] avg_epoch_loss=8.292715\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=131, batch=15 train loss <loss>=8.23870105743\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] Epoch[131] Batch [15]#011Speed: 1543.36 samples/sec#011loss=8.238701\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] Epoch[131] Batch[20] avg_epoch_loss=8.215042\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=131, batch=20 train loss <loss>=7.96648826599\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] Epoch[131] Batch [20]#011Speed: 772.19 samples/sec#011loss=7.966488\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] Epoch[131] Batch[25] avg_epoch_loss=8.112776\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=131, batch=25 train loss <loss>=7.68325624466\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] Epoch[131] Batch [25]#011Speed: 1323.66 samples/sec#011loss=7.683256\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] Epoch[131] Batch[30] avg_epoch_loss=8.024402\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=131, batch=30 train loss <loss>=7.56485776901\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] Epoch[131] Batch [30]#011Speed: 749.91 samples/sec#011loss=7.564858\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] Epoch[131] Batch[35] avg_epoch_loss=7.980420\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=131, batch=35 train loss <loss>=7.70773334503\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:36 INFO 139649395074880] Epoch[131] Batch [35]#011Speed: 1325.84 samples/sec#011loss=7.707733\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] Epoch[131] Batch[40] avg_epoch_loss=7.957681\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=131, batch=40 train loss <loss>=7.79395923615\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] Epoch[131] Batch [40]#011Speed: 740.94 samples/sec#011loss=7.793959\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] Epoch[131] Batch[45] avg_epoch_loss=7.945406\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=131, batch=45 train loss <loss>=7.8447561264\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] Epoch[131] Batch [45]#011Speed: 1327.82 samples/sec#011loss=7.844756\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] processed a total of 1574 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1651.6730785369873, \"sum\": 1651.6730785369873, \"min\": 1651.6730785369873}}, \"EndTime\": 1577414617.329688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414615.67754}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=952.915456872 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=131, train loss <loss>=7.8905542469\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] Epoch[132] Batch[0] avg_epoch_loss=8.391664\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=8.39166355133\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] Epoch[132] Batch[5] avg_epoch_loss=8.110858\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=8.11085812251\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] Epoch[132] Batch [5]#011Speed: 1276.05 samples/sec#011loss=8.110858\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] Epoch[132] Batch[10] avg_epoch_loss=8.101611\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=132, batch=10 train loss <loss>=8.09051361084\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] Epoch[132] Batch [10]#011Speed: 746.30 samples/sec#011loss=8.090514\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] Epoch[132] Batch[15] avg_epoch_loss=8.170818\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=132, batch=15 train loss <loss>=8.32307453156\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:37 INFO 139649395074880] Epoch[132] Batch [15]#011Speed: 1318.18 samples/sec#011loss=8.323075\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] Epoch[132] Batch[20] avg_epoch_loss=8.167562\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=132, batch=20 train loss <loss>=8.15714454651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] Epoch[132] Batch [20]#011Speed: 836.83 samples/sec#011loss=8.157145\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] Epoch[132] Batch[25] avg_epoch_loss=8.092890\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=132, batch=25 train loss <loss>=7.77926454544\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] Epoch[132] Batch [25]#011Speed: 1719.89 samples/sec#011loss=7.779265\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] Epoch[132] Batch[30] avg_epoch_loss=7.997942\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=132, batch=30 train loss <loss>=7.50421609879\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] Epoch[132] Batch [30]#011Speed: 785.85 samples/sec#011loss=7.504216\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] Epoch[132] Batch[35] avg_epoch_loss=7.998819\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=132, batch=35 train loss <loss>=8.00425624847\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] Epoch[132] Batch [35]#011Speed: 1439.68 samples/sec#011loss=8.004256\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] Epoch[132] Batch[40] avg_epoch_loss=7.974433\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=132, batch=40 train loss <loss>=7.79884843826\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] Epoch[132] Batch [40]#011Speed: 704.89 samples/sec#011loss=7.798848\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] Epoch[132] Batch[45] avg_epoch_loss=7.943772\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=132, batch=45 train loss <loss>=7.69235610962\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] Epoch[132] Batch [45]#011Speed: 1541.65 samples/sec#011loss=7.692356\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] processed a total of 1578 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1629.9757957458496, \"sum\": 1629.9757957458496, \"min\": 1629.9757957458496}}, \"EndTime\": 1577414618.960201, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414617.329758}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=968.050656928 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=132, train loss <loss>=7.98688533783\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:38 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] Epoch[133] Batch[0] avg_epoch_loss=8.582830\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=8.58283042908\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] Epoch[133] Batch[5] avg_epoch_loss=8.233439\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=8.23343920708\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] Epoch[133] Batch [5]#011Speed: 1518.43 samples/sec#011loss=8.233439\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] Epoch[133] Batch[10] avg_epoch_loss=8.189813\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=133, batch=10 train loss <loss>=8.13746213913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] Epoch[133] Batch [10]#011Speed: 758.41 samples/sec#011loss=8.137462\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] Epoch[133] Batch[15] avg_epoch_loss=8.276362\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=133, batch=15 train loss <loss>=8.46677017212\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] Epoch[133] Batch [15]#011Speed: 1293.88 samples/sec#011loss=8.466770\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] Epoch[133] Batch[20] avg_epoch_loss=8.170349\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=133, batch=20 train loss <loss>=7.83110694885\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] Epoch[133] Batch [20]#011Speed: 738.15 samples/sec#011loss=7.831107\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] Epoch[133] Batch[25] avg_epoch_loss=8.117901\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=133, batch=25 train loss <loss>=7.89761838913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:39 INFO 139649395074880] Epoch[133] Batch [25]#011Speed: 1364.33 samples/sec#011loss=7.897618\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] Epoch[133] Batch[30] avg_epoch_loss=8.032907\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=133, batch=30 train loss <loss>=7.59093875885\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] Epoch[133] Batch [30]#011Speed: 728.04 samples/sec#011loss=7.590939\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] Epoch[133] Batch[35] avg_epoch_loss=7.987039\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=133, batch=35 train loss <loss>=7.70265712738\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] Epoch[133] Batch [35]#011Speed: 1311.55 samples/sec#011loss=7.702657\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] Epoch[133] Batch[40] avg_epoch_loss=7.939352\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=133, batch=40 train loss <loss>=7.59600524902\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] Epoch[133] Batch [40]#011Speed: 710.22 samples/sec#011loss=7.596005\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] Epoch[133] Batch[45] avg_epoch_loss=7.949521\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=133, batch=45 train loss <loss>=8.03291034698\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] Epoch[133] Batch [45]#011Speed: 1257.43 samples/sec#011loss=8.032910\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] processed a total of 1577 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1732.9919338226318, \"sum\": 1732.9919338226318, \"min\": 1732.9919338226318}}, \"EndTime\": 1577414620.693777, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414618.960269}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=909.938602693 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=133, train loss <loss>=7.91724192619\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] Epoch[134] Batch[0] avg_epoch_loss=7.938719\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=7.93871879578\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] Epoch[134] Batch[5] avg_epoch_loss=8.055659\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=8.05565921466\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:40 INFO 139649395074880] Epoch[134] Batch [5]#011Speed: 1299.58 samples/sec#011loss=8.055659\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] Epoch[134] Batch[10] avg_epoch_loss=8.099981\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=8.15316610336\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] Epoch[134] Batch [10]#011Speed: 699.15 samples/sec#011loss=8.153166\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] Epoch[134] Batch[15] avg_epoch_loss=8.122418\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=134, batch=15 train loss <loss>=8.17178182602\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] Epoch[134] Batch [15]#011Speed: 1386.74 samples/sec#011loss=8.171782\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] Epoch[134] Batch[20] avg_epoch_loss=8.195208\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=134, batch=20 train loss <loss>=8.4281334877\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] Epoch[134] Batch [20]#011Speed: 761.37 samples/sec#011loss=8.428133\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] Epoch[134] Batch[25] avg_epoch_loss=8.109079\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=134, batch=25 train loss <loss>=7.74733724594\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] Epoch[134] Batch [25]#011Speed: 1469.51 samples/sec#011loss=7.747337\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] Epoch[134] Batch[30] avg_epoch_loss=8.042057\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=134, batch=30 train loss <loss>=7.69354505539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] Epoch[134] Batch [30]#011Speed: 796.37 samples/sec#011loss=7.693545\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] Epoch[134] Batch[35] avg_epoch_loss=8.004946\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=134, batch=35 train loss <loss>=7.7748547554\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:41 INFO 139649395074880] Epoch[134] Batch [35]#011Speed: 1547.11 samples/sec#011loss=7.774855\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[134] Batch[40] avg_epoch_loss=7.994758\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=134, batch=40 train loss <loss>=7.92140979767\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[134] Batch [40]#011Speed: 801.05 samples/sec#011loss=7.921410\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[134] Batch[45] avg_epoch_loss=7.947246\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=134, batch=45 train loss <loss>=7.55764188766\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[134] Batch [45]#011Speed: 1464.03 samples/sec#011loss=7.557642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[134] Batch[50] avg_epoch_loss=7.938759\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=134, batch=50 train loss <loss>=7.8606762886\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[134] Batch [50]#011Speed: 1178.56 samples/sec#011loss=7.860676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] processed a total of 1631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1665.8480167388916, \"sum\": 1665.8480167388916, \"min\": 1665.8480167388916}}, \"EndTime\": 1577414622.360164, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414620.693838}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=979.029210403 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=134, train loss <loss>=7.93875857895\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[135] Batch[0] avg_epoch_loss=8.292376\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=8.29237556458\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[135] Batch[5] avg_epoch_loss=8.066014\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=8.06601365407\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[135] Batch [5]#011Speed: 1340.70 samples/sec#011loss=8.066014\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[135] Batch[10] avg_epoch_loss=8.110658\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=8.16423063278\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[135] Batch [10]#011Speed: 733.19 samples/sec#011loss=8.164231\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[135] Batch[15] avg_epoch_loss=8.232611\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=135, batch=15 train loss <loss>=8.50090818405\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:42 INFO 139649395074880] Epoch[135] Batch [15]#011Speed: 1515.57 samples/sec#011loss=8.500908\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] Epoch[135] Batch[20] avg_epoch_loss=8.244021\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=135, batch=20 train loss <loss>=8.28053236008\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] Epoch[135] Batch [20]#011Speed: 821.22 samples/sec#011loss=8.280532\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] Epoch[135] Batch[25] avg_epoch_loss=8.194079\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=135, batch=25 train loss <loss>=7.984324646\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] Epoch[135] Batch [25]#011Speed: 1337.56 samples/sec#011loss=7.984325\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] Epoch[135] Batch[30] avg_epoch_loss=8.122719\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=135, batch=30 train loss <loss>=7.75164556503\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] Epoch[135] Batch [30]#011Speed: 695.13 samples/sec#011loss=7.751646\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] Epoch[135] Batch[35] avg_epoch_loss=8.069542\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=135, batch=35 train loss <loss>=7.73984222412\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] Epoch[135] Batch [35]#011Speed: 1279.61 samples/sec#011loss=7.739842\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] Epoch[135] Batch[40] avg_epoch_loss=8.038873\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=135, batch=40 train loss <loss>=7.81805963516\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] Epoch[135] Batch [40]#011Speed: 725.16 samples/sec#011loss=7.818060\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] Epoch[135] Batch[45] avg_epoch_loss=8.034868\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=135, batch=45 train loss <loss>=8.00202522278\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:43 INFO 139649395074880] Epoch[135] Batch [45]#011Speed: 1350.61 samples/sec#011loss=8.002025\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[135] Batch[50] avg_epoch_loss=8.017682\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=135, batch=50 train loss <loss>=7.85956954956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[135] Batch [50]#011Speed: 997.48 samples/sec#011loss=7.859570\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] processed a total of 1658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1760.970115661621, \"sum\": 1760.970115661621, \"min\": 1760.970115661621}}, \"EndTime\": 1577414624.121653, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414622.36022}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=941.466064525 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=135, train loss <loss>=8.01388656176\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[136] Batch[0] avg_epoch_loss=8.478875\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=8.47887516022\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[136] Batch[5] avg_epoch_loss=8.084676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=8.0846760273\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[136] Batch [5]#011Speed: 1547.98 samples/sec#011loss=8.084676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[136] Batch[10] avg_epoch_loss=8.025696\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=7.95491991043\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[136] Batch [10]#011Speed: 793.27 samples/sec#011loss=7.954920\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[136] Batch[15] avg_epoch_loss=8.128183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=136, batch=15 train loss <loss>=8.35365381241\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[136] Batch [15]#011Speed: 1522.91 samples/sec#011loss=8.353654\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[136] Batch[20] avg_epoch_loss=8.124863\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=136, batch=20 train loss <loss>=8.11423854828\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[136] Batch [20]#011Speed: 743.18 samples/sec#011loss=8.114239\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[136] Batch[25] avg_epoch_loss=8.054192\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=136, batch=25 train loss <loss>=7.75737457275\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:44 INFO 139649395074880] Epoch[136] Batch [25]#011Speed: 1674.66 samples/sec#011loss=7.757375\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] Epoch[136] Batch[30] avg_epoch_loss=7.984273\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=136, batch=30 train loss <loss>=7.62069234848\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] Epoch[136] Batch [30]#011Speed: 740.71 samples/sec#011loss=7.620692\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] Epoch[136] Batch[35] avg_epoch_loss=7.977885\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=136, batch=35 train loss <loss>=7.93827848434\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] Epoch[136] Batch [35]#011Speed: 1386.79 samples/sec#011loss=7.938278\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] Epoch[136] Batch[40] avg_epoch_loss=7.951654\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=136, batch=40 train loss <loss>=7.76279668808\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] Epoch[136] Batch [40]#011Speed: 793.92 samples/sec#011loss=7.762797\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] Epoch[136] Batch[45] avg_epoch_loss=7.921960\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=136, batch=45 train loss <loss>=7.67846946716\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] Epoch[136] Batch [45]#011Speed: 1291.23 samples/sec#011loss=7.678469\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] processed a total of 1578 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1636.2378597259521, \"sum\": 1636.2378597259521, \"min\": 1636.2378597259521}}, \"EndTime\": 1577414625.758393, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414624.121731}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=964.347320031 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=136, train loss <loss>=7.95981616974\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] Epoch[137] Batch[0] avg_epoch_loss=7.959614\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=7.95961380005\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] Epoch[137] Batch[5] avg_epoch_loss=8.162782\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=8.16278243065\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:45 INFO 139649395074880] Epoch[137] Batch [5]#011Speed: 1487.69 samples/sec#011loss=8.162782\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] Epoch[137] Batch[10] avg_epoch_loss=8.283858\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=8.42914848328\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] Epoch[137] Batch [10]#011Speed: 800.17 samples/sec#011loss=8.429148\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] Epoch[137] Batch[15] avg_epoch_loss=8.271703\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=137, batch=15 train loss <loss>=8.24496068954\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] Epoch[137] Batch [15]#011Speed: 1444.75 samples/sec#011loss=8.244961\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] Epoch[137] Batch[20] avg_epoch_loss=8.238192\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=137, batch=20 train loss <loss>=8.13095722198\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] Epoch[137] Batch [20]#011Speed: 797.85 samples/sec#011loss=8.130957\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] Epoch[137] Batch[25] avg_epoch_loss=8.149606\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=137, batch=25 train loss <loss>=7.77754631042\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] Epoch[137] Batch [25]#011Speed: 1513.14 samples/sec#011loss=7.777546\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] Epoch[137] Batch[30] avg_epoch_loss=8.105096\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=137, batch=30 train loss <loss>=7.87364549637\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] Epoch[137] Batch [30]#011Speed: 774.50 samples/sec#011loss=7.873645\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] Epoch[137] Batch[35] avg_epoch_loss=8.056900\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=137, batch=35 train loss <loss>=7.75808258057\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:46 INFO 139649395074880] Epoch[137] Batch [35]#011Speed: 1301.89 samples/sec#011loss=7.758083\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] Epoch[137] Batch[40] avg_epoch_loss=8.043774\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=137, batch=40 train loss <loss>=7.94926319122\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] Epoch[137] Batch [40]#011Speed: 694.31 samples/sec#011loss=7.949263\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] Epoch[137] Batch[45] avg_epoch_loss=7.984538\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=137, batch=45 train loss <loss>=7.49880714417\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] Epoch[137] Batch [45]#011Speed: 1265.20 samples/sec#011loss=7.498807\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] processed a total of 1596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1652.937889099121, \"sum\": 1652.937889099121, \"min\": 1652.937889099121}}, \"EndTime\": 1577414627.411873, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414625.758466}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=965.50380462 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=137, train loss <loss>=7.98689538956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] Epoch[138] Batch[0] avg_epoch_loss=7.790544\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=7.79054403305\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] Epoch[138] Batch[5] avg_epoch_loss=8.152832\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=8.15283155441\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] Epoch[138] Batch [5]#011Speed: 1268.43 samples/sec#011loss=8.152832\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] Epoch[138] Batch[10] avg_epoch_loss=8.095563\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=8.02684135437\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:47 INFO 139649395074880] Epoch[138] Batch [10]#011Speed: 751.59 samples/sec#011loss=8.026841\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch[15] avg_epoch_loss=8.208077\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=138, batch=15 train loss <loss>=8.45560684204\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch [15]#011Speed: 1252.98 samples/sec#011loss=8.455607\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch[20] avg_epoch_loss=8.115145\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=138, batch=20 train loss <loss>=7.81776371002\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch [20]#011Speed: 722.87 samples/sec#011loss=7.817764\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch[25] avg_epoch_loss=8.046591\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=138, batch=25 train loss <loss>=7.75866317749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch [25]#011Speed: 1527.23 samples/sec#011loss=7.758663\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch[30] avg_epoch_loss=8.000811\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=138, batch=30 train loss <loss>=7.76275682449\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch [30]#011Speed: 725.79 samples/sec#011loss=7.762757\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch[35] avg_epoch_loss=7.951475\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=138, batch=35 train loss <loss>=7.64559030533\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch [35]#011Speed: 1406.39 samples/sec#011loss=7.645590\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch[40] avg_epoch_loss=7.938476\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=138, batch=40 train loss <loss>=7.84488525391\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch [40]#011Speed: 739.89 samples/sec#011loss=7.844885\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch[45] avg_epoch_loss=7.952192\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=138, batch=45 train loss <loss>=8.06465654373\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:48 INFO 139649395074880] Epoch[138] Batch [45]#011Speed: 1567.64 samples/sec#011loss=8.064657\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] processed a total of 1587 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1682.7261447906494, \"sum\": 1682.7261447906494, \"min\": 1682.7261447906494}}, \"EndTime\": 1577414629.095157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414627.411929}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=943.048060403 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=138, train loss <loss>=7.89698297501\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] Epoch[139] Batch[0] avg_epoch_loss=7.672452\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=7.67245197296\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] Epoch[139] Batch[5] avg_epoch_loss=8.167662\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=8.16766206423\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] Epoch[139] Batch [5]#011Speed: 1499.87 samples/sec#011loss=8.167662\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] Epoch[139] Batch[10] avg_epoch_loss=8.239247\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=8.32514886856\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] Epoch[139] Batch [10]#011Speed: 832.22 samples/sec#011loss=8.325149\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] Epoch[139] Batch[15] avg_epoch_loss=8.268492\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=139, batch=15 train loss <loss>=8.33282995224\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] Epoch[139] Batch [15]#011Speed: 1463.94 samples/sec#011loss=8.332830\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] Epoch[139] Batch[20] avg_epoch_loss=8.211285\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=139, batch=20 train loss <loss>=8.02822465897\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] Epoch[139] Batch [20]#011Speed: 756.45 samples/sec#011loss=8.028225\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] Epoch[139] Batch[25] avg_epoch_loss=8.132425\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=139, batch=25 train loss <loss>=7.80121202469\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:49 INFO 139649395074880] Epoch[139] Batch [25]#011Speed: 1698.82 samples/sec#011loss=7.801212\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[139] Batch[30] avg_epoch_loss=8.055305\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=139, batch=30 train loss <loss>=7.65427856445\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[139] Batch [30]#011Speed: 775.23 samples/sec#011loss=7.654279\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[139] Batch[35] avg_epoch_loss=8.004063\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=139, batch=35 train loss <loss>=7.68636608124\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[139] Batch [35]#011Speed: 1717.59 samples/sec#011loss=7.686366\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[139] Batch[40] avg_epoch_loss=7.964845\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=139, batch=40 train loss <loss>=7.68247432709\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[139] Batch [40]#011Speed: 750.94 samples/sec#011loss=7.682474\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[139] Batch[45] avg_epoch_loss=7.950576\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=139, batch=45 train loss <loss>=7.83356781006\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[139] Batch [45]#011Speed: 1563.29 samples/sec#011loss=7.833568\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[139] Batch[50] avg_epoch_loss=7.834365\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=139, batch=50 train loss <loss>=6.76522221565\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[139] Batch [50]#011Speed: 1076.00 samples/sec#011loss=6.765222\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] processed a total of 1607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1609.1771125793457, \"sum\": 1609.1771125793457, \"min\": 1609.1771125793457}}, \"EndTime\": 1577414630.704897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414629.095235}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=998.585664479 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=139, train loss <loss>=7.83436460588\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_72032d6b-99a0-45e4-ad52-d879fc8a4e03-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.490148544311523, \"sum\": 17.490148544311523, \"min\": 17.490148544311523}}, \"EndTime\": 1577414630.72295, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414630.704967}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[140] Batch[0] avg_epoch_loss=8.571591\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=8.57159137726\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[140] Batch[5] avg_epoch_loss=8.271793\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=8.27179257075\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:50 INFO 139649395074880] Epoch[140] Batch [5]#011Speed: 1435.51 samples/sec#011loss=8.271793\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch[10] avg_epoch_loss=8.327511\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=8.3943731308\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch [10]#011Speed: 791.90 samples/sec#011loss=8.394373\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch[15] avg_epoch_loss=8.325016\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=140, batch=15 train loss <loss>=8.31952705383\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch [15]#011Speed: 1606.33 samples/sec#011loss=8.319527\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch[20] avg_epoch_loss=8.265123\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=140, batch=20 train loss <loss>=8.07346601486\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch [20]#011Speed: 786.59 samples/sec#011loss=8.073466\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch[25] avg_epoch_loss=8.196184\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=140, batch=25 train loss <loss>=7.90663881302\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch [25]#011Speed: 1553.67 samples/sec#011loss=7.906639\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch[30] avg_epoch_loss=8.146329\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=140, batch=30 train loss <loss>=7.88708314896\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch [30]#011Speed: 769.60 samples/sec#011loss=7.887083\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch[35] avg_epoch_loss=8.076318\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=140, batch=35 train loss <loss>=7.64224729538\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch [35]#011Speed: 1569.75 samples/sec#011loss=7.642247\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch[40] avg_epoch_loss=8.006634\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=140, batch=40 train loss <loss>=7.50491399765\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:51 INFO 139649395074880] Epoch[140] Batch [40]#011Speed: 1743.91 samples/sec#011loss=7.504914\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] Epoch[140] Batch[45] avg_epoch_loss=8.017380\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=140, batch=45 train loss <loss>=8.10549297333\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] Epoch[140] Batch [45]#011Speed: 769.93 samples/sec#011loss=8.105493\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] Epoch[140] Batch[50] avg_epoch_loss=8.018834\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=140, batch=50 train loss <loss>=8.03221073151\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] Epoch[140] Batch [50]#011Speed: 1394.12 samples/sec#011loss=8.032211\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] processed a total of 1666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1612.5688552856445, \"sum\": 1612.5688552856445, \"min\": 1612.5688552856445}}, \"EndTime\": 1577414632.335644, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414630.723016}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1033.06162805 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=140, train loss <loss>=7.98794456698\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] Epoch[141] Batch[0] avg_epoch_loss=7.655806\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=7.65580558777\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] Epoch[141] Batch[5] avg_epoch_loss=7.964364\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=7.96436444918\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] Epoch[141] Batch [5]#011Speed: 1531.41 samples/sec#011loss=7.964364\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] Epoch[141] Batch[10] avg_epoch_loss=8.165826\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=8.40757904053\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] Epoch[141] Batch [10]#011Speed: 706.19 samples/sec#011loss=8.407579\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] Epoch[141] Batch[15] avg_epoch_loss=8.195385\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=141, batch=15 train loss <loss>=8.26041612625\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:52 INFO 139649395074880] Epoch[141] Batch [15]#011Speed: 1538.12 samples/sec#011loss=8.260416\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch[20] avg_epoch_loss=8.106874\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=141, batch=20 train loss <loss>=7.82363710403\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch [20]#011Speed: 760.81 samples/sec#011loss=7.823637\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch[25] avg_epoch_loss=8.012366\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=141, batch=25 train loss <loss>=7.61543588638\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch [25]#011Speed: 1398.33 samples/sec#011loss=7.615436\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch[30] avg_epoch_loss=8.008630\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=141, batch=30 train loss <loss>=7.98919858932\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch [30]#011Speed: 752.08 samples/sec#011loss=7.989199\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch[35] avg_epoch_loss=7.959194\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=141, batch=35 train loss <loss>=7.65269451141\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch [35]#011Speed: 1528.92 samples/sec#011loss=7.652695\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch[40] avg_epoch_loss=7.903358\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=141, batch=40 train loss <loss>=7.50134067535\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch [40]#011Speed: 777.88 samples/sec#011loss=7.501341\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch[45] avg_epoch_loss=7.887970\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=141, batch=45 train loss <loss>=7.76178874969\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch [45]#011Speed: 1564.12 samples/sec#011loss=7.761789\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch[50] avg_epoch_loss=7.889606\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=141, batch=50 train loss <loss>=7.90465507507\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:53 INFO 139649395074880] Epoch[141] Batch [50]#011Speed: 1237.38 samples/sec#011loss=7.904655\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] processed a total of 1654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1667.4630641937256, \"sum\": 1667.4630641937256, \"min\": 1667.4630641937256}}, \"EndTime\": 1577414634.003626, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414632.335721}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=991.860073728 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=141, train loss <loss>=7.87974306253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] Epoch[142] Batch[0] avg_epoch_loss=8.224347\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=8.22434711456\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] Epoch[142] Batch[5] avg_epoch_loss=8.230635\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=8.23063484828\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] Epoch[142] Batch [5]#011Speed: 1666.72 samples/sec#011loss=8.230635\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] Epoch[142] Batch[10] avg_epoch_loss=8.165190\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=8.08665513992\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] Epoch[142] Batch [10]#011Speed: 769.50 samples/sec#011loss=8.086655\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] Epoch[142] Batch[15] avg_epoch_loss=8.244849\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=142, batch=15 train loss <loss>=8.42009935379\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] Epoch[142] Batch [15]#011Speed: 1426.60 samples/sec#011loss=8.420099\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] Epoch[142] Batch[20] avg_epoch_loss=8.227366\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=142, batch=20 train loss <loss>=8.17142248154\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] Epoch[142] Batch [20]#011Speed: 786.01 samples/sec#011loss=8.171422\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] Epoch[142] Batch[25] avg_epoch_loss=8.165360\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=142, batch=25 train loss <loss>=7.90493478775\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:54 INFO 139649395074880] Epoch[142] Batch [25]#011Speed: 1536.45 samples/sec#011loss=7.904935\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[142] Batch[30] avg_epoch_loss=8.122002\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=142, batch=30 train loss <loss>=7.89654026031\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[142] Batch [30]#011Speed: 709.82 samples/sec#011loss=7.896540\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[142] Batch[35] avg_epoch_loss=8.090090\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=142, batch=35 train loss <loss>=7.89223470688\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[142] Batch [35]#011Speed: 1341.00 samples/sec#011loss=7.892235\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[142] Batch[40] avg_epoch_loss=8.061761\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=142, batch=40 train loss <loss>=7.85779275894\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[142] Batch [40]#011Speed: 754.88 samples/sec#011loss=7.857793\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[142] Batch[45] avg_epoch_loss=8.045913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=142, batch=45 train loss <loss>=7.91596078873\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[142] Batch [45]#011Speed: 1635.74 samples/sec#011loss=7.915961\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[142] Batch[50] avg_epoch_loss=7.992987\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=142, batch=50 train loss <loss>=7.506062603\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[142] Batch [50]#011Speed: 1101.75 samples/sec#011loss=7.506063\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] processed a total of 1625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1691.7448043823242, \"sum\": 1691.7448043823242, \"min\": 1691.7448043823242}}, \"EndTime\": 1577414635.695886, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414634.003701}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=960.495056844 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=142, train loss <loss>=7.99298673518\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[143] Batch[0] avg_epoch_loss=8.628219\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=8.62821865082\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[143] Batch[5] avg_epoch_loss=8.179010\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=8.17901007334\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:55 INFO 139649395074880] Epoch[143] Batch [5]#011Speed: 1714.55 samples/sec#011loss=8.179010\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] Epoch[143] Batch[10] avg_epoch_loss=8.182122\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=8.18585681915\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] Epoch[143] Batch [10]#011Speed: 804.00 samples/sec#011loss=8.185857\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] Epoch[143] Batch[15] avg_epoch_loss=8.162151\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=143, batch=15 train loss <loss>=8.11821317673\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] Epoch[143] Batch [15]#011Speed: 1668.70 samples/sec#011loss=8.118213\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] Epoch[143] Batch[20] avg_epoch_loss=8.185248\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=143, batch=20 train loss <loss>=8.25915765762\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] Epoch[143] Batch [20]#011Speed: 799.25 samples/sec#011loss=8.259158\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] Epoch[143] Batch[25] avg_epoch_loss=8.114452\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=143, batch=25 train loss <loss>=7.81711053848\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] Epoch[143] Batch [25]#011Speed: 1433.04 samples/sec#011loss=7.817111\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] Epoch[143] Batch[30] avg_epoch_loss=8.045183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=143, batch=30 train loss <loss>=7.68498163223\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] Epoch[143] Batch [30]#011Speed: 698.74 samples/sec#011loss=7.684982\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] Epoch[143] Batch[35] avg_epoch_loss=7.984250\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=143, batch=35 train loss <loss>=7.60646696091\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:56 INFO 139649395074880] Epoch[143] Batch [35]#011Speed: 1751.02 samples/sec#011loss=7.606467\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[143] Batch[40] avg_epoch_loss=7.974889\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=143, batch=40 train loss <loss>=7.90748691559\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[143] Batch [40]#011Speed: 734.46 samples/sec#011loss=7.907487\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[143] Batch[45] avg_epoch_loss=7.981007\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=143, batch=45 train loss <loss>=8.0311788559\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[143] Batch [45]#011Speed: 1509.88 samples/sec#011loss=8.031179\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[143] Batch[50] avg_epoch_loss=7.938874\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=143, batch=50 train loss <loss>=7.55124673843\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[143] Batch [50]#011Speed: 1375.94 samples/sec#011loss=7.551247\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] processed a total of 1613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1587.2011184692383, \"sum\": 1587.2011184692383, \"min\": 1587.2011184692383}}, \"EndTime\": 1577414637.28357, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414635.695945}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1016.19616603 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=143, train loss <loss>=7.93887366501\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[144] Batch[0] avg_epoch_loss=8.275233\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=8.27523326874\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[144] Batch[5] avg_epoch_loss=8.273729\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=8.2737291654\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[144] Batch [5]#011Speed: 1548.92 samples/sec#011loss=8.273729\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[144] Batch[10] avg_epoch_loss=8.223808\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=8.16390361786\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[144] Batch [10]#011Speed: 749.12 samples/sec#011loss=8.163904\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[144] Batch[15] avg_epoch_loss=8.168340\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=144, batch=15 train loss <loss>=8.04630880356\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:57 INFO 139649395074880] Epoch[144] Batch [15]#011Speed: 1560.21 samples/sec#011loss=8.046309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] Epoch[144] Batch[20] avg_epoch_loss=8.110650\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=144, batch=20 train loss <loss>=7.92604265213\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] Epoch[144] Batch [20]#011Speed: 738.57 samples/sec#011loss=7.926043\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] Epoch[144] Batch[25] avg_epoch_loss=8.070325\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=144, batch=25 train loss <loss>=7.90096168518\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] Epoch[144] Batch [25]#011Speed: 1548.60 samples/sec#011loss=7.900962\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] Epoch[144] Batch[30] avg_epoch_loss=8.020302\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=144, batch=30 train loss <loss>=7.76018028259\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] Epoch[144] Batch [30]#011Speed: 756.27 samples/sec#011loss=7.760180\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] Epoch[144] Batch[35] avg_epoch_loss=7.970834\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=144, batch=35 train loss <loss>=7.66413164139\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] Epoch[144] Batch [35]#011Speed: 1582.40 samples/sec#011loss=7.664132\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] Epoch[144] Batch[40] avg_epoch_loss=7.936067\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=144, batch=40 train loss <loss>=7.68574171066\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] Epoch[144] Batch [40]#011Speed: 777.64 samples/sec#011loss=7.685742\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] Epoch[144] Batch[45] avg_epoch_loss=7.941076\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=144, batch=45 train loss <loss>=7.98215684891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] Epoch[144] Batch [45]#011Speed: 1699.52 samples/sec#011loss=7.982157\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] processed a total of 1591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1589.2419815063477, \"sum\": 1589.2419815063477, \"min\": 1589.2419815063477}}, \"EndTime\": 1577414638.87333, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414637.283629}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1001.03561681 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=144, train loss <loss>=7.90506757736\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:58 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch[0] avg_epoch_loss=8.193220\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=8.19322013855\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch[5] avg_epoch_loss=8.017766\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=8.01776607831\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch [5]#011Speed: 1577.04 samples/sec#011loss=8.017766\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch[10] avg_epoch_loss=8.114854\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=8.23135929108\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch [10]#011Speed: 809.70 samples/sec#011loss=8.231359\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch[15] avg_epoch_loss=8.162261\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=145, batch=15 train loss <loss>=8.2665561676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch [15]#011Speed: 1527.17 samples/sec#011loss=8.266556\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch[20] avg_epoch_loss=8.156866\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=145, batch=20 train loss <loss>=8.13960180283\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch [20]#011Speed: 761.15 samples/sec#011loss=8.139602\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch[25] avg_epoch_loss=8.106216\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=145, batch=25 train loss <loss>=7.89348697662\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch [25]#011Speed: 1543.15 samples/sec#011loss=7.893487\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch[30] avg_epoch_loss=8.052372\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=145, batch=30 train loss <loss>=7.77238588333\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:43:59 INFO 139649395074880] Epoch[145] Batch [30]#011Speed: 812.31 samples/sec#011loss=7.772386\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] Epoch[145] Batch[35] avg_epoch_loss=8.024531\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=145, batch=35 train loss <loss>=7.85191421509\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] Epoch[145] Batch [35]#011Speed: 1581.62 samples/sec#011loss=7.851914\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] Epoch[145] Batch[40] avg_epoch_loss=7.984812\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=145, batch=40 train loss <loss>=7.6988319397\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] Epoch[145] Batch [40]#011Speed: 728.57 samples/sec#011loss=7.698832\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] Epoch[145] Batch[45] avg_epoch_loss=7.969870\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=145, batch=45 train loss <loss>=7.84735298157\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] Epoch[145] Batch [45]#011Speed: 1569.75 samples/sec#011loss=7.847353\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] processed a total of 1582 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1592.1199321746826, \"sum\": 1592.1199321746826, \"min\": 1592.1199321746826}}, \"EndTime\": 1577414640.465972, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414638.873408}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=993.590768518 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=145, train loss <loss>=7.91831216812\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] Epoch[146] Batch[0] avg_epoch_loss=8.132349\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=8.13234901428\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] Epoch[146] Batch[5] avg_epoch_loss=7.914822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=7.91482186317\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] Epoch[146] Batch [5]#011Speed: 1338.04 samples/sec#011loss=7.914822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] Epoch[146] Batch[10] avg_epoch_loss=8.166941\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=8.46948471069\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:00 INFO 139649395074880] Epoch[146] Batch [10]#011Speed: 734.42 samples/sec#011loss=8.469485\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch[15] avg_epoch_loss=8.188991\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=146, batch=15 train loss <loss>=8.23749876022\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch [15]#011Speed: 1461.63 samples/sec#011loss=8.237499\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch[20] avg_epoch_loss=8.173144\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=146, batch=20 train loss <loss>=8.1224360466\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch [20]#011Speed: 777.92 samples/sec#011loss=8.122436\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch[25] avg_epoch_loss=8.123524\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=146, batch=25 train loss <loss>=7.91511917114\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch [25]#011Speed: 1574.32 samples/sec#011loss=7.915119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch[30] avg_epoch_loss=8.075288\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=146, batch=30 train loss <loss>=7.82445964813\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch [30]#011Speed: 783.09 samples/sec#011loss=7.824460\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch[35] avg_epoch_loss=8.018114\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=146, batch=35 train loss <loss>=7.66363430023\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch [35]#011Speed: 1552.69 samples/sec#011loss=7.663634\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch[40] avg_epoch_loss=7.989563\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=146, batch=40 train loss <loss>=7.78399429321\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch [40]#011Speed: 678.77 samples/sec#011loss=7.783994\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch[45] avg_epoch_loss=7.981408\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=146, batch=45 train loss <loss>=7.91453952789\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:01 INFO 139649395074880] Epoch[146] Batch [45]#011Speed: 1698.75 samples/sec#011loss=7.914540\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[146] Batch[50] avg_epoch_loss=8.010509\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=146, batch=50 train loss <loss>=8.27824010849\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[146] Batch [50]#011Speed: 1173.20 samples/sec#011loss=8.278240\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] processed a total of 1608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1652.660846710205, \"sum\": 1652.660846710205, \"min\": 1652.660846710205}}, \"EndTime\": 1577414642.119147, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414640.466025}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=972.910291965 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=146, train loss <loss>=8.01050909828\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[147] Batch[0] avg_epoch_loss=8.246950\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=8.24695014954\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[147] Batch[5] avg_epoch_loss=8.232334\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=8.23233437538\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[147] Batch [5]#011Speed: 1550.54 samples/sec#011loss=8.232334\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[147] Batch[10] avg_epoch_loss=8.207704\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=8.17814674377\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[147] Batch [10]#011Speed: 805.49 samples/sec#011loss=8.178147\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[147] Batch[15] avg_epoch_loss=8.208424\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=147, batch=15 train loss <loss>=8.21000995636\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[147] Batch [15]#011Speed: 1510.49 samples/sec#011loss=8.210010\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[147] Batch[20] avg_epoch_loss=8.205840\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=147, batch=20 train loss <loss>=8.19756803513\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[147] Batch [20]#011Speed: 690.95 samples/sec#011loss=8.197568\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[147] Batch[25] avg_epoch_loss=8.148917\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=147, batch=25 train loss <loss>=7.90984477997\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:02 INFO 139649395074880] Epoch[147] Batch [25]#011Speed: 1654.26 samples/sec#011loss=7.909845\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] Epoch[147] Batch[30] avg_epoch_loss=8.063084\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=147, batch=30 train loss <loss>=7.61674900055\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] Epoch[147] Batch [30]#011Speed: 756.16 samples/sec#011loss=7.616749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] Epoch[147] Batch[35] avg_epoch_loss=8.041636\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=147, batch=35 train loss <loss>=7.90866117477\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] Epoch[147] Batch [35]#011Speed: 1509.75 samples/sec#011loss=7.908661\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] Epoch[147] Batch[40] avg_epoch_loss=8.021107\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=147, batch=40 train loss <loss>=7.87329387665\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] Epoch[147] Batch [40]#011Speed: 737.13 samples/sec#011loss=7.873294\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] Epoch[147] Batch[45] avg_epoch_loss=7.984545\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=147, batch=45 train loss <loss>=7.68474092484\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] Epoch[147] Batch [45]#011Speed: 1513.20 samples/sec#011loss=7.684741\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] Epoch[147] Batch[50] avg_epoch_loss=7.957414\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=147, batch=50 train loss <loss>=7.70780687332\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] Epoch[147] Batch [50]#011Speed: 1133.82 samples/sec#011loss=7.707807\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] processed a total of 1610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1660.128116607666, \"sum\": 1660.128116607666, \"min\": 1660.128116607666}}, \"EndTime\": 1577414643.779798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414642.119224}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=969.748126226 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=147, train loss <loss>=7.95741398194\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] Epoch[148] Batch[0] avg_epoch_loss=8.048867\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=8.04886722565\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch[5] avg_epoch_loss=8.116075\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=8.11607503891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch [5]#011Speed: 1507.19 samples/sec#011loss=8.116075\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch[10] avg_epoch_loss=8.133793\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=8.1550538063\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch [10]#011Speed: 760.65 samples/sec#011loss=8.155054\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch[15] avg_epoch_loss=8.196546\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=148, batch=15 train loss <loss>=8.33460245132\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch [15]#011Speed: 1593.32 samples/sec#011loss=8.334602\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch[20] avg_epoch_loss=8.095428\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=148, batch=20 train loss <loss>=7.77185144424\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch [20]#011Speed: 764.95 samples/sec#011loss=7.771851\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch[25] avg_epoch_loss=8.013630\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=148, batch=25 train loss <loss>=7.67007932663\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch [25]#011Speed: 1406.62 samples/sec#011loss=7.670079\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch[30] avg_epoch_loss=7.946359\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=148, batch=30 train loss <loss>=7.59655179977\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch [30]#011Speed: 789.45 samples/sec#011loss=7.596552\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch[35] avg_epoch_loss=7.928950\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=148, batch=35 train loss <loss>=7.82101259232\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:04 INFO 139649395074880] Epoch[148] Batch [35]#011Speed: 1566.77 samples/sec#011loss=7.821013\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] Epoch[148] Batch[40] avg_epoch_loss=7.924637\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=148, batch=40 train loss <loss>=7.89357814789\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] Epoch[148] Batch [40]#011Speed: 797.83 samples/sec#011loss=7.893578\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] Epoch[148] Batch[45] avg_epoch_loss=7.922686\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=148, batch=45 train loss <loss>=7.90669317245\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] Epoch[148] Batch [45]#011Speed: 1412.09 samples/sec#011loss=7.906693\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] processed a total of 1579 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1604.543924331665, \"sum\": 1604.543924331665, \"min\": 1604.543924331665}}, \"EndTime\": 1577414645.384874, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414643.779861}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=984.010953256 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=148, train loss <loss>=7.87188406944\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] Epoch[149] Batch[0] avg_epoch_loss=8.028466\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=8.02846622467\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] Epoch[149] Batch[5] avg_epoch_loss=7.771601\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=7.77160088221\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] Epoch[149] Batch [5]#011Speed: 1551.29 samples/sec#011loss=7.771601\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] Epoch[149] Batch[10] avg_epoch_loss=7.938584\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=8.13896379471\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] Epoch[149] Batch [10]#011Speed: 765.27 samples/sec#011loss=8.138964\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] Epoch[149] Batch[15] avg_epoch_loss=8.031647\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=149, batch=15 train loss <loss>=8.2363863945\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:05 INFO 139649395074880] Epoch[149] Batch [15]#011Speed: 1600.54 samples/sec#011loss=8.236386\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch[20] avg_epoch_loss=8.054989\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=149, batch=20 train loss <loss>=8.12968435287\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch [20]#011Speed: 747.35 samples/sec#011loss=8.129684\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch[25] avg_epoch_loss=7.982248\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=149, batch=25 train loss <loss>=7.67673282623\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch [25]#011Speed: 1588.04 samples/sec#011loss=7.676733\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch[30] avg_epoch_loss=7.962093\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=149, batch=30 train loss <loss>=7.85728845596\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch [30]#011Speed: 802.22 samples/sec#011loss=7.857288\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch[35] avg_epoch_loss=7.923876\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=149, batch=35 train loss <loss>=7.68693227768\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch [35]#011Speed: 1597.68 samples/sec#011loss=7.686932\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch[40] avg_epoch_loss=7.935636\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=149, batch=40 train loss <loss>=8.02030563354\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch [40]#011Speed: 742.12 samples/sec#011loss=8.020306\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch[45] avg_epoch_loss=7.888820\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=149, batch=45 train loss <loss>=7.50493125916\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch [45]#011Speed: 1693.91 samples/sec#011loss=7.504931\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch[50] avg_epoch_loss=7.851010\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=149, batch=50 train loss <loss>=7.50315132141\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] Epoch[149] Batch [50]#011Speed: 1221.48 samples/sec#011loss=7.503151\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] processed a total of 1611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1605.6618690490723, \"sum\": 1605.6618690490723, \"min\": 1605.6618690490723}}, \"EndTime\": 1577414646.991084, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414645.38495}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1003.25708398 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=149, train loss <loss>=7.85100954654\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:06 INFO 139649395074880] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] Epoch[150] Batch[0] avg_epoch_loss=8.581053\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=8.58105278015\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] Epoch[150] Batch[5] avg_epoch_loss=8.043916\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=8.04391551018\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] Epoch[150] Batch [5]#011Speed: 1529.53 samples/sec#011loss=8.043916\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] Epoch[150] Batch[10] avg_epoch_loss=8.142045\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=8.25980081558\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] Epoch[150] Batch [10]#011Speed: 798.17 samples/sec#011loss=8.259801\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] Epoch[150] Batch[15] avg_epoch_loss=8.153970\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=150, batch=15 train loss <loss>=8.18020401001\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] Epoch[150] Batch [15]#011Speed: 1712.76 samples/sec#011loss=8.180204\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] Epoch[150] Batch[20] avg_epoch_loss=8.115481\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=150, batch=20 train loss <loss>=7.99231872559\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] Epoch[150] Batch [20]#011Speed: 762.11 samples/sec#011loss=7.992319\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] Epoch[150] Batch[25] avg_epoch_loss=7.983073\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=150, batch=25 train loss <loss>=7.4269575119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:07 INFO 139649395074880] Epoch[150] Batch [25]#011Speed: 1570.63 samples/sec#011loss=7.426958\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[150] Batch[30] avg_epoch_loss=7.949229\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=150, batch=30 train loss <loss>=7.77324075699\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[150] Batch [30]#011Speed: 798.09 samples/sec#011loss=7.773241\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[150] Batch[35] avg_epoch_loss=7.952571\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=150, batch=35 train loss <loss>=7.97328882217\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[150] Batch [35]#011Speed: 1721.06 samples/sec#011loss=7.973289\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[150] Batch[40] avg_epoch_loss=7.910980\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=150, batch=40 train loss <loss>=7.61153078079\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[150] Batch [40]#011Speed: 768.88 samples/sec#011loss=7.611531\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[150] Batch[45] avg_epoch_loss=7.924328\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=150, batch=45 train loss <loss>=8.03377723694\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[150] Batch [45]#011Speed: 1717.53 samples/sec#011loss=8.033777\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[150] Batch[50] avg_epoch_loss=7.904233\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=150, batch=50 train loss <loss>=7.71936178207\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[150] Batch [50]#011Speed: 1158.46 samples/sec#011loss=7.719362\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] processed a total of 1632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1577.2349834442139, \"sum\": 1577.2349834442139, \"min\": 1577.2349834442139}}, \"EndTime\": 1577414648.568833, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414646.991159}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1034.65069212 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=150, train loss <loss>=7.90423324061\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[151] Batch[0] avg_epoch_loss=7.830321\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=7.83032083511\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[151] Batch[5] avg_epoch_loss=8.166870\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=8.16686987877\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:08 INFO 139649395074880] Epoch[151] Batch [5]#011Speed: 1548.42 samples/sec#011loss=8.166870\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch[10] avg_epoch_loss=8.162010\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=8.15617904663\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch [10]#011Speed: 770.59 samples/sec#011loss=8.156179\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch[15] avg_epoch_loss=8.176043\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=151, batch=15 train loss <loss>=8.20691423416\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch [15]#011Speed: 1557.01 samples/sec#011loss=8.206914\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch[20] avg_epoch_loss=8.169866\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=151, batch=20 train loss <loss>=8.15010099411\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch [20]#011Speed: 793.44 samples/sec#011loss=8.150101\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch[25] avg_epoch_loss=8.083347\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=151, batch=25 train loss <loss>=7.71996688843\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch [25]#011Speed: 1517.16 samples/sec#011loss=7.719967\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch[30] avg_epoch_loss=8.013956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=151, batch=30 train loss <loss>=7.65312271118\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch [30]#011Speed: 809.92 samples/sec#011loss=7.653123\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch[35] avg_epoch_loss=7.945087\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=151, batch=35 train loss <loss>=7.51809568405\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch [35]#011Speed: 1451.31 samples/sec#011loss=7.518096\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch[40] avg_epoch_loss=7.936183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=151, batch=40 train loss <loss>=7.87207746506\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:09 INFO 139649395074880] Epoch[151] Batch [40]#011Speed: 683.83 samples/sec#011loss=7.872077\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] Epoch[151] Batch[45] avg_epoch_loss=7.946038\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=151, batch=45 train loss <loss>=8.0268445015\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] Epoch[151] Batch [45]#011Speed: 1656.55 samples/sec#011loss=8.026845\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] processed a total of 1588 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1596.6200828552246, \"sum\": 1596.6200828552246, \"min\": 1596.6200828552246}}, \"EndTime\": 1577414650.165947, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414648.568909}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=994.531391799 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=151, train loss <loss>=7.88434263229\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] Epoch[152] Batch[0] avg_epoch_loss=8.205797\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=8.20579719543\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] Epoch[152] Batch[5] avg_epoch_loss=8.156874\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=8.15687433879\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] Epoch[152] Batch [5]#011Speed: 1621.32 samples/sec#011loss=8.156874\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] Epoch[152] Batch[10] avg_epoch_loss=8.119616\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=8.07490568161\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] Epoch[152] Batch [10]#011Speed: 771.38 samples/sec#011loss=8.074906\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] Epoch[152] Batch[15] avg_epoch_loss=8.167596\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=152, batch=15 train loss <loss>=8.27315216064\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] Epoch[152] Batch [15]#011Speed: 1369.38 samples/sec#011loss=8.273152\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] Epoch[152] Batch[20] avg_epoch_loss=8.137001\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=152, batch=20 train loss <loss>=8.03909816742\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:10 INFO 139649395074880] Epoch[152] Batch [20]#011Speed: 769.43 samples/sec#011loss=8.039098\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[152] Batch[25] avg_epoch_loss=8.044379\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=152, batch=25 train loss <loss>=7.65536384583\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[152] Batch [25]#011Speed: 1564.61 samples/sec#011loss=7.655364\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[152] Batch[30] avg_epoch_loss=7.975764\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=152, batch=30 train loss <loss>=7.61897010803\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[152] Batch [30]#011Speed: 769.97 samples/sec#011loss=7.618970\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[152] Batch[35] avg_epoch_loss=7.951431\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=152, batch=35 train loss <loss>=7.80056610107\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[152] Batch [35]#011Speed: 1542.02 samples/sec#011loss=7.800566\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[152] Batch[40] avg_epoch_loss=7.927751\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=152, batch=40 train loss <loss>=7.75725297928\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[152] Batch [40]#011Speed: 760.90 samples/sec#011loss=7.757253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[152] Batch[45] avg_epoch_loss=7.943097\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=152, batch=45 train loss <loss>=8.06893768311\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[152] Batch [45]#011Speed: 1563.52 samples/sec#011loss=8.068938\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] processed a total of 1561 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1568.4120655059814, \"sum\": 1568.4120655059814, \"min\": 1568.4120655059814}}, \"EndTime\": 1577414651.73488, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414650.166025}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=995.209409583 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=152, train loss <loss>=7.90788346894\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[153] Batch[0] avg_epoch_loss=7.657764\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=7.65776443481\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[153] Batch[5] avg_epoch_loss=7.802584\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=7.80258425077\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:11 INFO 139649395074880] Epoch[153] Batch [5]#011Speed: 1564.82 samples/sec#011loss=7.802584\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] Epoch[153] Batch[10] avg_epoch_loss=8.067193\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=8.38472242355\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] Epoch[153] Batch [10]#011Speed: 806.09 samples/sec#011loss=8.384722\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] Epoch[153] Batch[15] avg_epoch_loss=8.100253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=153, batch=15 train loss <loss>=8.17298679352\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] Epoch[153] Batch [15]#011Speed: 1304.80 samples/sec#011loss=8.172987\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] Epoch[153] Batch[20] avg_epoch_loss=8.064012\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=153, batch=20 train loss <loss>=7.94804077148\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] Epoch[153] Batch [20]#011Speed: 761.66 samples/sec#011loss=7.948041\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] Epoch[153] Batch[25] avg_epoch_loss=7.980545\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=153, batch=25 train loss <loss>=7.62998046875\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] Epoch[153] Batch [25]#011Speed: 1565.31 samples/sec#011loss=7.629980\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] Epoch[153] Batch[30] avg_epoch_loss=7.939192\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=153, batch=30 train loss <loss>=7.72415781021\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] Epoch[153] Batch [30]#011Speed: 819.43 samples/sec#011loss=7.724158\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] Epoch[153] Batch[35] avg_epoch_loss=7.901108\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=153, batch=35 train loss <loss>=7.66498718262\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:12 INFO 139649395074880] Epoch[153] Batch [35]#011Speed: 1551.03 samples/sec#011loss=7.664987\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[153] Batch[40] avg_epoch_loss=7.894526\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=153, batch=40 train loss <loss>=7.84713945389\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[153] Batch [40]#011Speed: 805.75 samples/sec#011loss=7.847139\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[153] Batch[45] avg_epoch_loss=7.894106\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=153, batch=45 train loss <loss>=7.89065551758\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[153] Batch [45]#011Speed: 1574.37 samples/sec#011loss=7.890656\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[153] Batch[50] avg_epoch_loss=7.838230\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=153, batch=50 train loss <loss>=7.32417926788\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[153] Batch [50]#011Speed: 1280.84 samples/sec#011loss=7.324179\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] processed a total of 1608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1585.6969356536865, \"sum\": 1585.6969356536865, \"min\": 1585.6969356536865}}, \"EndTime\": 1577414653.321137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414651.734945}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1013.9966948 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=153, train loss <loss>=7.83823046965\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[154] Batch[0] avg_epoch_loss=7.857862\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=7.85786151886\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[154] Batch[5] avg_epoch_loss=8.128233\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=8.12823311488\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[154] Batch [5]#011Speed: 1398.27 samples/sec#011loss=8.128233\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[154] Batch[10] avg_epoch_loss=8.155716\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=8.18869457245\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[154] Batch [10]#011Speed: 789.12 samples/sec#011loss=8.188695\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[154] Batch[15] avg_epoch_loss=8.250980\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=154, batch=15 train loss <loss>=8.46056232452\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:13 INFO 139649395074880] Epoch[154] Batch [15]#011Speed: 1337.99 samples/sec#011loss=8.460562\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch[20] avg_epoch_loss=8.282857\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=154, batch=20 train loss <loss>=8.3848608017\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch [20]#011Speed: 772.97 samples/sec#011loss=8.384861\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch[25] avg_epoch_loss=8.157466\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=154, batch=25 train loss <loss>=7.63082418442\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch [25]#011Speed: 1576.55 samples/sec#011loss=7.630824\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch[30] avg_epoch_loss=8.111261\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=154, batch=30 train loss <loss>=7.87099428177\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch [30]#011Speed: 713.19 samples/sec#011loss=7.870994\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch[35] avg_epoch_loss=8.065889\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=154, batch=35 train loss <loss>=7.78458824158\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch [35]#011Speed: 1498.39 samples/sec#011loss=7.784588\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch[40] avg_epoch_loss=8.018699\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=154, batch=40 train loss <loss>=7.67893009186\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch [40]#011Speed: 797.83 samples/sec#011loss=7.678930\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch[45] avg_epoch_loss=8.013233\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=154, batch=45 train loss <loss>=7.96840896606\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch [45]#011Speed: 1593.40 samples/sec#011loss=7.968409\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch[50] avg_epoch_loss=8.007094\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=154, batch=50 train loss <loss>=7.95061149597\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] Epoch[154] Batch [50]#011Speed: 1240.03 samples/sec#011loss=7.950611\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] processed a total of 1663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1663.6319160461426, \"sum\": 1663.6319160461426, \"min\": 1663.6319160461426}}, \"EndTime\": 1577414654.985269, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414653.321212}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=999.554121319 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=154, train loss <loss>=7.98938174431\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:14 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] Epoch[155] Batch[0] avg_epoch_loss=7.570631\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=7.57063055038\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] Epoch[155] Batch[5] avg_epoch_loss=7.840225\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=7.84022466342\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] Epoch[155] Batch [5]#011Speed: 1706.16 samples/sec#011loss=7.840225\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] Epoch[155] Batch[10] avg_epoch_loss=7.913835\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=8.00216798782\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] Epoch[155] Batch [10]#011Speed: 759.51 samples/sec#011loss=8.002168\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] Epoch[155] Batch[15] avg_epoch_loss=8.058848\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=155, batch=15 train loss <loss>=8.37787628174\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] Epoch[155] Batch [15]#011Speed: 1684.92 samples/sec#011loss=8.377876\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] Epoch[155] Batch[20] avg_epoch_loss=8.100541\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=155, batch=20 train loss <loss>=8.23396034241\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] Epoch[155] Batch [20]#011Speed: 647.46 samples/sec#011loss=8.233960\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] Epoch[155] Batch[25] avg_epoch_loss=8.008965\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=155, batch=25 train loss <loss>=7.62434196472\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:15 INFO 139649395074880] Epoch[155] Batch [25]#011Speed: 1257.44 samples/sec#011loss=7.624342\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[155] Batch[30] avg_epoch_loss=7.927117\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=155, batch=30 train loss <loss>=7.50150747299\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[155] Batch [30]#011Speed: 745.66 samples/sec#011loss=7.501507\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[155] Batch[35] avg_epoch_loss=7.900542\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=155, batch=35 train loss <loss>=7.73577976227\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[155] Batch [35]#011Speed: 1725.78 samples/sec#011loss=7.735780\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[155] Batch[40] avg_epoch_loss=7.910244\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=155, batch=40 train loss <loss>=7.98009748459\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[155] Batch [40]#011Speed: 711.58 samples/sec#011loss=7.980097\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[155] Batch[45] avg_epoch_loss=7.883758\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=155, batch=45 train loss <loss>=7.66657657623\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[155] Batch [45]#011Speed: 1553.04 samples/sec#011loss=7.666577\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[155] Batch[50] avg_epoch_loss=7.831180\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=155, batch=50 train loss <loss>=7.34745435715\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[155] Batch [50]#011Speed: 1342.16 samples/sec#011loss=7.347454\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] processed a total of 1610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1675.7500171661377, \"sum\": 1675.7500171661377, \"min\": 1675.7500171661377}}, \"EndTime\": 1577414656.661527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414654.985345}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=960.699038949 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=155, train loss <loss>=7.83117959079\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_ab4e827b-c839-4df4-9fff-d65e03239d4b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 21.541118621826172, \"sum\": 21.541118621826172, \"min\": 21.541118621826172}}, \"EndTime\": 1577414656.683653, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414656.661607}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[156] Batch[0] avg_epoch_loss=7.937880\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=7.93788003922\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[156] Batch[5] avg_epoch_loss=8.101527\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=8.101527373\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:16 INFO 139649395074880] Epoch[156] Batch [5]#011Speed: 1680.49 samples/sec#011loss=8.101527\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] Epoch[156] Batch[10] avg_epoch_loss=8.230465\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=8.38518943787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] Epoch[156] Batch [10]#011Speed: 769.96 samples/sec#011loss=8.385189\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] Epoch[156] Batch[15] avg_epoch_loss=8.168919\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=156, batch=15 train loss <loss>=8.03351955414\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] Epoch[156] Batch [15]#011Speed: 1566.98 samples/sec#011loss=8.033520\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] Epoch[156] Batch[20] avg_epoch_loss=8.131265\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=156, batch=20 train loss <loss>=8.01077013016\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] Epoch[156] Batch [20]#011Speed: 788.37 samples/sec#011loss=8.010770\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] Epoch[156] Batch[25] avg_epoch_loss=8.069593\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=156, batch=25 train loss <loss>=7.81057195663\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] Epoch[156] Batch [25]#011Speed: 1563.35 samples/sec#011loss=7.810572\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] Epoch[156] Batch[30] avg_epoch_loss=8.002274\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=156, batch=30 train loss <loss>=7.65221729279\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] Epoch[156] Batch [30]#011Speed: 785.51 samples/sec#011loss=7.652217\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] Epoch[156] Batch[35] avg_epoch_loss=7.959064\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=156, batch=35 train loss <loss>=7.69116287231\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:17 INFO 139649395074880] Epoch[156] Batch [35]#011Speed: 1546.57 samples/sec#011loss=7.691163\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[156] Batch[40] avg_epoch_loss=7.922800\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=156, batch=40 train loss <loss>=7.66169261932\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[156] Batch [40]#011Speed: 777.92 samples/sec#011loss=7.661693\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[156] Batch[45] avg_epoch_loss=7.924353\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=156, batch=45 train loss <loss>=7.93709020615\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[156] Batch [45]#011Speed: 1668.46 samples/sec#011loss=7.937090\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] processed a total of 1591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1560.9118938446045, \"sum\": 1560.9118938446045, \"min\": 1560.9118938446045}}, \"EndTime\": 1577414658.24468, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414656.683715}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1019.20483563 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=156, train loss <loss>=7.89036944389\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[157] Batch[0] avg_epoch_loss=8.765049\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=8.76504898071\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[157] Batch[5] avg_epoch_loss=8.324655\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=8.32465545336\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[157] Batch [5]#011Speed: 1437.74 samples/sec#011loss=8.324655\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[157] Batch[10] avg_epoch_loss=8.199564\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=8.04945363998\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[157] Batch [10]#011Speed: 771.99 samples/sec#011loss=8.049454\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[157] Batch[15] avg_epoch_loss=8.266031\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=157, batch=15 train loss <loss>=8.41226043701\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[157] Batch [15]#011Speed: 1612.84 samples/sec#011loss=8.412260\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[157] Batch[20] avg_epoch_loss=8.190647\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=157, batch=20 train loss <loss>=7.94941473007\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:18 INFO 139649395074880] Epoch[157] Batch [20]#011Speed: 772.16 samples/sec#011loss=7.949415\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[157] Batch[25] avg_epoch_loss=8.113012\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=157, batch=25 train loss <loss>=7.78694458008\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[157] Batch [25]#011Speed: 1502.38 samples/sec#011loss=7.786945\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[157] Batch[30] avg_epoch_loss=8.076606\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=157, batch=30 train loss <loss>=7.8873003006\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[157] Batch [30]#011Speed: 772.25 samples/sec#011loss=7.887300\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[157] Batch[35] avg_epoch_loss=8.019091\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=157, batch=35 train loss <loss>=7.66249818802\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[157] Batch [35]#011Speed: 1502.01 samples/sec#011loss=7.662498\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[157] Batch[40] avg_epoch_loss=8.006364\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=157, batch=40 train loss <loss>=7.91472768784\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[157] Batch [40]#011Speed: 778.07 samples/sec#011loss=7.914728\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[157] Batch[45] avg_epoch_loss=7.993998\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=157, batch=45 train loss <loss>=7.89259843826\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[157] Batch [45]#011Speed: 1649.02 samples/sec#011loss=7.892598\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[157] Batch[50] avg_epoch_loss=7.933622\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=157, batch=50 train loss <loss>=7.37815933228\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[157] Batch [50]#011Speed: 1264.95 samples/sec#011loss=7.378159\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] processed a total of 1613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1604.3598651885986, \"sum\": 1604.3598651885986, \"min\": 1604.3598651885986}}, \"EndTime\": 1577414659.849607, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414658.244756}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1005.31504371 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=157, train loss <loss>=7.93362194884\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] Epoch[158] Batch[0] avg_epoch_loss=7.689423\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=7.68942308426\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] Epoch[158] Batch[5] avg_epoch_loss=8.161787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=8.16178679466\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] Epoch[158] Batch [5]#011Speed: 1560.78 samples/sec#011loss=8.161787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] Epoch[158] Batch[10] avg_epoch_loss=8.199695\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=8.24518375397\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] Epoch[158] Batch [10]#011Speed: 780.64 samples/sec#011loss=8.245184\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] Epoch[158] Batch[15] avg_epoch_loss=8.237690\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=158, batch=15 train loss <loss>=8.32128095627\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] Epoch[158] Batch [15]#011Speed: 1254.14 samples/sec#011loss=8.321281\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] Epoch[158] Batch[20] avg_epoch_loss=8.187042\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=158, batch=20 train loss <loss>=8.0249666214\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] Epoch[158] Batch [20]#011Speed: 797.79 samples/sec#011loss=8.024967\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] Epoch[158] Batch[25] avg_epoch_loss=8.146226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=158, batch=25 train loss <loss>=7.97480134964\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] Epoch[158] Batch [25]#011Speed: 1430.59 samples/sec#011loss=7.974801\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] Epoch[158] Batch[30] avg_epoch_loss=8.083272\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=158, batch=30 train loss <loss>=7.75590696335\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:20 INFO 139649395074880] Epoch[158] Batch [30]#011Speed: 710.45 samples/sec#011loss=7.755907\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] Epoch[158] Batch[35] avg_epoch_loss=8.020182\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=158, batch=35 train loss <loss>=7.62903003693\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] Epoch[158] Batch [35]#011Speed: 1307.19 samples/sec#011loss=7.629030\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] Epoch[158] Batch[40] avg_epoch_loss=7.979292\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=158, batch=40 train loss <loss>=7.68487892151\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] Epoch[158] Batch [40]#011Speed: 721.02 samples/sec#011loss=7.684879\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] Epoch[158] Batch[45] avg_epoch_loss=7.958758\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=158, batch=45 train loss <loss>=7.79037675858\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] Epoch[158] Batch [45]#011Speed: 1252.23 samples/sec#011loss=7.790377\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] processed a total of 1575 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1691.2658214569092, \"sum\": 1691.2658214569092, \"min\": 1691.2658214569092}}, \"EndTime\": 1577414661.541369, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414659.849683}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=931.198305751 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=158, train loss <loss>=7.91083983421\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] Epoch[159] Batch[0] avg_epoch_loss=7.937531\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=7.93753051758\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] Epoch[159] Batch[5] avg_epoch_loss=7.983054\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=7.98305376371\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:21 INFO 139649395074880] Epoch[159] Batch [5]#011Speed: 1288.82 samples/sec#011loss=7.983054\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch[10] avg_epoch_loss=8.099782\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=8.23985528946\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch [10]#011Speed: 738.76 samples/sec#011loss=8.239855\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch[15] avg_epoch_loss=8.129629\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=159, batch=15 train loss <loss>=8.19529285431\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch [15]#011Speed: 1358.90 samples/sec#011loss=8.195293\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch[20] avg_epoch_loss=8.101653\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=159, batch=20 train loss <loss>=8.01212902069\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch [20]#011Speed: 826.55 samples/sec#011loss=8.012129\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch[25] avg_epoch_loss=8.027152\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=159, batch=25 train loss <loss>=7.71424865723\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch [25]#011Speed: 1646.35 samples/sec#011loss=7.714249\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch[30] avg_epoch_loss=7.974623\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=159, batch=30 train loss <loss>=7.70147380829\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch [30]#011Speed: 715.25 samples/sec#011loss=7.701474\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch[35] avg_epoch_loss=7.943984\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=159, batch=35 train loss <loss>=7.75401973724\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch [35]#011Speed: 1417.18 samples/sec#011loss=7.754020\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch[40] avg_epoch_loss=7.891857\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=159, batch=40 train loss <loss>=7.51654653549\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:22 INFO 139649395074880] Epoch[159] Batch [40]#011Speed: 763.39 samples/sec#011loss=7.516547\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[159] Batch[45] avg_epoch_loss=7.905232\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=159, batch=45 train loss <loss>=8.01490812302\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[159] Batch [45]#011Speed: 1159.91 samples/sec#011loss=8.014908\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] processed a total of 1515 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1601.1638641357422, \"sum\": 1601.1638641357422, \"min\": 1601.1638641357422}}, \"EndTime\": 1577414663.143093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414661.541439}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=946.119247848 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=159, train loss <loss>=7.96523433924\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[160] Batch[0] avg_epoch_loss=8.830940\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=8.83094024658\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[160] Batch[5] avg_epoch_loss=8.340553\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=8.34055288633\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[160] Batch [5]#011Speed: 1550.39 samples/sec#011loss=8.340553\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[160] Batch[10] avg_epoch_loss=8.270561\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=8.18657121658\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[160] Batch [10]#011Speed: 814.56 samples/sec#011loss=8.186571\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[160] Batch[15] avg_epoch_loss=8.337452\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=160, batch=15 train loss <loss>=8.48461322784\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[160] Batch [15]#011Speed: 1665.04 samples/sec#011loss=8.484613\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[160] Batch[20] avg_epoch_loss=8.336942\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=160, batch=20 train loss <loss>=8.33530921936\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[160] Batch [20]#011Speed: 746.50 samples/sec#011loss=8.335309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[160] Batch[25] avg_epoch_loss=8.235479\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=160, batch=25 train loss <loss>=7.80933475494\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:23 INFO 139649395074880] Epoch[160] Batch [25]#011Speed: 1475.43 samples/sec#011loss=7.809335\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] Epoch[160] Batch[30] avg_epoch_loss=8.140424\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=160, batch=30 train loss <loss>=7.64613609314\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] Epoch[160] Batch [30]#011Speed: 773.25 samples/sec#011loss=7.646136\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] Epoch[160] Batch[35] avg_epoch_loss=8.094815\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=160, batch=35 train loss <loss>=7.81203861237\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] Epoch[160] Batch [35]#011Speed: 1342.34 samples/sec#011loss=7.812039\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] Epoch[160] Batch[40] avg_epoch_loss=8.041286\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=160, batch=40 train loss <loss>=7.6558763504\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] Epoch[160] Batch [40]#011Speed: 711.32 samples/sec#011loss=7.655876\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] Epoch[160] Batch[45] avg_epoch_loss=8.061937\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=160, batch=45 train loss <loss>=8.23127803802\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] Epoch[160] Batch [45]#011Speed: 1297.71 samples/sec#011loss=8.231278\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] Epoch[160] Batch[50] avg_epoch_loss=7.996530\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=160, batch=50 train loss <loss>=7.394789505\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] Epoch[160] Batch [50]#011Speed: 1174.79 samples/sec#011loss=7.394790\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] processed a total of 1643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1691.2651062011719, \"sum\": 1691.2651062011719, \"min\": 1691.2651062011719}}, \"EndTime\": 1577414664.834925, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414663.143171}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=971.402423079 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=160, train loss <loss>=7.97221221374\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] Epoch[161] Batch[0] avg_epoch_loss=8.208677\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=8.20867729187\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] Epoch[161] Batch[5] avg_epoch_loss=8.142400\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=8.14240018527\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] Epoch[161] Batch [5]#011Speed: 1320.62 samples/sec#011loss=8.142400\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] Epoch[161] Batch[10] avg_epoch_loss=8.111633\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=8.0747127533\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] Epoch[161] Batch [10]#011Speed: 738.85 samples/sec#011loss=8.074713\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] Epoch[161] Batch[15] avg_epoch_loss=8.084100\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=161, batch=15 train loss <loss>=8.02352828979\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] Epoch[161] Batch [15]#011Speed: 1486.22 samples/sec#011loss=8.023528\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] Epoch[161] Batch[20] avg_epoch_loss=8.165426\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=161, batch=20 train loss <loss>=8.42566900253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] Epoch[161] Batch [20]#011Speed: 768.86 samples/sec#011loss=8.425669\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] Epoch[161] Batch[25] avg_epoch_loss=8.100215\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=161, batch=25 train loss <loss>=7.82632761002\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] Epoch[161] Batch [25]#011Speed: 1503.34 samples/sec#011loss=7.826328\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] Epoch[161] Batch[30] avg_epoch_loss=8.035152\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=161, batch=30 train loss <loss>=7.69682741165\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:25 INFO 139649395074880] Epoch[161] Batch [30]#011Speed: 654.47 samples/sec#011loss=7.696827\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[161] Batch[35] avg_epoch_loss=7.982488\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=161, batch=35 train loss <loss>=7.6559679985\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[161] Batch [35]#011Speed: 1516.60 samples/sec#011loss=7.655968\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[161] Batch[40] avg_epoch_loss=7.941151\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=161, batch=40 train loss <loss>=7.64352464676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[161] Batch [40]#011Speed: 810.81 samples/sec#011loss=7.643525\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[161] Batch[45] avg_epoch_loss=7.921891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=161, batch=45 train loss <loss>=7.76396350861\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[161] Batch [45]#011Speed: 1691.33 samples/sec#011loss=7.763964\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[161] Batch[50] avg_epoch_loss=7.904411\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=161, batch=50 train loss <loss>=7.74359550476\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[161] Batch [50]#011Speed: 1003.50 samples/sec#011loss=7.743596\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] processed a total of 1608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1692.4808025360107, \"sum\": 1692.4808025360107, \"min\": 1692.4808025360107}}, \"EndTime\": 1577414666.527971, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414664.834994}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=950.021063058 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=161, train loss <loss>=7.90441146551\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[162] Batch[0] avg_epoch_loss=8.193850\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=8.1938495636\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[162] Batch[5] avg_epoch_loss=8.073669\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=8.07366903623\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[162] Batch [5]#011Speed: 1491.42 samples/sec#011loss=8.073669\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[162] Batch[10] avg_epoch_loss=8.096450\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=8.1237868309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:26 INFO 139649395074880] Epoch[162] Batch [10]#011Speed: 783.81 samples/sec#011loss=8.123787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] Epoch[162] Batch[15] avg_epoch_loss=8.233998\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=162, batch=15 train loss <loss>=8.53660316467\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] Epoch[162] Batch [15]#011Speed: 1743.43 samples/sec#011loss=8.536603\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] Epoch[162] Batch[20] avg_epoch_loss=8.202370\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=162, batch=20 train loss <loss>=8.10116128922\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] Epoch[162] Batch [20]#011Speed: 788.72 samples/sec#011loss=8.101161\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] Epoch[162] Batch[25] avg_epoch_loss=8.119353\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=162, batch=25 train loss <loss>=7.77068042755\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] Epoch[162] Batch [25]#011Speed: 1551.84 samples/sec#011loss=7.770680\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] Epoch[162] Batch[30] avg_epoch_loss=8.052109\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=162, batch=30 train loss <loss>=7.70244140625\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] Epoch[162] Batch [30]#011Speed: 804.63 samples/sec#011loss=7.702441\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] Epoch[162] Batch[35] avg_epoch_loss=8.001504\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=162, batch=35 train loss <loss>=7.68775472641\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] Epoch[162] Batch [35]#011Speed: 1540.88 samples/sec#011loss=7.687755\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] Epoch[162] Batch[40] avg_epoch_loss=7.948866\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=162, batch=40 train loss <loss>=7.5698682785\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:27 INFO 139649395074880] Epoch[162] Batch [40]#011Speed: 726.37 samples/sec#011loss=7.569868\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[162] Batch[45] avg_epoch_loss=7.898083\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=162, batch=45 train loss <loss>=7.48166265488\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[162] Batch [45]#011Speed: 1443.39 samples/sec#011loss=7.481663\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[162] Batch[50] avg_epoch_loss=7.880874\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=162, batch=50 train loss <loss>=7.72255191803\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[162] Batch [50]#011Speed: 1167.12 samples/sec#011loss=7.722552\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] processed a total of 1625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1614.0930652618408, \"sum\": 1614.0930652618408, \"min\": 1614.0930652618408}}, \"EndTime\": 1577414668.142564, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414666.528048}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1006.68683168 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=162, train loss <loss>=7.88087387646\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[163] Batch[0] avg_epoch_loss=7.951213\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=7.951212883\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[163] Batch[5] avg_epoch_loss=8.041759\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=8.0417590936\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[163] Batch [5]#011Speed: 1528.89 samples/sec#011loss=8.041759\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[163] Batch[10] avg_epoch_loss=8.071464\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=8.10710964203\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[163] Batch [10]#011Speed: 792.54 samples/sec#011loss=8.107110\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[163] Batch[15] avg_epoch_loss=8.203404\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=163, batch=15 train loss <loss>=8.49367179871\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[163] Batch [15]#011Speed: 1557.98 samples/sec#011loss=8.493672\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[163] Batch[20] avg_epoch_loss=8.223688\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=163, batch=20 train loss <loss>=8.28859624863\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[163] Batch [20]#011Speed: 811.28 samples/sec#011loss=8.288596\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[163] Batch[25] avg_epoch_loss=8.145767\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=163, batch=25 train loss <loss>=7.81849908829\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:28 INFO 139649395074880] Epoch[163] Batch [25]#011Speed: 1319.13 samples/sec#011loss=7.818499\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] Epoch[163] Batch[30] avg_epoch_loss=8.042358\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=163, batch=30 train loss <loss>=7.50463237762\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] Epoch[163] Batch [30]#011Speed: 730.99 samples/sec#011loss=7.504632\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] Epoch[163] Batch[35] avg_epoch_loss=7.978473\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=163, batch=35 train loss <loss>=7.58238754272\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] Epoch[163] Batch [35]#011Speed: 1325.47 samples/sec#011loss=7.582388\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] Epoch[163] Batch[40] avg_epoch_loss=7.936076\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=163, batch=40 train loss <loss>=7.6308172226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] Epoch[163] Batch [40]#011Speed: 744.01 samples/sec#011loss=7.630817\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] Epoch[163] Batch[45] avg_epoch_loss=7.920019\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=163, batch=45 train loss <loss>=7.78834934235\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] Epoch[163] Batch [45]#011Speed: 1332.18 samples/sec#011loss=7.788349\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] Epoch[163] Batch[50] avg_epoch_loss=7.878847\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=163, batch=50 train loss <loss>=7.50006427765\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] Epoch[163] Batch [50]#011Speed: 1068.91 samples/sec#011loss=7.500064\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] processed a total of 1635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1703.226089477539, \"sum\": 1703.226089477539, \"min\": 1703.226089477539}}, \"EndTime\": 1577414669.846327, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414668.14264}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=959.883901657 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=163, train loss <loss>=7.86722806784\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] Epoch[164] Batch[0] avg_epoch_loss=7.992192\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=7.99219179153\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] Epoch[164] Batch[5] avg_epoch_loss=8.131500\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=8.13150008519\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] Epoch[164] Batch [5]#011Speed: 1344.10 samples/sec#011loss=8.131500\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] Epoch[164] Batch[10] avg_epoch_loss=8.177388\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=8.23245315552\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] Epoch[164] Batch [10]#011Speed: 802.45 samples/sec#011loss=8.232453\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] Epoch[164] Batch[15] avg_epoch_loss=8.282824\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=164, batch=15 train loss <loss>=8.51478500366\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] Epoch[164] Batch [15]#011Speed: 1494.98 samples/sec#011loss=8.514785\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] Epoch[164] Batch[20] avg_epoch_loss=8.181130\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=164, batch=20 train loss <loss>=7.85570688248\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] Epoch[164] Batch [20]#011Speed: 811.56 samples/sec#011loss=7.855707\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] Epoch[164] Batch[25] avg_epoch_loss=8.105188\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=164, batch=25 train loss <loss>=7.78623447418\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] Epoch[164] Batch [25]#011Speed: 1549.94 samples/sec#011loss=7.786234\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] Epoch[164] Batch[30] avg_epoch_loss=8.045660\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=164, batch=30 train loss <loss>=7.73610963821\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:30 INFO 139649395074880] Epoch[164] Batch [30]#011Speed: 799.22 samples/sec#011loss=7.736110\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[164] Batch[35] avg_epoch_loss=7.989725\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=164, batch=35 train loss <loss>=7.64293394089\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[164] Batch [35]#011Speed: 1539.87 samples/sec#011loss=7.642934\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[164] Batch[40] avg_epoch_loss=7.942460\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=164, batch=40 train loss <loss>=7.60214834213\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[164] Batch [40]#011Speed: 826.02 samples/sec#011loss=7.602148\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[164] Batch[45] avg_epoch_loss=7.912970\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=164, batch=45 train loss <loss>=7.67115345001\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[164] Batch [45]#011Speed: 1655.99 samples/sec#011loss=7.671153\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] processed a total of 1589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1570.2428817749023, \"sum\": 1570.2428817749023, \"min\": 1570.2428817749023}}, \"EndTime\": 1577414671.417084, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414669.846397}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1011.88789955 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=164, train loss <loss>=7.91425677299\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[165] Batch[0] avg_epoch_loss=7.896968\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=7.89696836472\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[165] Batch[5] avg_epoch_loss=8.016171\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=8.01617058118\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[165] Batch [5]#011Speed: 1549.82 samples/sec#011loss=8.016171\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[165] Batch[10] avg_epoch_loss=8.022016\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=8.02903146744\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[165] Batch [10]#011Speed: 682.36 samples/sec#011loss=8.029031\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[165] Batch[15] avg_epoch_loss=8.113328\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=165, batch=15 train loss <loss>=8.31421298981\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:31 INFO 139649395074880] Epoch[165] Batch [15]#011Speed: 1338.03 samples/sec#011loss=8.314213\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] Epoch[165] Batch[20] avg_epoch_loss=8.051636\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=165, batch=20 train loss <loss>=7.85422391891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] Epoch[165] Batch [20]#011Speed: 761.71 samples/sec#011loss=7.854224\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] Epoch[165] Batch[25] avg_epoch_loss=7.960729\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=165, batch=25 train loss <loss>=7.57891969681\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] Epoch[165] Batch [25]#011Speed: 1325.72 samples/sec#011loss=7.578920\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] Epoch[165] Batch[30] avg_epoch_loss=7.943874\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=165, batch=30 train loss <loss>=7.85622901917\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] Epoch[165] Batch [30]#011Speed: 763.10 samples/sec#011loss=7.856229\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] Epoch[165] Batch[35] avg_epoch_loss=7.878491\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=165, batch=35 train loss <loss>=7.47311582565\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] Epoch[165] Batch [35]#011Speed: 1289.59 samples/sec#011loss=7.473116\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] Epoch[165] Batch[40] avg_epoch_loss=7.849605\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=165, batch=40 train loss <loss>=7.64162445068\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:32 INFO 139649395074880] Epoch[165] Batch [40]#011Speed: 724.30 samples/sec#011loss=7.641624\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[165] Batch[45] avg_epoch_loss=7.843968\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=165, batch=45 train loss <loss>=7.79774045944\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[165] Batch [45]#011Speed: 1282.65 samples/sec#011loss=7.797740\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] processed a total of 1547 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1690.6650066375732, \"sum\": 1690.6650066375732, \"min\": 1690.6650066375732}}, \"EndTime\": 1577414673.108377, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414671.417144}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=914.966107584 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=165, train loss <loss>=7.75237741276\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/state_9e4dd833-21d1-4257-b239-b213fff6452b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.507003784179688, \"sum\": 18.507003784179688, \"min\": 18.507003784179688}}, \"EndTime\": 1577414673.127509, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414673.108448}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[166] Batch[0] avg_epoch_loss=8.722093\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=8.72209262848\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[166] Batch[5] avg_epoch_loss=8.195245\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=8.19524542491\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[166] Batch [5]#011Speed: 1299.97 samples/sec#011loss=8.195245\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[166] Batch[10] avg_epoch_loss=8.158221\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=8.11379137039\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[166] Batch [10]#011Speed: 788.57 samples/sec#011loss=8.113791\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[166] Batch[15] avg_epoch_loss=8.272821\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=166, batch=15 train loss <loss>=8.52494049072\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[166] Batch [15]#011Speed: 1546.95 samples/sec#011loss=8.524940\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[166] Batch[20] avg_epoch_loss=8.202581\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=166, batch=20 train loss <loss>=7.97781333923\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[166] Batch [20]#011Speed: 798.94 samples/sec#011loss=7.977813\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[166] Batch[25] avg_epoch_loss=8.109099\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=166, batch=25 train loss <loss>=7.71647291183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:33 INFO 139649395074880] Epoch[166] Batch [25]#011Speed: 1615.67 samples/sec#011loss=7.716473\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] Epoch[166] Batch[30] avg_epoch_loss=8.035037\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=166, batch=30 train loss <loss>=7.64991941452\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] Epoch[166] Batch [30]#011Speed: 707.78 samples/sec#011loss=7.649919\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] Epoch[166] Batch[35] avg_epoch_loss=7.963361\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=166, batch=35 train loss <loss>=7.51896629333\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] Epoch[166] Batch [35]#011Speed: 1666.01 samples/sec#011loss=7.518966\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] Epoch[166] Batch[40] avg_epoch_loss=7.952360\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=166, batch=40 train loss <loss>=7.87315502167\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] Epoch[166] Batch [40]#011Speed: 740.55 samples/sec#011loss=7.873155\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] Epoch[166] Batch[45] avg_epoch_loss=7.912901\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=166, batch=45 train loss <loss>=7.58933582306\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] Epoch[166] Batch [45]#011Speed: 1559.58 samples/sec#011loss=7.589336\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] processed a total of 1599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1601.830005645752, \"sum\": 1601.830005645752, \"min\": 1601.830005645752}}, \"EndTime\": 1577414674.729447, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414673.127562}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=998.16344021 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=166, train loss <loss>=7.9153631115\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] Epoch[167] Batch[0] avg_epoch_loss=8.158285\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=8.15828514099\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] Epoch[167] Batch[5] avg_epoch_loss=8.176119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=8.17611940702\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:34 INFO 139649395074880] Epoch[167] Batch [5]#011Speed: 1553.34 samples/sec#011loss=8.176119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] Epoch[167] Batch[10] avg_epoch_loss=8.032510\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=7.86017866135\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] Epoch[167] Batch [10]#011Speed: 655.31 samples/sec#011loss=7.860179\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] Epoch[167] Batch[15] avg_epoch_loss=8.053414\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=167, batch=15 train loss <loss>=8.09940414429\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] Epoch[167] Batch [15]#011Speed: 1448.23 samples/sec#011loss=8.099404\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] Epoch[167] Batch[20] avg_epoch_loss=8.121729\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=167, batch=20 train loss <loss>=8.34033737183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] Epoch[167] Batch [20]#011Speed: 737.86 samples/sec#011loss=8.340337\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] Epoch[167] Batch[25] avg_epoch_loss=8.076474\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=167, batch=25 train loss <loss>=7.88640222549\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] Epoch[167] Batch [25]#011Speed: 1287.06 samples/sec#011loss=7.886402\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] Epoch[167] Batch[30] avg_epoch_loss=8.063910\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=167, batch=30 train loss <loss>=7.99857387543\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] Epoch[167] Batch [30]#011Speed: 777.34 samples/sec#011loss=7.998574\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] Epoch[167] Batch[35] avg_epoch_loss=8.034392\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=167, batch=35 train loss <loss>=7.8513835907\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:35 INFO 139649395074880] Epoch[167] Batch [35]#011Speed: 1554.93 samples/sec#011loss=7.851384\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[167] Batch[40] avg_epoch_loss=7.981830\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=167, batch=40 train loss <loss>=7.60338249207\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[167] Batch [40]#011Speed: 788.13 samples/sec#011loss=7.603382\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[167] Batch[45] avg_epoch_loss=7.938293\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=167, batch=45 train loss <loss>=7.5812874794\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[167] Batch [45]#011Speed: 1553.97 samples/sec#011loss=7.581287\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[167] Batch[50] avg_epoch_loss=7.901036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=167, batch=50 train loss <loss>=7.55827474594\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[167] Batch [50]#011Speed: 1182.27 samples/sec#011loss=7.558275\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] processed a total of 1623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1669.795036315918, \"sum\": 1669.795036315918, \"min\": 1669.795036315918}}, \"EndTime\": 1577414676.399769, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414674.729524}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=971.916185707 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=167, train loss <loss>=7.90103606617\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[168] Batch[0] avg_epoch_loss=8.606530\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=8.60653018951\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[168] Batch[5] avg_epoch_loss=7.873441\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=7.87344137828\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[168] Batch [5]#011Speed: 1537.97 samples/sec#011loss=7.873441\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[168] Batch[10] avg_epoch_loss=7.981568\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=8.11131954193\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[168] Batch [10]#011Speed: 762.58 samples/sec#011loss=8.111320\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[168] Batch[15] avg_epoch_loss=7.956795\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=168, batch=15 train loss <loss>=7.90229539871\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:36 INFO 139649395074880] Epoch[168] Batch [15]#011Speed: 1333.59 samples/sec#011loss=7.902295\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] Epoch[168] Batch[20] avg_epoch_loss=8.046966\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=168, batch=20 train loss <loss>=8.33551158905\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] Epoch[168] Batch [20]#011Speed: 734.13 samples/sec#011loss=8.335512\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] Epoch[168] Batch[25] avg_epoch_loss=7.989299\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=168, batch=25 train loss <loss>=7.74709672928\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] Epoch[168] Batch [25]#011Speed: 1325.72 samples/sec#011loss=7.747097\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] Epoch[168] Batch[30] avg_epoch_loss=7.960842\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=168, batch=30 train loss <loss>=7.81287050247\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] Epoch[168] Batch [30]#011Speed: 725.99 samples/sec#011loss=7.812871\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] Epoch[168] Batch[35] avg_epoch_loss=7.879093\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=168, batch=35 train loss <loss>=7.3722492218\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] Epoch[168] Batch [35]#011Speed: 1590.59 samples/sec#011loss=7.372249\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] Epoch[168] Batch[40] avg_epoch_loss=7.856929\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=168, batch=40 train loss <loss>=7.69734535217\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] Epoch[168] Batch [40]#011Speed: 692.67 samples/sec#011loss=7.697345\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] Epoch[168] Batch[45] avg_epoch_loss=7.869002\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=168, batch=45 train loss <loss>=7.96800117493\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:37 INFO 139649395074880] Epoch[168] Batch [45]#011Speed: 1690.35 samples/sec#011loss=7.968001\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] processed a total of 1588 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1659.2519283294678, \"sum\": 1659.2519283294678, \"min\": 1659.2519283294678}}, \"EndTime\": 1577414678.059523, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414676.399835}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=956.999494959 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=168, train loss <loss>=7.79422881126\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] Epoch[169] Batch[0] avg_epoch_loss=7.845785\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=7.84578514099\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] Epoch[169] Batch[5] avg_epoch_loss=8.136223\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=8.13622291883\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] Epoch[169] Batch [5]#011Speed: 1328.48 samples/sec#011loss=8.136223\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] Epoch[169] Batch[10] avg_epoch_loss=8.194643\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=8.26474666595\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] Epoch[169] Batch [10]#011Speed: 728.83 samples/sec#011loss=8.264747\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] Epoch[169] Batch[15] avg_epoch_loss=8.203675\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=169, batch=15 train loss <loss>=8.22354593277\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] Epoch[169] Batch [15]#011Speed: 1393.23 samples/sec#011loss=8.223546\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] Epoch[169] Batch[20] avg_epoch_loss=8.226686\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=169, batch=20 train loss <loss>=8.30032138824\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] Epoch[169] Batch [20]#011Speed: 794.35 samples/sec#011loss=8.300321\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] Epoch[169] Batch[25] avg_epoch_loss=8.127984\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=169, batch=25 train loss <loss>=7.71343307495\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:38 INFO 139649395074880] Epoch[169] Batch [25]#011Speed: 1566.37 samples/sec#011loss=7.713433\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] Epoch[169] Batch[30] avg_epoch_loss=8.083478\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=169, batch=30 train loss <loss>=7.85205116272\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] Epoch[169] Batch [30]#011Speed: 797.38 samples/sec#011loss=7.852051\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] Epoch[169] Batch[35] avg_epoch_loss=8.036362\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=169, batch=35 train loss <loss>=7.74424171448\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] Epoch[169] Batch [35]#011Speed: 1533.01 samples/sec#011loss=7.744242\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] Epoch[169] Batch[40] avg_epoch_loss=8.019862\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=169, batch=40 train loss <loss>=7.90105895996\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] Epoch[169] Batch [40]#011Speed: 798.71 samples/sec#011loss=7.901059\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] Epoch[169] Batch[45] avg_epoch_loss=7.987292\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=169, batch=45 train loss <loss>=7.72022447586\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] Epoch[169] Batch [45]#011Speed: 1514.10 samples/sec#011loss=7.720224\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] processed a total of 1581 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1596.1568355560303, \"sum\": 1596.1568355560303, \"min\": 1596.1568355560303}}, \"EndTime\": 1577414679.656263, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414678.05959}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=990.438334738 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=169, train loss <loss>=7.93534162521\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] Epoch[170] Batch[0] avg_epoch_loss=7.629226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=7.6292257309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] Epoch[170] Batch[5] avg_epoch_loss=8.080966\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=8.0809656779\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:39 INFO 139649395074880] Epoch[170] Batch [5]#011Speed: 1575.72 samples/sec#011loss=8.080966\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] Epoch[170] Batch[10] avg_epoch_loss=8.159778\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=8.25435171127\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] Epoch[170] Batch [10]#011Speed: 729.31 samples/sec#011loss=8.254352\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] Epoch[170] Batch[15] avg_epoch_loss=8.162672\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=170, batch=15 train loss <loss>=8.16903991699\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] Epoch[170] Batch [15]#011Speed: 1727.77 samples/sec#011loss=8.169040\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] Epoch[170] Batch[20] avg_epoch_loss=8.195961\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=170, batch=20 train loss <loss>=8.30248432159\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] Epoch[170] Batch [20]#011Speed: 804.49 samples/sec#011loss=8.302484\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] Epoch[170] Batch[25] avg_epoch_loss=8.137462\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=170, batch=25 train loss <loss>=7.89176607132\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] Epoch[170] Batch [25]#011Speed: 1460.09 samples/sec#011loss=7.891766\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] Epoch[170] Batch[30] avg_epoch_loss=8.088028\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=170, batch=30 train loss <loss>=7.83096971512\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] Epoch[170] Batch [30]#011Speed: 828.45 samples/sec#011loss=7.830970\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] Epoch[170] Batch[35] avg_epoch_loss=8.042812\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] #quality_metric: host=algo-1, epoch=170, batch=35 train loss <loss>=7.76247386932\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:40 INFO 139649395074880] Epoch[170] Batch [35]#011Speed: 1547.06 samples/sec#011loss=7.762474\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[170] Batch[40] avg_epoch_loss=7.999639\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=170, batch=40 train loss <loss>=7.68879289627\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[170] Batch [40]#011Speed: 786.11 samples/sec#011loss=7.688793\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[170] Batch[45] avg_epoch_loss=7.966155\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=170, batch=45 train loss <loss>=7.69158763885\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[170] Batch [45]#011Speed: 1394.02 samples/sec#011loss=7.691588\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] processed a total of 1592 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1579.4389247894287, \"sum\": 1579.4389247894287, \"min\": 1579.4389247894287}}, \"EndTime\": 1577414681.236258, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414679.656329}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1007.87938773 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=170, train loss <loss>=7.91465662956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[171] Batch[0] avg_epoch_loss=8.206885\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=8.20688533783\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[171] Batch[5] avg_epoch_loss=8.084745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=8.08474500974\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[171] Batch [5]#011Speed: 1598.09 samples/sec#011loss=8.084745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[171] Batch[10] avg_epoch_loss=8.102695\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=8.12423429489\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[171] Batch [10]#011Speed: 769.80 samples/sec#011loss=8.124234\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[171] Batch[15] avg_epoch_loss=8.239506\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=171, batch=15 train loss <loss>=8.54049110413\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[171] Batch [15]#011Speed: 1699.16 samples/sec#011loss=8.540491\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[171] Batch[20] avg_epoch_loss=8.210488\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] #quality_metric: host=algo-1, epoch=171, batch=20 train loss <loss>=8.11763000488\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:41 INFO 139649395074880] Epoch[171] Batch [20]#011Speed: 772.42 samples/sec#011loss=8.117630\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] Epoch[171] Batch[25] avg_epoch_loss=8.174206\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=171, batch=25 train loss <loss>=8.02182159424\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] Epoch[171] Batch [25]#011Speed: 1406.51 samples/sec#011loss=8.021822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] Epoch[171] Batch[30] avg_epoch_loss=8.113909\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=171, batch=30 train loss <loss>=7.80036506653\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] Epoch[171] Batch [30]#011Speed: 734.28 samples/sec#011loss=7.800365\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] Epoch[171] Batch[35] avg_epoch_loss=8.059901\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=171, batch=35 train loss <loss>=7.72505064011\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] Epoch[171] Batch [35]#011Speed: 1490.73 samples/sec#011loss=7.725051\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] Epoch[171] Batch[40] avg_epoch_loss=8.007756\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=171, batch=40 train loss <loss>=7.63231067657\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] Epoch[171] Batch [40]#011Speed: 779.62 samples/sec#011loss=7.632311\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] Epoch[171] Batch[45] avg_epoch_loss=7.972527\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=171, batch=45 train loss <loss>=7.68364934921\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] Epoch[171] Batch [45]#011Speed: 1504.60 samples/sec#011loss=7.683649\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] Epoch[171] Batch[50] avg_epoch_loss=7.976585\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=171, batch=50 train loss <loss>=8.01392297745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] Epoch[171] Batch [50]#011Speed: 963.02 samples/sec#011loss=8.013923\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] processed a total of 1686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1721.904993057251, \"sum\": 1721.904993057251, \"min\": 1721.904993057251}}, \"EndTime\": 1577414682.958699, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414681.236338}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=979.080451444 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] #quality_metric: host=algo-1, epoch=171, train loss <loss>=7.95188475555\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:42 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] Epoch[172] Batch[0] avg_epoch_loss=8.037551\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=8.03755092621\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] Epoch[172] Batch[5] avg_epoch_loss=7.920378\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=7.92037820816\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] Epoch[172] Batch [5]#011Speed: 1486.26 samples/sec#011loss=7.920378\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] Epoch[172] Batch[10] avg_epoch_loss=8.074957\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=8.26045227051\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] Epoch[172] Batch [10]#011Speed: 764.83 samples/sec#011loss=8.260452\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] Epoch[172] Batch[15] avg_epoch_loss=8.111983\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=172, batch=15 train loss <loss>=8.19343948364\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] Epoch[172] Batch [15]#011Speed: 1407.45 samples/sec#011loss=8.193439\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] Epoch[172] Batch[20] avg_epoch_loss=8.153793\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=172, batch=20 train loss <loss>=8.28758563995\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] Epoch[172] Batch [20]#011Speed: 745.52 samples/sec#011loss=8.287586\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] Epoch[172] Batch[25] avg_epoch_loss=8.068629\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] #quality_metric: host=algo-1, epoch=172, batch=25 train loss <loss>=7.71093711853\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:43 INFO 139649395074880] Epoch[172] Batch [25]#011Speed: 1561.34 samples/sec#011loss=7.710937\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] Epoch[172] Batch[30] avg_epoch_loss=8.029183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=172, batch=30 train loss <loss>=7.82406358719\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] Epoch[172] Batch [30]#011Speed: 788.08 samples/sec#011loss=7.824064\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] Epoch[172] Batch[35] avg_epoch_loss=7.970689\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=172, batch=35 train loss <loss>=7.60802536011\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] Epoch[172] Batch [35]#011Speed: 1477.58 samples/sec#011loss=7.608025\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] Epoch[172] Batch[40] avg_epoch_loss=7.960517\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=172, batch=40 train loss <loss>=7.88728046417\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] Epoch[172] Batch [40]#011Speed: 747.32 samples/sec#011loss=7.887280\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] Epoch[172] Batch[45] avg_epoch_loss=7.929486\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=172, batch=45 train loss <loss>=7.6750336647\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] Epoch[172] Batch [45]#011Speed: 1278.90 samples/sec#011loss=7.675034\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] processed a total of 1593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1618.3528900146484, \"sum\": 1618.3528900146484, \"min\": 1618.3528900146484}}, \"EndTime\": 1577414684.57764, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414682.95878}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=984.265988091 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=172, train loss <loss>=7.92143967628\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] Epoch[173] Batch[0] avg_epoch_loss=7.891558\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=7.89155769348\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] Epoch[173] Batch[5] avg_epoch_loss=8.241652\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=8.24165201187\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:44 INFO 139649395074880] Epoch[173] Batch [5]#011Speed: 1494.07 samples/sec#011loss=8.241652\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch[10] avg_epoch_loss=8.183797\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=8.11437044144\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch [10]#011Speed: 793.83 samples/sec#011loss=8.114370\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch[15] avg_epoch_loss=8.170956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=173, batch=15 train loss <loss>=8.14270563126\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch [15]#011Speed: 1485.46 samples/sec#011loss=8.142706\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch[20] avg_epoch_loss=8.171288\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=173, batch=20 train loss <loss>=8.17234945297\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch [20]#011Speed: 816.99 samples/sec#011loss=8.172349\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch[25] avg_epoch_loss=8.139362\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=173, batch=25 train loss <loss>=8.0052728653\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch [25]#011Speed: 1548.42 samples/sec#011loss=8.005273\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch[30] avg_epoch_loss=8.071436\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=173, batch=30 train loss <loss>=7.71822271347\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch [30]#011Speed: 685.88 samples/sec#011loss=7.718223\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch[35] avg_epoch_loss=8.008539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=173, batch=35 train loss <loss>=7.61858024597\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch [35]#011Speed: 1361.82 samples/sec#011loss=7.618580\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch[40] avg_epoch_loss=7.958082\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] #quality_metric: host=algo-1, epoch=173, batch=40 train loss <loss>=7.59479122162\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:45 INFO 139649395074880] Epoch[173] Batch [40]#011Speed: 747.04 samples/sec#011loss=7.594791\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] Epoch[173] Batch[45] avg_epoch_loss=7.940936\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=173, batch=45 train loss <loss>=7.80033664703\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] Epoch[173] Batch [45]#011Speed: 1513.98 samples/sec#011loss=7.800337\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] Epoch[173] Batch[50] avg_epoch_loss=7.929498\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=173, batch=50 train loss <loss>=7.82426490784\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] Epoch[173] Batch [50]#011Speed: 1282.63 samples/sec#011loss=7.824265\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] processed a total of 1667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1695.1470375061035, \"sum\": 1695.1470375061035, \"min\": 1695.1470375061035}}, \"EndTime\": 1577414686.273318, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414684.577717}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=983.328856538 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=173, train loss <loss>=7.89294611733\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] Epoch[174] Batch[0] avg_epoch_loss=8.310598\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=8.31059837341\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] Epoch[174] Batch[5] avg_epoch_loss=7.956539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=7.95653859774\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] Epoch[174] Batch [5]#011Speed: 1329.89 samples/sec#011loss=7.956539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] Epoch[174] Batch[10] avg_epoch_loss=8.041851\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=8.14422492981\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] Epoch[174] Batch [10]#011Speed: 773.33 samples/sec#011loss=8.144225\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] Epoch[174] Batch[15] avg_epoch_loss=8.163399\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] #quality_metric: host=algo-1, epoch=174, batch=15 train loss <loss>=8.43080539703\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:46 INFO 139649395074880] Epoch[174] Batch [15]#011Speed: 1686.30 samples/sec#011loss=8.430805\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[174] Batch[20] avg_epoch_loss=8.138121\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=174, batch=20 train loss <loss>=8.05722990036\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[174] Batch [20]#011Speed: 746.34 samples/sec#011loss=8.057230\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[174] Batch[25] avg_epoch_loss=8.086035\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=174, batch=25 train loss <loss>=7.86727409363\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[174] Batch [25]#011Speed: 1640.59 samples/sec#011loss=7.867274\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[174] Batch[30] avg_epoch_loss=8.045184\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=174, batch=30 train loss <loss>=7.83275899887\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[174] Batch [30]#011Speed: 742.60 samples/sec#011loss=7.832759\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[174] Batch[35] avg_epoch_loss=7.992180\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=174, batch=35 train loss <loss>=7.66355552673\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[174] Batch [35]#011Speed: 1344.46 samples/sec#011loss=7.663556\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[174] Batch[40] avg_epoch_loss=7.993750\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=174, batch=40 train loss <loss>=8.00505151749\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[174] Batch [40]#011Speed: 735.89 samples/sec#011loss=8.005052\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[174] Batch[45] avg_epoch_loss=7.981930\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=174, batch=45 train loss <loss>=7.88501091003\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[174] Batch [45]#011Speed: 1538.61 samples/sec#011loss=7.885011\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] processed a total of 1557 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1594.7010517120361, \"sum\": 1594.7010517120361, \"min\": 1594.7010517120361}}, \"EndTime\": 1577414687.868606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414686.273396}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=976.288192374 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=174, train loss <loss>=7.8972515476\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] Epoch[175] Batch[0] avg_epoch_loss=8.103603\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:47 INFO 139649395074880] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=8.10360336304\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] Epoch[175] Batch[5] avg_epoch_loss=8.009296\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=8.00929570198\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] Epoch[175] Batch [5]#011Speed: 1587.24 samples/sec#011loss=8.009296\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] Epoch[175] Batch[10] avg_epoch_loss=8.038149\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=8.07277288437\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] Epoch[175] Batch [10]#011Speed: 723.05 samples/sec#011loss=8.072773\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] Epoch[175] Batch[15] avg_epoch_loss=8.145525\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=175, batch=15 train loss <loss>=8.38175201416\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] Epoch[175] Batch [15]#011Speed: 1514.89 samples/sec#011loss=8.381752\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] Epoch[175] Batch[20] avg_epoch_loss=8.149173\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=175, batch=20 train loss <loss>=8.1608458519\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] Epoch[175] Batch [20]#011Speed: 797.43 samples/sec#011loss=8.160846\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] Epoch[175] Batch[25] avg_epoch_loss=8.089209\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=175, batch=25 train loss <loss>=7.8373591423\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] Epoch[175] Batch [25]#011Speed: 1520.77 samples/sec#011loss=7.837359\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] Epoch[175] Batch[30] avg_epoch_loss=8.015800\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] #quality_metric: host=algo-1, epoch=175, batch=30 train loss <loss>=7.63407278061\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:48 INFO 139649395074880] Epoch[175] Batch [30]#011Speed: 797.52 samples/sec#011loss=7.634073\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[175] Batch[35] avg_epoch_loss=7.967069\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=175, batch=35 train loss <loss>=7.66494178772\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[175] Batch [35]#011Speed: 1476.91 samples/sec#011loss=7.664942\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[175] Batch[40] avg_epoch_loss=7.919217\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=175, batch=40 train loss <loss>=7.57468080521\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[175] Batch [40]#011Speed: 668.87 samples/sec#011loss=7.574681\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[175] Batch[45] avg_epoch_loss=7.940381\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=175, batch=45 train loss <loss>=8.11392211914\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[175] Batch [45]#011Speed: 1645.12 samples/sec#011loss=8.113922\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[175] Batch[50] avg_epoch_loss=7.876978\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=175, batch=50 train loss <loss>=7.29367485046\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[175] Batch [50]#011Speed: 1175.73 samples/sec#011loss=7.293675\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] processed a total of 1623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1645.2429294586182, \"sum\": 1645.2429294586182, \"min\": 1645.2429294586182}}, \"EndTime\": 1577414689.514394, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414687.868686}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=986.412702976 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=175, train loss <loss>=7.87697814493\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[176] Batch[0] avg_epoch_loss=8.242883\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=8.24288272858\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[176] Batch[5] avg_epoch_loss=8.097386\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=8.09738556544\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[176] Batch [5]#011Speed: 1557.75 samples/sec#011loss=8.097386\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[176] Batch[10] avg_epoch_loss=8.247354\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=8.42731609344\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:49 INFO 139649395074880] Epoch[176] Batch [10]#011Speed: 793.26 samples/sec#011loss=8.427316\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] Epoch[176] Batch[15] avg_epoch_loss=8.244923\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=176, batch=15 train loss <loss>=8.23957386017\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] Epoch[176] Batch [15]#011Speed: 1535.22 samples/sec#011loss=8.239574\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] Epoch[176] Batch[20] avg_epoch_loss=8.253457\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=176, batch=20 train loss <loss>=8.28076658249\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] Epoch[176] Batch [20]#011Speed: 738.35 samples/sec#011loss=8.280767\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] Epoch[176] Batch[25] avg_epoch_loss=8.179217\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=176, batch=25 train loss <loss>=7.86741027832\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] Epoch[176] Batch [25]#011Speed: 1702.32 samples/sec#011loss=7.867410\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] Epoch[176] Batch[30] avg_epoch_loss=8.133876\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=176, batch=30 train loss <loss>=7.89810390472\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] Epoch[176] Batch [30]#011Speed: 713.62 samples/sec#011loss=7.898104\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] Epoch[176] Batch[35] avg_epoch_loss=8.092020\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=176, batch=35 train loss <loss>=7.83251304626\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] Epoch[176] Batch [35]#011Speed: 1493.36 samples/sec#011loss=7.832513\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] Epoch[176] Batch[40] avg_epoch_loss=8.070645\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] #quality_metric: host=algo-1, epoch=176, batch=40 train loss <loss>=7.91674003601\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:50 INFO 139649395074880] Epoch[176] Batch [40]#011Speed: 782.66 samples/sec#011loss=7.916740\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[176] Batch[45] avg_epoch_loss=8.041279\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=176, batch=45 train loss <loss>=7.80047960281\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[176] Batch [45]#011Speed: 1499.74 samples/sec#011loss=7.800480\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[176] Batch[50] avg_epoch_loss=8.005401\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=176, batch=50 train loss <loss>=7.67532539368\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[176] Batch [50]#011Speed: 1262.92 samples/sec#011loss=7.675325\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] processed a total of 1645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1649.7228145599365, \"sum\": 1649.7228145599365, \"min\": 1649.7228145599365}}, \"EndTime\": 1577414691.164639, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414689.514472}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=997.066888133 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=176, train loss <loss>=8.00081412609\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[177] Batch[0] avg_epoch_loss=8.776128\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=8.77612781525\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[177] Batch[5] avg_epoch_loss=8.150190\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=8.15018971761\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[177] Batch [5]#011Speed: 1288.50 samples/sec#011loss=8.150190\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[177] Batch[10] avg_epoch_loss=8.217973\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=8.29931201935\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[177] Batch [10]#011Speed: 728.57 samples/sec#011loss=8.299312\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[177] Batch[15] avg_epoch_loss=8.253080\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=177, batch=15 train loss <loss>=8.33031539917\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[177] Batch [15]#011Speed: 1512.44 samples/sec#011loss=8.330315\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[177] Batch[20] avg_epoch_loss=8.243422\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] #quality_metric: host=algo-1, epoch=177, batch=20 train loss <loss>=8.21251659393\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:51 INFO 139649395074880] Epoch[177] Batch [20]#011Speed: 831.66 samples/sec#011loss=8.212517\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[177] Batch[25] avg_epoch_loss=8.139002\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=177, batch=25 train loss <loss>=7.70043859482\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[177] Batch [25]#011Speed: 1432.58 samples/sec#011loss=7.700439\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[177] Batch[30] avg_epoch_loss=8.037080\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=177, batch=30 train loss <loss>=7.50708293915\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[177] Batch [30]#011Speed: 747.72 samples/sec#011loss=7.507083\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[177] Batch[35] avg_epoch_loss=7.978854\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=177, batch=35 train loss <loss>=7.61785316467\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[177] Batch [35]#011Speed: 1557.72 samples/sec#011loss=7.617853\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[177] Batch[40] avg_epoch_loss=7.940184\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=177, batch=40 train loss <loss>=7.66176404953\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[177] Batch [40]#011Speed: 793.90 samples/sec#011loss=7.661764\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[177] Batch[45] avg_epoch_loss=7.901940\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=177, batch=45 train loss <loss>=7.58833990097\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[177] Batch [45]#011Speed: 1610.03 samples/sec#011loss=7.588340\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[177] Batch[50] avg_epoch_loss=7.884028\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=177, batch=50 train loss <loss>=7.71923332214\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[177] Batch [50]#011Speed: 1322.09 samples/sec#011loss=7.719233\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] processed a total of 1659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1641.503095626831, \"sum\": 1641.503095626831, \"min\": 1641.503095626831}}, \"EndTime\": 1577414692.806687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414691.164718}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1010.59008722 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=177, train loss <loss>=7.85781353254\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] Epoch[178] Batch[0] avg_epoch_loss=8.084305\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:52 INFO 139649395074880] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=8.08430480957\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch[5] avg_epoch_loss=8.026913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=8.02691308657\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch [5]#011Speed: 1536.20 samples/sec#011loss=8.026913\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch[10] avg_epoch_loss=8.063125\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=8.10658016205\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch [10]#011Speed: 655.73 samples/sec#011loss=8.106580\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch[15] avg_epoch_loss=8.127042\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=178, batch=15 train loss <loss>=8.26765880585\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch [15]#011Speed: 1729.51 samples/sec#011loss=8.267659\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch[20] avg_epoch_loss=8.096786\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=178, batch=20 train loss <loss>=7.99996471405\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch [20]#011Speed: 797.19 samples/sec#011loss=7.999965\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch[25] avg_epoch_loss=7.997459\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=178, batch=25 train loss <loss>=7.58028650284\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch [25]#011Speed: 1728.27 samples/sec#011loss=7.580287\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch[30] avg_epoch_loss=7.960267\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=178, batch=30 train loss <loss>=7.76686754227\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch [30]#011Speed: 852.61 samples/sec#011loss=7.766868\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch[35] avg_epoch_loss=7.938655\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] #quality_metric: host=algo-1, epoch=178, batch=35 train loss <loss>=7.80466537476\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:53 INFO 139649395074880] Epoch[178] Batch [35]#011Speed: 1741.17 samples/sec#011loss=7.804665\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] Epoch[178] Batch[40] avg_epoch_loss=7.924598\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=178, batch=40 train loss <loss>=7.82338438034\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] Epoch[178] Batch [40]#011Speed: 776.90 samples/sec#011loss=7.823384\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] Epoch[178] Batch[45] avg_epoch_loss=7.912185\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=178, batch=45 train loss <loss>=7.81040258408\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] Epoch[178] Batch [45]#011Speed: 1563.11 samples/sec#011loss=7.810403\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] processed a total of 1540 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1539.1440391540527, \"sum\": 1539.1440391540527, \"min\": 1539.1440391540527}}, \"EndTime\": 1577414694.346336, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414692.806765}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1000.48204834 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=178, train loss <loss>=7.78760834129\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] Epoch[179] Batch[0] avg_epoch_loss=7.647880\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=7.64787960052\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] Epoch[179] Batch[5] avg_epoch_loss=8.185408\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=8.1854077975\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] Epoch[179] Batch [5]#011Speed: 1620.17 samples/sec#011loss=8.185408\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] Epoch[179] Batch[10] avg_epoch_loss=8.012421\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=7.80483665466\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] Epoch[179] Batch [10]#011Speed: 788.03 samples/sec#011loss=7.804837\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] Epoch[179] Batch[15] avg_epoch_loss=8.200727\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] #quality_metric: host=algo-1, epoch=179, batch=15 train loss <loss>=8.61500148773\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:54 INFO 139649395074880] Epoch[179] Batch [15]#011Speed: 1655.08 samples/sec#011loss=8.615001\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] Epoch[179] Batch[20] avg_epoch_loss=8.195757\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=179, batch=20 train loss <loss>=8.17985162735\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] Epoch[179] Batch [20]#011Speed: 797.56 samples/sec#011loss=8.179852\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] Epoch[179] Batch[25] avg_epoch_loss=8.119799\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=179, batch=25 train loss <loss>=7.80077514648\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] Epoch[179] Batch [25]#011Speed: 1678.25 samples/sec#011loss=7.800775\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] Epoch[179] Batch[30] avg_epoch_loss=8.101355\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=179, batch=30 train loss <loss>=8.00544719696\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] Epoch[179] Batch [30]#011Speed: 810.18 samples/sec#011loss=8.005447\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] Epoch[179] Batch[35] avg_epoch_loss=8.055355\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=179, batch=35 train loss <loss>=7.77015285492\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] Epoch[179] Batch [35]#011Speed: 1529.49 samples/sec#011loss=7.770153\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] Epoch[179] Batch[40] avg_epoch_loss=7.984935\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=179, batch=40 train loss <loss>=7.47791204453\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] Epoch[179] Batch [40]#011Speed: 800.07 samples/sec#011loss=7.477912\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] Epoch[179] Batch[45] avg_epoch_loss=7.954314\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=179, batch=45 train loss <loss>=7.7032248497\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] Epoch[179] Batch [45]#011Speed: 1318.99 samples/sec#011loss=7.703225\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] processed a total of 1570 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1554.6681880950928, \"sum\": 1554.6681880950928, \"min\": 1554.6681880950928}}, \"EndTime\": 1577414695.901524, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414694.346415}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1009.79628515 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] #quality_metric: host=algo-1, epoch=179, train loss <loss>=7.90924963951\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:55 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch[0] avg_epoch_loss=8.381353\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=8.3813533783\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch[5] avg_epoch_loss=8.146713\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=8.14671349525\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch [5]#011Speed: 1324.11 samples/sec#011loss=8.146713\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch[10] avg_epoch_loss=8.237807\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=8.34711875916\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch [10]#011Speed: 786.43 samples/sec#011loss=8.347119\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch[15] avg_epoch_loss=8.221341\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=180, batch=15 train loss <loss>=8.1851146698\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch [15]#011Speed: 1408.56 samples/sec#011loss=8.185115\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch[20] avg_epoch_loss=8.149226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=180, batch=20 train loss <loss>=7.91845989227\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch [20]#011Speed: 767.17 samples/sec#011loss=7.918460\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch[25] avg_epoch_loss=8.076048\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=180, batch=25 train loss <loss>=7.76870241165\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch [25]#011Speed: 1736.22 samples/sec#011loss=7.768702\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch[30] avg_epoch_loss=8.008723\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] #quality_metric: host=algo-1, epoch=180, batch=30 train loss <loss>=7.65863237381\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:56 INFO 139649395074880] Epoch[180] Batch [30]#011Speed: 781.30 samples/sec#011loss=7.658632\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] Epoch[180] Batch[35] avg_epoch_loss=7.974104\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=180, batch=35 train loss <loss>=7.75946655273\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] Epoch[180] Batch [35]#011Speed: 1590.26 samples/sec#011loss=7.759467\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] Epoch[180] Batch[40] avg_epoch_loss=7.954399\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=180, batch=40 train loss <loss>=7.81252326965\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] Epoch[180] Batch [40]#011Speed: 816.85 samples/sec#011loss=7.812523\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] Epoch[180] Batch[45] avg_epoch_loss=7.932846\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=180, batch=45 train loss <loss>=7.75610523224\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] Epoch[180] Batch [45]#011Speed: 1723.10 samples/sec#011loss=7.756105\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] processed a total of 1576 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1568.147897720337, \"sum\": 1568.147897720337, \"min\": 1568.147897720337}}, \"EndTime\": 1577414697.47025, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414695.901589}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1004.93726864 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=180, train loss <loss>=7.81813412666\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] Epoch[181] Batch[0] avg_epoch_loss=7.748575\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=7.74857473373\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] Epoch[181] Batch[5] avg_epoch_loss=8.140281\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=8.14028080304\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] Epoch[181] Batch [5]#011Speed: 1556.63 samples/sec#011loss=8.140281\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] Epoch[181] Batch[10] avg_epoch_loss=8.148480\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=8.15831918716\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:57 INFO 139649395074880] Epoch[181] Batch [10]#011Speed: 802.51 samples/sec#011loss=8.158319\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] Epoch[181] Batch[15] avg_epoch_loss=8.250815\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=181, batch=15 train loss <loss>=8.4759513855\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] Epoch[181] Batch [15]#011Speed: 1400.68 samples/sec#011loss=8.475951\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] Epoch[181] Batch[20] avg_epoch_loss=8.235166\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=181, batch=20 train loss <loss>=8.18509111404\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] Epoch[181] Batch [20]#011Speed: 671.00 samples/sec#011loss=8.185091\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] Epoch[181] Batch[25] avg_epoch_loss=8.171136\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=181, batch=25 train loss <loss>=7.90220756531\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] Epoch[181] Batch [25]#011Speed: 1279.82 samples/sec#011loss=7.902208\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] Epoch[181] Batch[30] avg_epoch_loss=8.065420\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=181, batch=30 train loss <loss>=7.5156993866\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] Epoch[181] Batch [30]#011Speed: 756.21 samples/sec#011loss=7.515699\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] Epoch[181] Batch[35] avg_epoch_loss=8.036168\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=181, batch=35 train loss <loss>=7.85480690002\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] Epoch[181] Batch [35]#011Speed: 1681.85 samples/sec#011loss=7.854807\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] Epoch[181] Batch[40] avg_epoch_loss=8.038123\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] #quality_metric: host=algo-1, epoch=181, batch=40 train loss <loss>=8.05219841003\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:58 INFO 139649395074880] Epoch[181] Batch [40]#011Speed: 795.85 samples/sec#011loss=8.052198\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[181] Batch[45] avg_epoch_loss=8.000013\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=181, batch=45 train loss <loss>=7.68750610352\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[181] Batch [45]#011Speed: 1379.98 samples/sec#011loss=7.687506\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] processed a total of 1546 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1607.848882675171, \"sum\": 1607.848882675171, \"min\": 1607.848882675171}}, \"EndTime\": 1577414699.078592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414697.470325}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=961.467281925 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=181, train loss <loss>=7.94231054734\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[182] Batch[0] avg_epoch_loss=8.152782\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=8.15278244019\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[182] Batch[5] avg_epoch_loss=8.212579\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=8.2125787735\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[182] Batch [5]#011Speed: 1661.02 samples/sec#011loss=8.212579\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[182] Batch[10] avg_epoch_loss=8.179651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=8.14013786316\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[182] Batch [10]#011Speed: 710.85 samples/sec#011loss=8.140138\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[182] Batch[15] avg_epoch_loss=8.236382\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=182, batch=15 train loss <loss>=8.36119041443\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[182] Batch [15]#011Speed: 1746.61 samples/sec#011loss=8.361190\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[182] Batch[20] avg_epoch_loss=8.200828\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=182, batch=20 train loss <loss>=8.08705406189\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[182] Batch [20]#011Speed: 764.16 samples/sec#011loss=8.087054\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[182] Batch[25] avg_epoch_loss=8.112421\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] #quality_metric: host=algo-1, epoch=182, batch=25 train loss <loss>=7.74111127853\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:44:59 INFO 139649395074880] Epoch[182] Batch [25]#011Speed: 1610.92 samples/sec#011loss=7.741111\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[182] Batch[30] avg_epoch_loss=8.061697\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=182, batch=30 train loss <loss>=7.79793157578\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[182] Batch [30]#011Speed: 806.88 samples/sec#011loss=7.797932\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[182] Batch[35] avg_epoch_loss=8.032070\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=182, batch=35 train loss <loss>=7.84838113785\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[182] Batch [35]#011Speed: 1649.39 samples/sec#011loss=7.848381\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[182] Batch[40] avg_epoch_loss=8.012084\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=182, batch=40 train loss <loss>=7.86818618774\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[182] Batch [40]#011Speed: 738.77 samples/sec#011loss=7.868186\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[182] Batch[45] avg_epoch_loss=7.987084\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=182, batch=45 train loss <loss>=7.78208198547\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[182] Batch [45]#011Speed: 1658.17 samples/sec#011loss=7.782082\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[182] Batch[50] avg_epoch_loss=7.971745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=182, batch=50 train loss <loss>=7.83062849045\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[182] Batch [50]#011Speed: 1072.19 samples/sec#011loss=7.830628\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] processed a total of 1602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1606.4021587371826, \"sum\": 1606.4021587371826, \"min\": 1606.4021587371826}}, \"EndTime\": 1577414700.6855, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414699.078668}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=997.192571538 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=182, train loss <loss>=7.97174485524\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[183] Batch[0] avg_epoch_loss=8.539223\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=8.53922271729\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[183] Batch[5] avg_epoch_loss=8.107846\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=8.10784554482\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:00 INFO 139649395074880] Epoch[183] Batch [5]#011Speed: 1561.02 samples/sec#011loss=8.107846\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] Epoch[183] Batch[10] avg_epoch_loss=8.172249\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=8.24953374863\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] Epoch[183] Batch [10]#011Speed: 790.77 samples/sec#011loss=8.249534\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] Epoch[183] Batch[15] avg_epoch_loss=8.169051\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=183, batch=15 train loss <loss>=8.16201505661\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] Epoch[183] Batch [15]#011Speed: 1355.58 samples/sec#011loss=8.162015\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] Epoch[183] Batch[20] avg_epoch_loss=8.202118\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=183, batch=20 train loss <loss>=8.30793333054\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] Epoch[183] Batch [20]#011Speed: 756.75 samples/sec#011loss=8.307933\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] Epoch[183] Batch[25] avg_epoch_loss=8.143735\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=183, batch=25 train loss <loss>=7.8985244751\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] Epoch[183] Batch [25]#011Speed: 1343.64 samples/sec#011loss=7.898524\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] Epoch[183] Batch[30] avg_epoch_loss=8.069718\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=183, batch=30 train loss <loss>=7.6848326683\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] Epoch[183] Batch [30]#011Speed: 771.71 samples/sec#011loss=7.684833\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] Epoch[183] Batch[35] avg_epoch_loss=7.998377\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] #quality_metric: host=algo-1, epoch=183, batch=35 train loss <loss>=7.55605831146\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:01 INFO 139649395074880] Epoch[183] Batch [35]#011Speed: 1666.25 samples/sec#011loss=7.556058\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[183] Batch[40] avg_epoch_loss=7.979465\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=183, batch=40 train loss <loss>=7.84330291748\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[183] Batch [40]#011Speed: 784.75 samples/sec#011loss=7.843303\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[183] Batch[45] avg_epoch_loss=7.947288\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=183, batch=45 train loss <loss>=7.68343105316\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[183] Batch [45]#011Speed: 1291.65 samples/sec#011loss=7.683431\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[183] Batch[50] avg_epoch_loss=7.909333\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=183, batch=50 train loss <loss>=7.56014862061\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[183] Batch [50]#011Speed: 1086.12 samples/sec#011loss=7.560149\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] processed a total of 1604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1659.5430374145508, \"sum\": 1659.5430374145508, \"min\": 1659.5430374145508}}, \"EndTime\": 1577414702.345575, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414700.685571}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=966.466561501 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=183, train loss <loss>=7.90933282703\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[184] Batch[0] avg_epoch_loss=7.738137\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=7.73813676834\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[184] Batch[5] avg_epoch_loss=8.037867\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=8.03786698977\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[184] Batch [5]#011Speed: 1280.30 samples/sec#011loss=8.037867\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[184] Batch[10] avg_epoch_loss=8.091755\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=8.15642004013\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[184] Batch [10]#011Speed: 746.60 samples/sec#011loss=8.156420\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[184] Batch[15] avg_epoch_loss=8.103390\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] #quality_metric: host=algo-1, epoch=184, batch=15 train loss <loss>=8.12898626328\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:02 INFO 139649395074880] Epoch[184] Batch [15]#011Speed: 1540.86 samples/sec#011loss=8.128986\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch[20] avg_epoch_loss=8.084242\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=184, batch=20 train loss <loss>=8.02296895981\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch [20]#011Speed: 742.56 samples/sec#011loss=8.022969\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch[25] avg_epoch_loss=8.069384\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=184, batch=25 train loss <loss>=8.0069817543\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch [25]#011Speed: 1549.89 samples/sec#011loss=8.006982\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch[30] avg_epoch_loss=8.022351\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=184, batch=30 train loss <loss>=7.77778015137\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch [30]#011Speed: 710.61 samples/sec#011loss=7.777780\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch[35] avg_epoch_loss=7.997822\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=184, batch=35 train loss <loss>=7.84574346542\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch [35]#011Speed: 1532.90 samples/sec#011loss=7.845743\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch[40] avg_epoch_loss=7.948194\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=184, batch=40 train loss <loss>=7.59087114334\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch [40]#011Speed: 805.26 samples/sec#011loss=7.590871\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch[45] avg_epoch_loss=7.927482\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=184, batch=45 train loss <loss>=7.7576467514\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch [45]#011Speed: 1572.58 samples/sec#011loss=7.757647\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch[50] avg_epoch_loss=7.909351\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=184, batch=50 train loss <loss>=7.74254426956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] Epoch[184] Batch [50]#011Speed: 1191.34 samples/sec#011loss=7.742544\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] processed a total of 1622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1651.8688201904297, \"sum\": 1651.8688201904297, \"min\": 1651.8688201904297}}, \"EndTime\": 1577414703.997968, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414702.345656}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=981.860345039 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] #quality_metric: host=algo-1, epoch=184, train loss <loss>=7.90935129278\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:03 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] Epoch[185] Batch[0] avg_epoch_loss=8.150326\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=8.15032577515\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] Epoch[185] Batch[5] avg_epoch_loss=8.149130\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=8.14913042386\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] Epoch[185] Batch [5]#011Speed: 1328.74 samples/sec#011loss=8.149130\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] Epoch[185] Batch[10] avg_epoch_loss=8.093986\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=8.0278134346\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] Epoch[185] Batch [10]#011Speed: 720.17 samples/sec#011loss=8.027813\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] Epoch[185] Batch[15] avg_epoch_loss=8.241201\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=185, batch=15 train loss <loss>=8.5650718689\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] Epoch[185] Batch [15]#011Speed: 1269.49 samples/sec#011loss=8.565072\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] Epoch[185] Batch[20] avg_epoch_loss=8.273020\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=185, batch=20 train loss <loss>=8.37484035492\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] Epoch[185] Batch [20]#011Speed: 716.38 samples/sec#011loss=8.374840\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] Epoch[185] Batch[25] avg_epoch_loss=8.203900\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] #quality_metric: host=algo-1, epoch=185, batch=25 train loss <loss>=7.91359853745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:04 INFO 139649395074880] Epoch[185] Batch [25]#011Speed: 1508.04 samples/sec#011loss=7.913599\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[185] Batch[30] avg_epoch_loss=8.100293\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=185, batch=30 train loss <loss>=7.56153411865\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[185] Batch [30]#011Speed: 1575.42 samples/sec#011loss=7.561534\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[185] Batch[35] avg_epoch_loss=8.014208\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=185, batch=35 train loss <loss>=7.48048191071\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[185] Batch [35]#011Speed: 781.95 samples/sec#011loss=7.480482\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[185] Batch[40] avg_epoch_loss=7.979736\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=185, batch=40 train loss <loss>=7.73153800964\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[185] Batch [40]#011Speed: 1417.31 samples/sec#011loss=7.731538\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[185] Batch[45] avg_epoch_loss=7.981699\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=185, batch=45 train loss <loss>=7.99779214859\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[185] Batch [45]#011Speed: 766.64 samples/sec#011loss=7.997792\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[185] Batch[50] avg_epoch_loss=7.961816\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=185, batch=50 train loss <loss>=7.77890024185\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[185] Batch [50]#011Speed: 1540.77 samples/sec#011loss=7.778900\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] processed a total of 1697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1729.8588752746582, \"sum\": 1729.8588752746582, \"min\": 1729.8588752746582}}, \"EndTime\": 1577414705.728379, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414703.998028}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=980.956073493 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=185, train loss <loss>=7.91961120676\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[186] Batch[0] avg_epoch_loss=7.545846\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=7.54584550858\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[186] Batch[5] avg_epoch_loss=8.261740\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=8.26173965136\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:05 INFO 139649395074880] Epoch[186] Batch [5]#011Speed: 1554.12 samples/sec#011loss=8.261740\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] Epoch[186] Batch[10] avg_epoch_loss=8.155677\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=8.02840270996\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] Epoch[186] Batch [10]#011Speed: 742.11 samples/sec#011loss=8.028403\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] Epoch[186] Batch[15] avg_epoch_loss=8.289440\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=186, batch=15 train loss <loss>=8.58371829987\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] Epoch[186] Batch [15]#011Speed: 1457.91 samples/sec#011loss=8.583718\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] Epoch[186] Batch[20] avg_epoch_loss=8.278427\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=186, batch=20 train loss <loss>=8.24318447113\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] Epoch[186] Batch [20]#011Speed: 779.79 samples/sec#011loss=8.243184\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] Epoch[186] Batch[25] avg_epoch_loss=8.178632\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=186, batch=25 train loss <loss>=7.75949268341\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] Epoch[186] Batch [25]#011Speed: 1310.02 samples/sec#011loss=7.759493\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] Epoch[186] Batch[30] avg_epoch_loss=8.131437\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=186, batch=30 train loss <loss>=7.88602457047\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] Epoch[186] Batch [30]#011Speed: 785.87 samples/sec#011loss=7.886025\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] Epoch[186] Batch[35] avg_epoch_loss=8.051891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] #quality_metric: host=algo-1, epoch=186, batch=35 train loss <loss>=7.55870389938\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:06 INFO 139649395074880] Epoch[186] Batch [35]#011Speed: 1569.32 samples/sec#011loss=7.558704\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[186] Batch[40] avg_epoch_loss=8.046477\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=186, batch=40 train loss <loss>=8.00749740601\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[186] Batch [40]#011Speed: 811.38 samples/sec#011loss=8.007497\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[186] Batch[45] avg_epoch_loss=8.020485\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=186, batch=45 train loss <loss>=7.80734634399\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[186] Batch [45]#011Speed: 1466.29 samples/sec#011loss=7.807346\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[186] Batch[50] avg_epoch_loss=7.985161\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=186, batch=50 train loss <loss>=7.66018276215\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[186] Batch [50]#011Speed: 1227.99 samples/sec#011loss=7.660183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] processed a total of 1631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1621.7880249023438, \"sum\": 1621.7880249023438, \"min\": 1621.7880249023438}}, \"EndTime\": 1577414707.350664, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414705.728436}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1005.61065288 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=186, train loss <loss>=7.98516085569\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[187] Batch[0] avg_epoch_loss=7.886468\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=7.88646841049\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[187] Batch[5] avg_epoch_loss=8.050081\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=8.05008101463\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[187] Batch [5]#011Speed: 1385.20 samples/sec#011loss=8.050081\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[187] Batch[10] avg_epoch_loss=8.047508\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=8.04442043304\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[187] Batch [10]#011Speed: 790.88 samples/sec#011loss=8.044420\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[187] Batch[15] avg_epoch_loss=8.096902\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] #quality_metric: host=algo-1, epoch=187, batch=15 train loss <loss>=8.20556945801\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:07 INFO 139649395074880] Epoch[187] Batch [15]#011Speed: 1686.69 samples/sec#011loss=8.205569\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] Epoch[187] Batch[20] avg_epoch_loss=8.165812\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=187, batch=20 train loss <loss>=8.38632125854\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] Epoch[187] Batch [20]#011Speed: 777.29 samples/sec#011loss=8.386321\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] Epoch[187] Batch[25] avg_epoch_loss=8.085204\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=187, batch=25 train loss <loss>=7.74665002823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] Epoch[187] Batch [25]#011Speed: 1564.36 samples/sec#011loss=7.746650\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] Epoch[187] Batch[30] avg_epoch_loss=8.030262\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=187, batch=30 train loss <loss>=7.74456357956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] Epoch[187] Batch [30]#011Speed: 778.34 samples/sec#011loss=7.744564\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] Epoch[187] Batch[35] avg_epoch_loss=8.024221\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=187, batch=35 train loss <loss>=7.98676710129\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] Epoch[187] Batch [35]#011Speed: 1519.50 samples/sec#011loss=7.986767\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] Epoch[187] Batch[40] avg_epoch_loss=8.005599\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=187, batch=40 train loss <loss>=7.87152633667\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] Epoch[187] Batch [40]#011Speed: 802.92 samples/sec#011loss=7.871526\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] Epoch[187] Batch[45] avg_epoch_loss=7.992831\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=187, batch=45 train loss <loss>=7.88813438416\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] Epoch[187] Batch [45]#011Speed: 1313.55 samples/sec#011loss=7.888134\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] processed a total of 1560 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1580.2290439605713, \"sum\": 1580.2290439605713, \"min\": 1580.2290439605713}}, \"EndTime\": 1577414708.931393, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414707.350741}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=987.135663836 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] #quality_metric: host=algo-1, epoch=187, train loss <loss>=7.9760022358\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:08 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] Epoch[188] Batch[0] avg_epoch_loss=8.284841\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=8.2848405838\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] Epoch[188] Batch[5] avg_epoch_loss=8.076804\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=8.07680376371\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] Epoch[188] Batch [5]#011Speed: 1310.55 samples/sec#011loss=8.076804\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] Epoch[188] Batch[10] avg_epoch_loss=8.101738\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=8.13165941238\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] Epoch[188] Batch [10]#011Speed: 688.30 samples/sec#011loss=8.131659\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] Epoch[188] Batch[15] avg_epoch_loss=8.224348\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=188, batch=15 train loss <loss>=8.49408874512\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] Epoch[188] Batch [15]#011Speed: 1298.13 samples/sec#011loss=8.494089\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] Epoch[188] Batch[20] avg_epoch_loss=8.256558\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=188, batch=20 train loss <loss>=8.35962944031\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] Epoch[188] Batch [20]#011Speed: 1397.06 samples/sec#011loss=8.359629\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] Epoch[188] Batch[25] avg_epoch_loss=8.154945\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] #quality_metric: host=algo-1, epoch=188, batch=25 train loss <loss>=7.72817192078\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:09 INFO 139649395074880] Epoch[188] Batch [25]#011Speed: 735.50 samples/sec#011loss=7.728172\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[188] Batch[30] avg_epoch_loss=8.055609\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=188, batch=30 train loss <loss>=7.53906078339\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[188] Batch [30]#011Speed: 822.89 samples/sec#011loss=7.539061\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[188] Batch[35] avg_epoch_loss=7.981760\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=188, batch=35 train loss <loss>=7.52389612198\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[188] Batch [35]#011Speed: 1506.82 samples/sec#011loss=7.523896\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[188] Batch[40] avg_epoch_loss=7.941326\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=188, batch=40 train loss <loss>=7.65020008087\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[188] Batch [40]#011Speed: 762.92 samples/sec#011loss=7.650200\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[188] Batch[45] avg_epoch_loss=7.951735\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=188, batch=45 train loss <loss>=8.03709440231\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[188] Batch [45]#011Speed: 1532.30 samples/sec#011loss=8.037094\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[188] Batch[50] avg_epoch_loss=7.893308\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=188, batch=50 train loss <loss>=7.35578050613\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[188] Batch [50]#011Speed: 1155.12 samples/sec#011loss=7.355781\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] processed a total of 1633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1711.289882659912, \"sum\": 1711.289882659912, \"min\": 1711.289882659912}}, \"EndTime\": 1577414710.643222, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414708.931456}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=954.177172212 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=188, train loss <loss>=7.83649282272\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[189] Batch[0] avg_epoch_loss=8.157700\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=8.15769958496\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[189] Batch[5] avg_epoch_loss=8.237414\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=8.23741388321\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:10 INFO 139649395074880] Epoch[189] Batch [5]#011Speed: 1323.68 samples/sec#011loss=8.237414\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] Epoch[189] Batch[10] avg_epoch_loss=8.072702\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=7.87504796982\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] Epoch[189] Batch [10]#011Speed: 749.74 samples/sec#011loss=7.875048\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] Epoch[189] Batch[15] avg_epoch_loss=8.038823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=189, batch=15 train loss <loss>=7.96428890228\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] Epoch[189] Batch [15]#011Speed: 1544.77 samples/sec#011loss=7.964289\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] Epoch[189] Batch[20] avg_epoch_loss=8.067509\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=189, batch=20 train loss <loss>=8.15930223465\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] Epoch[189] Batch [20]#011Speed: 785.14 samples/sec#011loss=8.159302\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] Epoch[189] Batch[25] avg_epoch_loss=8.003706\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=189, batch=25 train loss <loss>=7.73573589325\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] Epoch[189] Batch [25]#011Speed: 1539.42 samples/sec#011loss=7.735736\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] Epoch[189] Batch[30] avg_epoch_loss=7.932879\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=189, batch=30 train loss <loss>=7.56457529068\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] Epoch[189] Batch [30]#011Speed: 797.79 samples/sec#011loss=7.564575\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] Epoch[189] Batch[35] avg_epoch_loss=7.903078\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] #quality_metric: host=algo-1, epoch=189, batch=35 train loss <loss>=7.71831293106\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:11 INFO 139649395074880] Epoch[189] Batch [35]#011Speed: 1412.10 samples/sec#011loss=7.718313\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[189] Batch[40] avg_epoch_loss=7.892787\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=189, batch=40 train loss <loss>=7.81869306564\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[189] Batch [40]#011Speed: 734.58 samples/sec#011loss=7.818693\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[189] Batch[45] avg_epoch_loss=7.905866\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=189, batch=45 train loss <loss>=8.01311006546\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[189] Batch [45]#011Speed: 1326.07 samples/sec#011loss=8.013110\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[189] Batch[50] avg_epoch_loss=7.856714\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=189, batch=50 train loss <loss>=7.40451631546\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[189] Batch [50]#011Speed: 1178.91 samples/sec#011loss=7.404516\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] processed a total of 1620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1675.9719848632812, \"sum\": 1675.9719848632812, \"min\": 1675.9719848632812}}, \"EndTime\": 1577414712.319742, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414710.643299}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=966.540433255 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=189, train loss <loss>=7.85671365962\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[190] Batch[0] avg_epoch_loss=8.206123\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=8.20612335205\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[190] Batch[5] avg_epoch_loss=8.153541\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=8.15354084969\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[190] Batch [5]#011Speed: 1459.73 samples/sec#011loss=8.153541\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[190] Batch[10] avg_epoch_loss=7.964563\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=7.73779067993\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[190] Batch [10]#011Speed: 1269.47 samples/sec#011loss=7.737791\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[190] Batch[15] avg_epoch_loss=8.125396\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] #quality_metric: host=algo-1, epoch=190, batch=15 train loss <loss>=8.47922639847\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:12 INFO 139649395074880] Epoch[190] Batch [15]#011Speed: 762.55 samples/sec#011loss=8.479226\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch[20] avg_epoch_loss=8.109582\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=190, batch=20 train loss <loss>=8.05898008347\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch [20]#011Speed: 1447.08 samples/sec#011loss=8.058980\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch[25] avg_epoch_loss=8.036705\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=190, batch=25 train loss <loss>=7.73061943054\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch [25]#011Speed: 816.76 samples/sec#011loss=7.730619\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch[30] avg_epoch_loss=7.976648\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=190, batch=30 train loss <loss>=7.66435050964\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch [30]#011Speed: 692.36 samples/sec#011loss=7.664351\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch[35] avg_epoch_loss=7.955604\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=190, batch=35 train loss <loss>=7.82513113022\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch [35]#011Speed: 1542.41 samples/sec#011loss=7.825131\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch[40] avg_epoch_loss=7.955446\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=190, batch=40 train loss <loss>=7.95431184769\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch [40]#011Speed: 820.31 samples/sec#011loss=7.954312\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch[45] avg_epoch_loss=7.907956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=190, batch=45 train loss <loss>=7.51853160858\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch [45]#011Speed: 1473.04 samples/sec#011loss=7.518532\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch[50] avg_epoch_loss=7.880758\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] #quality_metric: host=algo-1, epoch=190, batch=50 train loss <loss>=7.63053894043\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:13 INFO 139649395074880] Epoch[190] Batch [50]#011Speed: 1201.40 samples/sec#011loss=7.630539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] processed a total of 1693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1709.7620964050293, \"sum\": 1709.7620964050293, \"min\": 1709.7620964050293}}, \"EndTime\": 1577414714.030001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414712.319818}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=990.129138949 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=190, train loss <loss>=7.88781388301\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] Epoch[191] Batch[0] avg_epoch_loss=8.639170\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=8.63916969299\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] Epoch[191] Batch[5] avg_epoch_loss=8.178098\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=8.17809844017\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] Epoch[191] Batch [5]#011Speed: 1326.46 samples/sec#011loss=8.178098\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] Epoch[191] Batch[10] avg_epoch_loss=8.196840\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=8.21932916641\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] Epoch[191] Batch [10]#011Speed: 798.18 samples/sec#011loss=8.219329\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] Epoch[191] Batch[15] avg_epoch_loss=8.324306\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=191, batch=15 train loss <loss>=8.60473327637\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] Epoch[191] Batch [15]#011Speed: 1261.16 samples/sec#011loss=8.604733\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] Epoch[191] Batch[20] avg_epoch_loss=8.206071\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=191, batch=20 train loss <loss>=7.82771615982\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] Epoch[191] Batch [20]#011Speed: 731.82 samples/sec#011loss=7.827716\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] Epoch[191] Batch[25] avg_epoch_loss=8.118609\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] #quality_metric: host=algo-1, epoch=191, batch=25 train loss <loss>=7.75127058029\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:14 INFO 139649395074880] Epoch[191] Batch [25]#011Speed: 1345.01 samples/sec#011loss=7.751271\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[191] Batch[30] avg_epoch_loss=8.080259\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=191, batch=30 train loss <loss>=7.880838871\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[191] Batch [30]#011Speed: 740.01 samples/sec#011loss=7.880839\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[191] Batch[35] avg_epoch_loss=8.021898\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=191, batch=35 train loss <loss>=7.66005954742\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[191] Batch [35]#011Speed: 1654.64 samples/sec#011loss=7.660060\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[191] Batch[40] avg_epoch_loss=7.986194\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=191, batch=40 train loss <loss>=7.72912836075\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[191] Batch [40]#011Speed: 704.03 samples/sec#011loss=7.729128\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[191] Batch[45] avg_epoch_loss=7.972260\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=191, batch=45 train loss <loss>=7.85799703598\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[191] Batch [45]#011Speed: 1363.29 samples/sec#011loss=7.857997\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[191] Batch[50] avg_epoch_loss=7.890993\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=191, batch=50 train loss <loss>=7.14333438873\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[191] Batch [50]#011Speed: 1215.08 samples/sec#011loss=7.143334\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] processed a total of 1601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1696.0790157318115, \"sum\": 1696.0790157318115, \"min\": 1696.0790157318115}}, \"EndTime\": 1577414715.726674, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414714.03008}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=943.879510976 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=191, train loss <loss>=7.89099269755\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[192] Batch[0] avg_epoch_loss=7.835616\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=7.83561563492\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[192] Batch[5] avg_epoch_loss=8.022724\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=8.02272431056\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:15 INFO 139649395074880] Epoch[192] Batch [5]#011Speed: 1525.36 samples/sec#011loss=8.022724\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] Epoch[192] Batch[10] avg_epoch_loss=8.067324\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=8.12084445953\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] Epoch[192] Batch [10]#011Speed: 752.06 samples/sec#011loss=8.120844\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] Epoch[192] Batch[15] avg_epoch_loss=8.063180\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=192, batch=15 train loss <loss>=8.05406265259\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] Epoch[192] Batch [15]#011Speed: 1332.75 samples/sec#011loss=8.054063\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] Epoch[192] Batch[20] avg_epoch_loss=8.010381\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=192, batch=20 train loss <loss>=7.84142246246\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] Epoch[192] Batch [20]#011Speed: 768.08 samples/sec#011loss=7.841422\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] Epoch[192] Batch[25] avg_epoch_loss=7.970752\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=192, batch=25 train loss <loss>=7.80431413651\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] Epoch[192] Batch [25]#011Speed: 1545.85 samples/sec#011loss=7.804314\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] Epoch[192] Batch[30] avg_epoch_loss=7.964800\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=192, batch=30 train loss <loss>=7.9338470459\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] Epoch[192] Batch [30]#011Speed: 791.93 samples/sec#011loss=7.933847\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] Epoch[192] Batch[35] avg_epoch_loss=7.924301\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] #quality_metric: host=algo-1, epoch=192, batch=35 train loss <loss>=7.6732049942\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:16 INFO 139649395074880] Epoch[192] Batch [35]#011Speed: 1581.36 samples/sec#011loss=7.673205\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] Epoch[192] Batch[40] avg_epoch_loss=7.890034\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=192, batch=40 train loss <loss>=7.64331140518\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] Epoch[192] Batch [40]#011Speed: 805.09 samples/sec#011loss=7.643311\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] Epoch[192] Batch[45] avg_epoch_loss=7.910740\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=192, batch=45 train loss <loss>=8.08053541183\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] Epoch[192] Batch [45]#011Speed: 1557.87 samples/sec#011loss=8.080535\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] processed a total of 1571 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1626.3980865478516, \"sum\": 1626.3980865478516, \"min\": 1626.3980865478516}}, \"EndTime\": 1577414717.353559, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414715.726752}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=965.875875397 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=192, train loss <loss>=7.85689936638\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] Epoch[193] Batch[0] avg_epoch_loss=8.191895\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=8.19189548492\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] Epoch[193] Batch[5] avg_epoch_loss=7.827271\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=7.82727098465\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] Epoch[193] Batch [5]#011Speed: 1556.57 samples/sec#011loss=7.827271\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] Epoch[193] Batch[10] avg_epoch_loss=7.929882\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=8.05301599503\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] Epoch[193] Batch [10]#011Speed: 764.79 samples/sec#011loss=8.053016\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] Epoch[193] Batch[15] avg_epoch_loss=8.072132\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] #quality_metric: host=algo-1, epoch=193, batch=15 train loss <loss>=8.38507995605\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:17 INFO 139649395074880] Epoch[193] Batch [15]#011Speed: 1569.86 samples/sec#011loss=8.385080\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] Epoch[193] Batch[20] avg_epoch_loss=8.090522\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=193, batch=20 train loss <loss>=8.14937076569\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] Epoch[193] Batch [20]#011Speed: 773.01 samples/sec#011loss=8.149371\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] Epoch[193] Batch[25] avg_epoch_loss=7.942724\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=193, batch=25 train loss <loss>=7.32197370529\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] Epoch[193] Batch [25]#011Speed: 1567.15 samples/sec#011loss=7.321974\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] Epoch[193] Batch[30] avg_epoch_loss=7.900305\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=193, batch=30 train loss <loss>=7.67972650528\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] Epoch[193] Batch [30]#011Speed: 799.72 samples/sec#011loss=7.679727\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] Epoch[193] Batch[35] avg_epoch_loss=7.872512\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=193, batch=35 train loss <loss>=7.70019159317\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] Epoch[193] Batch [35]#011Speed: 1640.15 samples/sec#011loss=7.700192\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] Epoch[193] Batch[40] avg_epoch_loss=7.863346\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=193, batch=40 train loss <loss>=7.79735155106\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] Epoch[193] Batch [40]#011Speed: 770.05 samples/sec#011loss=7.797352\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] Epoch[193] Batch[45] avg_epoch_loss=7.873330\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=193, batch=45 train loss <loss>=7.95519695282\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] Epoch[193] Batch [45]#011Speed: 1394.13 samples/sec#011loss=7.955197\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] processed a total of 1584 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1577.6028633117676, \"sum\": 1577.6028633117676, \"min\": 1577.6028633117676}}, \"EndTime\": 1577414718.931727, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414717.353625}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1003.99124606 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] #quality_metric: host=algo-1, epoch=193, train loss <loss>=7.82185951233\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:18 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] Epoch[194] Batch[0] avg_epoch_loss=8.582629\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=8.5826292038\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] Epoch[194] Batch[5] avg_epoch_loss=8.100884\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=8.10088396072\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] Epoch[194] Batch [5]#011Speed: 1528.01 samples/sec#011loss=8.100884\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] Epoch[194] Batch[10] avg_epoch_loss=8.083239\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=8.06206531525\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] Epoch[194] Batch [10]#011Speed: 764.58 samples/sec#011loss=8.062065\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] Epoch[194] Batch[15] avg_epoch_loss=8.143484\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=194, batch=15 train loss <loss>=8.27602376938\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] Epoch[194] Batch [15]#011Speed: 1700.79 samples/sec#011loss=8.276024\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] Epoch[194] Batch[20] avg_epoch_loss=8.070106\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=194, batch=20 train loss <loss>=7.83529415131\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] Epoch[194] Batch [20]#011Speed: 701.99 samples/sec#011loss=7.835294\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] Epoch[194] Batch[25] avg_epoch_loss=8.034582\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] #quality_metric: host=algo-1, epoch=194, batch=25 train loss <loss>=7.88538360596\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:19 INFO 139649395074880] Epoch[194] Batch [25]#011Speed: 1519.59 samples/sec#011loss=7.885384\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] Epoch[194] Batch[30] avg_epoch_loss=8.008653\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=194, batch=30 train loss <loss>=7.87381944656\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] Epoch[194] Batch [30]#011Speed: 754.87 samples/sec#011loss=7.873819\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] Epoch[194] Batch[35] avg_epoch_loss=7.973584\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=194, batch=35 train loss <loss>=7.75615472794\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] Epoch[194] Batch [35]#011Speed: 1326.95 samples/sec#011loss=7.756155\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] Epoch[194] Batch[40] avg_epoch_loss=7.944780\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=194, batch=40 train loss <loss>=7.73739652634\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] Epoch[194] Batch [40]#011Speed: 693.62 samples/sec#011loss=7.737397\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] Epoch[194] Batch[45] avg_epoch_loss=7.905780\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=194, batch=45 train loss <loss>=7.58597698212\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] Epoch[194] Batch [45]#011Speed: 1459.03 samples/sec#011loss=7.585977\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] processed a total of 1591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1664.8058891296387, \"sum\": 1664.8058891296387, \"min\": 1664.8058891296387}}, \"EndTime\": 1577414720.597098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414718.93179}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=955.596901942 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=194, train loss <loss>=7.83881574631\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] Epoch[195] Batch[0] avg_epoch_loss=7.809225\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=7.8092250824\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] Epoch[195] Batch[5] avg_epoch_loss=8.064029\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=8.06402921677\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:20 INFO 139649395074880] Epoch[195] Batch [5]#011Speed: 1632.58 samples/sec#011loss=8.064029\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] Epoch[195] Batch[10] avg_epoch_loss=8.226691\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=8.42188606262\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] Epoch[195] Batch [10]#011Speed: 770.55 samples/sec#011loss=8.421886\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] Epoch[195] Batch[15] avg_epoch_loss=8.199935\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=195, batch=15 train loss <loss>=8.1410695076\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] Epoch[195] Batch [15]#011Speed: 1514.35 samples/sec#011loss=8.141070\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] Epoch[195] Batch[20] avg_epoch_loss=8.203090\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=195, batch=20 train loss <loss>=8.21318635941\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] Epoch[195] Batch [20]#011Speed: 700.61 samples/sec#011loss=8.213186\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] Epoch[195] Batch[25] avg_epoch_loss=8.104896\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=195, batch=25 train loss <loss>=7.69248104095\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] Epoch[195] Batch [25]#011Speed: 1262.78 samples/sec#011loss=7.692481\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] Epoch[195] Batch[30] avg_epoch_loss=8.067303\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=195, batch=30 train loss <loss>=7.87181797028\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] Epoch[195] Batch [30]#011Speed: 747.49 samples/sec#011loss=7.871818\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] Epoch[195] Batch[35] avg_epoch_loss=7.991498\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] #quality_metric: host=algo-1, epoch=195, batch=35 train loss <loss>=7.52151041031\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:21 INFO 139649395074880] Epoch[195] Batch [35]#011Speed: 1312.88 samples/sec#011loss=7.521510\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[195] Batch[40] avg_epoch_loss=8.003093\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=195, batch=40 train loss <loss>=8.08657636642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[195] Batch [40]#011Speed: 720.93 samples/sec#011loss=8.086576\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[195] Batch[45] avg_epoch_loss=8.005366\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=195, batch=45 train loss <loss>=8.02399988174\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[195] Batch [45]#011Speed: 1384.11 samples/sec#011loss=8.024000\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[195] Batch[50] avg_epoch_loss=7.968177\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=195, batch=50 train loss <loss>=7.6260468483\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[195] Batch [50]#011Speed: 1108.63 samples/sec#011loss=7.626047\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] processed a total of 1615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1706.6590785980225, \"sum\": 1706.6590785980225, \"min\": 1706.6590785980225}}, \"EndTime\": 1577414722.304341, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414720.597184}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=946.237354145 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=195, train loss <loss>=7.96817740272\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[196] Batch[0] avg_epoch_loss=8.348185\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=8.34818458557\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[196] Batch[5] avg_epoch_loss=8.192320\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=8.19231994947\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[196] Batch [5]#011Speed: 1400.44 samples/sec#011loss=8.192320\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[196] Batch[10] avg_epoch_loss=8.207420\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=8.22553939819\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[196] Batch [10]#011Speed: 779.83 samples/sec#011loss=8.225539\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[196] Batch[15] avg_epoch_loss=8.218677\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] #quality_metric: host=algo-1, epoch=196, batch=15 train loss <loss>=8.24344425201\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:22 INFO 139649395074880] Epoch[196] Batch [15]#011Speed: 1518.60 samples/sec#011loss=8.243444\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] Epoch[196] Batch[20] avg_epoch_loss=8.246732\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=196, batch=20 train loss <loss>=8.33650522232\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] Epoch[196] Batch [20]#011Speed: 795.18 samples/sec#011loss=8.336505\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] Epoch[196] Batch[25] avg_epoch_loss=8.157669\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=196, batch=25 train loss <loss>=7.78360624313\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] Epoch[196] Batch [25]#011Speed: 1543.84 samples/sec#011loss=7.783606\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] Epoch[196] Batch[30] avg_epoch_loss=8.118204\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=196, batch=30 train loss <loss>=7.91298494339\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] Epoch[196] Batch [30]#011Speed: 842.38 samples/sec#011loss=7.912985\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] Epoch[196] Batch[35] avg_epoch_loss=8.036552\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=196, batch=35 train loss <loss>=7.53030948639\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] Epoch[196] Batch [35]#011Speed: 1324.09 samples/sec#011loss=7.530309\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] Epoch[196] Batch[40] avg_epoch_loss=7.959439\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=196, batch=40 train loss <loss>=7.40422925949\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] Epoch[196] Batch [40]#011Speed: 810.00 samples/sec#011loss=7.404229\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] Epoch[196] Batch[45] avg_epoch_loss=7.931022\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=196, batch=45 train loss <loss>=7.69800100327\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] Epoch[196] Batch [45]#011Speed: 1588.09 samples/sec#011loss=7.698001\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] processed a total of 1596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1580.9440612792969, \"sum\": 1580.9440612792969, \"min\": 1580.9440612792969}}, \"EndTime\": 1577414723.885806, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414722.304405}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1009.45320528 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] #quality_metric: host=algo-1, epoch=196, train loss <loss>=7.92170555115\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:23 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] Epoch[197] Batch[0] avg_epoch_loss=8.244030\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=8.24402999878\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] Epoch[197] Batch[5] avg_epoch_loss=7.884995\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=7.88499458631\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] Epoch[197] Batch [5]#011Speed: 1411.73 samples/sec#011loss=7.884995\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] Epoch[197] Batch[10] avg_epoch_loss=8.099846\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=8.35766744614\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] Epoch[197] Batch [10]#011Speed: 712.29 samples/sec#011loss=8.357667\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] Epoch[197] Batch[15] avg_epoch_loss=8.187428\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=197, batch=15 train loss <loss>=8.38010921478\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] Epoch[197] Batch [15]#011Speed: 1321.63 samples/sec#011loss=8.380109\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] Epoch[197] Batch[20] avg_epoch_loss=8.217934\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=197, batch=20 train loss <loss>=8.315554142\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] Epoch[197] Batch [20]#011Speed: 1330.69 samples/sec#011loss=8.315554\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] Epoch[197] Batch[25] avg_epoch_loss=8.117987\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] #quality_metric: host=algo-1, epoch=197, batch=25 train loss <loss>=7.69820995331\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:24 INFO 139649395074880] Epoch[197] Batch [25]#011Speed: 710.77 samples/sec#011loss=7.698210\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[197] Batch[30] avg_epoch_loss=8.078843\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=197, batch=30 train loss <loss>=7.8752948761\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[197] Batch [30]#011Speed: 725.17 samples/sec#011loss=7.875295\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[197] Batch[35] avg_epoch_loss=8.030061\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=197, batch=35 train loss <loss>=7.7276102066\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[197] Batch [35]#011Speed: 1345.64 samples/sec#011loss=7.727610\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[197] Batch[40] avg_epoch_loss=8.025809\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=197, batch=40 train loss <loss>=7.99519491196\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[197] Batch [40]#011Speed: 747.67 samples/sec#011loss=7.995195\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[197] Batch[45] avg_epoch_loss=8.030906\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=197, batch=45 train loss <loss>=8.07269887924\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[197] Batch [45]#011Speed: 1348.45 samples/sec#011loss=8.072699\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[197] Batch[50] avg_epoch_loss=8.005442\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=197, batch=50 train loss <loss>=7.77117424011\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[197] Batch [50]#011Speed: 1324.92 samples/sec#011loss=7.771174\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] processed a total of 1620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1728.4328937530518, \"sum\": 1728.4328937530518, \"min\": 1728.4328937530518}}, \"EndTime\": 1577414725.614757, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414723.885881}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=937.20560207 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=197, train loss <loss>=8.00544189939\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[198] Batch[0] avg_epoch_loss=7.895956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=7.89595603943\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[198] Batch[5] avg_epoch_loss=7.846642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=7.84664201736\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:25 INFO 139649395074880] Epoch[198] Batch [5]#011Speed: 1537.32 samples/sec#011loss=7.846642\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] Epoch[198] Batch[10] avg_epoch_loss=7.973291\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=198, batch=10 train loss <loss>=8.12527065277\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] Epoch[198] Batch [10]#011Speed: 677.74 samples/sec#011loss=8.125271\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] Epoch[198] Batch[15] avg_epoch_loss=8.054575\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=198, batch=15 train loss <loss>=8.23339805603\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] Epoch[198] Batch [15]#011Speed: 1526.75 samples/sec#011loss=8.233398\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] Epoch[198] Batch[20] avg_epoch_loss=8.139354\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=198, batch=20 train loss <loss>=8.41064586639\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] Epoch[198] Batch [20]#011Speed: 738.28 samples/sec#011loss=8.410646\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] Epoch[198] Batch[25] avg_epoch_loss=8.117557\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=198, batch=25 train loss <loss>=8.02600889206\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] Epoch[198] Batch [25]#011Speed: 1464.75 samples/sec#011loss=8.026009\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] Epoch[198] Batch[30] avg_epoch_loss=8.073683\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=198, batch=30 train loss <loss>=7.84554328918\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] Epoch[198] Batch [30]#011Speed: 733.51 samples/sec#011loss=7.845543\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] Epoch[198] Batch[35] avg_epoch_loss=8.040331\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] #quality_metric: host=algo-1, epoch=198, batch=35 train loss <loss>=7.8335442543\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:26 INFO 139649395074880] Epoch[198] Batch [35]#011Speed: 1294.58 samples/sec#011loss=7.833544\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[198] Batch[40] avg_epoch_loss=8.012240\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=198, batch=40 train loss <loss>=7.80998725891\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[198] Batch [40]#011Speed: 716.45 samples/sec#011loss=7.809987\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[198] Batch[45] avg_epoch_loss=7.995634\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=198, batch=45 train loss <loss>=7.8594619751\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[198] Batch [45]#011Speed: 1546.78 samples/sec#011loss=7.859462\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[198] Batch[50] avg_epoch_loss=7.997043\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=198, batch=50 train loss <loss>=8.01001081467\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[198] Batch [50]#011Speed: 1383.68 samples/sec#011loss=8.010011\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] processed a total of 1646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1714.2798900604248, \"sum\": 1714.2798900604248, \"min\": 1714.2798900604248}}, \"EndTime\": 1577414727.329526, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414725.614832}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=960.108905598 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=198, train loss <loss>=7.9777123653\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[199] Batch[0] avg_epoch_loss=8.312222\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=8.3122215271\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[199] Batch[5] avg_epoch_loss=8.415369\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=8.41536903381\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[199] Batch [5]#011Speed: 1548.44 samples/sec#011loss=8.415369\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[199] Batch[10] avg_epoch_loss=8.286386\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=8.13160715103\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[199] Batch [10]#011Speed: 816.58 samples/sec#011loss=8.131607\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[199] Batch[15] avg_epoch_loss=8.288806\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] #quality_metric: host=algo-1, epoch=199, batch=15 train loss <loss>=8.29412784576\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:27 INFO 139649395074880] Epoch[199] Batch [15]#011Speed: 1471.18 samples/sec#011loss=8.294128\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] Epoch[199] Batch[20] avg_epoch_loss=8.272038\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=199, batch=20 train loss <loss>=8.21838111877\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] Epoch[199] Batch [20]#011Speed: 760.12 samples/sec#011loss=8.218381\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] Epoch[199] Batch[25] avg_epoch_loss=8.160526\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=199, batch=25 train loss <loss>=7.6921754837\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] Epoch[199] Batch [25]#011Speed: 1626.10 samples/sec#011loss=7.692175\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] Epoch[199] Batch[30] avg_epoch_loss=8.085714\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=199, batch=30 train loss <loss>=7.69669065475\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] Epoch[199] Batch [30]#011Speed: 777.63 samples/sec#011loss=7.696691\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] Epoch[199] Batch[35] avg_epoch_loss=8.018893\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=199, batch=35 train loss <loss>=7.60460500717\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] Epoch[199] Batch [35]#011Speed: 1246.77 samples/sec#011loss=7.604605\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] Epoch[199] Batch[40] avg_epoch_loss=8.015147\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=199, batch=40 train loss <loss>=7.98817358017\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] Epoch[199] Batch [40]#011Speed: 709.48 samples/sec#011loss=7.988174\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] Epoch[199] Batch[45] avg_epoch_loss=7.996501\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=199, batch=45 train loss <loss>=7.84360208511\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] Epoch[199] Batch [45]#011Speed: 1306.97 samples/sec#011loss=7.843602\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] processed a total of 1579 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1640.4452323913574, \"sum\": 1640.4452323913574, \"min\": 1640.4452323913574}}, \"EndTime\": 1577414728.970505, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414727.329597}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=962.484951704 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] #quality_metric: host=algo-1, epoch=199, train loss <loss>=7.93245157242\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:28 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] Epoch[200] Batch[0] avg_epoch_loss=8.555028\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=8.55502796173\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] Epoch[200] Batch[5] avg_epoch_loss=8.042264\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=8.04226374626\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] Epoch[200] Batch [5]#011Speed: 1316.31 samples/sec#011loss=8.042264\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] Epoch[200] Batch[10] avg_epoch_loss=8.048362\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=8.05567932129\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] Epoch[200] Batch [10]#011Speed: 734.75 samples/sec#011loss=8.055679\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] Epoch[200] Batch[15] avg_epoch_loss=8.157213\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=200, batch=15 train loss <loss>=8.39668693542\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] Epoch[200] Batch [15]#011Speed: 1285.79 samples/sec#011loss=8.396687\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] Epoch[200] Batch[20] avg_epoch_loss=8.227953\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=200, batch=20 train loss <loss>=8.4543179512\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] Epoch[200] Batch [20]#011Speed: 649.02 samples/sec#011loss=8.454318\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] Epoch[200] Batch[25] avg_epoch_loss=8.120763\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] #quality_metric: host=algo-1, epoch=200, batch=25 train loss <loss>=7.67056512833\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:29 INFO 139649395074880] Epoch[200] Batch [25]#011Speed: 1393.45 samples/sec#011loss=7.670565\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[200] Batch[30] avg_epoch_loss=8.067548\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=200, batch=30 train loss <loss>=7.7908326149\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[200] Batch [30]#011Speed: 721.58 samples/sec#011loss=7.790833\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[200] Batch[35] avg_epoch_loss=8.033706\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=200, batch=35 train loss <loss>=7.82388267517\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[200] Batch [35]#011Speed: 1613.13 samples/sec#011loss=7.823883\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[200] Batch[40] avg_epoch_loss=8.013095\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=200, batch=40 train loss <loss>=7.86469869614\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[200] Batch [40]#011Speed: 785.34 samples/sec#011loss=7.864699\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[200] Batch[45] avg_epoch_loss=7.987271\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=200, batch=45 train loss <loss>=7.7755150795\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[200] Batch [45]#011Speed: 1515.88 samples/sec#011loss=7.775515\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[200] Batch[50] avg_epoch_loss=7.970554\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=200, batch=50 train loss <loss>=7.8167593956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[200] Batch [50]#011Speed: 1179.04 samples/sec#011loss=7.816759\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] processed a total of 1650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1742.7091598510742, \"sum\": 1742.7091598510742, \"min\": 1742.7091598510742}}, \"EndTime\": 1577414730.713774, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414728.970576}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=946.74147463 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=200, train loss <loss>=7.95842719995\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[201] Batch[0] avg_epoch_loss=7.875505\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=7.87550497055\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[201] Batch[5] avg_epoch_loss=8.080923\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=8.08092260361\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:30 INFO 139649395074880] Epoch[201] Batch [5]#011Speed: 1543.45 samples/sec#011loss=8.080923\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] Epoch[201] Batch[10] avg_epoch_loss=8.084002\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=8.08769826889\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] Epoch[201] Batch [10]#011Speed: 758.41 samples/sec#011loss=8.087698\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] Epoch[201] Batch[15] avg_epoch_loss=8.219874\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=201, batch=15 train loss <loss>=8.51879005432\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] Epoch[201] Batch [15]#011Speed: 1612.52 samples/sec#011loss=8.518790\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] Epoch[201] Batch[20] avg_epoch_loss=8.178253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=201, batch=20 train loss <loss>=8.04506750107\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] Epoch[201] Batch [20]#011Speed: 732.72 samples/sec#011loss=8.045068\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] Epoch[201] Batch[25] avg_epoch_loss=8.072525\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=201, batch=25 train loss <loss>=7.62846469879\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] Epoch[201] Batch [25]#011Speed: 1531.19 samples/sec#011loss=7.628465\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] Epoch[201] Batch[30] avg_epoch_loss=7.975597\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=201, batch=30 train loss <loss>=7.47157325745\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] Epoch[201] Batch [30]#011Speed: 814.30 samples/sec#011loss=7.471573\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] Epoch[201] Batch[35] avg_epoch_loss=7.922224\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] #quality_metric: host=algo-1, epoch=201, batch=35 train loss <loss>=7.59131269455\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:31 INFO 139649395074880] Epoch[201] Batch [35]#011Speed: 1362.87 samples/sec#011loss=7.591313\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] Epoch[201] Batch[40] avg_epoch_loss=7.917763\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=201, batch=40 train loss <loss>=7.8856461525\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] Epoch[201] Batch [40]#011Speed: 813.71 samples/sec#011loss=7.885646\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] Epoch[201] Batch[45] avg_epoch_loss=7.912475\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=201, batch=45 train loss <loss>=7.86910896301\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] Epoch[201] Batch [45]#011Speed: 1562.04 samples/sec#011loss=7.869109\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] processed a total of 1587 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1596.269130706787, \"sum\": 1596.269130706787, \"min\": 1596.269130706787}}, \"EndTime\": 1577414732.310571, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414730.713851}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=994.132226465 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=201, train loss <loss>=7.85226301193\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] Epoch[202] Batch[0] avg_epoch_loss=8.084253\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=8.08425331116\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] Epoch[202] Batch[5] avg_epoch_loss=7.911377\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=7.91137671471\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] Epoch[202] Batch [5]#011Speed: 1315.83 samples/sec#011loss=7.911377\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] Epoch[202] Batch[10] avg_epoch_loss=7.947153\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=7.9900847435\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] Epoch[202] Batch [10]#011Speed: 741.80 samples/sec#011loss=7.990085\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] Epoch[202] Batch[15] avg_epoch_loss=8.135820\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] #quality_metric: host=algo-1, epoch=202, batch=15 train loss <loss>=8.55088806152\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:32 INFO 139649395074880] Epoch[202] Batch [15]#011Speed: 1300.96 samples/sec#011loss=8.550888\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] Epoch[202] Batch[20] avg_epoch_loss=8.074002\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=202, batch=20 train loss <loss>=7.87618360519\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] Epoch[202] Batch [20]#011Speed: 739.80 samples/sec#011loss=7.876184\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] Epoch[202] Batch[25] avg_epoch_loss=8.005332\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=202, batch=25 train loss <loss>=7.71691856384\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] Epoch[202] Batch [25]#011Speed: 1344.88 samples/sec#011loss=7.716919\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] Epoch[202] Batch[30] avg_epoch_loss=7.985937\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=202, batch=30 train loss <loss>=7.88508319855\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] Epoch[202] Batch [30]#011Speed: 718.32 samples/sec#011loss=7.885083\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] Epoch[202] Batch[35] avg_epoch_loss=7.944245\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=202, batch=35 train loss <loss>=7.68575563431\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] Epoch[202] Batch [35]#011Speed: 1277.35 samples/sec#011loss=7.685756\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] Epoch[202] Batch[40] avg_epoch_loss=7.897826\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=202, batch=40 train loss <loss>=7.56361045837\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] Epoch[202] Batch [40]#011Speed: 752.33 samples/sec#011loss=7.563610\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] Epoch[202] Batch[45] avg_epoch_loss=7.869956\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] #quality_metric: host=algo-1, epoch=202, batch=45 train loss <loss>=7.64142227173\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:33 INFO 139649395074880] Epoch[202] Batch [45]#011Speed: 1354.92 samples/sec#011loss=7.641422\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] processed a total of 1557 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1698.1260776519775, \"sum\": 1698.1260776519775, \"min\": 1698.1260776519775}}, \"EndTime\": 1577414734.009271, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414732.310636}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=916.838471399 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=202, train loss <loss>=7.83012045646\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] Epoch[203] Batch[0] avg_epoch_loss=7.709040\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=7.70904016495\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] Epoch[203] Batch[5] avg_epoch_loss=8.058823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=8.05882263184\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] Epoch[203] Batch [5]#011Speed: 1496.10 samples/sec#011loss=8.058823\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] Epoch[203] Batch[10] avg_epoch_loss=8.100832\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=8.15124225616\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] Epoch[203] Batch [10]#011Speed: 794.68 samples/sec#011loss=8.151242\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] Epoch[203] Batch[15] avg_epoch_loss=8.137594\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=203, batch=15 train loss <loss>=8.21847028732\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] Epoch[203] Batch [15]#011Speed: 1514.29 samples/sec#011loss=8.218470\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] Epoch[203] Batch[20] avg_epoch_loss=8.105556\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=203, batch=20 train loss <loss>=8.0030374527\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] Epoch[203] Batch [20]#011Speed: 708.35 samples/sec#011loss=8.003037\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] Epoch[203] Batch[25] avg_epoch_loss=8.038491\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] #quality_metric: host=algo-1, epoch=203, batch=25 train loss <loss>=7.75681724548\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:34 INFO 139649395074880] Epoch[203] Batch [25]#011Speed: 1558.61 samples/sec#011loss=7.756817\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[203] Batch[30] avg_epoch_loss=8.002957\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=203, batch=30 train loss <loss>=7.81817626953\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[203] Batch [30]#011Speed: 813.02 samples/sec#011loss=7.818176\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[203] Batch[35] avg_epoch_loss=7.985996\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=203, batch=35 train loss <loss>=7.88084192276\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[203] Batch [35]#011Speed: 1564.06 samples/sec#011loss=7.880842\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[203] Batch[40] avg_epoch_loss=7.976228\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=203, batch=40 train loss <loss>=7.90589361191\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[203] Batch [40]#011Speed: 821.28 samples/sec#011loss=7.905894\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[203] Batch[45] avg_epoch_loss=7.967019\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=203, batch=45 train loss <loss>=7.89150619507\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[203] Batch [45]#011Speed: 1548.17 samples/sec#011loss=7.891506\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] processed a total of 1536 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1530.311107635498, \"sum\": 1530.311107635498, \"min\": 1530.311107635498}}, \"EndTime\": 1577414735.54015, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414734.009338}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1003.65789844 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=203, train loss <loss>=7.9058752358\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[204] Batch[0] avg_epoch_loss=8.537997\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=8.53799724579\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[204] Batch[5] avg_epoch_loss=8.123812\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=8.12381219864\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[204] Batch [5]#011Speed: 1307.80 samples/sec#011loss=8.123812\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[204] Batch[10] avg_epoch_loss=8.218638\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] #quality_metric: host=algo-1, epoch=204, batch=10 train loss <loss>=8.33242921829\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:35 INFO 139649395074880] Epoch[204] Batch [10]#011Speed: 773.25 samples/sec#011loss=8.332429\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] Epoch[204] Batch[15] avg_epoch_loss=8.264211\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=204, batch=15 train loss <loss>=8.36447124481\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] Epoch[204] Batch [15]#011Speed: 1573.84 samples/sec#011loss=8.364471\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] Epoch[204] Batch[20] avg_epoch_loss=8.189121\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=204, batch=20 train loss <loss>=7.94883232117\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] Epoch[204] Batch [20]#011Speed: 795.60 samples/sec#011loss=7.948832\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] Epoch[204] Batch[25] avg_epoch_loss=8.117747\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=204, batch=25 train loss <loss>=7.81797447205\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] Epoch[204] Batch [25]#011Speed: 1543.79 samples/sec#011loss=7.817974\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] Epoch[204] Batch[30] avg_epoch_loss=8.029872\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=204, batch=30 train loss <loss>=7.57292585373\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] Epoch[204] Batch [30]#011Speed: 768.26 samples/sec#011loss=7.572926\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] Epoch[204] Batch[35] avg_epoch_loss=7.965921\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=204, batch=35 train loss <loss>=7.56942491531\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] Epoch[204] Batch [35]#011Speed: 1712.52 samples/sec#011loss=7.569425\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] Epoch[204] Batch[40] avg_epoch_loss=7.932458\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] #quality_metric: host=algo-1, epoch=204, batch=40 train loss <loss>=7.6915230751\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:36 INFO 139649395074880] Epoch[204] Batch [40]#011Speed: 814.16 samples/sec#011loss=7.691523\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[204] Batch[45] avg_epoch_loss=7.931905\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=204, batch=45 train loss <loss>=7.92736997604\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[204] Batch [45]#011Speed: 1392.43 samples/sec#011loss=7.927370\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[204] Batch[50] avg_epoch_loss=7.887557\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=204, batch=50 train loss <loss>=7.47955532074\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[204] Batch [50]#011Speed: 1343.31 samples/sec#011loss=7.479555\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] processed a total of 1623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1588.7770652770996, \"sum\": 1588.7770652770996, \"min\": 1588.7770652770996}}, \"EndTime\": 1577414737.129473, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414735.540209}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1021.46853487 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=204, train loss <loss>=7.88755696428\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] loss did not improve\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[205] Batch[0] avg_epoch_loss=8.690751\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=8.69075107574\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[205] Batch[5] avg_epoch_loss=7.872576\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=7.87257552147\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[205] Batch [5]#011Speed: 1564.12 samples/sec#011loss=7.872576\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[205] Batch[10] avg_epoch_loss=8.082565\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=8.33455314636\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[205] Batch [10]#011Speed: 817.89 samples/sec#011loss=8.334553\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[205] Batch[15] avg_epoch_loss=8.114717\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=205, batch=15 train loss <loss>=8.18545045853\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[205] Batch [15]#011Speed: 1488.87 samples/sec#011loss=8.185450\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[205] Batch[20] avg_epoch_loss=8.117199\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=205, batch=20 train loss <loss>=8.12514200211\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[205] Batch [20]#011Speed: 734.64 samples/sec#011loss=8.125142\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[205] Batch[25] avg_epoch_loss=8.102369\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] #quality_metric: host=algo-1, epoch=205, batch=25 train loss <loss>=8.04008493423\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:37 INFO 139649395074880] Epoch[205] Batch [25]#011Speed: 1659.54 samples/sec#011loss=8.040085\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Epoch[205] Batch[30] avg_epoch_loss=7.994968\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=205, batch=30 train loss <loss>=7.43648061752\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Epoch[205] Batch [30]#011Speed: 714.82 samples/sec#011loss=7.436481\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Epoch[205] Batch[35] avg_epoch_loss=7.984048\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=205, batch=35 train loss <loss>=7.91634683609\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Epoch[205] Batch [35]#011Speed: 1560.65 samples/sec#011loss=7.916347\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Epoch[205] Batch[40] avg_epoch_loss=7.986349\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=205, batch=40 train loss <loss>=8.00291109085\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Epoch[205] Batch [40]#011Speed: 801.58 samples/sec#011loss=8.002911\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Epoch[205] Batch[45] avg_epoch_loss=7.974523\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=205, batch=45 train loss <loss>=7.8775519371\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Epoch[205] Batch [45]#011Speed: 1430.36 samples/sec#011loss=7.877552\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Epoch[205] Batch[50] avg_epoch_loss=7.922744\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=205, batch=50 train loss <loss>=7.44637908936\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Epoch[205] Batch [50]#011Speed: 1178.91 samples/sec#011loss=7.446379\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] processed a total of 1625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1612.6840114593506, \"sum\": 1612.6840114593506, \"min\": 1612.6840114593506}}, \"EndTime\": 1577414738.742669, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414737.12955}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] #throughput_metric: host=algo-1, train throughput=1007.57140891 records/second\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] #quality_metric: host=algo-1, epoch=205, train loss <loss>=7.92274418999\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Loading parameters from best epoch (165)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 10.55598258972168, \"sum\": 10.55598258972168, \"min\": 10.55598258972168}}, \"EndTime\": 1577414738.753836, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414738.74274}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] stopping training now\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Final loss: 7.75237741276 (occurred at epoch 165)\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] #quality_metric: host=algo-1, train final_loss <loss>=7.75237741276\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 WARNING 139649395074880] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 57.65795707702637, \"sum\": 57.65795707702637, \"min\": 57.65795707702637}}, \"EndTime\": 1577414738.812176, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414738.753882}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 92.8959846496582, \"sum\": 92.8959846496582, \"min\": 92.8959846496582}}, \"EndTime\": 1577414738.847383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414738.812225}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 4.857063293457031, \"sum\": 4.857063293457031, \"min\": 4.857063293457031}}, \"EndTime\": 1577414738.852335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414738.84744}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:38 INFO 139649395074880] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03600120544433594, \"sum\": 0.03600120544433594, \"min\": 0.03600120544433594}}, \"EndTime\": 1577414738.852995, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414738.852377}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:42 INFO 139649395074880] Number of test batches scored: 10\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:45 INFO 139649395074880] Number of test batches scored: 20\u001b[0m\n",
      "\n",
      "2019-12-27 02:46:00 Uploading - Uploading generated training model\u001b[34m[12/27/2019 02:45:49 INFO 139649395074880] Number of test batches scored: 30\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:52 INFO 139649395074880] Number of test batches scored: 40\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] Number of test batches scored: 50\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 17564.346075057983, \"sum\": 17564.346075057983, \"min\": 17564.346075057983}}, \"EndTime\": 1577414756.417305, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414738.853055}\n",
      "\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #test_score (algo-1, RMSE): 26104.2500754\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #test_score (algo-1, mean_wQuantileLoss): 0.27124798\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #test_score (algo-1, wQuantileLoss[0.1]): 0.13338172\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #test_score (algo-1, wQuantileLoss[0.2]): 0.24373843\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #test_score (algo-1, wQuantileLoss[0.3]): 0.3084552\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #test_score (algo-1, wQuantileLoss[0.4]): 0.34212184\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #test_score (algo-1, wQuantileLoss[0.5]): 0.3491238\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #test_score (algo-1, wQuantileLoss[0.6]): 0.33614308\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #test_score (algo-1, wQuantileLoss[0.7]): 0.30507028\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #test_score (algo-1, wQuantileLoss[0.8]): 0.2527512\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #test_score (algo-1, wQuantileLoss[0.9]): 0.17044629\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.271247982979\u001b[0m\n",
      "\u001b[34m[12/27/2019 02:45:56 INFO 139649395074880] #quality_metric: host=algo-1, test RMSE <loss>=26104.2500754\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 356498.0409145355, \"sum\": 356498.0409145355, \"min\": 356498.0409145355}, \"setuptime\": {\"count\": 1, \"max\": 9.361982345581055, \"sum\": 9.361982345581055, \"min\": 9.361982345581055}}, \"EndTime\": 1577414756.426305, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1577414756.417367}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-12-27 02:46:06 Completed - Training job completed\n",
      "Training seconds: 413\n",
      "Billable seconds: 413\n",
      "CPU times: user 1.52 s, sys: 123 ms, total: 1.64 s\n",
      "Wall time: 9min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator_new_features = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='deepar-stores-sales-demo',\n",
    "    output_path=s3_output_path_new_features\n",
    ")\n",
    "\n",
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "    \"epochs\": \"400\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"mini_batch_size\": \"32\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"num_dynamic_feat\": \"auto\",  # this will use the `dynamic_feat` field if it's present in the data\n",
    "}\n",
    "estimator_new_features.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "estimator_new_features.fit(\n",
    "    inputs={\n",
    "        \"train\": \"{}/train/\".format(s3_data_path_new_features),\n",
    "        \"test\": \"{}/test/\".format(s3_data_path_new_features)\n",
    "    }, \n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we spawn an endpoint to visualize our forecasts on examples we send on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------!CPU times: user 367 ms, sys: 18.8 ms, total: 386 ms\n",
      "Wall time: 8min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor_new_features = estimator_new_features.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    predictor_cls=DeepARPredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the new predictor to predict the same time series. You can see this time we need pass **cat**, **dynamic_feat** to the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "  app.launch_new_instance()\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:19: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:46: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-09-24</th>\n",
       "      <td>4342.921875</td>\n",
       "      <td>9852.457031</td>\n",
       "      <td>6970.287598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-25</th>\n",
       "      <td>5005.437012</td>\n",
       "      <td>10757.939453</td>\n",
       "      <td>8179.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-26</th>\n",
       "      <td>4635.657227</td>\n",
       "      <td>12504.510742</td>\n",
       "      <td>9130.428711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-27</th>\n",
       "      <td>5040.504883</td>\n",
       "      <td>13135.134766</td>\n",
       "      <td>8747.378906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-28</th>\n",
       "      <td>4245.379395</td>\n",
       "      <td>14405.345703</td>\n",
       "      <td>9177.897461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-29</th>\n",
       "      <td>3051.185547</td>\n",
       "      <td>13564.783203</td>\n",
       "      <td>8196.429688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>2698.427734</td>\n",
       "      <td>10766.007812</td>\n",
       "      <td>7395.402344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0.1           0.9          0.5\n",
       "2019-09-24  4342.921875   9852.457031  6970.287598\n",
       "2019-09-25  5005.437012  10757.939453  8179.601562\n",
       "2019-09-26  4635.657227  12504.510742  9130.428711\n",
       "2019-09-27  5040.504883  13135.134766  8747.378906\n",
       "2019-09-28  4245.379395  14405.345703  9177.897461\n",
       "2019-09-29  3051.185547  13564.783203  8196.429688\n",
       "2019-09-30  2698.427734  10766.007812  7395.402344"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_id = 120\n",
    "predictor_new_features.predict(\n",
    "    ts=timeseries[store_id][start_dataset:end_test-1], \n",
    "    cat=cat_timeseries[store_id].tolist(),\n",
    "    dynamic_feat=predict_dynamic_feat, \n",
    "    quantiles=[0.1, 0.5, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can query the endpoint to see predictions for arbitrary time series and time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfd3e64adf04239b0ab31f51e97ebac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=120, description='customer_id', max=1603, style=SliderStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "@interact_manual(\n",
    "    customer_id=IntSlider(min=0, max=1603, value=120, style=style), \n",
    "#     forecast_day=IntSlider(min=0, max=7, value=0,step=1, style=style),\n",
    "    confidence=IntSlider(min=60, max=95, value=80, step=5, style=style),\n",
    "    history_days_plot=IntSlider(min=1, max=50, value=7, style=style),\n",
    "    show_samples=Checkbox(value=False),\n",
    "    continuous_update=False\n",
    ")\n",
    "def plot_interact(customer_id, confidence, history_days_plot, show_samples):\n",
    "    target = timeseries[customer_id]\n",
    "    dynamic_feat = predict_dynamic_feat\n",
    "    cat=cat_timeseries[store_id].tolist()\n",
    "    plot(\n",
    "        predictor_new_features,\n",
    "        target_ts=target,\n",
    "        forecast_date= start_predict -1,\n",
    "        cat=cat,\n",
    "        dynamic_feat=dynamic_feat,\n",
    "        show_samples=show_samples,\n",
    "        plot_history=history_days_plot,\n",
    "        confidence=confidence\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:19: FutureWarning: Addition/subtraction of integers and integer-arrays to Timestamp is deprecated, will be removed in a future version.  Instead of adding/subtracting `n`, use `n * self.freq`\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:46: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.99 s, sys: 79.8 ms, total: 5.07 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds_new = []\n",
    "quantiles=[0.10, 0.5, 0.90]\n",
    "\n",
    "for i, ts_dict in enumerate(timeseries):\n",
    "    ts = ts_dict[start_dataset:end_test-1]\n",
    "    if ts.shape[0] == 0:\n",
    "        preds_new.append(None)\n",
    "        continue\n",
    "    cat = cat_timeseries[i].tolist()\n",
    "    dynamic_feat = predict_dynamic_feat   \n",
    "    pred = predictor_new_features.predict(ts, cat=cat, dynamic_feat=dynamic_feat, quantiles=quantiles)\n",
    "    preds_new.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predict result and label data into a csv for later use\n",
    "df_new = pd.DataFrame()\n",
    "for i in range(len(timeseries)):\n",
    "    y =  timeseries[i][start_predict:end_predict].fillna(0)\n",
    "    y_hat = preds_new[i]['0.5']\n",
    "    dd = pd.DataFrame({'store_id':i,'y_label': y, 'y_pred': y_hat})\n",
    "    df_new = pd.concat([df_new, dd])\n",
    "df_new.index.name='date'\n",
    "df_new.to_csv(\"data/deepar-new-features-predict-result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 24\n",
      "RMSE: 1406.6672841322722\n",
      "MAE: 1230.2035016741\n",
      "Target Mean: 5569.585714285714\n",
      "                 y_pred  y_label\n",
      "2019-09-24  4517.583496   7026.0\n",
      "2019-09-25  4354.111328   4043.6\n",
      "2019-09-26  4353.962402   6221.2\n",
      "2019-09-27  4917.299805   5847.8\n",
      "2019-09-28  6354.404785   5126.7\n",
      "2019-09-29  6803.198730   5775.6\n",
      "2019-09-30  4206.744629   4946.2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 31\n",
      "RMSE: 1892.5107264489236\n",
      "MAE: 1665.9226283482142\n",
      "Target Mean: 9007.67142857143\n",
      "                  y_pred  y_label\n",
      "2019-09-24   7729.753906   7383.9\n",
      "2019-09-25   7315.371094   8558.8\n",
      "2019-09-26   6695.611816   9763.9\n",
      "2019-09-27   6124.147461   8243.4\n",
      "2019-09-28   7967.549805   9221.3\n",
      "2019-09-29  11350.946289  10352.9\n",
      "2019-09-30   6896.661621   9529.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 36\n",
      "RMSE: 4986.11005131684\n",
      "MAE: 2990.2407645089293\n",
      "Target Mean: 18153.442857142858\n",
      "                  y_pred  y_label\n",
      "2019-09-24  13588.302734  13646.5\n",
      "2019-09-25  16151.426758  16744.0\n",
      "2019-09-26  16137.608398  15419.9\n",
      "2019-09-27  18191.798828  18162.3\n",
      "2019-09-28  28059.017578  26111.2\n",
      "2019-09-29  26696.355469  15189.3\n",
      "2019-09-30  15722.065430  21800.9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 87\n",
      "RMSE: 10562.167915809518\n",
      "MAE: 8261.332098214287\n",
      "Target Mean: 41728.84428571429\n",
      "                  y_pred   y_label\n",
      "2019-09-24  38413.855469  34817.70\n",
      "2019-09-25  38417.496094  33837.11\n",
      "2019-09-26  39688.996094  32969.10\n",
      "2019-09-27  53255.398438  36843.10\n",
      "2019-09-28  69847.070312  67866.62\n",
      "2019-09-29  60190.601562  39937.69\n",
      "2019-09-30  41543.363281  45830.59\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.56 s, sys: 666 ms, total: 3.22 s\n",
      "Wall time: 1.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "show_metrics( sample_sites, target_quantile='0.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_new_features.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
